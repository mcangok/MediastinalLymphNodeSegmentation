
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 224], 'median_image_size_in_voxels': [85.0, 209.0, 296.0], 'spacing': [3.0, 0.9335939884185791, 0.9335939884185791], 'normalization_schemes': ['Clip_Normalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [4, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset029_all_at_once', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.9335939884185791, 0.9335939884185791], 'original_median_shape_after_transp': [88, 222, 313], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 8913.0, 'mean': -123.09001922607422, 'median': -25.0, 'min': -3024.0, 'percentile_00_5': -1022.0, 'percentile_99_5': 463.0, 'std': 332.416259765625}}} 
 
2023-07-31 09:53:32.632758: unpacking dataset... 
2023-07-31 09:53:51.677943: unpacking done... 
2023-07-31 09:53:51.678981: do_dummy_2d_data_aug: True 
2023-07-31 09:53:51.689917: Unable to plot network architecture: 
2023-07-31 09:53:51.689967: No module named 'hiddenlayer' 
2023-07-31 09:53:51.694304:  
2023-07-31 09:53:51.694355: Epoch 0 
2023-07-31 09:53:51.694418: Current learning rate: 0.001 
2023-07-31 09:54:53.028638: train_loss 0.0866 
2023-07-31 09:54:53.028828: val_loss 0.0017 
2023-07-31 09:54:53.028894: Pseudo dice [0.0] 
2023-07-31 09:54:53.028956: Epoch time: 61.34 s 
2023-07-31 09:54:53.029002: Yayy! New best EMA pseudo Dice: 0.0 
2023-07-31 09:54:54.158564:  
2023-07-31 09:54:54.158648: Epoch 1 
2023-07-31 09:54:54.158737: Current learning rate: 0.001 
2023-07-31 09:55:49.270916: train_loss -0.0073 
2023-07-31 09:55:49.271062: val_loss -0.0142 
2023-07-31 09:55:49.271116: Pseudo dice [0.0] 
2023-07-31 09:55:49.271166: Epoch time: 55.11 s 
2023-07-31 09:55:50.312302:  
2023-07-31 09:55:50.312401: Epoch 2 
2023-07-31 09:55:50.312475: Current learning rate: 0.001 
2023-07-31 09:56:45.554423: train_loss -0.0226 
2023-07-31 09:56:45.554570: val_loss -0.0291 
2023-07-31 09:56:45.554641: Pseudo dice [0.0] 
2023-07-31 09:56:45.554692: Epoch time: 55.24 s 
2023-07-31 09:56:46.627696:  
2023-07-31 09:56:46.627800: Epoch 3 
2023-07-31 09:56:46.627871: Current learning rate: 0.001 
2023-07-31 09:57:41.940443: train_loss -0.0649 
2023-07-31 09:57:41.940594: val_loss -0.098 
2023-07-31 09:57:41.940649: Pseudo dice [0.2297] 
2023-07-31 09:57:41.940701: Epoch time: 55.31 s 
2023-07-31 09:57:41.940741: Yayy! New best EMA pseudo Dice: 0.023 
2023-07-31 09:57:43.296223:  
2023-07-31 09:57:43.296320: Epoch 4 
2023-07-31 09:57:43.296402: Current learning rate: 0.001 
2023-07-31 09:58:38.677981: train_loss -0.1013 
2023-07-31 09:58:38.678134: val_loss -0.1484 
2023-07-31 09:58:38.678188: Pseudo dice [0.2822] 
2023-07-31 09:58:38.678239: Epoch time: 55.38 s 
2023-07-31 09:58:38.678279: Yayy! New best EMA pseudo Dice: 0.0489 
2023-07-31 09:58:40.076432:  
2023-07-31 09:58:40.076523: Epoch 5 
2023-07-31 09:58:40.076599: Current learning rate: 0.001 
2023-07-31 09:59:35.461237: train_loss -0.1243 
2023-07-31 09:59:35.461411: val_loss -0.1328 
2023-07-31 09:59:35.461468: Pseudo dice [0.2288] 
2023-07-31 09:59:35.461520: Epoch time: 55.39 s 
2023-07-31 09:59:35.461561: Yayy! New best EMA pseudo Dice: 0.0669 
2023-07-31 09:59:36.902163:  
2023-07-31 09:59:36.902354: Epoch 6 
2023-07-31 09:59:36.902515: Current learning rate: 0.00099 
2023-07-31 10:00:32.346555: train_loss -0.158 
2023-07-31 10:00:32.346706: val_loss -0.171 
2023-07-31 10:00:32.346760: Pseudo dice [0.2483] 
2023-07-31 10:00:32.346813: Epoch time: 55.45 s 
2023-07-31 10:00:32.346852: Yayy! New best EMA pseudo Dice: 0.085 
2023-07-31 10:00:33.665142:  
2023-07-31 10:00:33.665305: Epoch 7 
2023-07-31 10:00:33.665382: Current learning rate: 0.00099 
2023-07-31 10:01:29.011254: train_loss -0.1493 
2023-07-31 10:01:29.011409: val_loss -0.2291 
2023-07-31 10:01:29.011466: Pseudo dice [0.3715] 
2023-07-31 10:01:29.011531: Epoch time: 55.35 s 
2023-07-31 10:01:29.011573: Yayy! New best EMA pseudo Dice: 0.1137 
2023-07-31 10:01:30.349275:  
2023-07-31 10:01:30.349371: Epoch 8 
2023-07-31 10:01:30.349444: Current learning rate: 0.00099 
2023-07-31 10:02:25.739864: train_loss -0.1735 
2023-07-31 10:02:25.740025: val_loss -0.2261 
2023-07-31 10:02:25.740076: Pseudo dice [0.333] 
2023-07-31 10:02:25.740128: Epoch time: 55.39 s 
2023-07-31 10:02:25.740170: Yayy! New best EMA pseudo Dice: 0.1356 
2023-07-31 10:02:27.083965:  
2023-07-31 10:02:27.084065: Epoch 9 
2023-07-31 10:02:27.084141: Current learning rate: 0.00099 
2023-07-31 10:03:22.447588: train_loss -0.1579 
2023-07-31 10:03:22.447740: val_loss -0.2053 
2023-07-31 10:03:22.447792: Pseudo dice [0.2919] 
2023-07-31 10:03:22.447843: Epoch time: 55.36 s 
2023-07-31 10:03:22.447884: Yayy! New best EMA pseudo Dice: 0.1512 
2023-07-31 10:03:23.726561:  
2023-07-31 10:03:23.726701: Epoch 10 
2023-07-31 10:03:23.726962: Current learning rate: 0.00099 
2023-07-31 10:04:19.096257: train_loss -0.1634 
2023-07-31 10:04:19.096411: val_loss -0.179 
2023-07-31 10:04:19.096465: Pseudo dice [0.3212] 
2023-07-31 10:04:19.096517: Epoch time: 55.37 s 
2023-07-31 10:04:19.096558: Yayy! New best EMA pseudo Dice: 0.1682 
2023-07-31 10:04:20.430565:  
2023-07-31 10:04:20.430665: Epoch 11 
2023-07-31 10:04:20.430783: Current learning rate: 0.00099 
2023-07-31 10:05:15.762141: train_loss -0.1919 
2023-07-31 10:05:15.762310: val_loss -0.2082 
2023-07-31 10:05:15.762394: Pseudo dice [0.3462] 
2023-07-31 10:05:15.762461: Epoch time: 55.33 s 
2023-07-31 10:05:15.762502: Yayy! New best EMA pseudo Dice: 0.186 
2023-07-31 10:05:17.206364:  
2023-07-31 10:05:17.206567: Epoch 12 
2023-07-31 10:05:17.206646: Current learning rate: 0.00099 
2023-07-31 10:06:13.156449: train_loss -0.1994 
2023-07-31 10:06:13.156605: val_loss -0.2298 
2023-07-31 10:06:13.156662: Pseudo dice [0.3066] 
2023-07-31 10:06:13.156713: Epoch time: 55.95 s 
2023-07-31 10:06:13.156754: Yayy! New best EMA pseudo Dice: 0.1981 
2023-07-31 10:06:14.564513:  
2023-07-31 10:06:14.564746: Epoch 13 
2023-07-31 10:06:14.564835: Current learning rate: 0.00099 
2023-07-31 10:07:12.840554: train_loss -0.1989 
2023-07-31 10:07:12.840725: val_loss -0.2132 
2023-07-31 10:07:12.840776: Pseudo dice [0.3431] 
2023-07-31 10:07:12.840829: Epoch time: 58.28 s 
2023-07-31 10:07:12.840871: Yayy! New best EMA pseudo Dice: 0.2126 
2023-07-31 10:07:14.216063:  
2023-07-31 10:07:14.216164: Epoch 14 
2023-07-31 10:07:14.216241: Current learning rate: 0.00099 
2023-07-31 10:08:11.271400: train_loss -0.2142 
2023-07-31 10:08:11.271555: val_loss -0.2335 
2023-07-31 10:08:11.271610: Pseudo dice [0.355] 
2023-07-31 10:08:11.271661: Epoch time: 57.06 s 
2023-07-31 10:08:11.271712: Yayy! New best EMA pseudo Dice: 0.2268 
2023-07-31 10:08:12.653069:  
2023-07-31 10:08:12.653275: Epoch 15 
2023-07-31 10:08:12.653359: Current learning rate: 0.00099 
2023-07-31 10:09:10.578061: train_loss -0.2074 
2023-07-31 10:09:10.578224: val_loss -0.2279 
2023-07-31 10:09:10.578277: Pseudo dice [0.3176] 
2023-07-31 10:09:10.578330: Epoch time: 57.93 s 
2023-07-31 10:09:10.578371: Yayy! New best EMA pseudo Dice: 0.2359 
2023-07-31 10:09:12.065701:  
2023-07-31 10:09:12.065869: Epoch 16 
2023-07-31 10:09:12.065966: Current learning rate: 0.00099 
2023-07-31 10:10:09.661437: train_loss -0.2271 
2023-07-31 10:10:09.661584: val_loss -0.2243 
2023-07-31 10:10:09.661640: Pseudo dice [0.3273] 
2023-07-31 10:10:09.661693: Epoch time: 57.6 s 
2023-07-31 10:10:09.661734: Yayy! New best EMA pseudo Dice: 0.2451 
2023-07-31 10:10:11.058001:  
2023-07-31 10:10:11.058109: Epoch 17 
2023-07-31 10:10:11.058188: Current learning rate: 0.00098 
2023-07-31 10:11:10.704519: train_loss -0.2042 
2023-07-31 10:11:10.704688: val_loss -0.2243 
2023-07-31 10:11:10.704753: Pseudo dice [0.3644] 
2023-07-31 10:11:10.704807: Epoch time: 59.65 s 
2023-07-31 10:11:10.704850: Yayy! New best EMA pseudo Dice: 0.257 
2023-07-31 10:11:12.107451:  
2023-07-31 10:11:12.107574: Epoch 18 
2023-07-31 10:11:12.107651: Current learning rate: 0.00098 
2023-07-31 10:12:09.738154: train_loss -0.2094 
2023-07-31 10:12:09.738297: val_loss -0.2702 
2023-07-31 10:12:09.738350: Pseudo dice [0.5783] 
2023-07-31 10:12:09.738402: Epoch time: 57.63 s 
2023-07-31 10:12:09.738443: Yayy! New best EMA pseudo Dice: 0.2891 
2023-07-31 10:12:11.116323:  
2023-07-31 10:12:11.116421: Epoch 19 
2023-07-31 10:12:11.116499: Current learning rate: 0.00098 
2023-07-31 10:13:09.127040: train_loss -0.2352 
2023-07-31 10:13:09.127191: val_loss -0.2478 
2023-07-31 10:13:09.127245: Pseudo dice [0.3448] 
2023-07-31 10:13:09.127296: Epoch time: 58.01 s 
2023-07-31 10:13:09.127335: Yayy! New best EMA pseudo Dice: 0.2947 
2023-07-31 10:13:10.486635:  
2023-07-31 10:13:10.486734: Epoch 20 
2023-07-31 10:13:10.486823: Current learning rate: 0.00098 
2023-07-31 10:14:07.798567: train_loss -0.1953 
2023-07-31 10:14:07.798720: val_loss -0.2218 
2023-07-31 10:14:07.798777: Pseudo dice [0.4307] 
2023-07-31 10:14:07.798829: Epoch time: 57.31 s 
2023-07-31 10:14:07.798871: Yayy! New best EMA pseudo Dice: 0.3083 
2023-07-31 10:14:09.337545:  
2023-07-31 10:14:09.337661: Epoch 21 
2023-07-31 10:14:09.337754: Current learning rate: 0.00098 
2023-07-31 10:15:07.493663: train_loss -0.2176 
2023-07-31 10:15:07.493808: val_loss -0.2453 
2023-07-31 10:15:07.493879: Pseudo dice [0.3486] 
2023-07-31 10:15:07.493929: Epoch time: 58.16 s 
2023-07-31 10:15:07.493969: Yayy! New best EMA pseudo Dice: 0.3123 
2023-07-31 10:15:08.790441:  
2023-07-31 10:15:08.790549: Epoch 22 
2023-07-31 10:15:08.790628: Current learning rate: 0.00098 
2023-07-31 10:16:06.626401: train_loss -0.2042 
2023-07-31 10:16:06.626552: val_loss -0.2572 
2023-07-31 10:16:06.626603: Pseudo dice [0.4389] 
2023-07-31 10:16:06.626655: Epoch time: 57.84 s 
2023-07-31 10:16:06.626696: Yayy! New best EMA pseudo Dice: 0.325 
2023-07-31 10:16:07.909554:  
2023-07-31 10:16:07.909653: Epoch 23 
2023-07-31 10:16:07.909740: Current learning rate: 0.00098 
2023-07-31 10:17:03.575090: train_loss -0.2425 
2023-07-31 10:17:03.575229: val_loss -0.2306 
2023-07-31 10:17:03.575283: Pseudo dice [0.4312] 
2023-07-31 10:17:03.575334: Epoch time: 55.67 s 
2023-07-31 10:17:03.575376: Yayy! New best EMA pseudo Dice: 0.3356 
2023-07-31 10:17:04.926371:  
2023-07-31 10:17:04.926467: Epoch 24 
2023-07-31 10:17:04.926543: Current learning rate: 0.00098 
2023-07-31 10:18:00.310991: train_loss -0.219 
2023-07-31 10:18:00.311140: val_loss -0.2125 
2023-07-31 10:18:00.311196: Pseudo dice [0.3753] 
2023-07-31 10:18:00.311248: Epoch time: 55.39 s 
2023-07-31 10:18:00.311288: Yayy! New best EMA pseudo Dice: 0.3396 
2023-07-31 10:18:01.688011:  
2023-07-31 10:18:01.688115: Epoch 25 
2023-07-31 10:18:01.688200: Current learning rate: 0.00098 
2023-07-31 10:18:58.348818: train_loss -0.2644 
2023-07-31 10:18:58.349062: val_loss -0.22 
2023-07-31 10:18:58.349118: Pseudo dice [0.4156] 
2023-07-31 10:18:58.349171: Epoch time: 56.66 s 
2023-07-31 10:18:58.349212: Yayy! New best EMA pseudo Dice: 0.3472 
2023-07-31 10:18:59.730362:  
2023-07-31 10:18:59.730585: Epoch 26 
2023-07-31 10:18:59.730670: Current learning rate: 0.00098 
2023-07-31 10:19:56.583587: train_loss -0.2176 
2023-07-31 10:19:56.583739: val_loss -0.2282 
2023-07-31 10:19:56.583794: Pseudo dice [0.4484] 
2023-07-31 10:19:56.583845: Epoch time: 56.85 s 
2023-07-31 10:19:56.583886: Yayy! New best EMA pseudo Dice: 0.3573 
2023-07-31 10:19:58.060864:  
2023-07-31 10:19:58.060967: Epoch 27 
2023-07-31 10:19:58.061044: Current learning rate: 0.00098 
2023-07-31 10:20:53.586807: train_loss -0.2288 
2023-07-31 10:20:53.586960: val_loss -0.2424 
2023-07-31 10:20:53.587030: Pseudo dice [0.4685] 
2023-07-31 10:20:53.587083: Epoch time: 55.53 s 
2023-07-31 10:20:53.587125: Yayy! New best EMA pseudo Dice: 0.3684 
2023-07-31 10:20:54.898214:  
2023-07-31 10:20:54.898319: Epoch 28 
2023-07-31 10:20:54.898411: Current learning rate: 0.00097 
2023-07-31 10:21:50.361110: train_loss -0.2168 
2023-07-31 10:21:50.361263: val_loss -0.2131 
2023-07-31 10:21:50.361324: Pseudo dice [0.3885] 
2023-07-31 10:21:50.361395: Epoch time: 55.46 s 
2023-07-31 10:21:50.361447: Yayy! New best EMA pseudo Dice: 0.3704 
2023-07-31 10:21:51.732501:  
2023-07-31 10:21:51.732603: Epoch 29 
2023-07-31 10:21:51.732681: Current learning rate: 0.00097 
2023-07-31 10:22:47.400457: train_loss -0.2346 
2023-07-31 10:22:47.400616: val_loss -0.2875 
2023-07-31 10:22:47.400669: Pseudo dice [0.4644] 
2023-07-31 10:22:47.400720: Epoch time: 55.67 s 
2023-07-31 10:22:47.400761: Yayy! New best EMA pseudo Dice: 0.3798 
2023-07-31 10:22:48.812118:  
2023-07-31 10:22:48.812222: Epoch 30 
2023-07-31 10:22:48.812300: Current learning rate: 0.00097 
2023-07-31 10:23:46.433152: train_loss -0.2337 
2023-07-31 10:23:46.433311: val_loss -0.2514 
2023-07-31 10:23:46.433366: Pseudo dice [0.5074] 
2023-07-31 10:23:46.433417: Epoch time: 57.62 s 
2023-07-31 10:23:46.433477: Yayy! New best EMA pseudo Dice: 0.3926 
2023-07-31 10:23:47.772293:  
2023-07-31 10:23:47.772386: Epoch 31 
2023-07-31 10:23:47.772475: Current learning rate: 0.00097 
2023-07-31 10:24:46.347307: train_loss -0.2091 
2023-07-31 10:24:46.347476: val_loss -0.2369 
2023-07-31 10:24:46.347546: Pseudo dice [0.3837] 
2023-07-31 10:24:46.347598: Epoch time: 58.58 s 
2023-07-31 10:24:47.491425:  
2023-07-31 10:24:47.491533: Epoch 32 
2023-07-31 10:24:47.491610: Current learning rate: 0.00097 
2023-07-31 10:25:44.857821: train_loss -0.2211 
2023-07-31 10:25:44.857978: val_loss -0.3051 
2023-07-31 10:25:44.858048: Pseudo dice [0.5912] 
2023-07-31 10:25:44.858101: Epoch time: 57.37 s 
2023-07-31 10:25:44.858142: Yayy! New best EMA pseudo Dice: 0.4116 
2023-07-31 10:25:46.235441:  
2023-07-31 10:25:46.235560: Epoch 33 
2023-07-31 10:25:46.235636: Current learning rate: 0.00097 
2023-07-31 10:26:41.669003: train_loss -0.2372 
2023-07-31 10:26:41.669156: val_loss -0.3073 
2023-07-31 10:26:41.669210: Pseudo dice [0.5437] 
2023-07-31 10:26:41.669262: Epoch time: 55.43 s 
2023-07-31 10:26:41.669303: Yayy! New best EMA pseudo Dice: 0.4248 
2023-07-31 10:26:43.069493:  
2023-07-31 10:26:43.069595: Epoch 34 
2023-07-31 10:26:43.069687: Current learning rate: 0.00097 
2023-07-31 10:27:38.464025: train_loss -0.2475 
2023-07-31 10:27:38.464172: val_loss -0.2702 
2023-07-31 10:27:38.464227: Pseudo dice [0.5987] 
2023-07-31 10:27:38.464279: Epoch time: 55.4 s 
2023-07-31 10:27:38.464319: Yayy! New best EMA pseudo Dice: 0.4422 
2023-07-31 10:27:39.844659:  
2023-07-31 10:27:39.844757: Epoch 35 
2023-07-31 10:27:39.844830: Current learning rate: 0.00097 
2023-07-31 10:28:35.599291: train_loss -0.238 
2023-07-31 10:28:35.599444: val_loss -0.2953 
2023-07-31 10:28:35.599509: Pseudo dice [0.4858] 
2023-07-31 10:28:35.599564: Epoch time: 55.76 s 
2023-07-31 10:28:35.599610: Yayy! New best EMA pseudo Dice: 0.4466 
2023-07-31 10:28:37.056506:  
2023-07-31 10:28:37.056686: Epoch 36 
2023-07-31 10:28:37.056768: Current learning rate: 0.00097 
2023-07-31 10:29:33.629056: train_loss -0.2756 
2023-07-31 10:29:33.629210: val_loss -0.2024 
2023-07-31 10:29:33.629267: Pseudo dice [0.5203] 
2023-07-31 10:29:33.629319: Epoch time: 56.57 s 
2023-07-31 10:29:33.629360: Yayy! New best EMA pseudo Dice: 0.454 
2023-07-31 10:29:35.015420:  
2023-07-31 10:29:35.015628: Epoch 37 
2023-07-31 10:29:35.015715: Current learning rate: 0.00097 
2023-07-31 10:30:34.444830: train_loss -0.2331 
2023-07-31 10:30:34.444975: val_loss -0.297 
2023-07-31 10:30:34.445048: Pseudo dice [0.5069] 
2023-07-31 10:30:34.445099: Epoch time: 59.43 s 
2023-07-31 10:30:34.445139: Yayy! New best EMA pseudo Dice: 0.4593 
2023-07-31 10:30:35.819567:  
2023-07-31 10:30:35.819759: Epoch 38 
2023-07-31 10:30:35.819840: Current learning rate: 0.00097 
2023-07-31 10:31:36.228452: train_loss -0.2567 
2023-07-31 10:31:36.228614: val_loss -0.3017 
2023-07-31 10:31:36.228674: Pseudo dice [0.5341] 
2023-07-31 10:31:36.228728: Epoch time: 60.41 s 
2023-07-31 10:31:36.228770: Yayy! New best EMA pseudo Dice: 0.4667 
2023-07-31 10:31:37.620911:  
2023-07-31 10:31:37.621016: Epoch 39 
2023-07-31 10:31:37.621092: Current learning rate: 0.00096 
2023-07-31 10:32:35.220155: train_loss -0.2695 
2023-07-31 10:32:35.220382: val_loss -0.2059 
2023-07-31 10:32:35.220439: Pseudo dice [0.5571] 
2023-07-31 10:32:35.220490: Epoch time: 57.6 s 
2023-07-31 10:32:35.220531: Yayy! New best EMA pseudo Dice: 0.4758 
2023-07-31 10:32:36.623724:  
2023-07-31 10:32:36.623825: Epoch 40 
2023-07-31 10:32:36.623904: Current learning rate: 0.00096 
2023-07-31 10:33:32.768478: train_loss -0.2669 
2023-07-31 10:33:32.768630: val_loss -0.2737 
2023-07-31 10:33:32.768684: Pseudo dice [0.511] 
2023-07-31 10:33:32.768737: Epoch time: 56.15 s 
2023-07-31 10:33:32.768779: Yayy! New best EMA pseudo Dice: 0.4793 
2023-07-31 10:33:34.319191:  
2023-07-31 10:33:34.319293: Epoch 41 
2023-07-31 10:33:34.319373: Current learning rate: 0.00096 
2023-07-31 10:34:30.477039: train_loss -0.27 
2023-07-31 10:34:30.477197: val_loss -0.298 
2023-07-31 10:34:30.477252: Pseudo dice [0.5166] 
2023-07-31 10:34:30.477307: Epoch time: 56.16 s 
2023-07-31 10:34:30.477349: Yayy! New best EMA pseudo Dice: 0.483 
2023-07-31 10:34:31.821677:  
2023-07-31 10:34:31.821782: Epoch 42 
2023-07-31 10:34:31.821856: Current learning rate: 0.00096 
2023-07-31 10:35:29.231307: train_loss -0.2772 
2023-07-31 10:35:29.231455: val_loss -0.2406 
2023-07-31 10:35:29.231533: Pseudo dice [0.5543] 
2023-07-31 10:35:29.231585: Epoch time: 57.41 s 
2023-07-31 10:35:29.231625: Yayy! New best EMA pseudo Dice: 0.4902 
2023-07-31 10:35:30.583802:  
2023-07-31 10:35:30.584058: Epoch 43 
2023-07-31 10:35:30.584216: Current learning rate: 0.00096 
2023-07-31 10:36:27.636052: train_loss -0.217 
2023-07-31 10:36:27.636596: val_loss -0.2463 
2023-07-31 10:36:27.637268: Pseudo dice [0.3689] 
2023-07-31 10:36:27.637787: Epoch time: 57.05 s 
2023-07-31 10:36:29.568622:  
2023-07-31 10:36:29.569156: Epoch 44 
2023-07-31 10:36:29.569361: Current learning rate: 0.00096 
2023-07-31 10:37:26.854797: train_loss -0.2236 
2023-07-31 10:37:26.854964: val_loss -0.2736 
2023-07-31 10:37:26.855022: Pseudo dice [0.4507] 
2023-07-31 10:37:26.855079: Epoch time: 57.29 s 
2023-07-31 10:37:27.848521:  
2023-07-31 10:37:27.848709: Epoch 45 
2023-07-31 10:37:27.848793: Current learning rate: 0.00096 
2023-07-31 10:38:24.220494: train_loss -0.2491 
2023-07-31 10:38:24.220671: val_loss -0.1917 
2023-07-31 10:38:24.220735: Pseudo dice [0.4087] 
2023-07-31 10:38:24.220794: Epoch time: 56.37 s 
2023-07-31 10:38:25.205717:  
2023-07-31 10:38:25.205898: Epoch 46 
2023-07-31 10:38:25.205980: Current learning rate: 0.00096 
2023-07-31 10:39:28.400810: train_loss -0.2483 
2023-07-31 10:39:28.400969: val_loss -0.1978 
2023-07-31 10:39:28.401047: Pseudo dice [0.5264] 
2023-07-31 10:39:28.401106: Epoch time: 63.2 s 
2023-07-31 10:39:29.704770:  
2023-07-31 10:39:29.704894: Epoch 47 
2023-07-31 10:39:29.704978: Current learning rate: 0.00096 
2023-07-31 10:40:41.661375: train_loss -0.2622 
2023-07-31 10:40:41.661704: val_loss -0.2174 
2023-07-31 10:40:41.661780: Pseudo dice [0.3195] 
2023-07-31 10:40:41.661848: Epoch time: 71.96 s 
2023-07-31 10:40:42.712317:  
2023-07-31 10:40:42.712434: Epoch 48 
2023-07-31 10:40:42.712517: Current learning rate: 0.00096 
2023-07-31 10:41:55.928682: train_loss -0.2312 
2023-07-31 10:41:55.928833: val_loss -0.296 
2023-07-31 10:41:55.928890: Pseudo dice [0.5038] 
2023-07-31 10:41:55.928944: Epoch time: 73.22 s 
2023-07-31 10:41:56.974391:  
2023-07-31 10:41:56.974533: Epoch 49 
2023-07-31 10:41:56.974635: Current learning rate: 0.00096 
2023-07-31 10:43:08.978696: train_loss -0.2648 
2023-07-31 10:43:08.978853: val_loss -0.2441 
2023-07-31 10:43:08.978921: Pseudo dice [0.5116] 
2023-07-31 10:43:08.978978: Epoch time: 72.01 s 
2023-07-31 10:43:10.279845:  
2023-07-31 10:43:10.279962: Epoch 50 
2023-07-31 10:43:10.280045: Current learning rate: 0.00095 
2023-07-31 10:44:24.577785: train_loss -0.2725 
2023-07-31 10:44:24.578071: val_loss -0.2323 
2023-07-31 10:44:24.578148: Pseudo dice [0.662] 
2023-07-31 10:44:24.578218: Epoch time: 74.3 s 
2023-07-31 10:44:25.620735:  
2023-07-31 10:44:25.620848: Epoch 51 
2023-07-31 10:44:25.620926: Current learning rate: 0.00095 
2023-07-31 10:45:35.787452: train_loss -0.2714 
2023-07-31 10:45:35.787637: val_loss -0.2867 
2023-07-31 10:45:35.787697: Pseudo dice [0.522] 
2023-07-31 10:45:35.787756: Epoch time: 70.17 s 
2023-07-31 10:45:35.787832: Yayy! New best EMA pseudo Dice: 0.4911 
2023-07-31 10:45:37.386245:  
2023-07-31 10:45:37.386446: Epoch 52 
2023-07-31 10:45:37.386541: Current learning rate: 0.00095 
2023-07-31 10:46:48.537772: train_loss -0.2612 
2023-07-31 10:46:48.537943: val_loss -0.3359 
2023-07-31 10:46:48.538005: Pseudo dice [0.4807] 
2023-07-31 10:46:48.538061: Epoch time: 71.15 s 
2023-07-31 10:46:49.533915:  
2023-07-31 10:46:49.534205: Epoch 53 
2023-07-31 10:46:49.534339: Current learning rate: 0.00095 
2023-07-31 10:48:00.089754: train_loss -0.2725 
2023-07-31 10:48:00.089926: val_loss -0.2711 
2023-07-31 10:48:00.089986: Pseudo dice [0.4383] 
2023-07-31 10:48:00.090042: Epoch time: 70.56 s 
2023-07-31 10:48:01.158449:  
2023-07-31 10:48:01.158556: Epoch 54 
2023-07-31 10:48:01.158634: Current learning rate: 0.00095 
2023-07-31 10:49:16.902097: train_loss -0.2542 
2023-07-31 10:49:16.902256: val_loss -0.1919 
2023-07-31 10:49:16.902337: Pseudo dice [0.5549] 
2023-07-31 10:49:16.902408: Epoch time: 75.74 s 
2023-07-31 10:49:16.902465: Yayy! New best EMA pseudo Dice: 0.4919 
2023-07-31 10:49:18.296285:  
2023-07-31 10:49:18.296394: Epoch 55 
2023-07-31 10:49:18.296477: Current learning rate: 0.00095 
2023-07-31 10:50:29.803145: train_loss -0.2817 
2023-07-31 10:50:29.803305: val_loss -0.3367 
2023-07-31 10:50:29.803365: Pseudo dice [0.641] 
2023-07-31 10:50:29.803420: Epoch time: 71.51 s 
2023-07-31 10:50:29.803464: Yayy! New best EMA pseudo Dice: 0.5068 
2023-07-31 10:50:31.233343:  
2023-07-31 10:50:31.233547: Epoch 56 
2023-07-31 10:50:31.233639: Current learning rate: 0.00095 
2023-07-31 10:51:44.629393: train_loss -0.274 
2023-07-31 10:51:44.629591: val_loss -0.2985 
2023-07-31 10:51:44.629661: Pseudo dice [0.6248] 
2023-07-31 10:51:44.629727: Epoch time: 73.4 s 
2023-07-31 10:51:44.629782: Yayy! New best EMA pseudo Dice: 0.5186 
2023-07-31 10:51:46.057090:  
2023-07-31 10:51:46.057275: Epoch 57 
2023-07-31 10:51:46.057359: Current learning rate: 0.00095 
2023-07-31 10:52:59.545140: train_loss -0.3051 
2023-07-31 10:52:59.545300: val_loss -0.3113 
2023-07-31 10:52:59.545357: Pseudo dice [0.5725] 
2023-07-31 10:52:59.545411: Epoch time: 73.49 s 
2023-07-31 10:52:59.545457: Yayy! New best EMA pseudo Dice: 0.524 
2023-07-31 10:53:01.161354:  
2023-07-31 10:53:01.161622: Epoch 58 
2023-07-31 10:53:01.161726: Current learning rate: 0.00095 
2023-07-31 10:54:15.141264: train_loss -0.2783 
2023-07-31 10:54:15.141422: val_loss -0.2375 
2023-07-31 10:54:15.141479: Pseudo dice [0.4743] 
2023-07-31 10:54:15.141534: Epoch time: 73.98 s 
2023-07-31 10:54:16.203968:  
2023-07-31 10:54:16.204089: Epoch 59 
2023-07-31 10:54:16.204170: Current learning rate: 0.00095 
2023-07-31 10:55:29.013294: train_loss -0.2769 
2023-07-31 10:55:29.013950: val_loss -0.2882 
2023-07-31 10:55:29.014026: Pseudo dice [0.6417] 
2023-07-31 10:55:29.014077: Epoch time: 72.81 s 
2023-07-31 10:55:29.014116: Yayy! New best EMA pseudo Dice: 0.5313 
2023-07-31 10:55:30.463103:  
2023-07-31 10:55:30.463219: Epoch 60 
2023-07-31 10:55:30.463299: Current learning rate: 0.00095 
2023-07-31 10:56:42.297046: train_loss -0.2671 
2023-07-31 10:56:42.297207: val_loss -0.3235 
2023-07-31 10:56:42.297266: Pseudo dice [0.6614] 
2023-07-31 10:56:42.297322: Epoch time: 71.83 s 
2023-07-31 10:56:42.297367: Yayy! New best EMA pseudo Dice: 0.5443 
2023-07-31 10:56:43.781356:  
2023-07-31 10:56:43.785755: Epoch 61 
2023-07-31 10:56:43.785928: Current learning rate: 0.00094 
2023-07-31 10:57:55.626718: train_loss -0.2779 
2023-07-31 10:57:55.626889: val_loss -0.2136 
2023-07-31 10:57:55.626951: Pseudo dice [0.3678] 
2023-07-31 10:57:55.627008: Epoch time: 71.85 s 
2023-07-31 10:57:56.742252:  
2023-07-31 10:57:56.742365: Epoch 62 
2023-07-31 10:57:56.742441: Current learning rate: 0.00094 
2023-07-31 10:59:13.916450: train_loss -0.2722 
2023-07-31 10:59:13.916611: val_loss -0.3404 
2023-07-31 10:59:13.916678: Pseudo dice [0.6367] 
2023-07-31 10:59:13.916757: Epoch time: 77.17 s 
2023-07-31 10:59:15.187381:  
2023-07-31 10:59:15.187509: Epoch 63 
2023-07-31 10:59:15.187607: Current learning rate: 0.00094 
2023-07-31 11:00:29.684957: train_loss -0.2836 
2023-07-31 11:00:29.685115: val_loss -0.2973 
2023-07-31 11:00:29.685194: Pseudo dice [0.536] 
2023-07-31 11:00:29.685255: Epoch time: 74.5 s 
2023-07-31 11:00:30.735760:  
2023-07-31 11:00:30.736104: Epoch 64 
2023-07-31 11:00:30.736282: Current learning rate: 0.00094 
2023-07-31 11:01:42.623824: train_loss -0.2661 
2023-07-31 11:01:42.624003: val_loss -0.2895 
2023-07-31 11:01:42.624071: Pseudo dice [0.4752] 
2023-07-31 11:01:42.624130: Epoch time: 71.89 s 
2023-07-31 11:01:43.777009:  
2023-07-31 11:01:43.777126: Epoch 65 
2023-07-31 11:01:43.777220: Current learning rate: 0.00094 
2023-07-31 11:02:55.882696: train_loss -0.2812 
2023-07-31 11:02:55.883073: val_loss -0.3014 
2023-07-31 11:02:55.883247: Pseudo dice [0.5505] 
2023-07-31 11:02:55.883397: Epoch time: 72.11 s 
2023-07-31 11:02:56.960089:  
2023-07-31 11:02:56.960349: Epoch 66 
2023-07-31 11:02:56.960445: Current learning rate: 0.00094 
2023-07-31 11:04:08.886067: train_loss -0.2906 
2023-07-31 11:04:08.886225: val_loss -0.2558 
2023-07-31 11:04:08.886284: Pseudo dice [0.6336] 
2023-07-31 11:04:08.886339: Epoch time: 71.93 s 
2023-07-31 11:04:09.994308:  
2023-07-31 11:04:09.994539: Epoch 67 
2023-07-31 11:04:09.994642: Current learning rate: 0.00094 
2023-07-31 11:05:22.977135: train_loss -0.282 
2023-07-31 11:05:22.977296: val_loss -0.2503 
2023-07-31 11:05:22.977362: Pseudo dice [0.4682] 
2023-07-31 11:05:22.977418: Epoch time: 72.98 s 
2023-07-31 11:05:24.123300:  
2023-07-31 11:05:24.123500: Epoch 68 
2023-07-31 11:05:24.123603: Current learning rate: 0.00094 
2023-07-31 11:06:35.439699: train_loss -0.2727 
2023-07-31 11:06:35.439989: val_loss -0.3055 
2023-07-31 11:06:35.440053: Pseudo dice [0.7162] 
2023-07-31 11:06:35.440117: Epoch time: 71.32 s 
2023-07-31 11:06:35.440168: Yayy! New best EMA pseudo Dice: 0.5538 
2023-07-31 11:06:37.089106:  
2023-07-31 11:06:37.089222: Epoch 69 
2023-07-31 11:06:37.089303: Current learning rate: 0.00094 
2023-07-31 11:07:51.910871: train_loss -0.2868 
2023-07-31 11:07:51.911049: val_loss -0.3299 
2023-07-31 11:07:51.911107: Pseudo dice [0.4967] 
2023-07-31 11:07:51.911162: Epoch time: 74.82 s 
2023-07-31 11:07:53.001444:  
2023-07-31 11:07:53.001555: Epoch 70 
2023-07-31 11:07:53.001636: Current learning rate: 0.00094 
2023-07-31 11:09:06.674659: train_loss -0.3042 
2023-07-31 11:09:06.674835: val_loss -0.2815 
2023-07-31 11:09:06.674916: Pseudo dice [0.6789] 
2023-07-31 11:09:06.674980: Epoch time: 73.67 s 
2023-07-31 11:09:06.675029: Yayy! New best EMA pseudo Dice: 0.5611 
2023-07-31 11:09:08.200657:  
2023-07-31 11:09:08.201010: Epoch 71 
2023-07-31 11:09:08.201110: Current learning rate: 0.00094 
2023-07-31 11:10:22.237172: train_loss -0.2673 
2023-07-31 11:10:22.237367: val_loss -0.2561 
2023-07-31 11:10:22.237435: Pseudo dice [0.494] 
2023-07-31 11:10:22.237501: Epoch time: 74.04 s 
2023-07-31 11:10:23.304370:  
2023-07-31 11:10:23.304478: Epoch 72 
2023-07-31 11:10:23.304561: Current learning rate: 0.00093 
2023-07-31 11:11:35.837222: train_loss -0.2714 
2023-07-31 11:11:35.837386: val_loss -0.2758 
2023-07-31 11:11:35.837448: Pseudo dice [0.5166] 
2023-07-31 11:11:35.837505: Epoch time: 72.53 s 
2023-07-31 11:11:36.972627:  
2023-07-31 11:11:36.972816: Epoch 73 
2023-07-31 11:11:36.972915: Current learning rate: 0.00093 
2023-07-31 11:12:49.647598: train_loss -0.2912 
2023-07-31 11:12:49.647788: val_loss -0.2445 
2023-07-31 11:12:49.647854: Pseudo dice [0.751] 
2023-07-31 11:12:49.647920: Epoch time: 72.68 s 
2023-07-31 11:12:49.647994: Yayy! New best EMA pseudo Dice: 0.5707 
2023-07-31 11:12:51.356755:  
2023-07-31 11:12:51.356876: Epoch 74 
2023-07-31 11:12:51.356971: Current learning rate: 0.00093 
2023-07-31 11:14:05.056651: train_loss -0.2808 
2023-07-31 11:14:05.057187: val_loss -0.363 
2023-07-31 11:14:05.057398: Pseudo dice [0.6506] 
2023-07-31 11:14:05.057564: Epoch time: 73.7 s 
2023-07-31 11:14:05.057698: Yayy! New best EMA pseudo Dice: 0.5787 
2023-07-31 11:14:06.587689:  
2023-07-31 11:14:06.588008: Epoch 75 
2023-07-31 11:14:06.588131: Current learning rate: 0.00093 
2023-07-31 11:15:19.623838: train_loss -0.2774 
2023-07-31 11:15:19.624024: val_loss -0.2666 
2023-07-31 11:15:19.624112: Pseudo dice [0.6932] 
2023-07-31 11:15:19.624187: Epoch time: 73.04 s 
2023-07-31 11:15:19.624249: Yayy! New best EMA pseudo Dice: 0.5901 
2023-07-31 11:15:21.056374:  
2023-07-31 11:15:21.056484: Epoch 76 
2023-07-31 11:15:21.056568: Current learning rate: 0.00093 
2023-07-31 11:16:34.339913: train_loss -0.2819 
2023-07-31 11:16:34.340123: val_loss -0.2535 
2023-07-31 11:16:34.340198: Pseudo dice [0.4449] 
2023-07-31 11:16:34.340264: Epoch time: 73.28 s 
2023-07-31 11:16:35.442373:  
2023-07-31 11:16:35.442498: Epoch 77 
2023-07-31 11:16:35.442607: Current learning rate: 0.00093 
2023-07-31 11:17:41.412261: train_loss -0.2522 
2023-07-31 11:17:41.412429: val_loss -0.3167 
2023-07-31 11:17:41.412502: Pseudo dice [0.5305] 
2023-07-31 11:17:41.412571: Epoch time: 65.97 s 
2023-07-31 11:17:42.555112:  
2023-07-31 11:17:42.555223: Epoch 78 
2023-07-31 11:17:42.555303: Current learning rate: 0.00093 
2023-07-31 11:18:40.747674: train_loss -0.3009 
2023-07-31 11:18:40.747841: val_loss -0.3765 
2023-07-31 11:18:40.747899: Pseudo dice [0.6722] 
2023-07-31 11:18:40.747952: Epoch time: 58.19 s 
2023-07-31 11:18:41.972050:  
2023-07-31 11:18:41.972266: Epoch 79 
2023-07-31 11:18:41.972355: Current learning rate: 0.00093 
2023-07-31 11:19:38.223388: train_loss -0.3109 
2023-07-31 11:19:38.223556: val_loss -0.2903 
2023-07-31 11:19:38.223637: Pseudo dice [0.4279] 
2023-07-31 11:19:38.223696: Epoch time: 56.25 s 
2023-07-31 11:19:39.288931:  
2023-07-31 11:19:39.289038: Epoch 80 
2023-07-31 11:19:39.289114: Current learning rate: 0.00093 
2023-07-31 11:20:36.247703: train_loss -0.2831 
2023-07-31 11:20:36.247865: val_loss -0.3006 
2023-07-31 11:20:36.247943: Pseudo dice [0.5736] 
2023-07-31 11:20:36.248003: Epoch time: 56.96 s 
2023-07-31 11:20:37.307287:  
2023-07-31 11:20:37.307395: Epoch 81 
2023-07-31 11:20:37.307476: Current learning rate: 0.00093 
2023-07-31 11:21:33.540044: train_loss -0.303 
2023-07-31 11:21:33.540209: val_loss -0.3388 
2023-07-31 11:21:33.540271: Pseudo dice [0.6288] 
2023-07-31 11:21:33.540326: Epoch time: 56.23 s 
2023-07-31 11:21:34.614239:  
2023-07-31 11:21:34.614424: Epoch 82 
2023-07-31 11:21:34.614506: Current learning rate: 0.00093 
2023-07-31 11:22:30.844012: train_loss -0.2938 
2023-07-31 11:22:30.844176: val_loss -0.316 
2023-07-31 11:22:30.844238: Pseudo dice [0.6813] 
2023-07-31 11:22:30.844295: Epoch time: 56.23 s 
2023-07-31 11:22:31.825121:  
2023-07-31 11:22:31.825228: Epoch 83 
2023-07-31 11:22:31.825308: Current learning rate: 0.00092 
2023-07-31 11:23:28.138470: train_loss -0.2767 
2023-07-31 11:23:28.138630: val_loss -0.2739 
2023-07-31 11:23:28.138688: Pseudo dice [0.6205] 
2023-07-31 11:23:28.138744: Epoch time: 56.31 s 
2023-07-31 11:23:29.358941:  
2023-07-31 11:23:29.359047: Epoch 84 
2023-07-31 11:23:29.359157: Current learning rate: 0.00092 
2023-07-31 11:24:25.597919: train_loss -0.2891 
2023-07-31 11:24:25.598085: val_loss -0.2799 
2023-07-31 11:24:25.598145: Pseudo dice [0.5694] 
2023-07-31 11:24:25.598200: Epoch time: 56.24 s 
2023-07-31 11:24:26.598369:  
2023-07-31 11:24:26.598482: Epoch 85 
2023-07-31 11:24:26.598560: Current learning rate: 0.00092 
2023-07-31 11:25:22.837886: train_loss -0.2953 
2023-07-31 11:25:22.838047: val_loss -0.2576 
2023-07-31 11:25:22.838105: Pseudo dice [0.6799] 
2023-07-31 11:25:22.838159: Epoch time: 56.24 s 
2023-07-31 11:25:22.838204: Yayy! New best EMA pseudo Dice: 0.595 
2023-07-31 11:25:24.206334:  
2023-07-31 11:25:24.206443: Epoch 86 
2023-07-31 11:25:24.206539: Current learning rate: 0.00092 
2023-07-31 11:26:20.435506: train_loss -0.273 
2023-07-31 11:26:20.435686: val_loss -0.2507 
2023-07-31 11:26:20.435750: Pseudo dice [0.5525] 
2023-07-31 11:26:20.435809: Epoch time: 56.23 s 
2023-07-31 11:26:21.425302:  
2023-07-31 11:26:21.425412: Epoch 87 
2023-07-31 11:26:21.425504: Current learning rate: 0.00092 
2023-07-31 11:27:17.688984: train_loss -0.2669 
2023-07-31 11:27:17.689144: val_loss -0.3443 
2023-07-31 11:27:17.689201: Pseudo dice [0.6814] 
2023-07-31 11:27:17.689256: Epoch time: 56.26 s 
2023-07-31 11:27:17.689300: Yayy! New best EMA pseudo Dice: 0.5998 
2023-07-31 11:27:19.067575:  
2023-07-31 11:27:19.067680: Epoch 88 
2023-07-31 11:27:19.067761: Current learning rate: 0.00092 
2023-07-31 11:28:15.229851: train_loss -0.3061 
2023-07-31 11:28:15.230017: val_loss -0.2965 
2023-07-31 11:28:15.230073: Pseudo dice [0.6167] 
2023-07-31 11:28:15.230127: Epoch time: 56.16 s 
2023-07-31 11:28:15.230172: Yayy! New best EMA pseudo Dice: 0.6015 
2023-07-31 11:28:16.571847:  
2023-07-31 11:28:16.572041: Epoch 89 
2023-07-31 11:28:16.572127: Current learning rate: 0.00092 
2023-07-31 11:29:12.850257: train_loss -0.2954 
2023-07-31 11:29:12.850428: val_loss -0.321 
2023-07-31 11:29:12.850487: Pseudo dice [0.619] 
2023-07-31 11:29:12.850541: Epoch time: 56.28 s 
2023-07-31 11:29:12.850584: Yayy! New best EMA pseudo Dice: 0.6033 
2023-07-31 11:29:14.179421:  
2023-07-31 11:29:14.179533: Epoch 90 
2023-07-31 11:29:14.179612: Current learning rate: 0.00092 
2023-07-31 11:30:10.373938: train_loss -0.2975 
2023-07-31 11:30:10.374100: val_loss -0.3097 
2023-07-31 11:30:10.374159: Pseudo dice [0.5363] 
2023-07-31 11:30:10.374213: Epoch time: 56.2 s 
2023-07-31 11:30:11.385371:  
2023-07-31 11:30:11.385479: Epoch 91 
2023-07-31 11:30:11.385557: Current learning rate: 0.00092 
2023-07-31 11:31:15.306391: train_loss -0.2639 
2023-07-31 11:31:15.306580: val_loss -0.3264 
2023-07-31 11:31:15.306676: Pseudo dice [0.5855] 
2023-07-31 11:31:15.306758: Epoch time: 63.92 s 
2023-07-31 11:31:16.320979:  
2023-07-31 11:31:16.321106: Epoch 92 
2023-07-31 11:31:16.321204: Current learning rate: 0.00092 
2023-07-31 11:32:27.338154: train_loss -0.2738 
2023-07-31 11:32:27.338319: val_loss -0.2511 
2023-07-31 11:32:27.338380: Pseudo dice [0.4424] 
2023-07-31 11:32:27.338434: Epoch time: 71.02 s 
2023-07-31 11:32:28.394012:  
2023-07-31 11:32:28.394146: Epoch 93 
2023-07-31 11:32:28.394236: Current learning rate: 0.00092 
2023-07-31 11:33:39.486131: train_loss -0.2563 
2023-07-31 11:33:39.486319: val_loss -0.2855 
2023-07-31 11:33:39.486405: Pseudo dice [0.5567] 
2023-07-31 11:33:39.486468: Epoch time: 71.09 s 
2023-07-31 11:33:40.546851:  
2023-07-31 11:33:40.546971: Epoch 94 
2023-07-31 11:33:40.547053: Current learning rate: 0.00091 
2023-07-31 11:34:51.733769: train_loss -0.2673 
2023-07-31 11:34:51.733922: val_loss -0.3034 
2023-07-31 11:34:51.733981: Pseudo dice [0.6261] 
2023-07-31 11:34:51.734035: Epoch time: 71.19 s 
2023-07-31 11:34:52.969304:  
2023-07-31 11:34:52.969425: Epoch 95 
2023-07-31 11:34:52.969524: Current learning rate: 0.00091 
2023-07-31 11:36:03.771501: train_loss -0.3057 
2023-07-31 11:36:03.771660: val_loss -0.3238 
2023-07-31 11:36:03.771721: Pseudo dice [0.6491] 
2023-07-31 11:36:03.771776: Epoch time: 70.8 s 
2023-07-31 11:36:04.821949:  
2023-07-31 11:36:04.822078: Epoch 96 
2023-07-31 11:36:04.822189: Current learning rate: 0.00091 
2023-07-31 11:37:15.943474: train_loss -0.2809 
2023-07-31 11:37:15.943663: val_loss -0.2388 
2023-07-31 11:37:15.943728: Pseudo dice [0.4883] 
2023-07-31 11:37:15.943788: Epoch time: 71.12 s 
2023-07-31 11:37:16.975112:  
2023-07-31 11:37:16.975234: Epoch 97 
2023-07-31 11:37:16.975343: Current learning rate: 0.00091 
2023-07-31 11:38:29.941128: train_loss -0.2746 
2023-07-31 11:38:29.941286: val_loss -0.2964 
2023-07-31 11:38:29.941347: Pseudo dice [0.6891] 
2023-07-31 11:38:29.941400: Epoch time: 72.97 s 
2023-07-31 11:38:31.034771:  
2023-07-31 11:38:31.034938: Epoch 98 
2023-07-31 11:38:31.035027: Current learning rate: 0.00091 
2023-07-31 11:39:44.158832: train_loss -0.2892 
2023-07-31 11:39:44.159007: val_loss -0.3063 
2023-07-31 11:39:44.159075: Pseudo dice [0.6656] 
2023-07-31 11:39:44.159132: Epoch time: 73.12 s 
2023-07-31 11:39:45.178347:  
2023-07-31 11:39:45.178477: Epoch 99 
2023-07-31 11:39:45.178568: Current learning rate: 0.00091 
2023-07-31 11:40:57.607663: train_loss -0.2821 
2023-07-31 11:40:57.607842: val_loss -0.2735 
2023-07-31 11:40:57.607910: Pseudo dice [0.5674] 
2023-07-31 11:40:57.607972: Epoch time: 72.43 s 
2023-07-31 11:40:59.028956:  
2023-07-31 11:40:59.029063: Epoch 100 
2023-07-31 11:40:59.029142: Current learning rate: 0.00091 
2023-07-31 11:42:10.958984: train_loss -0.3115 
2023-07-31 11:42:10.959240: val_loss -0.287 
2023-07-31 11:42:10.959316: Pseudo dice [0.662] 
2023-07-31 11:42:10.959386: Epoch time: 71.93 s 
2023-07-31 11:42:12.200407:  
2023-07-31 11:42:12.200638: Epoch 101 
2023-07-31 11:42:12.200731: Current learning rate: 0.00091 
2023-07-31 11:43:24.754719: train_loss -0.3128 
2023-07-31 11:43:24.754888: val_loss -0.292 
2023-07-31 11:43:24.754945: Pseudo dice [0.5939] 
2023-07-31 11:43:24.755020: Epoch time: 72.56 s 
2023-07-31 11:43:25.914094:  
2023-07-31 11:43:25.914215: Epoch 102 
2023-07-31 11:43:25.914299: Current learning rate: 0.00091 
2023-07-31 11:44:39.298892: train_loss -0.2927 
2023-07-31 11:44:39.299345: val_loss -0.287 
2023-07-31 11:44:39.299433: Pseudo dice [0.5849] 
2023-07-31 11:44:39.299541: Epoch time: 73.39 s 
2023-07-31 11:44:40.364172:  
2023-07-31 11:44:40.364290: Epoch 103 
2023-07-31 11:44:40.364372: Current learning rate: 0.00091 
2023-07-31 11:45:57.978353: train_loss -0.3102 
2023-07-31 11:45:57.978603: val_loss -0.3496 
2023-07-31 11:45:57.978672: Pseudo dice [0.6907] 
2023-07-31 11:45:57.978733: Epoch time: 77.61 s 
2023-07-31 11:45:57.978779: Yayy! New best EMA pseudo Dice: 0.6083 
2023-07-31 11:45:59.530291:  
2023-07-31 11:45:59.530490: Epoch 104 
2023-07-31 11:45:59.530578: Current learning rate: 0.00091 
2023-07-31 11:47:13.579135: train_loss -0.3065 
2023-07-31 11:47:13.579296: val_loss -0.2678 
2023-07-31 11:47:13.579358: Pseudo dice [0.6456] 
2023-07-31 11:47:13.579414: Epoch time: 74.05 s 
2023-07-31 11:47:13.579458: Yayy! New best EMA pseudo Dice: 0.612 
2023-07-31 11:47:15.058678:  
2023-07-31 11:47:15.058817: Epoch 105 
2023-07-31 11:47:15.058907: Current learning rate: 0.0009 
2023-07-31 11:48:52.998286: train_loss -0.3253 
2023-07-31 11:48:52.998446: val_loss -0.3363 
2023-07-31 11:48:52.998504: Pseudo dice [0.7166] 
2023-07-31 11:48:52.998559: Epoch time: 97.94 s 
2023-07-31 11:48:52.998605: Yayy! New best EMA pseudo Dice: 0.6224 
2023-07-31 11:48:54.693224:  
2023-07-31 11:48:54.696836: Epoch 106 
2023-07-31 11:48:54.696973: Current learning rate: 0.0009 
2023-07-31 11:50:36.507535: train_loss -0.3188 
2023-07-31 11:50:36.507693: val_loss -0.3492 
2023-07-31 11:50:36.507754: Pseudo dice [0.593] 
2023-07-31 11:50:36.507810: Epoch time: 101.82 s 
2023-07-31 11:50:37.558104:  
2023-07-31 11:50:37.558256: Epoch 107 
2023-07-31 11:50:37.558369: Current learning rate: 0.0009 
2023-07-31 11:52:17.764725: train_loss -0.3156 
2023-07-31 11:52:17.764887: val_loss -0.2799 
2023-07-31 11:52:17.764948: Pseudo dice [0.5582] 
2023-07-31 11:52:17.765006: Epoch time: 100.21 s 
2023-07-31 11:52:18.877711:  
2023-07-31 11:52:18.877813: Epoch 108 
2023-07-31 11:52:18.877895: Current learning rate: 0.0009 
2023-07-31 11:53:59.815020: train_loss -0.2929 
2023-07-31 11:53:59.815173: val_loss -0.3635 
2023-07-31 11:53:59.815232: Pseudo dice [0.6166] 
2023-07-31 11:53:59.815287: Epoch time: 100.94 s 
2023-07-31 11:54:00.826423:  
2023-07-31 11:54:00.826636: Epoch 109 
2023-07-31 11:54:00.826714: Current learning rate: 0.0009 
2023-07-31 11:55:43.337905: train_loss -0.2984 
2023-07-31 11:55:43.338075: val_loss -0.3615 
2023-07-31 11:55:43.338133: Pseudo dice [0.7275] 
2023-07-31 11:55:43.338206: Epoch time: 102.51 s 
2023-07-31 11:55:43.338254: Yayy! New best EMA pseudo Dice: 0.6251 
2023-07-31 11:55:44.847986:  
2023-07-31 11:55:44.848097: Epoch 110 
2023-07-31 11:55:44.848182: Current learning rate: 0.0009 
2023-07-31 11:57:26.428303: train_loss -0.3031 
2023-07-31 11:57:26.428459: val_loss -0.3509 
2023-07-31 11:57:26.428519: Pseudo dice [0.7017] 
2023-07-31 11:57:26.428573: Epoch time: 101.58 s 
2023-07-31 11:57:26.428618: Yayy! New best EMA pseudo Dice: 0.6327 
2023-07-31 11:57:27.865613:  
2023-07-31 11:57:27.865870: Epoch 111 
2023-07-31 11:57:27.865977: Current learning rate: 0.0009 
2023-07-31 11:59:08.564084: train_loss -0.291 
2023-07-31 11:59:08.564244: val_loss -0.2737 
2023-07-31 11:59:08.564301: Pseudo dice [0.4384] 
2023-07-31 11:59:08.564356: Epoch time: 100.7 s 
2023-07-31 11:59:09.757261:  
2023-07-31 11:59:09.757376: Epoch 112 
2023-07-31 11:59:09.757457: Current learning rate: 0.0009 
2023-07-31 12:00:51.247661: train_loss -0.3214 
2023-07-31 12:00:51.247817: val_loss -0.2787 
2023-07-31 12:00:51.247880: Pseudo dice [0.6733] 
2023-07-31 12:00:51.247934: Epoch time: 101.49 s 
2023-07-31 12:00:52.262555:  
2023-07-31 12:00:52.263036: Epoch 113 
2023-07-31 12:00:52.263203: Current learning rate: 0.0009 
2023-07-31 12:01:58.978658: train_loss -0.2894 
2023-07-31 12:01:58.978818: val_loss -0.2772 
2023-07-31 12:01:58.978877: Pseudo dice [0.6346] 
2023-07-31 12:01:58.978932: Epoch time: 66.72 s 
2023-07-31 12:01:59.975224:  
2023-07-31 12:01:59.975424: Epoch 114 
2023-07-31 12:01:59.975512: Current learning rate: 0.0009 
2023-07-31 12:02:58.582694: train_loss -0.2856 
2023-07-31 12:02:58.582872: val_loss -0.2922 
2023-07-31 12:02:58.582935: Pseudo dice [0.4976] 
2023-07-31 12:02:58.582991: Epoch time: 58.61 s 
2023-07-31 12:02:59.628727:  
2023-07-31 12:02:59.628834: Epoch 115 
2023-07-31 12:02:59.628914: Current learning rate: 0.0009 
2023-07-31 12:03:58.462834: train_loss -0.2826 
2023-07-31 12:03:58.463009: val_loss -0.3182 
2023-07-31 12:03:58.463068: Pseudo dice [0.7008] 
2023-07-31 12:03:58.463123: Epoch time: 58.83 s 
2023-07-31 12:03:59.709884:  
2023-07-31 12:03:59.710089: Epoch 116 
2023-07-31 12:03:59.710179: Current learning rate: 0.00089 
2023-07-31 12:04:58.768028: train_loss -0.2936 
2023-07-31 12:04:58.768194: val_loss -0.2683 
2023-07-31 12:04:58.768260: Pseudo dice [0.4937] 
2023-07-31 12:04:58.768320: Epoch time: 59.06 s 
2023-07-31 12:04:59.960426:  
2023-07-31 12:04:59.960541: Epoch 117 
2023-07-31 12:04:59.960624: Current learning rate: 0.00089 
2023-07-31 12:05:56.369317: train_loss -0.2649 
2023-07-31 12:05:56.369489: val_loss -0.3253 
2023-07-31 12:05:56.369554: Pseudo dice [0.6995] 
2023-07-31 12:05:56.369627: Epoch time: 56.41 s 
2023-07-31 12:05:57.387725:  
2023-07-31 12:05:57.387836: Epoch 118 
2023-07-31 12:05:57.387918: Current learning rate: 0.00089 
2023-07-31 12:06:54.851349: train_loss -0.3127 
2023-07-31 12:06:54.851734: val_loss -0.2445 
2023-07-31 12:06:54.851834: Pseudo dice [0.5516] 
2023-07-31 12:06:54.851897: Epoch time: 57.46 s 
2023-07-31 12:06:55.922974:  
2023-07-31 12:06:55.923254: Epoch 119 
2023-07-31 12:06:55.923421: Current learning rate: 0.00089 
2023-07-31 12:07:59.316556: train_loss -0.2946 
2023-07-31 12:07:59.316740: val_loss -0.3584 
2023-07-31 12:07:59.316799: Pseudo dice [0.6065] 
2023-07-31 12:07:59.316854: Epoch time: 63.39 s 
2023-07-31 12:08:00.403580:  
2023-07-31 12:08:00.403691: Epoch 120 
2023-07-31 12:08:00.403773: Current learning rate: 0.00089 
2023-07-31 12:09:12.995918: train_loss -0.2887 
2023-07-31 12:09:12.996087: val_loss -0.343 
2023-07-31 12:09:12.996151: Pseudo dice [0.6755] 
2023-07-31 12:09:12.996213: Epoch time: 72.59 s 
2023-07-31 12:09:14.093330:  
2023-07-31 12:09:14.093507: Epoch 121 
2023-07-31 12:09:14.093594: Current learning rate: 0.00089 
2023-07-31 12:10:26.847450: train_loss -0.2633 
2023-07-31 12:10:26.847888: val_loss -0.299 
2023-07-31 12:10:26.848038: Pseudo dice [0.6741] 
2023-07-31 12:10:26.848136: Epoch time: 72.75 s 
2023-07-31 12:10:27.956761:  
2023-07-31 12:10:27.956864: Epoch 122 
2023-07-31 12:10:27.956969: Current learning rate: 0.00089 
2023-07-31 12:11:38.668633: train_loss -0.2851 
2023-07-31 12:11:38.668791: val_loss -0.3087 
2023-07-31 12:11:38.668853: Pseudo dice [0.6991] 
2023-07-31 12:11:38.668910: Epoch time: 70.71 s 
2023-07-31 12:11:39.980987:  
2023-07-31 12:11:39.981104: Epoch 123 
2023-07-31 12:11:39.981183: Current learning rate: 0.00089 
2023-07-31 12:12:50.509680: train_loss -0.3179 
2023-07-31 12:12:50.509855: val_loss -0.2842 
2023-07-31 12:12:50.509921: Pseudo dice [0.577] 
2023-07-31 12:12:50.509977: Epoch time: 70.53 s 
2023-07-31 12:12:51.643053:  
2023-07-31 12:12:51.643163: Epoch 124 
2023-07-31 12:12:51.643243: Current learning rate: 0.00089 
2023-07-31 12:14:04.297714: train_loss -0.2791 
2023-07-31 12:14:04.297873: val_loss -0.3339 
2023-07-31 12:14:04.297935: Pseudo dice [0.5844] 
2023-07-31 12:14:04.297991: Epoch time: 72.66 s 
2023-07-31 12:14:05.424105:  
2023-07-31 12:14:05.424215: Epoch 125 
2023-07-31 12:14:05.424299: Current learning rate: 0.00089 
2023-07-31 12:15:16.899511: train_loss -0.3062 
2023-07-31 12:15:16.899675: val_loss -0.3322 
2023-07-31 12:15:16.899732: Pseudo dice [0.5586] 
2023-07-31 12:15:16.899799: Epoch time: 71.48 s 
2023-07-31 12:15:17.987220:  
2023-07-31 12:15:17.987392: Epoch 126 
2023-07-31 12:15:17.987819: Current learning rate: 0.00089 
2023-07-31 12:16:23.731555: train_loss -0.2616 
2023-07-31 12:16:23.731722: val_loss -0.2769 
2023-07-31 12:16:23.731781: Pseudo dice [0.5903] 
2023-07-31 12:16:23.731836: Epoch time: 65.75 s 
2023-07-31 12:16:24.771174:  
2023-07-31 12:16:24.771280: Epoch 127 
2023-07-31 12:16:24.771361: Current learning rate: 0.00088 
2023-07-31 12:17:23.919022: train_loss -0.2904 
2023-07-31 12:17:23.919206: val_loss -0.306 
2023-07-31 12:17:23.919277: Pseudo dice [0.7056] 
2023-07-31 12:17:23.919342: Epoch time: 59.15 s 
2023-07-31 12:17:25.185223:  
2023-07-31 12:17:25.185336: Epoch 128 
2023-07-31 12:17:25.185421: Current learning rate: 0.00088 
2023-07-31 12:18:27.058668: train_loss -0.2627 
2023-07-31 12:18:27.058844: val_loss -0.3545 
2023-07-31 12:18:27.058905: Pseudo dice [0.6343] 
2023-07-31 12:18:27.058958: Epoch time: 61.87 s 
2023-07-31 12:18:28.079344:  
2023-07-31 12:18:28.079453: Epoch 129 
2023-07-31 12:18:28.079555: Current learning rate: 0.00088 
2023-07-31 12:19:28.504219: train_loss -0.2632 
2023-07-31 12:19:28.504390: val_loss -0.2494 
2023-07-31 12:19:28.504450: Pseudo dice [0.6529] 
2023-07-31 12:19:28.504506: Epoch time: 60.43 s 
2023-07-31 12:19:29.577675:  
2023-07-31 12:19:29.577801: Epoch 130 
2023-07-31 12:19:29.577885: Current learning rate: 0.00088 
2023-07-31 12:20:34.018541: train_loss -0.2806 
2023-07-31 12:20:34.018715: val_loss -0.2762 
2023-07-31 12:20:34.018785: Pseudo dice [0.5977] 
2023-07-31 12:20:34.018846: Epoch time: 64.44 s 
2023-07-31 12:20:35.123962:  
2023-07-31 12:20:35.124073: Epoch 131 
2023-07-31 12:20:35.124154: Current learning rate: 0.00088 
2023-07-31 12:21:43.672498: train_loss -0.2921 
2023-07-31 12:21:43.672666: val_loss -0.326 
2023-07-31 12:21:43.672724: Pseudo dice [0.5678] 
2023-07-31 12:21:43.672779: Epoch time: 68.55 s 
2023-07-31 12:21:44.785383:  
2023-07-31 12:21:44.785643: Epoch 132 
2023-07-31 12:21:44.785735: Current learning rate: 0.00088 
2023-07-31 12:22:57.949715: train_loss -0.2541 
2023-07-31 12:22:57.949864: val_loss -0.2632 
2023-07-31 12:22:57.949922: Pseudo dice [0.697] 
2023-07-31 12:22:57.949977: Epoch time: 73.17 s 
2023-07-31 12:22:59.186713:  
2023-07-31 12:22:59.186831: Epoch 133 
2023-07-31 12:22:59.186932: Current learning rate: 0.00088 
2023-07-31 12:24:09.795708: train_loss -0.3018 
2023-07-31 12:24:09.795893: val_loss -0.3213 
2023-07-31 12:24:09.795966: Pseudo dice [0.6764] 
2023-07-31 12:24:09.796031: Epoch time: 70.61 s 
2023-07-31 12:24:10.880675:  
2023-07-31 12:24:10.880789: Epoch 134 
2023-07-31 12:24:10.880869: Current learning rate: 0.00088 
2023-07-31 12:25:21.532346: train_loss -0.3092 
2023-07-31 12:25:21.532515: val_loss -0.3126 
2023-07-31 12:25:21.532581: Pseudo dice [0.7464] 
2023-07-31 12:25:21.532644: Epoch time: 70.65 s 
2023-07-31 12:25:21.532694: Yayy! New best EMA pseudo Dice: 0.6417 
2023-07-31 12:25:23.025028:  
2023-07-31 12:25:23.025147: Epoch 135 
2023-07-31 12:25:23.025242: Current learning rate: 0.00088 
2023-07-31 12:26:33.367605: train_loss -0.3063 
2023-07-31 12:26:33.367776: val_loss -0.3231 
2023-07-31 12:26:33.367848: Pseudo dice [0.6347] 
2023-07-31 12:26:33.367913: Epoch time: 70.34 s 
2023-07-31 12:26:34.521107:  
2023-07-31 12:26:34.521217: Epoch 136 
2023-07-31 12:26:34.521305: Current learning rate: 0.00088 
2023-07-31 12:27:44.681196: train_loss -0.3138 
2023-07-31 12:27:44.681374: val_loss -0.3364 
2023-07-31 12:27:44.681446: Pseudo dice [0.7267] 
2023-07-31 12:27:44.681513: Epoch time: 70.16 s 
2023-07-31 12:27:44.681566: Yayy! New best EMA pseudo Dice: 0.6496 
2023-07-31 12:27:46.162859:  
2023-07-31 12:27:46.162974: Epoch 137 
2023-07-31 12:27:46.163062: Current learning rate: 0.00088 
2023-07-31 12:28:56.548233: train_loss -0.2731 
2023-07-31 12:28:56.548397: val_loss -0.3046 
2023-07-31 12:28:56.548460: Pseudo dice [0.7362] 
2023-07-31 12:28:56.548516: Epoch time: 70.39 s 
2023-07-31 12:28:56.548560: Yayy! New best EMA pseudo Dice: 0.6582 
2023-07-31 12:28:57.983121:  
2023-07-31 12:28:57.983223: Epoch 138 
2023-07-31 12:28:57.983306: Current learning rate: 0.00087 
2023-07-31 12:30:08.526453: train_loss -0.3006 
2023-07-31 12:30:08.526622: val_loss -0.3104 
2023-07-31 12:30:08.526683: Pseudo dice [0.6956] 
2023-07-31 12:30:08.526744: Epoch time: 70.54 s 
2023-07-31 12:30:08.526792: Yayy! New best EMA pseudo Dice: 0.662 
2023-07-31 12:30:10.144390:  
2023-07-31 12:30:10.144506: Epoch 139 
2023-07-31 12:30:10.144587: Current learning rate: 0.00087 
2023-07-31 12:31:20.190097: train_loss -0.3221 
2023-07-31 12:31:20.190255: val_loss -0.2976 
2023-07-31 12:31:20.190319: Pseudo dice [0.6861] 
2023-07-31 12:31:20.190373: Epoch time: 70.05 s 
2023-07-31 12:31:20.190419: Yayy! New best EMA pseudo Dice: 0.6644 
2023-07-31 12:31:21.680341:  
2023-07-31 12:31:21.680450: Epoch 140 
2023-07-31 12:31:21.680531: Current learning rate: 0.00087 
2023-07-31 12:32:32.211689: train_loss -0.3365 
2023-07-31 12:32:32.211846: val_loss -0.3199 
2023-07-31 12:32:32.211905: Pseudo dice [0.625] 
2023-07-31 12:32:32.211961: Epoch time: 70.53 s 
2023-07-31 12:32:33.335798:  
2023-07-31 12:32:33.335907: Epoch 141 
2023-07-31 12:32:33.335987: Current learning rate: 0.00087 
2023-07-31 12:33:43.932786: train_loss -0.3064 
2023-07-31 12:33:43.932951: val_loss -0.2652 
2023-07-31 12:33:43.933017: Pseudo dice [0.635] 
2023-07-31 12:33:43.933073: Epoch time: 70.6 s 
2023-07-31 12:33:45.199055:  
2023-07-31 12:33:45.199169: Epoch 142 
2023-07-31 12:33:45.199253: Current learning rate: 0.00087 
2023-07-31 12:34:55.772788: train_loss -0.3062 
2023-07-31 12:34:55.772990: val_loss -0.2775 
2023-07-31 12:34:55.773081: Pseudo dice [0.6548] 
2023-07-31 12:34:55.773162: Epoch time: 70.57 s 
2023-07-31 12:34:56.858305:  
2023-07-31 12:34:56.858414: Epoch 143 
2023-07-31 12:34:56.858501: Current learning rate: 0.00087 
2023-07-31 12:36:07.411337: train_loss -0.3058 
2023-07-31 12:36:07.411518: val_loss -0.3773 
2023-07-31 12:36:07.411617: Pseudo dice [0.6789] 
2023-07-31 12:36:07.411699: Epoch time: 70.55 s 
2023-07-31 12:36:08.651245:  
2023-07-31 12:36:08.651406: Epoch 144 
2023-07-31 12:36:08.651569: Current learning rate: 0.00087 
2023-07-31 12:37:06.837592: train_loss -0.3268 
2023-07-31 12:37:06.837754: val_loss -0.3139 
2023-07-31 12:37:06.837816: Pseudo dice [0.601] 
2023-07-31 12:37:06.837871: Epoch time: 58.19 s 
2023-07-31 12:37:07.898437:  
2023-07-31 12:37:07.898537: Epoch 145 
2023-07-31 12:37:07.898644: Current learning rate: 0.00087 
2023-07-31 12:38:03.764757: train_loss -0.3002 
2023-07-31 12:38:03.764928: val_loss -0.3318 
2023-07-31 12:38:03.765019: Pseudo dice [0.6401] 
2023-07-31 12:38:03.765087: Epoch time: 55.87 s 
2023-07-31 12:38:04.819113:  
2023-07-31 12:38:04.819217: Epoch 146 
2023-07-31 12:38:04.819309: Current learning rate: 0.00087 
2023-07-31 12:39:00.694257: train_loss -0.3027 
2023-07-31 12:39:00.694430: val_loss -0.3072 
2023-07-31 12:39:00.694495: Pseudo dice [0.5991] 
2023-07-31 12:39:00.694552: Epoch time: 55.88 s 
2023-07-31 12:39:01.889166:  
2023-07-31 12:39:01.889332: Epoch 147 
2023-07-31 12:39:01.889459: Current learning rate: 0.00087 
2023-07-31 12:40:12.538985: train_loss -0.2833 
2023-07-31 12:40:12.539150: val_loss -0.2774 
2023-07-31 12:40:12.539212: Pseudo dice [0.5262] 
2023-07-31 12:40:12.539276: Epoch time: 70.65 s 
2023-07-31 12:40:13.657550:  
2023-07-31 12:40:13.657731: Epoch 148 
2023-07-31 12:40:13.657854: Current learning rate: 0.00087 
2023-07-31 12:41:24.206595: train_loss -0.3047 
2023-07-31 12:41:24.206738: val_loss -0.3921 
2023-07-31 12:41:24.206794: Pseudo dice [0.766] 
2023-07-31 12:41:24.206847: Epoch time: 70.55 s 
2023-07-31 12:41:25.526012:  
2023-07-31 12:41:25.526130: Epoch 149 
2023-07-31 12:41:25.526214: Current learning rate: 0.00086 
2023-07-31 12:42:36.086068: train_loss -0.3323 
2023-07-31 12:42:36.086253: val_loss -0.3318 
2023-07-31 12:42:36.086314: Pseudo dice [0.7481] 
2023-07-31 12:42:36.086372: Epoch time: 70.56 s 
2023-07-31 12:42:37.548110:  
2023-07-31 12:42:37.548239: Epoch 150 
2023-07-31 12:42:37.548323: Current learning rate: 0.00086 
2023-07-31 12:43:48.060031: train_loss -0.2653 
2023-07-31 12:43:48.060192: val_loss -0.3605 
2023-07-31 12:43:48.060256: Pseudo dice [0.7291] 
2023-07-31 12:43:48.060313: Epoch time: 70.51 s 
2023-07-31 12:43:48.060358: Yayy! New best EMA pseudo Dice: 0.6652 
2023-07-31 12:43:49.574328:  
2023-07-31 12:43:49.574440: Epoch 151 
2023-07-31 12:43:49.574535: Current learning rate: 0.00086 
2023-07-31 12:44:59.605972: train_loss -0.2845 
2023-07-31 12:44:59.606143: val_loss -0.3016 
2023-07-31 12:44:59.606206: Pseudo dice [0.6307] 
2023-07-31 12:44:59.606270: Epoch time: 70.03 s 
2023-07-31 12:45:00.734897:  
2023-07-31 12:45:00.735132: Epoch 152 
2023-07-31 12:45:00.735231: Current learning rate: 0.00086 
2023-07-31 12:46:11.291967: train_loss -0.2966 
2023-07-31 12:46:11.292146: val_loss -0.3039 
2023-07-31 12:46:11.292213: Pseudo dice [0.6914] 
2023-07-31 12:46:11.292279: Epoch time: 70.56 s 
2023-07-31 12:46:12.403080:  
2023-07-31 12:46:12.403198: Epoch 153 
2023-07-31 12:46:12.403280: Current learning rate: 0.00086 
2023-07-31 12:47:23.179941: train_loss -0.2802 
2023-07-31 12:47:23.180118: val_loss -0.3791 
2023-07-31 12:47:23.180186: Pseudo dice [0.7056] 
2023-07-31 12:47:23.180247: Epoch time: 70.78 s 
2023-07-31 12:47:23.180295: Yayy! New best EMA pseudo Dice: 0.6688 
2023-07-31 12:47:24.694304:  
2023-07-31 12:47:24.694407: Epoch 154 
2023-07-31 12:47:24.694488: Current learning rate: 0.00086 
2023-07-31 12:48:35.412314: train_loss -0.3095 
2023-07-31 12:48:35.412495: val_loss -0.3472 
2023-07-31 12:48:35.412575: Pseudo dice [0.6387] 
2023-07-31 12:48:35.412639: Epoch time: 70.72 s 
2023-07-31 12:48:36.754053:  
2023-07-31 12:48:36.754438: Epoch 155 
2023-07-31 12:48:36.754554: Current learning rate: 0.00086 
2023-07-31 12:49:47.756160: train_loss -0.3553 
2023-07-31 12:49:47.756324: val_loss -0.3978 
2023-07-31 12:49:47.756401: Pseudo dice [0.7387] 
2023-07-31 12:49:47.756461: Epoch time: 71.0 s 
2023-07-31 12:49:47.756510: Yayy! New best EMA pseudo Dice: 0.6731 
2023-07-31 12:49:49.233244:  
2023-07-31 12:49:49.233362: Epoch 156 
2023-07-31 12:49:49.233443: Current learning rate: 0.00086 
2023-07-31 12:50:59.538234: train_loss -0.3189 
2023-07-31 12:50:59.538409: val_loss -0.3223 
2023-07-31 12:50:59.538469: Pseudo dice [0.7256] 
2023-07-31 12:50:59.538534: Epoch time: 70.31 s 
2023-07-31 12:50:59.538580: Yayy! New best EMA pseudo Dice: 0.6784 
2023-07-31 12:51:01.024527:  
2023-07-31 12:51:01.024638: Epoch 157 
2023-07-31 12:51:01.024719: Current learning rate: 0.00086 
2023-07-31 12:52:11.968253: train_loss -0.308 
2023-07-31 12:52:11.968417: val_loss -0.279 
2023-07-31 12:52:11.968480: Pseudo dice [0.7708] 
2023-07-31 12:52:11.968537: Epoch time: 70.94 s 
2023-07-31 12:52:11.968582: Yayy! New best EMA pseudo Dice: 0.6876 
2023-07-31 12:52:13.463444:  
2023-07-31 12:52:13.463583: Epoch 158 
2023-07-31 12:52:13.463666: Current learning rate: 0.00086 
2023-07-31 12:53:24.450691: train_loss -0.3482 
2023-07-31 12:53:24.450861: val_loss -0.3333 
2023-07-31 12:53:24.450922: Pseudo dice [0.6842] 
2023-07-31 12:53:24.450977: Epoch time: 70.99 s 
2023-07-31 12:53:25.585340:  
2023-07-31 12:53:25.585608: Epoch 159 
2023-07-31 12:53:25.585798: Current learning rate: 0.00086 
2023-07-31 12:54:36.584068: train_loss -0.3092 
2023-07-31 12:54:36.584225: val_loss -0.3102 
2023-07-31 12:54:36.584290: Pseudo dice [0.6748] 
2023-07-31 12:54:36.584347: Epoch time: 71.0 s 
2023-07-31 12:54:37.871041:  
2023-07-31 12:54:37.871155: Epoch 160 
2023-07-31 12:54:37.871251: Current learning rate: 0.00085 
2023-07-31 12:55:48.203898: train_loss -0.3098 
2023-07-31 12:55:48.204067: val_loss -0.3761 
2023-07-31 12:55:48.204129: Pseudo dice [0.692] 
2023-07-31 12:55:48.204184: Epoch time: 70.33 s 
2023-07-31 12:55:49.391458:  
2023-07-31 12:55:49.391624: Epoch 161 
2023-07-31 12:55:49.391711: Current learning rate: 0.00085 
2023-07-31 12:57:00.309582: train_loss -0.3148 
2023-07-31 12:57:00.309743: val_loss -0.3792 
2023-07-31 12:57:00.309804: Pseudo dice [0.7638] 
2023-07-31 12:57:00.309860: Epoch time: 70.92 s 
2023-07-31 12:57:00.309906: Yayy! New best EMA pseudo Dice: 0.6943 
2023-07-31 12:57:01.866177:  
2023-07-31 12:57:01.866407: Epoch 162 
2023-07-31 12:57:01.866491: Current learning rate: 0.00085 
2023-07-31 12:58:12.512084: train_loss -0.3198 
2023-07-31 12:58:12.512247: val_loss -0.3576 
2023-07-31 12:58:12.512306: Pseudo dice [0.7129] 
2023-07-31 12:58:12.512361: Epoch time: 70.65 s 
2023-07-31 12:58:12.512406: Yayy! New best EMA pseudo Dice: 0.6962 
2023-07-31 12:58:13.971751:  
2023-07-31 12:58:13.972006: Epoch 163 
2023-07-31 12:58:13.972217: Current learning rate: 0.00085 
2023-07-31 12:59:24.731148: train_loss -0.2767 
2023-07-31 12:59:24.731331: val_loss -0.3217 
2023-07-31 12:59:24.731504: Pseudo dice [0.8166] 
2023-07-31 12:59:24.731565: Epoch time: 70.76 s 
2023-07-31 12:59:24.731612: Yayy! New best EMA pseudo Dice: 0.7082 
2023-07-31 12:59:26.453526:  
2023-07-31 12:59:26.453637: Epoch 164 
2023-07-31 12:59:26.453718: Current learning rate: 0.00085 
2023-07-31 13:00:37.351150: train_loss -0.3295 
2023-07-31 13:00:37.351331: val_loss -0.2772 
2023-07-31 13:00:37.351404: Pseudo dice [0.6976] 
2023-07-31 13:00:37.351467: Epoch time: 70.9 s 
2023-07-31 13:00:38.497499:  
2023-07-31 13:00:38.497615: Epoch 165 
2023-07-31 13:00:38.497711: Current learning rate: 0.00085 
2023-07-31 13:01:48.846266: train_loss -0.3166 
2023-07-31 13:01:48.846425: val_loss -0.3554 
2023-07-31 13:01:48.846483: Pseudo dice [0.6839] 
2023-07-31 13:01:48.846537: Epoch time: 70.35 s 
2023-07-31 13:01:49.934718:  
2023-07-31 13:01:49.934990: Epoch 166 
2023-07-31 13:01:49.935173: Current learning rate: 0.00085 
2023-07-31 13:03:00.794568: train_loss -0.3122 
2023-07-31 13:03:00.794794: val_loss -0.3075 
2023-07-31 13:03:00.794859: Pseudo dice [0.6391] 
2023-07-31 13:03:00.794917: Epoch time: 70.86 s 
2023-07-31 13:03:01.864366:  
2023-07-31 13:03:01.864471: Epoch 167 
2023-07-31 13:03:01.864552: Current learning rate: 0.00085 
2023-07-31 13:04:12.693205: train_loss -0.3005 
2023-07-31 13:04:12.693376: val_loss -0.2735 
2023-07-31 13:04:12.693447: Pseudo dice [0.6775] 
2023-07-31 13:04:12.693504: Epoch time: 70.83 s 
2023-07-31 13:04:13.920517:  
2023-07-31 13:04:13.920625: Epoch 168 
2023-07-31 13:04:13.920706: Current learning rate: 0.00085 
2023-07-31 13:05:24.868935: train_loss -0.2997 
2023-07-31 13:05:24.869114: val_loss -0.3484 
2023-07-31 13:05:24.869175: Pseudo dice [0.7216] 
2023-07-31 13:05:24.869232: Epoch time: 70.95 s 
2023-07-31 13:05:26.014171:  
2023-07-31 13:05:26.014393: Epoch 169 
2023-07-31 13:05:26.014479: Current learning rate: 0.00085 
2023-07-31 13:06:29.478848: train_loss -0.2765 
2023-07-31 13:06:29.479009: val_loss -0.3111 
2023-07-31 13:06:29.479067: Pseudo dice [0.7568] 
2023-07-31 13:06:29.479120: Epoch time: 63.47 s 
2023-07-31 13:06:30.699460:  
2023-07-31 13:06:30.699703: Epoch 170 
2023-07-31 13:06:30.699790: Current learning rate: 0.00085 
2023-07-31 13:07:26.566937: train_loss -0.3071 
2023-07-31 13:07:26.567110: val_loss -0.2785 
2023-07-31 13:07:26.567167: Pseudo dice [0.7377] 
2023-07-31 13:07:26.567221: Epoch time: 55.87 s 
2023-07-31 13:07:27.620788:  
2023-07-31 13:07:27.620900: Epoch 171 
2023-07-31 13:07:27.621008: Current learning rate: 0.00084 
2023-07-31 13:08:23.557266: train_loss -0.3014 
2023-07-31 13:08:23.557425: val_loss -0.3338 
2023-07-31 13:08:23.557489: Pseudo dice [0.6579] 
2023-07-31 13:08:23.557544: Epoch time: 55.94 s 
2023-07-31 13:08:24.610165:  
2023-07-31 13:08:24.610515: Epoch 172 
2023-07-31 13:08:24.610598: Current learning rate: 0.00084 
2023-07-31 13:09:20.503314: train_loss -0.3174 
2023-07-31 13:09:20.503497: val_loss -0.3316 
2023-07-31 13:09:20.503556: Pseudo dice [0.789] 
2023-07-31 13:09:20.503613: Epoch time: 55.89 s 
2023-07-31 13:09:20.503658: Yayy! New best EMA pseudo Dice: 0.7115 
2023-07-31 13:09:21.943554:  
2023-07-31 13:09:21.943739: Epoch 173 
2023-07-31 13:09:21.943848: Current learning rate: 0.00084 
2023-07-31 13:10:17.782006: train_loss -0.3176 
2023-07-31 13:10:17.782169: val_loss -0.3136 
2023-07-31 13:10:17.782228: Pseudo dice [0.7064] 
2023-07-31 13:10:17.782291: Epoch time: 55.84 s 
2023-07-31 13:10:18.871928:  
2023-07-31 13:10:18.872266: Epoch 174 
2023-07-31 13:10:18.872350: Current learning rate: 0.00084 
2023-07-31 13:11:14.699032: train_loss -0.3338 
2023-07-31 13:11:14.699203: val_loss -0.358 
2023-07-31 13:11:14.699268: Pseudo dice [0.7124] 
2023-07-31 13:11:14.699323: Epoch time: 55.83 s 
2023-07-31 13:11:15.901386:  
2023-07-31 13:11:15.901491: Epoch 175 
2023-07-31 13:11:15.901585: Current learning rate: 0.00084 
2023-07-31 13:12:11.684175: train_loss -0.3188 
2023-07-31 13:12:11.684339: val_loss -0.2762 
2023-07-31 13:12:11.684399: Pseudo dice [0.6139] 
2023-07-31 13:12:11.684454: Epoch time: 55.78 s 
2023-07-31 13:12:12.762794:  
2023-07-31 13:12:12.763006: Epoch 176 
2023-07-31 13:12:12.763121: Current learning rate: 0.00084 
2023-07-31 13:13:08.574473: train_loss -0.3115 
2023-07-31 13:13:08.574647: val_loss -0.3271 
2023-07-31 13:13:08.574712: Pseudo dice [0.7427] 
2023-07-31 13:13:08.574770: Epoch time: 55.81 s 
2023-07-31 13:13:09.626687:  
2023-07-31 13:13:09.626809: Epoch 177 
2023-07-31 13:13:09.626886: Current learning rate: 0.00084 
2023-07-31 13:14:05.502316: train_loss -0.3033 
2023-07-31 13:14:05.502484: val_loss -0.276 
2023-07-31 13:14:05.502541: Pseudo dice [0.6372] 
2023-07-31 13:14:05.502594: Epoch time: 55.88 s 
2023-07-31 13:14:06.576797:  
2023-07-31 13:14:06.576899: Epoch 178 
2023-07-31 13:14:06.577056: Current learning rate: 0.00084 
2023-07-31 13:15:02.987234: train_loss -0.286 
2023-07-31 13:15:02.987494: val_loss -0.3418 
2023-07-31 13:15:02.987565: Pseudo dice [0.759] 
2023-07-31 13:15:02.987623: Epoch time: 56.41 s 
2023-07-31 13:15:04.083302:  
2023-07-31 13:15:04.083404: Epoch 179 
2023-07-31 13:15:04.083521: Current learning rate: 0.00084 
2023-07-31 13:16:00.282003: train_loss -0.3252 
2023-07-31 13:16:00.282166: val_loss -0.3256 
2023-07-31 13:16:00.282222: Pseudo dice [0.7432] 
2023-07-31 13:16:00.282276: Epoch time: 56.2 s 
2023-07-31 13:16:01.486353:  
2023-07-31 13:16:01.486454: Epoch 180 
2023-07-31 13:16:01.486561: Current learning rate: 0.00084 
2023-07-31 13:17:00.649456: train_loss -0.3437 
2023-07-31 13:17:00.649618: val_loss -0.35 
2023-07-31 13:17:00.649681: Pseudo dice [0.7385] 
2023-07-31 13:17:00.649737: Epoch time: 59.16 s 
2023-07-31 13:17:00.649781: Yayy! New best EMA pseudo Dice: 0.7116 
2023-07-31 13:17:02.122351:  
2023-07-31 13:17:02.122474: Epoch 181 
2023-07-31 13:17:02.122573: Current learning rate: 0.00084 
2023-07-31 13:18:12.730716: train_loss -0.3386 
2023-07-31 13:18:12.730875: val_loss -0.2863 
2023-07-31 13:18:12.730938: Pseudo dice [0.6942] 
2023-07-31 13:18:12.730994: Epoch time: 70.61 s 
2023-07-31 13:18:13.825824:  
2023-07-31 13:18:13.826099: Epoch 182 
2023-07-31 13:18:13.826207: Current learning rate: 0.00083 
2023-07-31 13:19:24.131964: train_loss -0.3228 
2023-07-31 13:19:24.132129: val_loss -0.2592 
2023-07-31 13:19:24.132188: Pseudo dice [0.7475] 
2023-07-31 13:19:24.132243: Epoch time: 70.31 s 
2023-07-31 13:19:24.132289: Yayy! New best EMA pseudo Dice: 0.7136 
2023-07-31 13:19:25.599613:  
2023-07-31 13:19:25.599720: Epoch 183 
2023-07-31 13:19:25.599802: Current learning rate: 0.00083 
2023-07-31 13:20:36.018495: train_loss -0.269 
2023-07-31 13:20:36.018669: val_loss -0.3629 
2023-07-31 13:20:36.018746: Pseudo dice [0.7594] 
2023-07-31 13:20:36.018816: Epoch time: 70.42 s 
2023-07-31 13:20:36.018889: Yayy! New best EMA pseudo Dice: 0.7182 
2023-07-31 13:20:37.487161:  
2023-07-31 13:20:37.487284: Epoch 184 
2023-07-31 13:20:37.487368: Current learning rate: 0.00083 
2023-07-31 13:21:53.647672: train_loss -0.3142 
2023-07-31 13:21:53.647861: val_loss -0.2829 
2023-07-31 13:21:53.647930: Pseudo dice [0.6871] 
2023-07-31 13:21:53.647993: Epoch time: 76.16 s 
2023-07-31 13:21:54.888706:  
2023-07-31 13:21:54.888955: Epoch 185 
2023-07-31 13:21:54.889048: Current learning rate: 0.00083 
2023-07-31 13:23:05.073313: train_loss -0.3272 
2023-07-31 13:23:05.073528: val_loss -0.2905 
2023-07-31 13:23:05.073626: Pseudo dice [0.6859] 
2023-07-31 13:23:05.073720: Epoch time: 70.19 s 
2023-07-31 13:23:06.184843:  
2023-07-31 13:23:06.184952: Epoch 186 
2023-07-31 13:23:06.185046: Current learning rate: 0.00083 
2023-07-31 13:24:17.021872: train_loss -0.338 
2023-07-31 13:24:17.022058: val_loss -0.3582 
2023-07-31 13:24:17.022133: Pseudo dice [0.7675] 
2023-07-31 13:24:17.022215: Epoch time: 70.84 s 
2023-07-31 13:24:18.098880:  
2023-07-31 13:24:18.098989: Epoch 187 
2023-07-31 13:24:18.099067: Current learning rate: 0.00083 
2023-07-31 13:25:28.913717: train_loss -0.3116 
2023-07-31 13:25:28.913878: val_loss -0.2753 
2023-07-31 13:25:28.913938: Pseudo dice [0.5664] 
2023-07-31 13:25:28.913993: Epoch time: 70.82 s 
2023-07-31 13:25:30.038288:  
2023-07-31 13:25:30.038408: Epoch 188 
2023-07-31 13:25:30.038509: Current learning rate: 0.00083 
2023-07-31 13:26:40.599461: train_loss -0.2978 
2023-07-31 13:26:40.599646: val_loss -0.3113 
2023-07-31 13:26:40.599707: Pseudo dice [0.6869] 
2023-07-31 13:26:40.599765: Epoch time: 70.56 s 
2023-07-31 13:26:41.700541:  
2023-07-31 13:26:41.700733: Epoch 189 
2023-07-31 13:26:41.700820: Current learning rate: 0.00083 
2023-07-31 13:27:52.068342: train_loss -0.3423 
2023-07-31 13:27:52.068564: val_loss -0.4083 
2023-07-31 13:27:52.068638: Pseudo dice [0.7275] 
2023-07-31 13:27:52.068705: Epoch time: 70.37 s 
2023-07-31 13:27:53.170264:  
2023-07-31 13:27:53.170441: Epoch 190 
2023-07-31 13:27:53.170524: Current learning rate: 0.00083 
2023-07-31 13:29:03.173707: train_loss -0.3142 
2023-07-31 13:29:03.173864: val_loss -0.332 
2023-07-31 13:29:03.173922: Pseudo dice [0.7289] 
2023-07-31 13:29:03.173978: Epoch time: 70.0 s 
2023-07-31 13:29:04.460385:  
2023-07-31 13:29:04.460619: Epoch 191 
2023-07-31 13:29:04.460704: Current learning rate: 0.00083 
2023-07-31 13:30:15.078732: train_loss -0.328 
2023-07-31 13:30:15.078942: val_loss -0.3059 
2023-07-31 13:30:15.079008: Pseudo dice [0.6143] 
2023-07-31 13:30:15.079071: Epoch time: 70.62 s 
2023-07-31 13:30:16.305188:  
2023-07-31 13:30:16.305312: Epoch 192 
2023-07-31 13:30:16.305397: Current learning rate: 0.00083 
2023-07-31 13:31:26.878766: train_loss -0.3504 
2023-07-31 13:31:26.879041: val_loss -0.2791 
2023-07-31 13:31:26.879103: Pseudo dice [0.6671] 
2023-07-31 13:31:26.879178: Epoch time: 70.57 s 
2023-07-31 13:31:27.972765:  
2023-07-31 13:31:27.972871: Epoch 193 
2023-07-31 13:31:27.972950: Current learning rate: 0.00082 
2023-07-31 13:32:38.512376: train_loss -0.3364 
2023-07-31 13:32:38.512533: val_loss -0.3037 
2023-07-31 13:32:38.512594: Pseudo dice [0.6854] 
2023-07-31 13:32:38.512653: Epoch time: 70.54 s 
2023-07-31 13:32:39.682990:  
2023-07-31 13:32:39.683108: Epoch 194 
2023-07-31 13:32:39.683189: Current learning rate: 0.00082 
2023-07-31 13:33:52.962644: train_loss -0.3614 
2023-07-31 13:33:52.962809: val_loss -0.3376 
2023-07-31 13:33:52.962875: Pseudo dice [0.7291] 
2023-07-31 13:33:52.962929: Epoch time: 73.28 s 
2023-07-31 13:33:54.039289:  
2023-07-31 13:33:54.039419: Epoch 195 
2023-07-31 13:33:54.039520: Current learning rate: 0.00082 
2023-07-31 13:35:34.620602: train_loss -0.3167 
2023-07-31 13:35:34.620875: val_loss -0.3749 
2023-07-31 13:35:34.621009: Pseudo dice [0.7392] 
2023-07-31 13:35:34.621127: Epoch time: 100.58 s 
2023-07-31 13:35:35.955356:  
2023-07-31 13:35:35.955513: Epoch 196 
2023-07-31 13:35:35.955603: Current learning rate: 0.00082 
2023-07-31 13:37:21.770545: train_loss -0.3158 
2023-07-31 13:37:21.770702: val_loss -0.2688 
2023-07-31 13:37:21.770760: Pseudo dice [0.7803] 
2023-07-31 13:37:21.770814: Epoch time: 105.82 s 
2023-07-31 13:37:22.920218:  
2023-07-31 13:37:22.920330: Epoch 197 
2023-07-31 13:37:22.920407: Current learning rate: 0.00082 
2023-07-31 13:38:37.761480: train_loss -0.3144 
2023-07-31 13:38:37.761654: val_loss -0.3411 
2023-07-31 13:38:37.761721: Pseudo dice [0.691] 
2023-07-31 13:38:37.761782: Epoch time: 74.84 s 
2023-07-31 13:38:38.863627:  
2023-07-31 13:38:38.863850: Epoch 198 
2023-07-31 13:38:38.863932: Current learning rate: 0.00082 
2023-07-31 13:39:35.081085: train_loss -0.3042 
2023-07-31 13:39:35.081370: val_loss -0.3332 
2023-07-31 13:39:35.081433: Pseudo dice [0.5814] 
2023-07-31 13:39:35.081492: Epoch time: 56.22 s 
2023-07-31 13:39:36.159150:  
2023-07-31 13:39:36.159257: Epoch 199 
2023-07-31 13:39:36.159351: Current learning rate: 0.00082 
2023-07-31 13:40:34.094022: train_loss -0.3274 
2023-07-31 13:40:34.094184: val_loss -0.4025 
2023-07-31 13:40:34.094245: Pseudo dice [0.7895] 
2023-07-31 13:40:34.094301: Epoch time: 57.94 s 
2023-07-31 13:40:35.665226:  
2023-07-31 13:40:35.665334: Epoch 200 
2023-07-31 13:40:35.665431: Current learning rate: 0.00082 
2023-07-31 13:41:34.781500: train_loss -0.3036 
2023-07-31 13:41:34.781666: val_loss -0.3133 
2023-07-31 13:41:34.781723: Pseudo dice [0.6596] 
2023-07-31 13:41:34.781779: Epoch time: 59.12 s 
2023-07-31 13:41:35.907740:  
2023-07-31 13:41:35.907854: Epoch 201 
2023-07-31 13:41:35.907934: Current learning rate: 0.00082 
2023-07-31 13:42:32.776173: train_loss -0.3017 
2023-07-31 13:42:32.776485: val_loss -0.2975 
2023-07-31 13:42:32.776636: Pseudo dice [0.6445] 
2023-07-31 13:42:32.776749: Epoch time: 56.87 s 
2023-07-31 13:42:33.879610:  
2023-07-31 13:42:33.879720: Epoch 202 
2023-07-31 13:42:33.879800: Current learning rate: 0.00082 
2023-07-31 13:43:31.130310: train_loss -0.3141 
2023-07-31 13:43:31.130476: val_loss -0.2416 
2023-07-31 13:43:31.130534: Pseudo dice [0.4505] 
2023-07-31 13:43:31.130590: Epoch time: 57.25 s 
2023-07-31 13:43:32.297694:  
2023-07-31 13:43:32.297906: Epoch 203 
2023-07-31 13:43:32.297989: Current learning rate: 0.00082 
2023-07-31 13:44:30.606806: train_loss -0.3174 
2023-07-31 13:44:30.606965: val_loss -0.2759 
2023-07-31 13:44:30.607024: Pseudo dice [0.725] 
2023-07-31 13:44:30.607078: Epoch time: 58.31 s 
2023-07-31 13:44:31.688974:  
2023-07-31 13:44:31.689078: Epoch 204 
2023-07-31 13:44:31.689159: Current learning rate: 0.00081 
2023-07-31 13:45:31.960104: train_loss -0.3679 
2023-07-31 13:45:31.960279: val_loss -0.265 
2023-07-31 13:45:31.960335: Pseudo dice [0.7001] 
2023-07-31 13:45:31.960391: Epoch time: 60.27 s 
2023-07-31 13:45:33.075832:  
2023-07-31 13:45:33.075939: Epoch 205 
2023-07-31 13:45:33.076022: Current learning rate: 0.00081 
2023-07-31 13:46:30.555416: train_loss -0.3062 
2023-07-31 13:46:30.555627: val_loss -0.3168 
2023-07-31 13:46:30.555692: Pseudo dice [0.814] 
2023-07-31 13:46:30.555753: Epoch time: 57.48 s 
2023-07-31 13:46:31.784930:  
2023-07-31 13:46:31.785149: Epoch 206 
2023-07-31 13:46:31.785250: Current learning rate: 0.00081 
2023-07-31 13:47:31.594903: train_loss -0.3067 
2023-07-31 13:47:31.595068: val_loss -0.2996 
2023-07-31 13:47:31.595129: Pseudo dice [0.7616] 
2023-07-31 13:47:31.595184: Epoch time: 59.81 s 
2023-07-31 13:47:32.623767:  
2023-07-31 13:47:32.624074: Epoch 207 
2023-07-31 13:47:32.624162: Current learning rate: 0.00081 
2023-07-31 13:48:29.860836: train_loss -0.3345 
2023-07-31 13:48:29.861017: val_loss -0.2658 
2023-07-31 13:48:29.861101: Pseudo dice [0.6222] 
2023-07-31 13:48:29.861217: Epoch time: 57.24 s 
2023-07-31 13:48:30.895317:  
2023-07-31 13:48:30.895439: Epoch 208 
2023-07-31 13:48:30.895525: Current learning rate: 0.00081 
2023-07-31 13:49:30.654944: train_loss -0.3151 
2023-07-31 13:49:30.655113: val_loss -0.3389 
2023-07-31 13:49:30.655190: Pseudo dice [0.712] 
2023-07-31 13:49:30.655258: Epoch time: 59.76 s 
2023-07-31 13:49:31.681480:  
2023-07-31 13:49:31.681577: Epoch 209 
2023-07-31 13:49:31.681668: Current learning rate: 0.00081 
2023-07-31 13:50:29.906085: train_loss -0.3062 
2023-07-31 13:50:29.906243: val_loss -0.3126 
2023-07-31 13:50:29.906302: Pseudo dice [0.7461] 
2023-07-31 13:50:29.906357: Epoch time: 58.23 s 
2023-07-31 13:50:30.935836:  
2023-07-31 13:50:30.935946: Epoch 210 
2023-07-31 13:50:30.936025: Current learning rate: 0.00081 
2023-07-31 13:51:31.278792: train_loss -0.3165 
2023-07-31 13:51:31.278955: val_loss -0.3021 
2023-07-31 13:51:31.279018: Pseudo dice [0.7294] 
2023-07-31 13:51:31.279075: Epoch time: 60.34 s 
2023-07-31 13:51:32.445986:  
2023-07-31 13:51:32.446259: Epoch 211 
2023-07-31 13:51:32.446449: Current learning rate: 0.00081 
2023-07-31 13:52:32.283156: train_loss -0.3196 
2023-07-31 13:52:32.283338: val_loss -0.3532 
2023-07-31 13:52:32.283400: Pseudo dice [0.7742] 
2023-07-31 13:52:32.283457: Epoch time: 59.84 s 
2023-07-31 13:52:33.361383:  
2023-07-31 13:52:33.361495: Epoch 212 
2023-07-31 13:52:33.361573: Current learning rate: 0.00081 
2023-07-31 13:53:30.568787: train_loss -0.3116 
2023-07-31 13:53:30.569057: val_loss -0.378 
2023-07-31 13:53:30.569126: Pseudo dice [0.6795] 
2023-07-31 13:53:30.569183: Epoch time: 57.21 s 
2023-07-31 13:53:31.602746:  
2023-07-31 13:53:31.602851: Epoch 213 
2023-07-31 13:53:31.602927: Current learning rate: 0.00081 
2023-07-31 13:54:27.697446: train_loss -0.3236 
2023-07-31 13:54:27.697606: val_loss -0.3625 
2023-07-31 13:54:27.697669: Pseudo dice [0.7031] 
2023-07-31 13:54:27.697724: Epoch time: 56.1 s 
2023-07-31 13:54:28.743526:  
2023-07-31 13:54:28.743630: Epoch 214 
2023-07-31 13:54:28.743707: Current learning rate: 0.00081 
2023-07-31 13:55:24.891253: train_loss -0.3337 
2023-07-31 13:55:24.891428: val_loss -0.3269 
2023-07-31 13:55:24.891505: Pseudo dice [0.6935] 
2023-07-31 13:55:24.891564: Epoch time: 56.15 s 
2023-07-31 13:55:25.923781:  
2023-07-31 13:55:25.923963: Epoch 215 
2023-07-31 13:55:25.924048: Current learning rate: 0.0008 
2023-07-31 13:56:21.915781: train_loss -0.3173 
2023-07-31 13:56:21.915949: val_loss -0.2787 
2023-07-31 13:56:21.916025: Pseudo dice [0.5886] 
2023-07-31 13:56:21.916112: Epoch time: 55.99 s 
2023-07-31 13:56:23.086993:  
2023-07-31 13:56:23.087214: Epoch 216 
2023-07-31 13:56:23.087457: Current learning rate: 0.0008 
2023-07-31 13:57:19.114320: train_loss -0.3245 
2023-07-31 13:57:19.114498: val_loss -0.4049 
2023-07-31 13:57:19.114587: Pseudo dice [0.7799] 
2023-07-31 13:57:19.114656: Epoch time: 56.03 s 
2023-07-31 13:57:20.137704:  
2023-07-31 13:57:20.137921: Epoch 217 
2023-07-31 13:57:20.138006: Current learning rate: 0.0008 
2023-07-31 13:58:16.172247: train_loss -0.2882 
2023-07-31 13:58:16.172422: val_loss -0.3239 
2023-07-31 13:58:16.180820: Pseudo dice [0.7558] 
2023-07-31 13:58:16.181090: Epoch time: 56.04 s 
2023-07-31 13:58:17.216644:  
2023-07-31 13:58:17.216921: Epoch 218 
2023-07-31 13:58:17.217055: Current learning rate: 0.0008 
2023-07-31 13:59:13.236794: train_loss -0.3474 
2023-07-31 13:59:13.236956: val_loss -0.358 
2023-07-31 13:59:13.237014: Pseudo dice [0.8414] 
2023-07-31 13:59:13.237069: Epoch time: 56.02 s 
2023-07-31 13:59:13.237115: Yayy! New best EMA pseudo Dice: 0.7203 
2023-07-31 13:59:14.599390:  
2023-07-31 13:59:14.599510: Epoch 219 
2023-07-31 13:59:14.599607: Current learning rate: 0.0008 
2023-07-31 14:00:10.593395: train_loss -0.326 
2023-07-31 14:00:10.593566: val_loss -0.3212 
2023-07-31 14:00:10.593646: Pseudo dice [0.6664] 
2023-07-31 14:00:10.593715: Epoch time: 55.99 s 
2023-07-31 14:00:11.601859:  
2023-07-31 14:00:11.601984: Epoch 220 
2023-07-31 14:00:11.602060: Current learning rate: 0.0008 
2023-07-31 14:01:08.409738: train_loss -0.3058 
2023-07-31 14:01:08.409902: val_loss -0.3623 
2023-07-31 14:01:08.409983: Pseudo dice [0.6836] 
2023-07-31 14:01:08.410057: Epoch time: 56.81 s 
2023-07-31 14:01:09.415863:  
2023-07-31 14:01:09.416072: Epoch 221 
2023-07-31 14:01:09.416158: Current learning rate: 0.0008 
2023-07-31 14:02:08.658992: train_loss -0.323 
2023-07-31 14:02:08.659152: val_loss -0.2713 
2023-07-31 14:02:08.659214: Pseudo dice [0.6725] 
2023-07-31 14:02:08.659269: Epoch time: 59.24 s 
2023-07-31 14:02:09.831314:  
2023-07-31 14:02:09.831722: Epoch 222 
2023-07-31 14:02:09.832003: Current learning rate: 0.0008 
2023-07-31 14:03:08.617054: train_loss -0.3278 
2023-07-31 14:03:08.617224: val_loss -0.3501 
2023-07-31 14:03:08.617286: Pseudo dice [0.6805] 
2023-07-31 14:03:08.617340: Epoch time: 58.79 s 
2023-07-31 14:03:09.640601:  
2023-07-31 14:03:09.640720: Epoch 223 
2023-07-31 14:03:09.640810: Current learning rate: 0.0008 
2023-07-31 14:04:08.962277: train_loss -0.3266 
2023-07-31 14:04:08.962442: val_loss -0.3712 
2023-07-31 14:04:08.962501: Pseudo dice [0.7816] 
2023-07-31 14:04:08.962556: Epoch time: 59.32 s 
2023-07-31 14:04:09.974380:  
2023-07-31 14:04:09.974632: Epoch 224 
2023-07-31 14:04:09.974846: Current learning rate: 0.0008 
2023-07-31 14:05:07.753443: train_loss -0.3369 
2023-07-31 14:05:07.753618: val_loss -0.3284 
2023-07-31 14:05:07.753679: Pseudo dice [0.743] 
2023-07-31 14:05:07.753734: Epoch time: 57.78 s 
2023-07-31 14:05:08.772069:  
2023-07-31 14:05:08.772174: Epoch 225 
2023-07-31 14:05:08.772253: Current learning rate: 0.0008 
2023-07-31 14:06:07.145517: train_loss -0.3219 
2023-07-31 14:06:07.145693: val_loss -0.2982 
2023-07-31 14:06:07.154087: Pseudo dice [0.6911] 
2023-07-31 14:06:07.154210: Epoch time: 58.37 s 
2023-07-31 14:06:08.232280:  
2023-07-31 14:06:08.232541: Epoch 226 
2023-07-31 14:06:08.232706: Current learning rate: 0.00079 
2023-07-31 14:07:05.953510: train_loss -0.301 
2023-07-31 14:07:05.953679: val_loss -0.3444 
2023-07-31 14:07:05.953745: Pseudo dice [0.7127] 
2023-07-31 14:07:05.953821: Epoch time: 57.72 s 
2023-07-31 14:07:07.084337:  
2023-07-31 14:07:07.084449: Epoch 227 
2023-07-31 14:07:07.084524: Current learning rate: 0.00079 
2023-07-31 14:08:04.305616: train_loss -0.2965 
2023-07-31 14:08:04.305770: val_loss -0.3219 
2023-07-31 14:08:04.305832: Pseudo dice [0.6957] 
2023-07-31 14:08:04.305887: Epoch time: 57.22 s 
2023-07-31 14:08:05.303641:  
2023-07-31 14:08:05.303828: Epoch 228 
2023-07-31 14:08:05.303911: Current learning rate: 0.00079 
2023-07-31 14:09:03.855715: train_loss -0.3153 
2023-07-31 14:09:03.855871: val_loss -0.317 
2023-07-31 14:09:03.855947: Pseudo dice [0.6435] 
2023-07-31 14:09:03.856004: Epoch time: 58.55 s 
2023-07-31 14:09:04.874374:  
2023-07-31 14:09:04.874482: Epoch 229 
2023-07-31 14:09:04.874575: Current learning rate: 0.00079 
2023-07-31 14:10:03.163293: train_loss -0.3001 
2023-07-31 14:10:03.163455: val_loss -0.2903 
2023-07-31 14:10:03.163526: Pseudo dice [0.644] 
2023-07-31 14:10:03.163581: Epoch time: 58.29 s 
2023-07-31 14:10:04.219954:  
2023-07-31 14:10:04.220065: Epoch 230 
2023-07-31 14:10:04.220141: Current learning rate: 0.00079 
2023-07-31 14:11:20.245241: train_loss -0.3372 
2023-07-31 14:11:20.245410: val_loss -0.3669 
2023-07-31 14:11:20.245470: Pseudo dice [0.7188] 
2023-07-31 14:11:20.245525: Epoch time: 76.03 s 
2023-07-31 14:11:21.278196:  
2023-07-31 14:11:21.278327: Epoch 231 
2023-07-31 14:11:21.278431: Current learning rate: 0.00079 
2023-07-31 14:12:57.760554: train_loss -0.3394 
2023-07-31 14:12:57.760722: val_loss -0.2938 
2023-07-31 14:12:57.769098: Pseudo dice [0.6666] 
2023-07-31 14:12:57.769223: Epoch time: 96.48 s 
2023-07-31 14:12:58.771129:  
2023-07-31 14:12:58.771235: Epoch 232 
2023-07-31 14:12:58.771314: Current learning rate: 0.00079 
2023-07-31 14:14:21.823318: train_loss -0.3183 
2023-07-31 14:14:21.823466: val_loss -0.2848 
2023-07-31 14:14:21.823535: Pseudo dice [0.73] 
2023-07-31 14:14:21.823591: Epoch time: 83.05 s 
2023-07-31 14:14:22.902245:  
2023-07-31 14:14:22.902457: Epoch 233 
2023-07-31 14:14:22.902550: Current learning rate: 0.00079 
2023-07-31 14:15:32.025931: train_loss -0.3076 
2023-07-31 14:15:32.026103: val_loss -0.2982 
2023-07-31 14:15:32.026184: Pseudo dice [0.7417] 
2023-07-31 14:15:32.026253: Epoch time: 69.12 s 
2023-07-31 14:15:33.105121:  
2023-07-31 14:15:33.105233: Epoch 234 
2023-07-31 14:15:33.105328: Current learning rate: 0.00079 
2023-07-31 14:16:41.232022: train_loss -0.3114 
2023-07-31 14:16:41.232186: val_loss -0.2781 
2023-07-31 14:16:41.232249: Pseudo dice [0.7149] 
2023-07-31 14:16:41.232306: Epoch time: 68.13 s 
2023-07-31 14:16:42.329196:  
2023-07-31 14:16:42.329306: Epoch 235 
2023-07-31 14:16:42.329386: Current learning rate: 0.00079 
2023-07-31 14:17:51.894495: train_loss -0.3417 
2023-07-31 14:17:51.894657: val_loss -0.3587 
2023-07-31 14:17:51.894720: Pseudo dice [0.7748] 
2023-07-31 14:17:51.894797: Epoch time: 69.57 s 
2023-07-31 14:17:52.978103:  
2023-07-31 14:17:52.978318: Epoch 236 
2023-07-31 14:17:52.978407: Current learning rate: 0.00078 
2023-07-31 14:18:55.977508: train_loss -0.3143 
2023-07-31 14:18:55.977688: val_loss -0.2718 
2023-07-31 14:18:55.977762: Pseudo dice [0.7398] 
2023-07-31 14:18:55.977838: Epoch time: 63.0 s 
2023-07-31 14:18:56.969285:  
2023-07-31 14:18:56.969523: Epoch 237 
2023-07-31 14:18:56.969685: Current learning rate: 0.00078 
2023-07-31 14:19:54.538508: train_loss -0.31 
2023-07-31 14:19:54.538686: val_loss -0.307 
2023-07-31 14:19:54.538749: Pseudo dice [0.6391] 
2023-07-31 14:19:54.538806: Epoch time: 57.57 s 
2023-07-31 14:19:55.583502:  
2023-07-31 14:19:55.583726: Epoch 238 
2023-07-31 14:19:55.583809: Current learning rate: 0.00078 
2023-07-31 14:20:54.421049: train_loss -0.2943 
2023-07-31 14:20:54.421216: val_loss -0.3145 
2023-07-31 14:20:54.421288: Pseudo dice [0.7772] 
2023-07-31 14:20:54.421343: Epoch time: 58.84 s 
2023-07-31 14:20:55.570962:  
2023-07-31 14:20:55.571151: Epoch 239 
2023-07-31 14:20:55.571239: Current learning rate: 0.00078 
2023-07-31 14:21:53.899687: train_loss -0.3131 
2023-07-31 14:21:53.899853: val_loss -0.3135 
2023-07-31 14:21:53.899921: Pseudo dice [0.7674] 
2023-07-31 14:21:53.899980: Epoch time: 58.33 s 
2023-07-31 14:21:54.978456:  
2023-07-31 14:21:54.978639: Epoch 240 
2023-07-31 14:21:54.978721: Current learning rate: 0.00078 
2023-07-31 14:22:55.450151: train_loss -0.2917 
2023-07-31 14:22:55.450308: val_loss -0.2826 
2023-07-31 14:22:55.450367: Pseudo dice [0.5867] 
2023-07-31 14:22:55.450422: Epoch time: 60.47 s 
2023-07-31 14:22:56.501221:  
2023-07-31 14:22:56.501346: Epoch 241 
2023-07-31 14:22:56.501426: Current learning rate: 0.00078 
2023-07-31 14:23:54.784580: train_loss -0.2895 
2023-07-31 14:23:54.784748: val_loss -0.3165 
2023-07-31 14:23:54.784808: Pseudo dice [0.7862] 
2023-07-31 14:23:54.784867: Epoch time: 58.28 s 
2023-07-31 14:23:55.812065:  
2023-07-31 14:23:55.812167: Epoch 242 
2023-07-31 14:23:55.812248: Current learning rate: 0.00078 
2023-07-31 14:24:53.918184: train_loss -0.3567 
2023-07-31 14:24:53.918341: val_loss -0.2982 
2023-07-31 14:24:53.918401: Pseudo dice [0.7385] 
2023-07-31 14:24:53.918456: Epoch time: 58.11 s 
2023-07-31 14:24:54.981797:  
2023-07-31 14:24:54.981927: Epoch 243 
2023-07-31 14:24:54.982026: Current learning rate: 0.00078 
2023-07-31 14:25:52.391542: train_loss -0.3309 
2023-07-31 14:25:52.391716: val_loss -0.3326 
2023-07-31 14:25:52.391782: Pseudo dice [0.6303] 
2023-07-31 14:25:52.391843: Epoch time: 57.41 s 
2023-07-31 14:25:53.419245:  
2023-07-31 14:25:53.419349: Epoch 244 
2023-07-31 14:25:53.419430: Current learning rate: 0.00078 
2023-07-31 14:26:51.993825: train_loss -0.3104 
2023-07-31 14:26:51.993987: val_loss -0.2619 
2023-07-31 14:26:51.994045: Pseudo dice [0.6523] 
2023-07-31 14:26:51.994099: Epoch time: 58.58 s 
2023-07-31 14:26:53.216954:  
2023-07-31 14:26:53.217078: Epoch 245 
2023-07-31 14:26:53.217174: Current learning rate: 0.00078 
2023-07-31 14:27:53.719841: train_loss -0.3337 
2023-07-31 14:27:53.720002: val_loss -0.2725 
2023-07-31 14:27:53.720066: Pseudo dice [0.639] 
2023-07-31 14:27:53.720126: Epoch time: 60.5 s 
2023-07-31 14:27:54.745042:  
2023-07-31 14:27:54.745259: Epoch 246 
2023-07-31 14:27:54.745354: Current learning rate: 0.00078 
2023-07-31 14:28:54.291849: train_loss -0.3063 
2023-07-31 14:28:54.292011: val_loss -0.3392 
2023-07-31 14:28:54.292072: Pseudo dice [0.8499] 
2023-07-31 14:28:54.292126: Epoch time: 59.55 s 
2023-07-31 14:28:55.332153:  
2023-07-31 14:28:55.332464: Epoch 247 
2023-07-31 14:28:55.332549: Current learning rate: 0.00077 
2023-07-31 14:29:53.401705: train_loss -0.3443 
2023-07-31 14:29:53.401871: val_loss -0.3312 
2023-07-31 14:29:53.401931: Pseudo dice [0.6815] 
2023-07-31 14:29:53.401985: Epoch time: 58.07 s 
2023-07-31 14:29:54.474470:  
2023-07-31 14:29:54.474591: Epoch 248 
2023-07-31 14:29:54.474674: Current learning rate: 0.00077 
2023-07-31 14:30:51.784192: train_loss -0.303 
2023-07-31 14:30:51.784356: val_loss -0.3216 
2023-07-31 14:30:51.784416: Pseudo dice [0.7663] 
2023-07-31 14:30:51.784472: Epoch time: 57.31 s 
2023-07-31 14:30:52.855630:  
2023-07-31 14:30:52.855871: Epoch 249 
2023-07-31 14:30:52.856082: Current learning rate: 0.00077 
2023-07-31 14:31:50.778254: train_loss -0.3374 
2023-07-31 14:31:50.778445: val_loss -0.3879 
2023-07-31 14:31:50.778510: Pseudo dice [0.7165] 
2023-07-31 14:31:50.778584: Epoch time: 57.92 s 
2023-07-31 14:31:52.175471:  
2023-07-31 14:31:52.175740: Epoch 250 
2023-07-31 14:31:52.175834: Current learning rate: 0.00077 
2023-07-31 14:32:51.980923: train_loss -0.311 
2023-07-31 14:32:51.981472: val_loss -0.3879 
2023-07-31 14:32:51.981560: Pseudo dice [0.7141] 
2023-07-31 14:32:51.981610: Epoch time: 59.81 s 
2023-07-31 14:32:53.174376:  
2023-07-31 14:32:53.174597: Epoch 251 
2023-07-31 14:32:53.174681: Current learning rate: 0.00077 
2023-07-31 14:33:52.097497: train_loss -0.3338 
2023-07-31 14:33:52.097666: val_loss -0.3251 
2023-07-31 14:33:52.097729: Pseudo dice [0.7306] 
2023-07-31 14:33:52.097784: Epoch time: 58.92 s 
2023-07-31 14:33:53.187443:  
2023-07-31 14:33:53.187562: Epoch 252 
2023-07-31 14:33:53.187644: Current learning rate: 0.00077 
2023-07-31 14:34:51.020505: train_loss -0.3065 
2023-07-31 14:34:51.020661: val_loss -0.39 
2023-07-31 14:34:51.020715: Pseudo dice [0.7938] 
2023-07-31 14:34:51.020771: Epoch time: 57.83 s 
2023-07-31 14:34:51.020834: Yayy! New best EMA pseudo Dice: 0.7239 
2023-07-31 14:34:52.385781:  
2023-07-31 14:34:52.385986: Epoch 253 
2023-07-31 14:34:52.386068: Current learning rate: 0.00077 
2023-07-31 14:35:49.563003: train_loss -0.3098 
2023-07-31 14:35:49.563164: val_loss -0.3555 
2023-07-31 14:35:49.563241: Pseudo dice [0.7601] 
2023-07-31 14:35:49.563296: Epoch time: 57.18 s 
2023-07-31 14:35:49.563340: Yayy! New best EMA pseudo Dice: 0.7276 
2023-07-31 14:35:50.987211:  
2023-07-31 14:35:50.987420: Epoch 254 
2023-07-31 14:35:50.987509: Current learning rate: 0.00077 
2023-07-31 14:36:47.644161: train_loss -0.3387 
2023-07-31 14:36:47.644337: val_loss -0.314 
2023-07-31 14:36:47.644403: Pseudo dice [0.7824] 
2023-07-31 14:36:47.644463: Epoch time: 56.66 s 
2023-07-31 14:36:47.644512: Yayy! New best EMA pseudo Dice: 0.733 
2023-07-31 14:36:49.021131:  
2023-07-31 14:36:49.021232: Epoch 255 
2023-07-31 14:36:49.021318: Current learning rate: 0.00077 
2023-07-31 14:37:46.450608: train_loss -0.3206 
2023-07-31 14:37:46.450800: val_loss -0.2968 
2023-07-31 14:37:46.450861: Pseudo dice [0.6198] 
2023-07-31 14:37:46.450915: Epoch time: 57.43 s 
2023-07-31 14:37:47.608816:  
2023-07-31 14:37:47.608928: Epoch 256 
2023-07-31 14:37:47.609009: Current learning rate: 0.00077 
2023-07-31 14:38:44.570545: train_loss -0.3415 
2023-07-31 14:38:44.570703: val_loss -0.2589 
2023-07-31 14:38:44.570763: Pseudo dice [0.7351] 
2023-07-31 14:38:44.570818: Epoch time: 56.96 s 
2023-07-31 14:38:45.650263:  
2023-07-31 14:38:45.650592: Epoch 257 
2023-07-31 14:38:45.650733: Current learning rate: 0.00077 
2023-07-31 14:39:43.233499: train_loss -0.3479 
2023-07-31 14:39:43.233664: val_loss -0.4043 
2023-07-31 14:39:43.233723: Pseudo dice [0.7989] 
2023-07-31 14:39:43.233778: Epoch time: 57.58 s 
2023-07-31 14:39:44.252053:  
2023-07-31 14:39:44.252167: Epoch 258 
2023-07-31 14:39:44.252246: Current learning rate: 0.00076 
2023-07-31 14:40:42.117294: train_loss -0.291 
2023-07-31 14:40:42.117464: val_loss -0.2738 
2023-07-31 14:40:42.117521: Pseudo dice [0.7102] 
2023-07-31 14:40:42.117575: Epoch time: 57.87 s 
2023-07-31 14:40:43.141880:  
2023-07-31 14:40:43.141991: Epoch 259 
2023-07-31 14:40:43.142087: Current learning rate: 0.00076 
2023-07-31 14:41:40.692957: train_loss -0.3523 
2023-07-31 14:41:40.693122: val_loss -0.3476 
2023-07-31 14:41:40.693185: Pseudo dice [0.6995] 
2023-07-31 14:41:40.693241: Epoch time: 57.55 s 
2023-07-31 14:41:41.705627:  
2023-07-31 14:41:41.705738: Epoch 260 
2023-07-31 14:41:41.705830: Current learning rate: 0.00076 
2023-07-31 14:42:39.678774: train_loss -0.3265 
2023-07-31 14:42:39.678947: val_loss -0.4087 
2023-07-31 14:42:39.679009: Pseudo dice [0.8409] 
2023-07-31 14:42:39.679064: Epoch time: 57.97 s 
2023-07-31 14:42:39.679108: Yayy! New best EMA pseudo Dice: 0.7372 
2023-07-31 14:42:41.087802:  
2023-07-31 14:42:41.087901: Epoch 261 
2023-07-31 14:42:41.087980: Current learning rate: 0.00076 
2023-07-31 14:43:36.879086: train_loss -0.2962 
2023-07-31 14:43:36.879248: val_loss -0.3712 
2023-07-31 14:43:36.879308: Pseudo dice [0.7969] 
2023-07-31 14:43:36.879363: Epoch time: 55.79 s 
2023-07-31 14:43:36.879410: Yayy! New best EMA pseudo Dice: 0.7432 
2023-07-31 14:43:38.419335:  
2023-07-31 14:43:38.419445: Epoch 262 
2023-07-31 14:43:38.419531: Current learning rate: 0.00076 
2023-07-31 14:44:34.366414: train_loss -0.2852 
2023-07-31 14:44:34.366579: val_loss -0.2491 
2023-07-31 14:44:34.366640: Pseudo dice [0.728] 
2023-07-31 14:44:34.366694: Epoch time: 55.95 s 
2023-07-31 14:44:35.376961:  
2023-07-31 14:44:35.377172: Epoch 263 
2023-07-31 14:44:35.377258: Current learning rate: 0.00076 
2023-07-31 14:45:32.436374: train_loss -0.3185 
2023-07-31 14:45:32.436533: val_loss -0.2934 
2023-07-31 14:45:32.436593: Pseudo dice [0.7525] 
2023-07-31 14:45:32.436647: Epoch time: 57.06 s 
2023-07-31 14:45:33.466806:  
2023-07-31 14:45:33.466970: Epoch 264 
2023-07-31 14:45:33.467132: Current learning rate: 0.00076 
2023-07-31 14:46:30.283051: train_loss -0.2843 
2023-07-31 14:46:30.283242: val_loss -0.3892 
2023-07-31 14:46:30.283302: Pseudo dice [0.7291] 
2023-07-31 14:46:30.283356: Epoch time: 56.82 s 
2023-07-31 14:46:31.328696:  
2023-07-31 14:46:31.328811: Epoch 265 
2023-07-31 14:46:31.328889: Current learning rate: 0.00076 
2023-07-31 14:47:28.736948: train_loss -0.3055 
2023-07-31 14:47:28.737110: val_loss -0.2403 
2023-07-31 14:47:28.737169: Pseudo dice [0.6607] 
2023-07-31 14:47:28.737225: Epoch time: 57.41 s 
2023-07-31 14:47:29.789032:  
2023-07-31 14:47:29.789137: Epoch 266 
2023-07-31 14:47:29.789217: Current learning rate: 0.00076 
2023-07-31 14:48:28.637840: train_loss -0.3036 
2023-07-31 14:48:28.638006: val_loss -0.3098 
2023-07-31 14:48:28.638089: Pseudo dice [0.7236] 
2023-07-31 14:48:28.638149: Epoch time: 58.85 s 
2023-07-31 14:48:29.803703:  
2023-07-31 14:48:29.803883: Epoch 267 
2023-07-31 14:48:29.803965: Current learning rate: 0.00076 
2023-07-31 14:49:27.376699: train_loss -0.3473 
2023-07-31 14:49:27.376871: val_loss -0.3687 
2023-07-31 14:49:27.376934: Pseudo dice [0.7796] 
2023-07-31 14:49:27.376989: Epoch time: 57.57 s 
2023-07-31 14:49:28.405361:  
2023-07-31 14:49:28.405722: Epoch 268 
2023-07-31 14:49:28.405803: Current learning rate: 0.00076 
2023-07-31 14:50:26.818909: train_loss -0.3168 
2023-07-31 14:50:26.819519: val_loss -0.3194 
2023-07-31 14:50:26.819605: Pseudo dice [0.7434] 
2023-07-31 14:50:26.819659: Epoch time: 58.41 s 
2023-07-31 14:50:27.841961:  
2023-07-31 14:50:27.842068: Epoch 269 
2023-07-31 14:50:27.842176: Current learning rate: 0.00075 
2023-07-31 14:51:28.149859: train_loss -0.3209 
2023-07-31 14:51:28.150027: val_loss -0.3532 
2023-07-31 14:51:28.150086: Pseudo dice [0.7294] 
2023-07-31 14:51:28.150141: Epoch time: 60.31 s 
2023-07-31 14:51:29.194502:  
2023-07-31 14:51:29.194623: Epoch 270 
2023-07-31 14:51:29.194701: Current learning rate: 0.00075 
2023-07-31 14:52:26.285060: train_loss -0.3411 
2023-07-31 14:52:26.285227: val_loss -0.3102 
2023-07-31 14:52:26.285288: Pseudo dice [0.6263] 
2023-07-31 14:52:26.285343: Epoch time: 57.09 s 
2023-07-31 14:52:27.336012:  
2023-07-31 14:52:27.336122: Epoch 271 
2023-07-31 14:52:27.336207: Current learning rate: 0.00075 
2023-07-31 14:53:27.329076: train_loss -0.3063 
2023-07-31 14:53:27.329239: val_loss -0.3342 
2023-07-31 14:53:27.329315: Pseudo dice [0.6873] 
2023-07-31 14:53:27.329376: Epoch time: 59.99 s 
2023-07-31 14:53:28.346578:  
2023-07-31 14:53:28.346683: Epoch 272 
2023-07-31 14:53:28.346761: Current learning rate: 0.00075 
2023-07-31 14:54:26.297446: train_loss -0.3154 
2023-07-31 14:54:26.297709: val_loss -0.3207 
2023-07-31 14:54:26.297768: Pseudo dice [0.6856] 
2023-07-31 14:54:26.297825: Epoch time: 57.95 s 
2023-07-31 14:54:27.479408:  
2023-07-31 14:54:27.479778: Epoch 273 
2023-07-31 14:54:27.480005: Current learning rate: 0.00075 
2023-07-31 14:55:27.325859: train_loss -0.3537 
2023-07-31 14:55:27.326445: val_loss -0.3885 
2023-07-31 14:55:27.326544: Pseudo dice [0.8049] 
2023-07-31 14:55:27.326596: Epoch time: 59.85 s 
2023-07-31 14:55:28.350173:  
2023-07-31 14:55:28.350281: Epoch 274 
2023-07-31 14:55:28.350375: Current learning rate: 0.00075 
2023-07-31 14:56:27.430416: train_loss -0.3305 
2023-07-31 14:56:27.430586: val_loss -0.4083 
2023-07-31 14:56:27.430643: Pseudo dice [0.7716] 
2023-07-31 14:56:27.430696: Epoch time: 59.08 s 
2023-07-31 14:56:28.440694:  
2023-07-31 14:56:28.440818: Epoch 275 
2023-07-31 14:56:28.440945: Current learning rate: 0.00075 
2023-07-31 14:57:25.767214: train_loss -0.3482 
2023-07-31 14:57:25.767367: val_loss -0.3168 
2023-07-31 14:57:25.767423: Pseudo dice [0.6818] 
2023-07-31 14:57:25.767478: Epoch time: 57.33 s 
2023-07-31 14:57:26.829489:  
2023-07-31 14:57:26.829707: Epoch 276 
2023-07-31 14:57:26.829793: Current learning rate: 0.00075 
2023-07-31 14:58:26.825544: train_loss -0.3146 
2023-07-31 14:58:26.825697: val_loss -0.2083 
2023-07-31 14:58:26.825758: Pseudo dice [0.6252] 
2023-07-31 14:58:26.825810: Epoch time: 60.0 s 
2023-07-31 14:58:27.841677:  
2023-07-31 14:58:27.841780: Epoch 277 
2023-07-31 14:58:27.841887: Current learning rate: 0.00075 
2023-07-31 14:59:25.298950: train_loss -0.3232 
2023-07-31 14:59:25.299113: val_loss -0.389 
2023-07-31 14:59:25.299173: Pseudo dice [0.747] 
2023-07-31 14:59:25.299227: Epoch time: 57.46 s 
2023-07-31 14:59:26.369773:  
2023-07-31 14:59:26.369876: Epoch 278 
2023-07-31 14:59:26.369998: Current learning rate: 0.00075 
2023-07-31 15:00:24.273249: train_loss -0.371 
2023-07-31 15:00:24.273408: val_loss -0.3001 
2023-07-31 15:00:24.273466: Pseudo dice [0.7523] 
2023-07-31 15:00:24.273520: Epoch time: 57.9 s 
2023-07-31 15:00:25.490718:  
2023-07-31 15:00:25.490823: Epoch 279 
2023-07-31 15:00:25.490935: Current learning rate: 0.00074 
2023-07-31 15:01:23.613829: train_loss -0.3018 
2023-07-31 15:01:23.613989: val_loss -0.3535 
2023-07-31 15:01:23.614053: Pseudo dice [0.7686] 
2023-07-31 15:01:23.614107: Epoch time: 58.12 s 
2023-07-31 15:01:24.658808:  
2023-07-31 15:01:24.658910: Epoch 280 
2023-07-31 15:01:24.659011: Current learning rate: 0.00074 
2023-07-31 15:02:23.759797: train_loss -0.3553 
2023-07-31 15:02:23.759972: val_loss -0.361 
2023-07-31 15:02:23.760031: Pseudo dice [0.7455] 
2023-07-31 15:02:23.760085: Epoch time: 59.1 s 
2023-07-31 15:02:24.799674:  
2023-07-31 15:02:24.799777: Epoch 281 
2023-07-31 15:02:24.799856: Current learning rate: 0.00074 
2023-07-31 15:03:32.868706: train_loss -0.2931 
2023-07-31 15:03:32.868858: val_loss -0.2253 
2023-07-31 15:03:32.868916: Pseudo dice [0.4743] 
2023-07-31 15:03:32.868971: Epoch time: 68.07 s 
2023-07-31 15:03:33.987183:  
2023-07-31 15:03:33.987427: Epoch 282 
2023-07-31 15:03:33.987537: Current learning rate: 0.00074 
2023-07-31 15:04:48.079739: train_loss -0.3563 
2023-07-31 15:04:48.079897: val_loss -0.4005 
2023-07-31 15:04:48.079957: Pseudo dice [0.7415] 
2023-07-31 15:04:48.080011: Epoch time: 74.09 s 
2023-07-31 15:04:49.146256:  
2023-07-31 15:04:49.146372: Epoch 283 
2023-07-31 15:04:49.146451: Current learning rate: 0.00074 
2023-07-31 15:06:02.596165: train_loss -0.2938 
2023-07-31 15:06:02.596321: val_loss -0.3541 
2023-07-31 15:06:02.596380: Pseudo dice [0.7858] 
2023-07-31 15:06:02.596455: Epoch time: 73.45 s 
2023-07-31 15:06:03.627390:  
2023-07-31 15:06:03.627499: Epoch 284 
2023-07-31 15:06:03.627580: Current learning rate: 0.00074 
2023-07-31 15:07:10.113321: train_loss -0.3142 
2023-07-31 15:07:10.113502: val_loss -0.3132 
2023-07-31 15:07:10.113567: Pseudo dice [0.7601] 
2023-07-31 15:07:10.113627: Epoch time: 66.49 s 
2023-07-31 15:07:11.500438:  
2023-07-31 15:07:11.500547: Epoch 285 
2023-07-31 15:07:11.500633: Current learning rate: 0.00074 
2023-07-31 15:08:20.887826: train_loss -0.2936 
2023-07-31 15:08:20.887993: val_loss -0.2548 
2023-07-31 15:08:20.888053: Pseudo dice [0.5899] 
2023-07-31 15:08:20.888111: Epoch time: 69.39 s 
2023-07-31 15:08:21.941313:  
2023-07-31 15:08:21.941687: Epoch 286 
2023-07-31 15:08:21.941775: Current learning rate: 0.00074 
2023-07-31 15:09:33.964186: train_loss -0.3175 
2023-07-31 15:09:33.964349: val_loss -0.3759 
2023-07-31 15:09:33.964407: Pseudo dice [0.6749] 
2023-07-31 15:09:33.964463: Epoch time: 72.02 s 
2023-07-31 15:09:35.053175:  
2023-07-31 15:09:35.053538: Epoch 287 
2023-07-31 15:09:35.053632: Current learning rate: 0.00074 
2023-07-31 15:10:47.007665: train_loss -0.3158 
2023-07-31 15:10:47.007853: val_loss -0.3777 
2023-07-31 15:10:47.007944: Pseudo dice [0.7269] 
2023-07-31 15:10:47.008021: Epoch time: 71.96 s 
2023-07-31 15:10:48.188525:  
2023-07-31 15:10:48.188638: Epoch 288 
2023-07-31 15:10:48.188721: Current learning rate: 0.00074 
2023-07-31 15:12:03.247386: train_loss -0.3419 
2023-07-31 15:12:03.247633: val_loss -0.3426 
2023-07-31 15:12:03.247842: Pseudo dice [0.8093] 
2023-07-31 15:12:03.248017: Epoch time: 75.06 s 
2023-07-31 15:12:04.370593:  
2023-07-31 15:12:04.370701: Epoch 289 
2023-07-31 15:12:04.370788: Current learning rate: 0.00074 
2023-07-31 15:13:18.274167: train_loss -0.3079 
2023-07-31 15:13:18.274328: val_loss -0.3144 
2023-07-31 15:13:18.274386: Pseudo dice [0.7352] 
2023-07-31 15:13:18.274439: Epoch time: 73.9 s 
2023-07-31 15:13:19.351927:  
2023-07-31 15:13:19.352047: Epoch 290 
2023-07-31 15:13:19.352131: Current learning rate: 0.00073 
2023-07-31 15:14:34.413810: train_loss -0.3681 
2023-07-31 15:14:34.414008: val_loss -0.2722 
2023-07-31 15:14:34.414068: Pseudo dice [0.6957] 
2023-07-31 15:14:34.414124: Epoch time: 75.06 s 
2023-07-31 15:14:35.759095:  
2023-07-31 15:14:35.759212: Epoch 291 
2023-07-31 15:14:35.759307: Current learning rate: 0.00073 
2023-07-31 15:15:46.017840: train_loss -0.3715 
2023-07-31 15:15:46.018060: val_loss -0.2821 
2023-07-31 15:15:46.018128: Pseudo dice [0.7608] 
2023-07-31 15:15:46.018211: Epoch time: 70.26 s 
2023-07-31 15:15:47.315224:  
2023-07-31 15:15:47.315335: Epoch 292 
2023-07-31 15:15:47.315429: Current learning rate: 0.00073 
2023-07-31 15:17:00.948209: train_loss -0.3626 
2023-07-31 15:17:00.948367: val_loss -0.3345 
2023-07-31 15:17:00.948427: Pseudo dice [0.7851] 
2023-07-31 15:17:00.948480: Epoch time: 73.63 s 
2023-07-31 15:17:02.035406:  
2023-07-31 15:17:02.035531: Epoch 293 
2023-07-31 15:17:02.035616: Current learning rate: 0.00073 
2023-07-31 15:18:11.462611: train_loss -0.3057 
2023-07-31 15:18:11.462771: val_loss -0.2722 
2023-07-31 15:18:11.462830: Pseudo dice [0.692] 
2023-07-31 15:18:11.462886: Epoch time: 69.43 s 
2023-07-31 15:18:12.501204:  
2023-07-31 15:18:12.501414: Epoch 294 
2023-07-31 15:18:12.501495: Current learning rate: 0.00073 
2023-07-31 15:19:21.924660: train_loss -0.3425 
2023-07-31 15:19:21.924894: val_loss -0.3796 
2023-07-31 15:19:21.924965: Pseudo dice [0.7738] 
2023-07-31 15:19:21.925028: Epoch time: 69.42 s 
2023-07-31 15:19:23.070779:  
2023-07-31 15:19:23.070887: Epoch 295 
2023-07-31 15:19:23.070982: Current learning rate: 0.00073 
2023-07-31 15:20:36.493638: train_loss -0.3084 
2023-07-31 15:20:36.493793: val_loss -0.3783 
2023-07-31 15:20:36.493850: Pseudo dice [0.7742] 
2023-07-31 15:20:36.493904: Epoch time: 73.42 s 
2023-07-31 15:20:37.807307:  
2023-07-31 15:20:37.807719: Epoch 296 
2023-07-31 15:20:37.807810: Current learning rate: 0.00073 
2023-07-31 15:21:48.097332: train_loss -0.3517 
2023-07-31 15:21:48.097492: val_loss -0.2749 
2023-07-31 15:21:48.097553: Pseudo dice [0.6398] 
2023-07-31 15:21:48.097607: Epoch time: 70.29 s 
2023-07-31 15:21:49.145808:  
2023-07-31 15:21:49.145922: Epoch 297 
2023-07-31 15:21:49.146007: Current learning rate: 0.00073 
2023-07-31 15:23:03.491877: train_loss -0.309 
2023-07-31 15:23:03.492040: val_loss -0.3805 
2023-07-31 15:23:03.492102: Pseudo dice [0.7494] 
2023-07-31 15:23:03.492162: Epoch time: 74.35 s 
2023-07-31 15:23:04.641645:  
2023-07-31 15:23:04.641782: Epoch 298 
2023-07-31 15:23:04.641877: Current learning rate: 0.00073 
2023-07-31 15:24:19.505452: train_loss -0.2983 
2023-07-31 15:24:19.505625: val_loss -0.3544 
2023-07-31 15:24:19.505687: Pseudo dice [0.7938] 
2023-07-31 15:24:19.505744: Epoch time: 74.86 s 
2023-07-31 15:24:20.619394:  
2023-07-31 15:24:20.619743: Epoch 299 
2023-07-31 15:24:20.619883: Current learning rate: 0.00073 
2023-07-31 15:25:34.236869: train_loss -0.306 
2023-07-31 15:25:34.237024: val_loss -0.3498 
2023-07-31 15:25:34.237084: Pseudo dice [0.7524] 
2023-07-31 15:25:34.237151: Epoch time: 73.62 s 
2023-07-31 15:25:35.702013:  
2023-07-31 15:25:35.702129: Epoch 300 
2023-07-31 15:25:35.702213: Current learning rate: 0.00073 
2023-07-31 15:26:53.132102: train_loss -0.3302 
2023-07-31 15:26:53.132262: val_loss -0.3652 
2023-07-31 15:26:53.132326: Pseudo dice [0.7736] 
2023-07-31 15:26:53.132381: Epoch time: 77.43 s 
2023-07-31 15:26:54.233004:  
2023-07-31 15:26:54.233132: Epoch 301 
2023-07-31 15:26:54.233223: Current learning rate: 0.00072 
2023-07-31 15:27:57.853642: train_loss -0.3339 
2023-07-31 15:27:57.853814: val_loss -0.3909 
2023-07-31 15:27:57.853873: Pseudo dice [0.8452] 
2023-07-31 15:27:57.853933: Epoch time: 63.62 s 
2023-07-31 15:27:57.853984: Yayy! New best EMA pseudo Dice: 0.7494 
2023-07-31 15:27:59.471622:  
2023-07-31 15:27:59.471736: Epoch 302 
2023-07-31 15:27:59.471836: Current learning rate: 0.00072 
2023-07-31 15:29:05.803590: train_loss -0.3042 
2023-07-31 15:29:05.803756: val_loss -0.378 
2023-07-31 15:29:05.803815: Pseudo dice [0.7804] 
2023-07-31 15:29:05.803890: Epoch time: 66.33 s 
2023-07-31 15:29:05.803938: Yayy! New best EMA pseudo Dice: 0.7525 
2023-07-31 15:29:07.424849:  
2023-07-31 15:29:07.425098: Epoch 303 
2023-07-31 15:29:07.425194: Current learning rate: 0.00072 
2023-07-31 15:30:16.523645: train_loss -0.3336 
2023-07-31 15:30:16.523820: val_loss -0.3158 
2023-07-31 15:30:16.523884: Pseudo dice [0.818] 
2023-07-31 15:30:16.523945: Epoch time: 69.1 s 
2023-07-31 15:30:16.523994: Yayy! New best EMA pseudo Dice: 0.7591 
2023-07-31 15:30:18.013089:  
2023-07-31 15:30:18.013220: Epoch 304 
2023-07-31 15:30:18.013299: Current learning rate: 0.00072 
2023-07-31 15:31:28.440118: train_loss -0.3439 
2023-07-31 15:31:28.440284: val_loss -0.29 
2023-07-31 15:31:28.440346: Pseudo dice [0.6866] 
2023-07-31 15:31:28.440408: Epoch time: 70.43 s 
2023-07-31 15:31:29.539847:  
2023-07-31 15:31:29.540066: Epoch 305 
2023-07-31 15:31:29.540159: Current learning rate: 0.00072 
2023-07-31 15:32:40.029952: train_loss -0.3577 
2023-07-31 15:32:40.030120: val_loss -0.3426 
2023-07-31 15:32:40.030179: Pseudo dice [0.7892] 
2023-07-31 15:32:40.030232: Epoch time: 70.49 s 
2023-07-31 15:32:41.324383:  
2023-07-31 15:32:41.324530: Epoch 306 
2023-07-31 15:32:41.324625: Current learning rate: 0.00072 
2023-07-31 15:33:51.733053: train_loss -0.3354 
2023-07-31 15:33:51.733220: val_loss -0.3458 
2023-07-31 15:33:51.733299: Pseudo dice [0.7756] 
2023-07-31 15:33:51.733357: Epoch time: 70.41 s 
2023-07-31 15:33:52.900408:  
2023-07-31 15:33:52.900678: Epoch 307 
2023-07-31 15:33:52.900777: Current learning rate: 0.00072 
2023-07-31 15:35:03.592938: train_loss -0.3175 
2023-07-31 15:35:03.593103: val_loss -0.3078 
2023-07-31 15:35:03.593166: Pseudo dice [0.7619] 
2023-07-31 15:35:03.593230: Epoch time: 70.69 s 
2023-07-31 15:35:04.737775:  
2023-07-31 15:35:04.737887: Epoch 308 
2023-07-31 15:35:04.737972: Current learning rate: 0.00072 
2023-07-31 15:36:16.894657: train_loss -0.3273 
2023-07-31 15:36:16.894836: val_loss -0.4043 
2023-07-31 15:36:16.894894: Pseudo dice [0.7933] 
2023-07-31 15:36:16.894949: Epoch time: 72.16 s 
2023-07-31 15:36:16.894995: Yayy! New best EMA pseudo Dice: 0.7615 
2023-07-31 15:36:18.408533:  
2023-07-31 15:36:18.408653: Epoch 309 
2023-07-31 15:36:18.408741: Current learning rate: 0.00072 
2023-07-31 15:37:29.561029: train_loss -0.34 
2023-07-31 15:37:29.561216: val_loss -0.3439 
2023-07-31 15:37:29.561299: Pseudo dice [0.7542] 
2023-07-31 15:37:29.561360: Epoch time: 71.15 s 
2023-07-31 15:37:30.693237:  
2023-07-31 15:37:30.693350: Epoch 310 
2023-07-31 15:37:30.693450: Current learning rate: 0.00072 
2023-07-31 15:38:43.193887: train_loss -0.3185 
2023-07-31 15:38:43.194088: val_loss -0.3229 
2023-07-31 15:38:43.194151: Pseudo dice [0.7539] 
2023-07-31 15:38:43.194215: Epoch time: 72.5 s 
2023-07-31 15:38:44.336310:  
2023-07-31 15:38:44.336488: Epoch 311 
2023-07-31 15:38:44.336642: Current learning rate: 0.00072 
2023-07-31 15:39:50.358943: train_loss -0.3311 
2023-07-31 15:39:50.359108: val_loss -0.2782 
2023-07-31 15:39:50.359166: Pseudo dice [0.7344] 
2023-07-31 15:39:50.359221: Epoch time: 66.02 s 
2023-07-31 15:39:51.595647:  
2023-07-31 15:39:51.595997: Epoch 312 
2023-07-31 15:39:51.596083: Current learning rate: 0.00071 
2023-07-31 15:40:48.734837: train_loss -0.3279 
2023-07-31 15:40:48.734993: val_loss -0.2421 
2023-07-31 15:40:48.735049: Pseudo dice [0.7067] 
2023-07-31 15:40:48.735102: Epoch time: 57.14 s 
2023-07-31 15:40:49.789537:  
2023-07-31 15:40:49.789649: Epoch 313 
2023-07-31 15:40:49.789726: Current learning rate: 0.00071 
2023-07-31 15:41:47.444454: train_loss -0.334 
2023-07-31 15:41:47.444615: val_loss -0.2738 
2023-07-31 15:41:47.444673: Pseudo dice [0.7066] 
2023-07-31 15:41:47.444747: Epoch time: 57.66 s 
2023-07-31 15:41:48.522276:  
2023-07-31 15:41:48.522385: Epoch 314 
2023-07-31 15:41:48.522462: Current learning rate: 0.00071 
2023-07-31 15:42:45.385421: train_loss -0.3308 
2023-07-31 15:42:45.385593: val_loss -0.2989 
2023-07-31 15:42:45.385653: Pseudo dice [0.7216] 
2023-07-31 15:42:45.385709: Epoch time: 56.86 s 
2023-07-31 15:42:46.441009:  
2023-07-31 15:42:46.441215: Epoch 315 
2023-07-31 15:42:46.441311: Current learning rate: 0.00071 
2023-07-31 15:43:43.082602: train_loss -0.3189 
2023-07-31 15:43:43.082768: val_loss -0.2527 
2023-07-31 15:43:43.082846: Pseudo dice [0.6849] 
2023-07-31 15:43:43.082914: Epoch time: 56.64 s 
2023-07-31 15:43:44.217814:  
2023-07-31 15:43:44.217926: Epoch 316 
2023-07-31 15:43:44.218005: Current learning rate: 0.00071 
2023-07-31 15:44:43.123492: train_loss -0.3462 
2023-07-31 15:44:43.123661: val_loss -0.339 
2023-07-31 15:44:43.123729: Pseudo dice [0.7764] 
2023-07-31 15:44:43.123809: Epoch time: 58.91 s 
2023-07-31 15:44:44.230757:  
2023-07-31 15:44:44.230864: Epoch 317 
2023-07-31 15:44:44.230946: Current learning rate: 0.00071 
2023-07-31 15:45:44.128869: train_loss -0.3017 
2023-07-31 15:45:44.129044: val_loss -0.3784 
2023-07-31 15:45:44.129107: Pseudo dice [0.7717] 
2023-07-31 15:45:44.129163: Epoch time: 59.9 s 
2023-07-31 15:45:45.394675:  
2023-07-31 15:45:45.394786: Epoch 318 
2023-07-31 15:45:45.394879: Current learning rate: 0.00071 
2023-07-31 15:46:43.563963: train_loss -0.3474 
2023-07-31 15:46:43.564131: val_loss -0.2911 
2023-07-31 15:46:43.572464: Pseudo dice [0.7374] 
2023-07-31 15:46:43.572566: Epoch time: 58.17 s 
2023-07-31 15:46:44.707399:  
2023-07-31 15:46:44.707546: Epoch 319 
2023-07-31 15:46:44.707644: Current learning rate: 0.00071 
2023-07-31 15:47:46.570967: train_loss -0.3357 
2023-07-31 15:47:46.571236: val_loss -0.3756 
2023-07-31 15:47:46.571297: Pseudo dice [0.8399] 
2023-07-31 15:47:46.571356: Epoch time: 61.86 s 
2023-07-31 15:47:47.613412:  
2023-07-31 15:47:47.613637: Epoch 320 
2023-07-31 15:47:47.613721: Current learning rate: 0.00071 
2023-07-31 15:48:47.216851: train_loss -0.3392 
2023-07-31 15:48:47.217083: val_loss -0.3699 
2023-07-31 15:48:47.217182: Pseudo dice [0.799] 
2023-07-31 15:48:47.217280: Epoch time: 59.6 s 
2023-07-31 15:48:48.263780:  
2023-07-31 15:48:48.263954: Epoch 321 
2023-07-31 15:48:48.264033: Current learning rate: 0.00071 
2023-07-31 15:49:47.888955: train_loss -0.3628 
2023-07-31 15:49:47.889117: val_loss -0.3553 
2023-07-31 15:49:47.889174: Pseudo dice [0.744] 
2023-07-31 15:49:47.889228: Epoch time: 59.63 s 
2023-07-31 15:49:48.959100:  
2023-07-31 15:49:48.959215: Epoch 322 
2023-07-31 15:49:48.959306: Current learning rate: 0.0007 
2023-07-31 15:50:47.570689: train_loss -0.3347 
2023-07-31 15:50:47.570852: val_loss -0.2777 
2023-07-31 15:50:47.570912: Pseudo dice [0.7722] 
2023-07-31 15:50:47.570967: Epoch time: 58.61 s 
2023-07-31 15:50:48.786559:  
2023-07-31 15:50:48.786668: Epoch 323 
2023-07-31 15:50:48.786761: Current learning rate: 0.0007 
2023-07-31 15:51:49.419198: train_loss -0.3315 
2023-07-31 15:51:49.419479: val_loss -0.4512 
2023-07-31 15:51:49.419621: Pseudo dice [0.7576] 
2023-07-31 15:51:49.419687: Epoch time: 60.63 s 
2023-07-31 15:51:50.501637:  
2023-07-31 15:51:50.501832: Epoch 324 
2023-07-31 15:51:50.501963: Current learning rate: 0.0007 
2023-07-31 15:52:49.049475: train_loss -0.3203 
2023-07-31 15:52:49.049625: val_loss -0.408 
2023-07-31 15:52:49.049685: Pseudo dice [0.8124] 
2023-07-31 15:52:49.049737: Epoch time: 58.55 s 
2023-07-31 15:52:49.049782: Yayy! New best EMA pseudo Dice: 0.7641 
2023-07-31 15:52:50.533087:  
2023-07-31 15:52:50.533215: Epoch 325 
2023-07-31 15:52:50.533404: Current learning rate: 0.0007 
2023-07-31 15:53:49.220644: train_loss -0.3188 
2023-07-31 15:53:49.220806: val_loss -0.2685 
2023-07-31 15:53:49.220864: Pseudo dice [0.6516] 
2023-07-31 15:53:49.220919: Epoch time: 58.69 s 
2023-07-31 15:53:50.263160:  
2023-07-31 15:53:50.263386: Epoch 326 
2023-07-31 15:53:50.263473: Current learning rate: 0.0007 
2023-07-31 15:54:49.100740: train_loss -0.3406 
2023-07-31 15:54:49.100913: val_loss -0.31 
2023-07-31 15:54:49.100973: Pseudo dice [0.7155] 
2023-07-31 15:54:49.101027: Epoch time: 58.84 s 
2023-07-31 15:54:50.190083:  
2023-07-31 15:54:50.190311: Epoch 327 
2023-07-31 15:54:50.190394: Current learning rate: 0.0007 
2023-07-31 15:55:47.966763: train_loss -0.3301 
2023-07-31 15:55:47.966934: val_loss -0.332 
2023-07-31 15:55:47.966993: Pseudo dice [0.7807] 
2023-07-31 15:55:47.967048: Epoch time: 57.78 s 
2023-07-31 15:55:49.206502:  
2023-07-31 15:55:49.206701: Epoch 328 
2023-07-31 15:55:49.206791: Current learning rate: 0.0007 
2023-07-31 15:56:48.007569: train_loss -0.343 
2023-07-31 15:56:48.007737: val_loss -0.2725 
2023-07-31 15:56:48.007801: Pseudo dice [0.8014] 
2023-07-31 15:56:48.007862: Epoch time: 58.8 s 
2023-07-31 15:56:49.064443:  
2023-07-31 15:56:49.064617: Epoch 329 
2023-07-31 15:56:49.064700: Current learning rate: 0.0007 
2023-07-31 15:57:47.881634: train_loss -0.3273 
2023-07-31 15:57:47.881793: val_loss -0.2549 
2023-07-31 15:57:47.881853: Pseudo dice [0.6764] 
2023-07-31 15:57:47.881907: Epoch time: 58.82 s 
2023-07-31 15:57:48.921593:  
2023-07-31 15:57:48.921695: Epoch 330 
2023-07-31 15:57:48.921794: Current learning rate: 0.0007 
2023-07-31 15:58:47.899328: train_loss -0.3366 
2023-07-31 15:58:47.899547: val_loss -0.3498 
2023-07-31 15:58:47.899620: Pseudo dice [0.7659] 
2023-07-31 15:58:47.899683: Epoch time: 58.98 s 
2023-07-31 15:58:49.118163:  
2023-07-31 15:58:49.118282: Epoch 331 
2023-07-31 15:58:49.118365: Current learning rate: 0.0007 
2023-07-31 15:59:49.249418: train_loss -0.3311 
2023-07-31 15:59:49.249577: val_loss -0.3675 
2023-07-31 15:59:49.249635: Pseudo dice [0.7167] 
2023-07-31 15:59:49.249689: Epoch time: 60.13 s 
2023-07-31 15:59:50.309464:  
2023-07-31 15:59:50.309649: Epoch 332 
2023-07-31 15:59:50.309732: Current learning rate: 0.0007 
2023-07-31 16:00:49.067428: train_loss -0.3665 
2023-07-31 16:00:49.067611: val_loss -0.3121 
2023-07-31 16:00:49.067673: Pseudo dice [0.6725] 
2023-07-31 16:00:49.067729: Epoch time: 58.76 s 
2023-07-31 16:00:50.144765:  
2023-07-31 16:00:50.144889: Epoch 333 
2023-07-31 16:00:50.144966: Current learning rate: 0.00069 
2023-07-31 16:01:47.562749: train_loss -0.3174 
2023-07-31 16:01:47.562905: val_loss -0.3041 
2023-07-31 16:01:47.562963: Pseudo dice [0.8244] 
2023-07-31 16:01:47.563018: Epoch time: 57.42 s 
2023-07-31 16:01:48.756633:  
2023-07-31 16:01:48.756770: Epoch 334 
2023-07-31 16:01:48.756866: Current learning rate: 0.00069 
2023-07-31 16:02:46.886590: train_loss -0.3517 
2023-07-31 16:02:46.886763: val_loss -0.3256 
2023-07-31 16:02:46.886824: Pseudo dice [0.7152] 
2023-07-31 16:02:46.886879: Epoch time: 58.13 s 
2023-07-31 16:02:47.944772:  
2023-07-31 16:02:47.944878: Epoch 335 
2023-07-31 16:02:47.944957: Current learning rate: 0.00069 
2023-07-31 16:03:49.211452: train_loss -0.3526 
2023-07-31 16:03:49.211612: val_loss -0.2795 
2023-07-31 16:03:49.211674: Pseudo dice [0.7109] 
2023-07-31 16:03:49.211728: Epoch time: 61.27 s 
2023-07-31 16:03:50.286984:  
2023-07-31 16:03:50.287087: Epoch 336 
2023-07-31 16:03:50.287183: Current learning rate: 0.00069 
2023-07-31 16:04:50.035338: train_loss -0.3045 
2023-07-31 16:04:50.035542: val_loss -0.3871 
2023-07-31 16:04:50.035621: Pseudo dice [0.8369] 
2023-07-31 16:04:50.035683: Epoch time: 59.75 s 
2023-07-31 16:04:51.094324:  
2023-07-31 16:04:51.094618: Epoch 337 
2023-07-31 16:04:51.094795: Current learning rate: 0.00069 
2023-07-31 16:05:49.249617: train_loss -0.3281 
2023-07-31 16:05:49.249775: val_loss -0.362 
2023-07-31 16:05:49.249935: Pseudo dice [0.7725] 
2023-07-31 16:05:49.250001: Epoch time: 58.16 s 
2023-07-31 16:05:50.334333:  
2023-07-31 16:05:50.334440: Epoch 338 
2023-07-31 16:05:50.334542: Current learning rate: 0.00069 
2023-07-31 16:06:47.257571: train_loss -0.332 
2023-07-31 16:06:47.257751: val_loss -0.3164 
2023-07-31 16:06:47.257814: Pseudo dice [0.7394] 
2023-07-31 16:06:47.257871: Epoch time: 56.92 s 
2023-07-31 16:06:48.335676:  
2023-07-31 16:06:48.335856: Epoch 339 
2023-07-31 16:06:48.335939: Current learning rate: 0.00069 
2023-07-31 16:07:45.628198: train_loss -0.3492 
2023-07-31 16:07:45.628426: val_loss -0.3601 
2023-07-31 16:07:45.628487: Pseudo dice [0.8465] 
2023-07-31 16:07:45.628541: Epoch time: 57.29 s 
2023-07-31 16:07:46.915294:  
2023-07-31 16:07:46.915514: Epoch 340 
2023-07-31 16:07:46.915632: Current learning rate: 0.00069 
2023-07-31 16:08:44.947795: train_loss -0.3393 
2023-07-31 16:08:44.947981: val_loss -0.3127 
2023-07-31 16:08:44.948044: Pseudo dice [0.7243] 
2023-07-31 16:08:44.948100: Epoch time: 58.03 s 
2023-07-31 16:08:46.005720:  
2023-07-31 16:08:46.005927: Epoch 341 
2023-07-31 16:08:46.006006: Current learning rate: 0.00069 
2023-07-31 16:09:43.593477: train_loss -0.3289 
2023-07-31 16:09:43.593656: val_loss -0.2444 
2023-07-31 16:09:43.593715: Pseudo dice [0.7731] 
2023-07-31 16:09:43.593771: Epoch time: 57.59 s 
2023-07-31 16:09:44.674873:  
2023-07-31 16:09:44.675004: Epoch 342 
2023-07-31 16:09:44.675093: Current learning rate: 0.00069 
2023-07-31 16:10:42.292686: train_loss -0.3534 
2023-07-31 16:10:42.292859: val_loss -0.309 
2023-07-31 16:10:42.292917: Pseudo dice [0.827] 
2023-07-31 16:10:42.292984: Epoch time: 57.62 s 
2023-07-31 16:10:42.293031: Yayy! New best EMA pseudo Dice: 0.766 
2023-07-31 16:10:43.747425:  
2023-07-31 16:10:43.747556: Epoch 343 
2023-07-31 16:10:43.747656: Current learning rate: 0.00069 
2023-07-31 16:11:40.775902: train_loss -0.3201 
2023-07-31 16:11:40.776080: val_loss -0.3559 
2023-07-31 16:11:40.776145: Pseudo dice [0.7362] 
2023-07-31 16:11:40.776208: Epoch time: 57.03 s 
2023-07-31 16:11:41.836917:  
2023-07-31 16:11:41.837022: Epoch 344 
2023-07-31 16:11:41.837116: Current learning rate: 0.00068 
2023-07-31 16:12:41.351797: train_loss -0.2986 
2023-07-31 16:12:41.352065: val_loss -0.2883 
2023-07-31 16:12:41.352131: Pseudo dice [0.7565] 
2023-07-31 16:12:41.352202: Epoch time: 59.52 s 
2023-07-31 16:12:42.597765:  
2023-07-31 16:12:42.597898: Epoch 345 
2023-07-31 16:12:42.597992: Current learning rate: 0.00068 
2023-07-31 16:13:40.494478: train_loss -0.3319 
2023-07-31 16:13:40.494655: val_loss -0.3143 
2023-07-31 16:13:40.494721: Pseudo dice [0.7865] 
2023-07-31 16:13:40.494777: Epoch time: 57.9 s 
2023-07-31 16:13:41.571398:  
2023-07-31 16:13:41.571876: Epoch 346 
2023-07-31 16:13:41.572128: Current learning rate: 0.00068 
2023-07-31 16:14:42.226520: train_loss -0.3028 
2023-07-31 16:14:42.226679: val_loss -0.3712 
2023-07-31 16:14:42.226739: Pseudo dice [0.7522] 
2023-07-31 16:14:42.226795: Epoch time: 60.66 s 
2023-07-31 16:14:43.316579:  
2023-07-31 16:14:43.316693: Epoch 347 
2023-07-31 16:14:43.316788: Current learning rate: 0.00068 
2023-07-31 16:15:41.619441: train_loss -0.3613 
2023-07-31 16:15:41.619617: val_loss -0.4062 
2023-07-31 16:15:41.619678: Pseudo dice [0.7314] 
2023-07-31 16:15:41.619732: Epoch time: 58.3 s 
2023-07-31 16:15:42.682523:  
2023-07-31 16:15:42.682630: Epoch 348 
2023-07-31 16:15:42.682709: Current learning rate: 0.00068 
2023-07-31 16:16:42.475023: train_loss -0.3076 
2023-07-31 16:16:42.475181: val_loss -0.347 
2023-07-31 16:16:42.475405: Pseudo dice [0.7737] 
2023-07-31 16:16:42.475463: Epoch time: 59.79 s 
2023-07-31 16:16:43.543722:  
2023-07-31 16:16:43.543826: Epoch 349 
2023-07-31 16:16:43.543905: Current learning rate: 0.00068 
2023-07-31 16:17:41.482810: train_loss -0.3179 
2023-07-31 16:17:41.482959: val_loss -0.2358 
2023-07-31 16:17:41.483014: Pseudo dice [0.6158] 
2023-07-31 16:17:41.483068: Epoch time: 57.94 s 
2023-07-31 16:17:43.093513:  
2023-07-31 16:17:43.093641: Epoch 350 
2023-07-31 16:17:43.093736: Current learning rate: 0.00068 
2023-07-31 16:18:42.299607: train_loss -0.3166 
2023-07-31 16:18:42.299765: val_loss -0.3885 
2023-07-31 16:18:42.299827: Pseudo dice [0.8442] 
2023-07-31 16:18:42.299899: Epoch time: 59.21 s 
2023-07-31 16:18:43.386064:  
2023-07-31 16:18:43.386181: Epoch 351 
2023-07-31 16:18:43.386260: Current learning rate: 0.00068 
2023-07-31 16:19:40.637138: train_loss -0.3079 
2023-07-31 16:19:40.637300: val_loss -0.4139 
2023-07-31 16:19:40.637357: Pseudo dice [0.8239] 
2023-07-31 16:19:40.637412: Epoch time: 57.25 s 
2023-07-31 16:19:41.749790:  
2023-07-31 16:19:41.749900: Epoch 352 
2023-07-31 16:19:41.749980: Current learning rate: 0.00068 
2023-07-31 16:20:41.960688: train_loss -0.3252 
2023-07-31 16:20:41.960844: val_loss -0.3133 
2023-07-31 16:20:41.960907: Pseudo dice [0.7919] 
2023-07-31 16:20:41.960962: Epoch time: 60.21 s 
2023-07-31 16:20:41.961008: Yayy! New best EMA pseudo Dice: 0.7663 
2023-07-31 16:20:43.502725:  
2023-07-31 16:20:43.502832: Epoch 353 
2023-07-31 16:20:43.502912: Current learning rate: 0.00068 
2023-07-31 16:21:42.159879: train_loss -0.3377 
2023-07-31 16:21:42.160041: val_loss -0.3695 
2023-07-31 16:21:42.160099: Pseudo dice [0.7487] 
2023-07-31 16:21:42.160153: Epoch time: 58.66 s 
2023-07-31 16:21:43.221500:  
2023-07-31 16:21:43.221607: Epoch 354 
2023-07-31 16:21:43.221702: Current learning rate: 0.00067 
2023-07-31 16:22:42.707657: train_loss -0.3504 
2023-07-31 16:22:42.707856: val_loss -0.3604 
2023-07-31 16:22:42.707921: Pseudo dice [0.7319] 
2023-07-31 16:22:42.707981: Epoch time: 59.49 s 
2023-07-31 16:22:43.822347:  
2023-07-31 16:22:43.822452: Epoch 355 
2023-07-31 16:22:43.822553: Current learning rate: 0.00067 
2023-07-31 16:23:41.981029: train_loss -0.3176 
2023-07-31 16:23:41.981200: val_loss -0.3751 
2023-07-31 16:23:41.981261: Pseudo dice [0.7753] 
2023-07-31 16:23:41.981318: Epoch time: 58.16 s 
2023-07-31 16:23:43.241464:  
2023-07-31 16:23:43.241773: Epoch 356 
2023-07-31 16:23:43.241865: Current learning rate: 0.00067 
2023-07-31 16:24:41.035345: train_loss -0.3456 
2023-07-31 16:24:41.035539: val_loss -0.3549 
2023-07-31 16:24:41.035601: Pseudo dice [0.7659] 
2023-07-31 16:24:41.035656: Epoch time: 57.79 s 
2023-07-31 16:24:42.101471:  
2023-07-31 16:24:42.101581: Epoch 357 
2023-07-31 16:24:42.101664: Current learning rate: 0.00067 
2023-07-31 16:25:40.551500: train_loss -0.315 
2023-07-31 16:25:40.551664: val_loss -0.3367 
2023-07-31 16:25:40.551723: Pseudo dice [0.7328] 
2023-07-31 16:25:40.551778: Epoch time: 58.45 s 
2023-07-31 16:25:41.620484:  
2023-07-31 16:25:41.620712: Epoch 358 
2023-07-31 16:25:41.620799: Current learning rate: 0.00067 
2023-07-31 16:26:38.691461: train_loss -0.3204 
2023-07-31 16:26:38.691631: val_loss -0.354 
2023-07-31 16:26:38.691689: Pseudo dice [0.7465] 
2023-07-31 16:26:38.691763: Epoch time: 57.07 s 
2023-07-31 16:26:39.758042:  
2023-07-31 16:26:39.758151: Epoch 359 
2023-07-31 16:26:39.758246: Current learning rate: 0.00067 
2023-07-31 16:27:38.102571: train_loss -0.3332 
2023-07-31 16:27:38.102741: val_loss -0.2606 
2023-07-31 16:27:38.102804: Pseudo dice [0.7463] 
2023-07-31 16:27:38.102858: Epoch time: 58.35 s 
2023-07-31 16:27:39.175635:  
2023-07-31 16:27:39.175856: Epoch 360 
2023-07-31 16:27:39.175936: Current learning rate: 0.00067 
2023-07-31 16:28:37.566859: train_loss -0.3755 
2023-07-31 16:28:37.567020: val_loss -0.297 
2023-07-31 16:28:37.567201: Pseudo dice [0.7031] 
2023-07-31 16:28:37.567265: Epoch time: 58.39 s 
2023-07-31 16:28:38.857032:  
2023-07-31 16:28:38.857138: Epoch 361 
2023-07-31 16:28:38.857233: Current learning rate: 0.00067 
2023-07-31 16:29:39.970628: train_loss -0.3369 
2023-07-31 16:29:39.970788: val_loss -0.2934 
2023-07-31 16:29:39.970845: Pseudo dice [0.7467] 
2023-07-31 16:29:39.970900: Epoch time: 61.11 s 
2023-07-31 16:29:41.109958:  
2023-07-31 16:29:41.110073: Epoch 362 
2023-07-31 16:29:41.110154: Current learning rate: 0.00067 
2023-07-31 16:30:39.573871: train_loss -0.3412 
2023-07-31 16:30:39.574041: val_loss -0.3363 
2023-07-31 16:30:39.574102: Pseudo dice [0.7847] 
2023-07-31 16:30:39.574157: Epoch time: 58.46 s 
2023-07-31 16:30:40.653862:  
2023-07-31 16:30:40.654149: Epoch 363 
2023-07-31 16:30:40.654348: Current learning rate: 0.00067 
2023-07-31 16:31:39.058383: train_loss -0.3324 
2023-07-31 16:31:39.058549: val_loss -0.3765 
2023-07-31 16:31:39.058612: Pseudo dice [0.7554] 
2023-07-31 16:31:39.058668: Epoch time: 58.41 s 
2023-07-31 16:31:40.127049:  
2023-07-31 16:31:40.127154: Epoch 364 
2023-07-31 16:31:40.127233: Current learning rate: 0.00067 
2023-07-31 16:32:38.986887: train_loss -0.3281 
2023-07-31 16:32:38.987070: val_loss -0.3938 
2023-07-31 16:32:38.987129: Pseudo dice [0.7972] 
2023-07-31 16:32:38.987183: Epoch time: 58.86 s 
2023-07-31 16:32:40.139894:  
2023-07-31 16:32:40.140005: Epoch 365 
2023-07-31 16:32:40.140084: Current learning rate: 0.00066 
2023-07-31 16:33:39.678224: train_loss -0.3089 
2023-07-31 16:33:39.678381: val_loss -0.3128 
2023-07-31 16:33:39.678440: Pseudo dice [0.7138] 
2023-07-31 16:33:39.678494: Epoch time: 59.54 s 
2023-07-31 16:33:40.894561:  
2023-07-31 16:33:40.894751: Epoch 366 
2023-07-31 16:33:40.894855: Current learning rate: 0.00066 
2023-07-31 16:34:40.044624: train_loss -0.3335 
2023-07-31 16:34:40.044783: val_loss -0.4079 
2023-07-31 16:34:40.044859: Pseudo dice [0.8166] 
2023-07-31 16:34:40.044941: Epoch time: 59.15 s 
2023-07-31 16:34:41.124116:  
2023-07-31 16:34:41.124320: Epoch 367 
2023-07-31 16:34:41.124405: Current learning rate: 0.00066 
2023-07-31 16:35:38.912513: train_loss -0.3385 
2023-07-31 16:35:38.912675: val_loss -0.3436 
2023-07-31 16:35:38.912731: Pseudo dice [0.7122] 
2023-07-31 16:35:38.912786: Epoch time: 57.79 s 
2023-07-31 16:35:39.996435:  
2023-07-31 16:35:39.996544: Epoch 368 
2023-07-31 16:35:39.996643: Current learning rate: 0.00066 
2023-07-31 16:36:37.102759: train_loss -0.3107 
2023-07-31 16:36:37.102916: val_loss -0.3571 
2023-07-31 16:36:37.102973: Pseudo dice [0.7164] 
2023-07-31 16:36:37.103027: Epoch time: 57.11 s 
2023-07-31 16:36:38.198311:  
2023-07-31 16:36:38.198417: Epoch 369 
2023-07-31 16:36:38.198494: Current learning rate: 0.00066 
2023-07-31 16:37:36.591965: train_loss -0.304 
2023-07-31 16:37:36.592126: val_loss -0.3414 
2023-07-31 16:37:36.592192: Pseudo dice [0.8216] 
2023-07-31 16:37:36.592248: Epoch time: 58.39 s 
2023-07-31 16:37:37.724422:  
2023-07-31 16:37:37.724529: Epoch 370 
2023-07-31 16:37:37.724613: Current learning rate: 0.00066 
2023-07-31 16:38:36.542185: train_loss -0.3116 
2023-07-31 16:38:36.542353: val_loss -0.3337 
2023-07-31 16:38:36.542508: Pseudo dice [0.8129] 
2023-07-31 16:38:36.542567: Epoch time: 58.82 s 
2023-07-31 16:38:37.643193:  
2023-07-31 16:38:37.643417: Epoch 371 
2023-07-31 16:38:37.643511: Current learning rate: 0.00066 
2023-07-31 16:39:35.581004: train_loss -0.3297 
2023-07-31 16:39:35.581179: val_loss -0.2495 
2023-07-31 16:39:35.581243: Pseudo dice [0.727] 
2023-07-31 16:39:35.581301: Epoch time: 57.94 s 
2023-07-31 16:39:36.688717:  
2023-07-31 16:39:36.688839: Epoch 372 
2023-07-31 16:39:36.688951: Current learning rate: 0.00066 
2023-07-31 16:40:36.626838: train_loss -0.2915 
2023-07-31 16:40:36.627055: val_loss -0.4095 
2023-07-31 16:40:36.635355: Pseudo dice [0.6824] 
2023-07-31 16:40:36.635675: Epoch time: 59.94 s 
2023-07-31 16:40:37.786190:  
2023-07-31 16:40:37.786296: Epoch 373 
2023-07-31 16:40:37.786390: Current learning rate: 0.00066 
2023-07-31 16:41:37.546937: train_loss -0.3213 
2023-07-31 16:41:37.547108: val_loss -0.2534 
2023-07-31 16:41:37.547168: Pseudo dice [0.6298] 
2023-07-31 16:41:37.547224: Epoch time: 59.76 s 
2023-07-31 16:41:38.656338:  
2023-07-31 16:41:38.656443: Epoch 374 
2023-07-31 16:41:38.656524: Current learning rate: 0.00066 
2023-07-31 16:42:39.453785: train_loss -0.3221 
2023-07-31 16:42:39.453936: val_loss -0.347 
2023-07-31 16:42:39.453994: Pseudo dice [0.6998] 
2023-07-31 16:42:39.454048: Epoch time: 60.8 s 
2023-07-31 16:42:40.785575:  
2023-07-31 16:42:40.785928: Epoch 375 
2023-07-31 16:42:40.786030: Current learning rate: 0.00066 
2023-07-31 16:43:39.181736: train_loss -0.3293 
2023-07-31 16:43:39.181911: val_loss -0.3926 
2023-07-31 16:43:39.181973: Pseudo dice [0.8206] 
2023-07-31 16:43:39.182029: Epoch time: 58.4 s 
2023-07-31 16:43:40.310466:  
2023-07-31 16:43:40.310570: Epoch 376 
2023-07-31 16:43:40.310655: Current learning rate: 0.00065 
2023-07-31 16:44:37.984602: train_loss -0.3225 
2023-07-31 16:44:37.984764: val_loss -0.3529 
2023-07-31 16:44:37.984827: Pseudo dice [0.757] 
2023-07-31 16:44:37.984883: Epoch time: 57.67 s 
2023-07-31 16:44:39.217150:  
2023-07-31 16:44:39.217264: Epoch 377 
2023-07-31 16:44:39.217365: Current learning rate: 0.00065 
2023-07-31 16:45:37.352957: train_loss -0.3548 
2023-07-31 16:45:37.353124: val_loss -0.3271 
2023-07-31 16:45:37.353192: Pseudo dice [0.7777] 
2023-07-31 16:45:37.353271: Epoch time: 58.14 s 
2023-07-31 16:45:38.510910:  
2023-07-31 16:45:38.511163: Epoch 378 
2023-07-31 16:45:38.511258: Current learning rate: 0.00065 
2023-07-31 16:46:35.723643: train_loss -0.3102 
2023-07-31 16:46:35.723799: val_loss -0.32 
2023-07-31 16:46:35.723872: Pseudo dice [0.7936] 
2023-07-31 16:46:35.723951: Epoch time: 57.21 s 
2023-07-31 16:46:36.783170:  
2023-07-31 16:46:36.783346: Epoch 379 
2023-07-31 16:46:36.783422: Current learning rate: 0.00065 
2023-07-31 16:47:33.539309: train_loss -0.2913 
2023-07-31 16:47:33.539462: val_loss -0.3564 
2023-07-31 16:47:33.539530: Pseudo dice [0.7091] 
2023-07-31 16:47:33.539586: Epoch time: 56.76 s 
2023-07-31 16:47:34.596160:  
2023-07-31 16:47:34.596365: Epoch 380 
2023-07-31 16:47:34.596447: Current learning rate: 0.00065 
2023-07-31 16:48:32.306863: train_loss -0.2915 
2023-07-31 16:48:32.307024: val_loss -0.3569 
2023-07-31 16:48:32.307093: Pseudo dice [0.7792] 
2023-07-31 16:48:32.307149: Epoch time: 57.71 s 
2023-07-31 16:48:33.390759:  
2023-07-31 16:48:33.390861: Epoch 381 
2023-07-31 16:48:33.390940: Current learning rate: 0.00065 
2023-07-31 16:49:30.580014: train_loss -0.3285 
2023-07-31 16:49:30.580173: val_loss -0.317 
2023-07-31 16:49:30.580232: Pseudo dice [0.702] 
2023-07-31 16:49:30.580289: Epoch time: 57.19 s 
2023-07-31 16:49:31.828250:  
2023-07-31 16:49:31.828469: Epoch 382 
2023-07-31 16:49:31.828559: Current learning rate: 0.00065 
2023-07-31 16:50:29.483015: train_loss -0.3535 
2023-07-31 16:50:29.483179: val_loss -0.3379 
2023-07-31 16:50:29.483238: Pseudo dice [0.7087] 
2023-07-31 16:50:29.483292: Epoch time: 57.66 s 
2023-07-31 16:50:30.566672:  
2023-07-31 16:50:30.566928: Epoch 383 
2023-07-31 16:50:30.567159: Current learning rate: 0.00065 
2023-07-31 16:51:28.631818: train_loss -0.3509 
2023-07-31 16:51:28.631990: val_loss -0.2969 
2023-07-31 16:51:28.632052: Pseudo dice [0.7471] 
2023-07-31 16:51:28.632107: Epoch time: 58.07 s 
2023-07-31 16:51:29.805468:  
2023-07-31 16:51:29.805575: Epoch 384 
2023-07-31 16:51:29.805652: Current learning rate: 0.00065 
2023-07-31 16:52:28.663284: train_loss -0.2934 
2023-07-31 16:52:28.663464: val_loss -0.336 
2023-07-31 16:52:28.663534: Pseudo dice [0.7688] 
2023-07-31 16:52:28.663589: Epoch time: 58.86 s 
2023-07-31 16:52:29.760650:  
2023-07-31 16:52:29.760753: Epoch 385 
2023-07-31 16:52:29.760834: Current learning rate: 0.00065 
2023-07-31 16:53:28.262470: train_loss -0.3289 
2023-07-31 16:53:28.262637: val_loss -0.3327 
2023-07-31 16:53:28.262698: Pseudo dice [0.6216] 
2023-07-31 16:53:28.262753: Epoch time: 58.5 s 
2023-07-31 16:53:29.372279:  
2023-07-31 16:53:29.372399: Epoch 386 
2023-07-31 16:53:29.372494: Current learning rate: 0.00064 
2023-07-31 16:54:26.474293: train_loss -0.3364 
2023-07-31 16:54:26.474452: val_loss -0.3098 
2023-07-31 16:54:26.474510: Pseudo dice [0.7437] 
2023-07-31 16:54:26.474565: Epoch time: 57.1 s 
2023-07-31 16:54:27.704103:  
2023-07-31 16:54:27.704313: Epoch 387 
2023-07-31 16:54:27.704401: Current learning rate: 0.00064 
2023-07-31 16:55:29.111941: train_loss -0.3597 
2023-07-31 16:55:29.112096: val_loss -0.4123 
2023-07-31 16:55:29.112158: Pseudo dice [0.8159] 
2023-07-31 16:55:29.112213: Epoch time: 61.41 s 
2023-07-31 16:55:30.188131:  
2023-07-31 16:55:30.188455: Epoch 388 
2023-07-31 16:55:30.188540: Current learning rate: 0.00064 
2023-07-31 16:56:28.598616: train_loss -0.347 
2023-07-31 16:56:28.598794: val_loss -0.3847 
2023-07-31 16:56:28.598992: Pseudo dice [0.7238] 
2023-07-31 16:56:28.599066: Epoch time: 58.41 s 
2023-07-31 16:56:29.679903:  
2023-07-31 16:56:29.680267: Epoch 389 
2023-07-31 16:56:29.680368: Current learning rate: 0.00064 
2023-07-31 16:57:27.221977: train_loss -0.3434 
2023-07-31 16:57:27.222152: val_loss -0.3794 
2023-07-31 16:57:27.222213: Pseudo dice [0.8097] 
2023-07-31 16:57:27.222268: Epoch time: 57.54 s 
2023-07-31 16:57:28.368310:  
2023-07-31 16:57:28.368416: Epoch 390 
2023-07-31 16:57:28.368513: Current learning rate: 0.00064 
2023-07-31 16:58:29.702195: train_loss -0.3414 
2023-07-31 16:58:29.702348: val_loss -0.3906 
2023-07-31 16:58:29.702406: Pseudo dice [0.8655] 
2023-07-31 16:58:29.702460: Epoch time: 61.33 s 
2023-07-31 16:58:30.812010:  
2023-07-31 16:58:30.812105: Epoch 391 
2023-07-31 16:58:30.812180: Current learning rate: 0.00064 
2023-07-31 16:59:28.871142: train_loss -0.3221 
2023-07-31 16:59:28.871326: val_loss -0.3315 
2023-07-31 16:59:28.871385: Pseudo dice [0.7935] 
2023-07-31 16:59:28.871441: Epoch time: 58.06 s 
2023-07-31 16:59:30.186996:  
2023-07-31 16:59:30.187347: Epoch 392 
2023-07-31 16:59:30.187433: Current learning rate: 0.00064 
2023-07-31 17:00:28.244360: train_loss -0.3264 
2023-07-31 17:00:28.244521: val_loss -0.3405 
2023-07-31 17:00:28.244599: Pseudo dice [0.7893] 
2023-07-31 17:00:28.244658: Epoch time: 58.06 s 
2023-07-31 17:00:29.347461:  
2023-07-31 17:00:29.347596: Epoch 393 
2023-07-31 17:00:29.347677: Current learning rate: 0.00064 
2023-07-31 17:01:27.543533: train_loss -0.3213 
2023-07-31 17:01:27.543695: val_loss -0.3135 
2023-07-31 17:01:27.543756: Pseudo dice [0.7283] 
2023-07-31 17:01:27.543812: Epoch time: 58.2 s 
2023-07-31 17:01:28.645504:  
2023-07-31 17:01:28.645618: Epoch 394 
2023-07-31 17:01:28.645699: Current learning rate: 0.00064 
2023-07-31 17:02:26.979522: train_loss -0.3263 
2023-07-31 17:02:26.979725: val_loss -0.3917 
2023-07-31 17:02:26.979816: Pseudo dice [0.7614] 
2023-07-31 17:02:26.979909: Epoch time: 58.33 s 
2023-07-31 17:02:28.188967:  
2023-07-31 17:02:28.189168: Epoch 395 
2023-07-31 17:02:28.189256: Current learning rate: 0.00064 
2023-07-31 17:03:25.443568: train_loss -0.298 
2023-07-31 17:03:25.443723: val_loss -0.3116 
2023-07-31 17:03:25.443781: Pseudo dice [0.7996] 
2023-07-31 17:03:25.443836: Epoch time: 57.26 s 
2023-07-31 17:03:26.600769:  
2023-07-31 17:03:26.600980: Epoch 396 
2023-07-31 17:03:26.601064: Current learning rate: 0.00064 
2023-07-31 17:04:26.414279: train_loss -0.3151 
2023-07-31 17:04:26.414438: val_loss -0.3375 
2023-07-31 17:04:26.414494: Pseudo dice [0.7835] 
2023-07-31 17:04:26.414551: Epoch time: 59.81 s 
2023-07-31 17:04:26.414595: Yayy! New best EMA pseudo Dice: 0.7674 
2023-07-31 17:04:27.988760:  
2023-07-31 17:04:27.988888: Epoch 397 
2023-07-31 17:04:27.988984: Current learning rate: 0.00063 
2023-07-31 17:05:24.723067: train_loss -0.3354 
2023-07-31 17:05:24.723244: val_loss -0.3509 
2023-07-31 17:05:24.723322: Pseudo dice [0.75] 
2023-07-31 17:05:24.723392: Epoch time: 56.74 s 
2023-07-31 17:05:25.817477:  
2023-07-31 17:05:25.817582: Epoch 398 
2023-07-31 17:05:25.817680: Current learning rate: 0.00063 
2023-07-31 17:06:23.427534: train_loss -0.3613 
2023-07-31 17:06:23.427691: val_loss -0.3432 
2023-07-31 17:06:23.427750: Pseudo dice [0.7992] 
2023-07-31 17:06:23.427806: Epoch time: 57.61 s 
2023-07-31 17:06:23.427856: Yayy! New best EMA pseudo Dice: 0.769 
2023-07-31 17:06:24.950964:  
2023-07-31 17:06:24.951169: Epoch 399 
2023-07-31 17:06:24.951256: Current learning rate: 0.00063 
2023-07-31 17:07:22.539079: train_loss -0.3442 
2023-07-31 17:07:22.539333: val_loss -0.3558 
2023-07-31 17:07:22.539397: Pseudo dice [0.7534] 
2023-07-31 17:07:22.539452: Epoch time: 57.59 s 
2023-07-31 17:07:24.059859:  
2023-07-31 17:07:24.059965: Epoch 400 
2023-07-31 17:07:24.060051: Current learning rate: 0.00063 
2023-07-31 17:08:30.626286: train_loss -0.3049 
2023-07-31 17:08:30.626436: val_loss -0.3961 
2023-07-31 17:08:30.626498: Pseudo dice [0.7955] 
2023-07-31 17:08:30.626557: Epoch time: 66.57 s 
2023-07-31 17:08:30.626606: Yayy! New best EMA pseudo Dice: 0.7703 
2023-07-31 17:08:32.167924:  
2023-07-31 17:08:32.168118: Epoch 401 
2023-07-31 17:08:32.168203: Current learning rate: 0.00063 
2023-07-31 17:09:44.794236: train_loss -0.3246 
2023-07-31 17:09:44.794414: val_loss -0.3106 
2023-07-31 17:09:44.794493: Pseudo dice [0.8515] 
2023-07-31 17:09:44.794563: Epoch time: 72.63 s 
2023-07-31 17:09:44.794621: Yayy! New best EMA pseudo Dice: 0.7784 
2023-07-31 17:09:46.500905:  
2023-07-31 17:09:46.501249: Epoch 402 
2023-07-31 17:09:46.501353: Current learning rate: 0.00063 
2023-07-31 17:11:00.330588: train_loss -0.3324 
2023-07-31 17:11:00.330763: val_loss -0.3432 
2023-07-31 17:11:00.330827: Pseudo dice [0.7957] 
2023-07-31 17:11:00.330890: Epoch time: 73.83 s 
2023-07-31 17:11:00.330940: Yayy! New best EMA pseudo Dice: 0.7801 
2023-07-31 17:11:01.889067:  
2023-07-31 17:11:01.889238: Epoch 403 
2023-07-31 17:11:01.889334: Current learning rate: 0.00063 
2023-07-31 17:12:14.661164: train_loss -0.2946 
2023-07-31 17:12:14.661449: val_loss -0.2996 
2023-07-31 17:12:14.661526: Pseudo dice [0.7062] 
2023-07-31 17:12:14.661585: Epoch time: 72.77 s 
2023-07-31 17:12:15.839073:  
2023-07-31 17:12:15.839270: Epoch 404 
2023-07-31 17:12:15.839354: Current learning rate: 0.00063 
2023-07-31 17:13:28.977658: train_loss -0.3125 
2023-07-31 17:13:28.977825: val_loss -0.3452 
2023-07-31 17:13:28.977892: Pseudo dice [0.715] 
2023-07-31 17:13:28.977970: Epoch time: 73.14 s 
2023-07-31 17:13:30.109004:  
2023-07-31 17:13:30.109202: Epoch 405 
2023-07-31 17:13:30.109296: Current learning rate: 0.00063 
2023-07-31 17:14:34.766904: train_loss -0.3264 
2023-07-31 17:14:34.767063: val_loss -0.2945 
2023-07-31 17:14:34.767123: Pseudo dice [0.6994] 
2023-07-31 17:14:34.767178: Epoch time: 64.66 s 
2023-07-31 17:14:35.860343:  
2023-07-31 17:14:35.860598: Epoch 406 
2023-07-31 17:14:35.860729: Current learning rate: 0.00063 
2023-07-31 17:15:58.681758: train_loss -0.3311 
2023-07-31 17:15:58.681914: val_loss -0.2593 
2023-07-31 17:15:58.690200: Pseudo dice [0.686] 
2023-07-31 17:15:58.690358: Epoch time: 82.82 s 
2023-07-31 17:15:59.853611:  
2023-07-31 17:15:59.853741: Epoch 407 
2023-07-31 17:15:59.853848: Current learning rate: 0.00062 
2023-07-31 17:17:31.531272: train_loss -0.3238 
2023-07-31 17:17:31.531432: val_loss -0.3362 
2023-07-31 17:17:31.531502: Pseudo dice [0.8572] 
2023-07-31 17:17:31.531577: Epoch time: 91.68 s 
2023-07-31 17:17:32.631645:  
2023-07-31 17:17:32.631765: Epoch 408 
2023-07-31 17:17:32.631844: Current learning rate: 0.00062 
2023-07-31 17:19:03.947347: train_loss -0.31 
2023-07-31 17:19:03.947541: val_loss -0.3369 
2023-07-31 17:19:03.947606: Pseudo dice [0.8618] 
2023-07-31 17:19:03.947668: Epoch time: 91.32 s 
2023-07-31 17:19:05.169315:  
2023-07-31 17:19:05.169428: Epoch 409 
2023-07-31 17:19:05.169507: Current learning rate: 0.00062 
2023-07-31 17:20:34.701063: train_loss -0.3407 
2023-07-31 17:20:34.701236: val_loss -0.337 
2023-07-31 17:20:34.701296: Pseudo dice [0.7373] 
2023-07-31 17:20:34.701351: Epoch time: 89.53 s 
2023-07-31 17:20:35.856194:  
2023-07-31 17:20:35.856321: Epoch 410 
2023-07-31 17:20:35.856431: Current learning rate: 0.00062 
2023-07-31 17:21:40.265843: train_loss -0.3552 
2023-07-31 17:21:40.266012: val_loss -0.3524 
2023-07-31 17:21:40.266070: Pseudo dice [0.7377] 
2023-07-31 17:21:40.266124: Epoch time: 64.41 s 
2023-07-31 17:21:41.308872:  
2023-07-31 17:21:41.314429: Epoch 411 
2023-07-31 17:21:41.314661: Current learning rate: 0.00062 
2023-07-31 17:23:13.181657: train_loss -0.2978 
2023-07-31 17:23:13.181865: val_loss -0.239 
2023-07-31 17:23:13.181932: Pseudo dice [0.7268] 
2023-07-31 17:23:13.181996: Epoch time: 91.87 s 
2023-07-31 17:23:14.242765:  
2023-07-31 17:23:14.242888: Epoch 412 
2023-07-31 17:23:14.242970: Current learning rate: 0.00062 
2023-07-31 17:24:41.147186: train_loss -0.3011 
2023-07-31 17:24:41.147351: val_loss -0.3359 
2023-07-31 17:24:41.147408: Pseudo dice [0.7052] 
2023-07-31 17:24:41.147462: Epoch time: 86.91 s 
2023-07-31 17:24:42.482648:  
2023-07-31 17:24:42.482775: Epoch 413 
2023-07-31 17:24:42.482853: Current learning rate: 0.00062 
2023-07-31 17:26:02.043989: train_loss -0.3371 
2023-07-31 17:26:02.044145: val_loss -0.3759 
2023-07-31 17:26:02.044206: Pseudo dice [0.8451] 
2023-07-31 17:26:02.044280: Epoch time: 79.56 s 
2023-07-31 17:26:03.094869:  
2023-07-31 17:26:03.094982: Epoch 414 
2023-07-31 17:26:03.095062: Current learning rate: 0.00062 
2023-07-31 17:27:40.212946: train_loss -0.3354 
2023-07-31 17:27:40.213098: val_loss -0.3753 
2023-07-31 17:27:40.213156: Pseudo dice [0.8423] 
2023-07-31 17:27:40.213216: Epoch time: 97.12 s 
2023-07-31 17:27:41.286103:  
2023-07-31 17:27:41.286242: Epoch 415 
2023-07-31 17:27:41.286463: Current learning rate: 0.00062 
2023-07-31 17:29:19.114116: train_loss -0.3193 
2023-07-31 17:29:19.114271: val_loss -0.3458 
2023-07-31 17:29:19.114331: Pseudo dice [0.8191] 
2023-07-31 17:29:19.114487: Epoch time: 97.83 s 
2023-07-31 17:29:20.208271:  
2023-07-31 17:29:20.208395: Epoch 416 
2023-07-31 17:29:20.208476: Current learning rate: 0.00062 
2023-07-31 17:30:58.587279: train_loss -0.3498 
2023-07-31 17:30:58.587441: val_loss -0.301 
2023-07-31 17:30:58.587512: Pseudo dice [0.7242] 
2023-07-31 17:30:58.587574: Epoch time: 98.38 s 
2023-07-31 17:30:59.658782:  
2023-07-31 17:30:59.658893: Epoch 417 
2023-07-31 17:30:59.658973: Current learning rate: 0.00062 
2023-07-31 17:32:37.950998: train_loss -0.3519 
2023-07-31 17:32:37.951150: val_loss -0.2666 
2023-07-31 17:32:37.951222: Pseudo dice [0.7186] 
2023-07-31 17:32:37.951284: Epoch time: 98.29 s 
2023-07-31 17:32:39.158120:  
2023-07-31 17:32:39.158490: Epoch 418 
2023-07-31 17:32:39.158659: Current learning rate: 0.00061 
2023-07-31 17:34:17.974767: train_loss -0.3621 
2023-07-31 17:34:17.974936: val_loss -0.3846 
2023-07-31 17:34:17.975001: Pseudo dice [0.797] 
2023-07-31 17:34:17.975070: Epoch time: 98.82 s 
2023-07-31 17:34:19.214607:  
2023-07-31 17:34:19.214988: Epoch 419 
2023-07-31 17:34:19.215127: Current learning rate: 0.00061 
2023-07-31 17:35:57.956448: train_loss -0.3046 
2023-07-31 17:35:57.956697: val_loss -0.3566 
2023-07-31 17:35:57.956756: Pseudo dice [0.8129] 
2023-07-31 17:35:57.956811: Epoch time: 98.74 s 
2023-07-31 17:35:58.997562:  
2023-07-31 17:35:58.997682: Epoch 420 
2023-07-31 17:35:58.997784: Current learning rate: 0.00061 
2023-07-31 17:37:01.833033: train_loss -0.3274 
2023-07-31 17:37:01.833204: val_loss -0.3963 
2023-07-31 17:37:01.833267: Pseudo dice [0.704] 
2023-07-31 17:37:01.833325: Epoch time: 62.84 s 
2023-07-31 17:37:02.917293:  
2023-07-31 17:37:02.917420: Epoch 421 
2023-07-31 17:37:02.917499: Current learning rate: 0.00061 
2023-07-31 17:38:13.271530: train_loss -0.3317 
2023-07-31 17:38:13.271686: val_loss -0.3964 
2023-07-31 17:38:13.271764: Pseudo dice [0.7354] 
2023-07-31 17:38:13.271822: Epoch time: 70.35 s 
2023-07-31 17:38:14.399060:  
2023-07-31 17:38:14.399284: Epoch 422 
2023-07-31 17:38:14.399391: Current learning rate: 0.00061 
2023-07-31 17:39:24.499788: train_loss -0.3334 
2023-07-31 17:39:24.499976: val_loss -0.3487 
2023-07-31 17:39:24.500045: Pseudo dice [0.7851] 
2023-07-31 17:39:24.500107: Epoch time: 70.1 s 
2023-07-31 17:39:25.586861:  
2023-07-31 17:39:25.587162: Epoch 423 
2023-07-31 17:39:25.587248: Current learning rate: 0.00061 
2023-07-31 17:40:34.951727: train_loss -0.3155 
2023-07-31 17:40:34.951897: val_loss -0.3067 
2023-07-31 17:40:34.951956: Pseudo dice [0.7766] 
2023-07-31 17:40:34.952010: Epoch time: 69.37 s 
2023-07-31 17:40:36.226418:  
2023-07-31 17:40:36.226649: Epoch 424 
2023-07-31 17:40:36.226737: Current learning rate: 0.00061 
2023-07-31 17:41:47.692281: train_loss -0.3459 
2023-07-31 17:41:47.692451: val_loss -0.3381 
2023-07-31 17:41:47.692519: Pseudo dice [0.8061] 
2023-07-31 17:41:47.692580: Epoch time: 71.47 s 
2023-07-31 17:41:48.808864:  
2023-07-31 17:41:48.808972: Epoch 425 
2023-07-31 17:41:48.809052: Current learning rate: 0.00061 
2023-07-31 17:42:59.270338: train_loss -0.3345 
2023-07-31 17:42:59.270501: val_loss -0.3125 
2023-07-31 17:42:59.270579: Pseudo dice [0.7611] 
2023-07-31 17:42:59.270692: Epoch time: 70.46 s 
2023-07-31 17:43:00.400597:  
2023-07-31 17:43:00.400708: Epoch 426 
2023-07-31 17:43:00.400789: Current learning rate: 0.00061 
2023-07-31 17:44:12.504505: train_loss -0.332 
2023-07-31 17:44:12.504659: val_loss -0.3649 
2023-07-31 17:44:12.504720: Pseudo dice [0.8232] 
2023-07-31 17:44:12.504779: Epoch time: 72.1 s 
2023-07-31 17:44:13.638127:  
2023-07-31 17:44:13.638327: Epoch 427 
2023-07-31 17:44:13.638415: Current learning rate: 0.00061 
2023-07-31 17:45:23.977251: train_loss -0.3446 
2023-07-31 17:45:23.977470: val_loss -0.4175 
2023-07-31 17:45:23.977542: Pseudo dice [0.846] 
2023-07-31 17:45:23.977605: Epoch time: 70.34 s 
2023-07-31 17:45:23.977659: Yayy! New best EMA pseudo Dice: 0.7825 
2023-07-31 17:45:25.445074:  
2023-07-31 17:45:25.445277: Epoch 428 
2023-07-31 17:45:25.445486: Current learning rate: 0.0006 
2023-07-31 17:46:35.635767: train_loss -0.3249 
2023-07-31 17:46:35.635928: val_loss -0.3285 
2023-07-31 17:46:35.636023: Pseudo dice [0.8065] 
2023-07-31 17:46:35.636083: Epoch time: 70.19 s 
2023-07-31 17:46:35.636133: Yayy! New best EMA pseudo Dice: 0.7849 
2023-07-31 17:46:37.080369:  
2023-07-31 17:46:37.080480: Epoch 429 
2023-07-31 17:46:37.080561: Current learning rate: 0.0006 
2023-07-31 17:47:48.851335: train_loss -0.3215 
2023-07-31 17:47:48.851555: val_loss -0.3641 
2023-07-31 17:47:48.851631: Pseudo dice [0.8208] 
2023-07-31 17:47:48.851700: Epoch time: 71.77 s 
2023-07-31 17:47:48.851754: Yayy! New best EMA pseudo Dice: 0.7885 
2023-07-31 17:47:50.337745:  
2023-07-31 17:47:50.337894: Epoch 430 
2023-07-31 17:47:50.338001: Current learning rate: 0.0006 
2023-07-31 17:48:56.907262: train_loss -0.3241 
2023-07-31 17:48:56.907428: val_loss -0.3852 
2023-07-31 17:48:56.907496: Pseudo dice [0.8264] 
2023-07-31 17:48:56.907553: Epoch time: 66.57 s 
2023-07-31 17:48:56.907598: Yayy! New best EMA pseudo Dice: 0.7923 
2023-07-31 17:48:58.299068:  
2023-07-31 17:48:58.299173: Epoch 431 
2023-07-31 17:48:58.299282: Current learning rate: 0.0006 
2023-07-31 17:49:57.439214: train_loss -0.3179 
2023-07-31 17:49:57.439372: val_loss -0.2938 
2023-07-31 17:49:57.439435: Pseudo dice [0.7622] 
2023-07-31 17:49:57.439496: Epoch time: 59.14 s 
2023-07-31 17:49:58.497101:  
2023-07-31 17:49:58.497205: Epoch 432 
2023-07-31 17:49:58.497298: Current learning rate: 0.0006 
2023-07-31 17:50:56.580084: train_loss -0.3512 
2023-07-31 17:50:56.580260: val_loss -0.3758 
2023-07-31 17:50:56.580329: Pseudo dice [0.7366] 
2023-07-31 17:50:56.580391: Epoch time: 58.08 s 
2023-07-31 17:50:57.650597:  
2023-07-31 17:50:57.650713: Epoch 433 
2023-07-31 17:50:57.650808: Current learning rate: 0.0006 
2023-07-31 17:52:00.919736: train_loss -0.3037 
2023-07-31 17:52:00.919905: val_loss -0.3153 
2023-07-31 17:52:00.919963: Pseudo dice [0.8667] 
2023-07-31 17:52:00.920026: Epoch time: 63.27 s 
2023-07-31 17:52:00.920074: Yayy! New best EMA pseudo Dice: 0.7923 
2023-07-31 17:52:02.445292:  
2023-07-31 17:52:02.445491: Epoch 434 
2023-07-31 17:52:02.445712: Current learning rate: 0.0006 
2023-07-31 17:53:12.193798: train_loss -0.3267 
2023-07-31 17:53:12.193963: val_loss -0.3687 
2023-07-31 17:53:12.194022: Pseudo dice [0.8364] 
2023-07-31 17:53:12.194097: Epoch time: 69.75 s 
2023-07-31 17:53:12.194145: Yayy! New best EMA pseudo Dice: 0.7967 
2023-07-31 17:53:13.704215:  
2023-07-31 17:53:13.704438: Epoch 435 
2023-07-31 17:53:13.704524: Current learning rate: 0.0006 
2023-07-31 17:54:24.073835: train_loss -0.3363 
2023-07-31 17:54:24.073991: val_loss -0.3264 
2023-07-31 17:54:24.074049: Pseudo dice [0.8421] 
2023-07-31 17:54:24.074121: Epoch time: 70.37 s 
2023-07-31 17:54:24.074178: Yayy! New best EMA pseudo Dice: 0.8012 
2023-07-31 17:54:25.507105:  
2023-07-31 17:54:25.507426: Epoch 436 
2023-07-31 17:54:25.507534: Current learning rate: 0.0006 
2023-07-31 17:55:33.609399: train_loss -0.3337 
2023-07-31 17:55:33.609555: val_loss -0.3261 
2023-07-31 17:55:33.609613: Pseudo dice [0.8071] 
2023-07-31 17:55:33.609668: Epoch time: 68.1 s 
2023-07-31 17:55:33.609713: Yayy! New best EMA pseudo Dice: 0.8018 
2023-07-31 17:55:35.224350:  
2023-07-31 17:55:35.224473: Epoch 437 
2023-07-31 17:55:35.224555: Current learning rate: 0.0006 
2023-07-31 17:56:37.079735: train_loss -0.3702 
2023-07-31 17:56:37.079898: val_loss -0.3128 
2023-07-31 17:56:37.079958: Pseudo dice [0.7893] 
2023-07-31 17:56:37.080013: Epoch time: 61.86 s 
2023-07-31 17:56:38.127639:  
2023-07-31 17:56:38.127747: Epoch 438 
2023-07-31 17:56:38.127829: Current learning rate: 0.0006 
2023-07-31 17:57:35.026699: train_loss -0.3323 
2023-07-31 17:57:35.026874: val_loss -0.3005 
2023-07-31 17:57:35.026935: Pseudo dice [0.7333] 
2023-07-31 17:57:35.026991: Epoch time: 56.9 s 
2023-07-31 17:57:36.080541:  
2023-07-31 17:57:36.080639: Epoch 439 
2023-07-31 17:57:36.080715: Current learning rate: 0.00059 
2023-07-31 17:58:33.664501: train_loss -0.3313 
2023-07-31 17:58:33.664952: val_loss -0.3134 
2023-07-31 17:58:33.665036: Pseudo dice [0.7726] 
2023-07-31 17:58:33.665093: Epoch time: 57.58 s 
2023-07-31 17:58:34.867525:  
2023-07-31 17:58:34.867631: Epoch 440 
2023-07-31 17:58:34.867743: Current learning rate: 0.00059 
2023-07-31 17:59:32.733322: train_loss -0.3338 
2023-07-31 17:59:32.733480: val_loss -0.3158 
2023-07-31 17:59:32.733541: Pseudo dice [0.7444] 
2023-07-31 17:59:32.733596: Epoch time: 57.87 s 
2023-07-31 17:59:33.777779:  
2023-07-31 17:59:33.777897: Epoch 441 
2023-07-31 17:59:33.777993: Current learning rate: 0.00059 
2023-07-31 18:00:32.181879: train_loss -0.3514 
2023-07-31 18:00:32.182053: val_loss -0.3191 
2023-07-31 18:00:32.182131: Pseudo dice [0.7546] 
2023-07-31 18:00:32.182212: Epoch time: 58.4 s 
2023-07-31 18:00:33.258120:  
2023-07-31 18:00:33.258224: Epoch 442 
2023-07-31 18:00:33.258335: Current learning rate: 0.00059 
2023-07-31 18:01:31.225549: train_loss -0.2852 
2023-07-31 18:01:31.225708: val_loss -0.3338 
2023-07-31 18:01:31.225778: Pseudo dice [0.8196] 
2023-07-31 18:01:31.225853: Epoch time: 57.97 s 
2023-07-31 18:01:32.345754:  
2023-07-31 18:01:32.346044: Epoch 443 
2023-07-31 18:01:32.346271: Current learning rate: 0.00059 
2023-07-31 18:02:32.223468: train_loss -0.3362 
2023-07-31 18:02:32.223652: val_loss -0.3481 
2023-07-31 18:02:32.223710: Pseudo dice [0.6646] 
2023-07-31 18:02:32.223764: Epoch time: 59.88 s 
2023-07-31 18:02:33.236277:  
2023-07-31 18:02:33.236382: Epoch 444 
2023-07-31 18:02:33.236459: Current learning rate: 0.00059 
2023-07-31 18:03:31.577197: train_loss -0.344 
2023-07-31 18:03:31.577366: val_loss -0.3084 
2023-07-31 18:03:31.577429: Pseudo dice [0.8142] 
2023-07-31 18:03:31.577485: Epoch time: 58.34 s 
2023-07-31 18:03:32.585476:  
2023-07-31 18:03:32.585576: Epoch 445 
2023-07-31 18:03:32.585658: Current learning rate: 0.00059 
2023-07-31 18:04:31.860086: train_loss -0.318 
2023-07-31 18:04:31.860252: val_loss -0.3015 
2023-07-31 18:04:31.860313: Pseudo dice [0.7573] 
2023-07-31 18:04:31.860385: Epoch time: 59.28 s 
2023-07-31 18:04:32.895530:  
2023-07-31 18:04:32.895640: Epoch 446 
2023-07-31 18:04:32.895734: Current learning rate: 0.00059 
2023-07-31 18:05:31.460762: train_loss -0.3264 
2023-07-31 18:05:31.460927: val_loss -0.3278 
2023-07-31 18:05:31.460987: Pseudo dice [0.8435] 
2023-07-31 18:05:31.461043: Epoch time: 58.57 s 
2023-07-31 18:05:32.479256:  
2023-07-31 18:05:32.479372: Epoch 447 
2023-07-31 18:05:32.479453: Current learning rate: 0.00059 
2023-07-31 18:06:37.091473: train_loss -0.3775 
2023-07-31 18:06:37.091675: val_loss -0.3872 
2023-07-31 18:06:37.091743: Pseudo dice [0.8066] 
2023-07-31 18:06:37.091805: Epoch time: 64.61 s 
2023-07-31 18:06:38.131310:  
2023-07-31 18:06:38.131424: Epoch 448 
2023-07-31 18:06:38.131510: Current learning rate: 0.00059 
2023-07-31 18:07:48.714668: train_loss -0.35 
2023-07-31 18:07:48.714865: val_loss -0.411 
2023-07-31 18:07:48.714953: Pseudo dice [0.8591] 
2023-07-31 18:07:48.715049: Epoch time: 70.58 s 
2023-07-31 18:07:49.818801:  
2023-07-31 18:07:49.818919: Epoch 449 
2023-07-31 18:07:49.818997: Current learning rate: 0.00058 
2023-07-31 18:08:58.552416: train_loss -0.3566 
2023-07-31 18:08:58.552591: val_loss -0.2374 
2023-07-31 18:08:58.552657: Pseudo dice [0.7495] 
2023-07-31 18:08:58.552721: Epoch time: 68.73 s 
2023-07-31 18:09:00.122954:  
2023-07-31 18:09:00.123252: Epoch 450 
2023-07-31 18:09:00.123377: Current learning rate: 0.00058 
2023-07-31 18:10:09.195988: train_loss -0.3396 
2023-07-31 18:10:09.196149: val_loss -0.4141 
2023-07-31 18:10:09.196215: Pseudo dice [0.8238] 
2023-07-31 18:10:09.196291: Epoch time: 69.07 s 
2023-07-31 18:10:10.479698:  
2023-07-31 18:10:10.479910: Epoch 451 
2023-07-31 18:10:10.479993: Current learning rate: 0.00058 
2023-07-31 18:11:19.339783: train_loss -0.3176 
2023-07-31 18:11:19.339971: val_loss -0.3518 
2023-07-31 18:11:19.340057: Pseudo dice [0.8055] 
2023-07-31 18:11:19.340138: Epoch time: 68.86 s 
2023-07-31 18:11:20.398810:  
2023-07-31 18:11:20.398932: Epoch 452 
2023-07-31 18:11:20.399014: Current learning rate: 0.00058 
2023-07-31 18:12:29.262174: train_loss -0.309 
2023-07-31 18:12:29.262343: val_loss -0.3209 
2023-07-31 18:12:29.262408: Pseudo dice [0.7644] 
2023-07-31 18:12:29.262464: Epoch time: 68.86 s 
2023-07-31 18:12:30.277509:  
2023-07-31 18:12:30.277803: Epoch 453 
2023-07-31 18:12:30.277890: Current learning rate: 0.00058 
2023-07-31 18:13:39.371213: train_loss -0.3268 
2023-07-31 18:13:39.371372: val_loss -0.3636 
2023-07-31 18:13:39.371431: Pseudo dice [0.8584] 
2023-07-31 18:13:39.371493: Epoch time: 69.09 s 
2023-07-31 18:13:40.615476:  
2023-07-31 18:13:40.615601: Epoch 454 
2023-07-31 18:13:40.615680: Current learning rate: 0.00058 
2023-07-31 18:14:48.479050: train_loss -0.3159 
2023-07-31 18:14:48.479223: val_loss -0.2931 
2023-07-31 18:14:48.479284: Pseudo dice [0.8064] 
2023-07-31 18:14:48.479357: Epoch time: 67.86 s 
2023-07-31 18:14:49.562863:  
2023-07-31 18:14:49.562976: Epoch 455 
2023-07-31 18:14:49.563060: Current learning rate: 0.00058 
2023-07-31 18:16:23.410340: train_loss -0.3494 
2023-07-31 18:16:23.410494: val_loss -0.389 
2023-07-31 18:16:23.410555: Pseudo dice [0.8353] 
2023-07-31 18:16:23.410609: Epoch time: 93.85 s 
2023-07-31 18:16:23.410652: Yayy! New best EMA pseudo Dice: 0.802 
2023-07-31 18:16:24.867576:  
2023-07-31 18:16:24.867677: Epoch 456 
2023-07-31 18:16:24.867760: Current learning rate: 0.00058 
2023-07-31 18:17:58.986606: train_loss -0.3325 
2023-07-31 18:17:58.986853: val_loss -0.3546 
2023-07-31 18:17:58.986913: Pseudo dice [0.7662] 
2023-07-31 18:17:58.986969: Epoch time: 94.12 s 
2023-07-31 18:18:00.254270:  
2023-07-31 18:18:00.254395: Epoch 457 
2023-07-31 18:18:00.254494: Current learning rate: 0.00058 
2023-07-31 18:19:34.619315: train_loss -0.325 
2023-07-31 18:19:34.619506: val_loss -0.3753 
2023-07-31 18:19:34.619588: Pseudo dice [0.7625] 
2023-07-31 18:19:34.619648: Epoch time: 94.37 s 
2023-07-31 18:19:35.669481:  
2023-07-31 18:19:35.669600: Epoch 458 
2023-07-31 18:19:35.669679: Current learning rate: 0.00058 
2023-07-31 18:21:13.113541: train_loss -0.3023 
2023-07-31 18:21:13.113708: val_loss -0.3611 
2023-07-31 18:21:13.113769: Pseudo dice [0.8244] 
2023-07-31 18:21:13.113827: Epoch time: 97.44 s 
2023-07-31 18:21:14.165426:  
2023-07-31 18:21:14.165542: Epoch 459 
2023-07-31 18:21:14.165624: Current learning rate: 0.00058 
2023-07-31 18:22:18.428161: train_loss -0.356 
2023-07-31 18:22:18.428330: val_loss -0.3721 
2023-07-31 18:22:18.428391: Pseudo dice [0.7869] 
2023-07-31 18:22:18.428446: Epoch time: 64.26 s 
2023-07-31 18:22:19.444128:  
2023-07-31 18:22:19.444232: Epoch 460 
2023-07-31 18:22:19.444324: Current learning rate: 0.00057 
2023-07-31 18:23:17.550596: train_loss -0.344 
2023-07-31 18:23:17.550769: val_loss -0.3485 
2023-07-31 18:23:17.550831: Pseudo dice [0.7494] 
2023-07-31 18:23:17.550886: Epoch time: 58.11 s 
2023-07-31 18:23:18.567530:  
2023-07-31 18:23:18.567636: Epoch 461 
2023-07-31 18:23:18.567730: Current learning rate: 0.00057 
2023-07-31 18:24:19.366047: train_loss -0.3175 
2023-07-31 18:24:19.366217: val_loss -0.3158 
2023-07-31 18:24:19.366277: Pseudo dice [0.7532] 
2023-07-31 18:24:19.366332: Epoch time: 60.8 s 
2023-07-31 18:24:20.410880:  
2023-07-31 18:24:20.410988: Epoch 462 
2023-07-31 18:24:20.411073: Current learning rate: 0.00057 
2023-07-31 18:25:22.218527: train_loss -0.3216 
2023-07-31 18:25:22.218704: val_loss -0.3338 
2023-07-31 18:25:22.218769: Pseudo dice [0.7658] 
2023-07-31 18:25:22.218837: Epoch time: 61.81 s 
2023-07-31 18:25:23.481055:  
2023-07-31 18:25:23.481339: Epoch 463 
2023-07-31 18:25:23.481457: Current learning rate: 0.00057 
2023-07-31 18:26:28.181931: train_loss -0.327 
2023-07-31 18:26:28.182091: val_loss -0.3108 
2023-07-31 18:26:28.182150: Pseudo dice [0.8445] 
2023-07-31 18:26:28.182204: Epoch time: 64.7 s 
2023-07-31 18:26:29.223544:  
2023-07-31 18:26:29.223669: Epoch 464 
2023-07-31 18:26:29.223759: Current learning rate: 0.00057 
2023-07-31 18:27:33.878457: train_loss -0.3522 
2023-07-31 18:27:33.878613: val_loss -0.3704 
2023-07-31 18:27:33.878675: Pseudo dice [0.8273] 
2023-07-31 18:27:33.878730: Epoch time: 64.66 s 
2023-07-31 18:27:34.937126:  
2023-07-31 18:27:34.937331: Epoch 465 
2023-07-31 18:27:34.937416: Current learning rate: 0.00057 
2023-07-31 18:28:39.514044: train_loss -0.3202 
2023-07-31 18:28:39.514208: val_loss -0.3 
2023-07-31 18:28:39.514284: Pseudo dice [0.807] 
2023-07-31 18:28:39.514345: Epoch time: 64.58 s 
2023-07-31 18:28:40.625518:  
2023-07-31 18:28:40.625632: Epoch 466 
2023-07-31 18:28:40.625710: Current learning rate: 0.00057 
2023-07-31 18:29:45.221862: train_loss -0.327 
2023-07-31 18:29:45.222017: val_loss -0.3238 
2023-07-31 18:29:45.222080: Pseudo dice [0.7984] 
2023-07-31 18:29:45.222135: Epoch time: 64.6 s 
2023-07-31 18:29:46.265985:  
2023-07-31 18:29:46.266115: Epoch 467 
2023-07-31 18:29:46.266201: Current learning rate: 0.00057 
2023-07-31 18:30:51.272202: train_loss -0.3378 
2023-07-31 18:30:51.272363: val_loss -0.2861 
2023-07-31 18:30:51.272424: Pseudo dice [0.8319] 
2023-07-31 18:30:51.272483: Epoch time: 65.01 s 
2023-07-31 18:30:52.319393:  
2023-07-31 18:30:52.319505: Epoch 468 
2023-07-31 18:30:52.319586: Current learning rate: 0.00057 
2023-07-31 18:31:56.674948: train_loss -0.3474 
2023-07-31 18:31:56.675187: val_loss -0.3071 
2023-07-31 18:31:56.675247: Pseudo dice [0.7899] 
2023-07-31 18:31:56.675303: Epoch time: 64.36 s 
2023-07-31 18:31:57.934639:  
2023-07-31 18:31:57.934754: Epoch 469 
2023-07-31 18:31:57.934839: Current learning rate: 0.00057 
2023-07-31 18:33:02.267001: train_loss -0.3544 
2023-07-31 18:33:02.267194: val_loss -0.2859 
2023-07-31 18:33:02.267256: Pseudo dice [0.7309] 
2023-07-31 18:33:02.267313: Epoch time: 64.33 s 
2023-07-31 18:33:03.289633:  
2023-07-31 18:33:03.289886: Epoch 470 
2023-07-31 18:33:03.289993: Current learning rate: 0.00056 
2023-07-31 18:34:07.827306: train_loss -0.3542 
2023-07-31 18:34:07.827479: val_loss -0.3258 
2023-07-31 18:34:07.827557: Pseudo dice [0.7308] 
2023-07-31 18:34:07.827637: Epoch time: 64.54 s 
2023-07-31 18:34:08.888977:  
2023-07-31 18:34:08.889095: Epoch 471 
2023-07-31 18:34:08.889176: Current learning rate: 0.00056 
2023-07-31 18:35:13.379469: train_loss -0.338 
2023-07-31 18:35:13.379633: val_loss -0.3834 
2023-07-31 18:35:13.379694: Pseudo dice [0.7731] 
2023-07-31 18:35:13.379770: Epoch time: 64.49 s 
2023-07-31 18:35:14.442102:  
2023-07-31 18:35:14.442291: Epoch 472 
2023-07-31 18:35:14.442370: Current learning rate: 0.00056 
2023-07-31 18:36:18.336124: train_loss -0.3486 
2023-07-31 18:36:18.336288: val_loss -0.3303 
2023-07-31 18:36:18.336346: Pseudo dice [0.7893] 
2023-07-31 18:36:18.336400: Epoch time: 63.89 s 
2023-07-31 18:36:19.388934:  
2023-07-31 18:36:19.389110: Epoch 473 
2023-07-31 18:36:19.389188: Current learning rate: 0.00056 
2023-07-31 18:37:15.201261: train_loss -0.3536 
2023-07-31 18:37:15.201430: val_loss -0.3468 
2023-07-31 18:37:15.201490: Pseudo dice [0.8668] 
2023-07-31 18:37:15.201546: Epoch time: 55.81 s 
2023-07-31 18:37:16.435181:  
2023-07-31 18:37:16.435284: Epoch 474 
2023-07-31 18:37:16.435378: Current learning rate: 0.00056 
2023-07-31 18:38:12.347758: train_loss -0.3229 
2023-07-31 18:38:12.347916: val_loss -0.3538 
2023-07-31 18:38:12.347977: Pseudo dice [0.7867] 
2023-07-31 18:38:12.348032: Epoch time: 55.91 s 
2023-07-31 18:38:13.376530:  
2023-07-31 18:38:13.376630: Epoch 475 
2023-07-31 18:38:13.376724: Current learning rate: 0.00056 
2023-07-31 18:39:09.345373: train_loss -0.3177 
2023-07-31 18:39:09.345548: val_loss -0.3358 
2023-07-31 18:39:09.345610: Pseudo dice [0.8106] 
2023-07-31 18:39:09.345666: Epoch time: 55.97 s 
2023-07-31 18:39:10.373867:  
2023-07-31 18:39:10.373972: Epoch 476 
2023-07-31 18:39:10.374065: Current learning rate: 0.00056 
2023-07-31 18:40:06.145955: train_loss -0.3247 
2023-07-31 18:40:06.146112: val_loss -0.3577 
2023-07-31 18:40:06.146170: Pseudo dice [0.8864] 
2023-07-31 18:40:06.146223: Epoch time: 55.77 s 
2023-07-31 18:40:06.146267: Yayy! New best EMA pseudo Dice: 0.8038 
2023-07-31 18:40:07.542681:  
2023-07-31 18:40:07.542954: Epoch 477 
2023-07-31 18:40:07.543146: Current learning rate: 0.00056 
2023-07-31 18:41:03.291307: train_loss -0.3547 
2023-07-31 18:41:03.291476: val_loss -0.3639 
2023-07-31 18:41:03.291548: Pseudo dice [0.8304] 
2023-07-31 18:41:03.291603: Epoch time: 55.75 s 
2023-07-31 18:41:03.291656: Yayy! New best EMA pseudo Dice: 0.8064 
2023-07-31 18:41:04.668211:  
2023-07-31 18:41:04.668419: Epoch 478 
2023-07-31 18:41:04.668499: Current learning rate: 0.00056 
2023-07-31 18:42:04.536079: train_loss -0.3318 
2023-07-31 18:42:04.536240: val_loss -0.3023 
2023-07-31 18:42:04.536298: Pseudo dice [0.8609] 
2023-07-31 18:42:04.536351: Epoch time: 59.87 s 
2023-07-31 18:42:04.536396: Yayy! New best EMA pseudo Dice: 0.8119 
2023-07-31 18:42:05.980292:  
2023-07-31 18:42:05.980408: Epoch 479 
2023-07-31 18:42:05.980490: Current learning rate: 0.00056 
2023-07-31 18:43:10.093777: train_loss -0.2957 
2023-07-31 18:43:10.093939: val_loss -0.298 
2023-07-31 18:43:10.094001: Pseudo dice [0.7347] 
2023-07-31 18:43:10.094059: Epoch time: 64.11 s 
2023-07-31 18:43:11.202966:  
2023-07-31 18:43:11.203085: Epoch 480 
2023-07-31 18:43:11.203166: Current learning rate: 0.00056 
2023-07-31 18:44:15.172983: train_loss -0.3351 
2023-07-31 18:44:15.173275: val_loss -0.3283 
2023-07-31 18:44:15.173344: Pseudo dice [0.8062] 
2023-07-31 18:44:15.173426: Epoch time: 63.97 s 
2023-07-31 18:44:16.411976:  
2023-07-31 18:44:16.412107: Epoch 481 
2023-07-31 18:44:16.412192: Current learning rate: 0.00055 
2023-07-31 18:45:20.266834: train_loss -0.3348 
2023-07-31 18:45:20.266989: val_loss -0.3017 
2023-07-31 18:45:20.267047: Pseudo dice [0.7413] 
2023-07-31 18:45:20.267118: Epoch time: 63.86 s 
2023-07-31 18:45:21.342058:  
2023-07-31 18:45:21.342177: Epoch 482 
2023-07-31 18:45:21.342257: Current learning rate: 0.00055 
2023-07-31 18:46:25.208179: train_loss -0.3719 
2023-07-31 18:46:25.208340: val_loss -0.2622 
2023-07-31 18:46:25.208399: Pseudo dice [0.7078] 
2023-07-31 18:46:25.208456: Epoch time: 63.87 s 
2023-07-31 18:46:26.336391:  
2023-07-31 18:46:26.336498: Epoch 483 
2023-07-31 18:46:26.336576: Current learning rate: 0.00055 
2023-07-31 18:47:30.464128: train_loss -0.3349 
2023-07-31 18:47:30.464297: val_loss -0.357 
2023-07-31 18:47:30.464358: Pseudo dice [0.7756] 
2023-07-31 18:47:30.464415: Epoch time: 64.13 s 
2023-07-31 18:47:31.582884:  
2023-07-31 18:47:31.583140: Epoch 484 
2023-07-31 18:47:31.583231: Current learning rate: 0.00055 
2023-07-31 18:48:35.487779: train_loss -0.3172 
2023-07-31 18:48:35.487940: val_loss -0.3535 
2023-07-31 18:48:35.488000: Pseudo dice [0.8081] 
2023-07-31 18:48:35.488055: Epoch time: 63.91 s 
2023-07-31 18:48:36.526604:  
2023-07-31 18:48:36.526730: Epoch 485 
2023-07-31 18:48:36.526811: Current learning rate: 0.00055 
2023-07-31 18:49:40.387348: train_loss -0.3261 
2023-07-31 18:49:40.387517: val_loss -0.3379 
2023-07-31 18:49:40.387577: Pseudo dice [0.7179] 
2023-07-31 18:49:40.387631: Epoch time: 63.86 s 
2023-07-31 18:49:41.708592:  
2023-07-31 18:49:41.708830: Epoch 486 
2023-07-31 18:49:41.708922: Current learning rate: 0.00055 
2023-07-31 18:50:45.380490: train_loss -0.3364 
2023-07-31 18:50:45.380657: val_loss -0.3563 
2023-07-31 18:50:45.380717: Pseudo dice [0.7902] 
2023-07-31 18:50:45.380772: Epoch time: 63.67 s 
2023-07-31 18:50:46.427654:  
2023-07-31 18:50:46.427778: Epoch 487 
2023-07-31 18:50:46.427860: Current learning rate: 0.00055 
2023-07-31 18:51:50.146739: train_loss -0.2913 
2023-07-31 18:51:50.146940: val_loss -0.3477 
2023-07-31 18:51:50.147011: Pseudo dice [0.7707] 
2023-07-31 18:51:50.147075: Epoch time: 63.72 s 
2023-07-31 18:51:51.249038:  
2023-07-31 18:51:51.249148: Epoch 488 
2023-07-31 18:51:51.249227: Current learning rate: 0.00055 
2023-07-31 18:52:55.366377: train_loss -0.3247 
2023-07-31 18:52:55.366547: val_loss -0.3334 
2023-07-31 18:52:55.366608: Pseudo dice [0.7805] 
2023-07-31 18:52:55.366663: Epoch time: 64.12 s 
2023-07-31 18:52:56.431014:  
2023-07-31 18:52:56.431124: Epoch 489 
2023-07-31 18:52:56.431219: Current learning rate: 0.00055 
2023-07-31 18:54:00.719575: train_loss -0.3513 
2023-07-31 18:54:00.719736: val_loss -0.3237 
2023-07-31 18:54:00.719794: Pseudo dice [0.8226] 
2023-07-31 18:54:00.719849: Epoch time: 64.29 s 
2023-07-31 18:54:01.817394:  
2023-07-31 18:54:01.817751: Epoch 490 
2023-07-31 18:54:01.817849: Current learning rate: 0.00055 
2023-07-31 18:55:06.178506: train_loss -0.3486 
2023-07-31 18:55:06.178658: val_loss -0.266 
2023-07-31 18:55:06.178719: Pseudo dice [0.6047] 
2023-07-31 18:55:06.178771: Epoch time: 64.36 s 
2023-07-31 18:55:07.330550:  
2023-07-31 18:55:07.330925: Epoch 491 
2023-07-31 18:55:07.331073: Current learning rate: 0.00054 
2023-07-31 18:56:11.586037: train_loss -0.3445 
2023-07-31 18:56:11.586203: val_loss -0.3085 
2023-07-31 18:56:11.586264: Pseudo dice [0.7586] 
2023-07-31 18:56:11.586329: Epoch time: 64.26 s 
2023-07-31 18:56:12.815174:  
2023-07-31 18:56:12.815293: Epoch 492 
2023-07-31 18:56:12.815377: Current learning rate: 0.00054 
2023-07-31 18:57:17.226007: train_loss -0.3581 
2023-07-31 18:57:17.226177: val_loss -0.3992 
2023-07-31 18:57:17.226253: Pseudo dice [0.8255] 
2023-07-31 18:57:17.226312: Epoch time: 64.41 s 
2023-07-31 18:57:18.342797:  
2023-07-31 18:57:18.342911: Epoch 493 
2023-07-31 18:57:18.343005: Current learning rate: 0.00054 
2023-07-31 18:58:22.306188: train_loss -0.377 
2023-07-31 18:58:22.306359: val_loss -0.3149 
2023-07-31 18:58:22.306420: Pseudo dice [0.875] 
2023-07-31 18:58:22.306476: Epoch time: 63.96 s 
2023-07-31 18:58:23.447935:  
2023-07-31 18:58:23.455584: Epoch 494 
2023-07-31 18:58:23.455699: Current learning rate: 0.00054 
2023-07-31 18:59:52.320743: train_loss -0.3366 
2023-07-31 18:59:52.320902: val_loss -0.3223 
2023-07-31 18:59:52.320962: Pseudo dice [0.6802] 
2023-07-31 18:59:52.321017: Epoch time: 88.87 s 
2023-07-31 18:59:53.515175:  
2023-07-31 18:59:53.515386: Epoch 495 
2023-07-31 18:59:53.515474: Current learning rate: 0.00054 
2023-07-31 19:01:21.627682: train_loss -0.3478 
2023-07-31 19:01:21.627842: val_loss -0.3846 
2023-07-31 19:01:21.627902: Pseudo dice [0.7496] 
2023-07-31 19:01:21.627960: Epoch time: 88.11 s 
2023-07-31 19:01:22.672628:  
2023-07-31 19:01:22.672852: Epoch 496 
2023-07-31 19:01:22.672944: Current learning rate: 0.00054 
2023-07-31 19:02:50.956874: train_loss -0.3487 
2023-07-31 19:02:50.957046: val_loss -0.3034 
2023-07-31 19:02:50.965516: Pseudo dice [0.8271] 
2023-07-31 19:02:50.965707: Epoch time: 88.29 s 
2023-07-31 19:02:52.119282:  
2023-07-31 19:02:52.119495: Epoch 497 
2023-07-31 19:02:52.119581: Current learning rate: 0.00054 
2023-07-31 19:04:20.169519: train_loss -0.3508 
2023-07-31 19:04:20.169679: val_loss -0.3193 
2023-07-31 19:04:20.169743: Pseudo dice [0.8398] 
2023-07-31 19:04:20.169797: Epoch time: 88.05 s 
2023-07-31 19:04:21.461396:  
2023-07-31 19:04:21.461521: Epoch 498 
2023-07-31 19:04:21.461615: Current learning rate: 0.00054 
2023-07-31 19:05:49.235016: train_loss -0.339 
2023-07-31 19:05:49.235210: val_loss -0.3123 
2023-07-31 19:05:49.235275: Pseudo dice [0.7728] 
2023-07-31 19:05:49.235335: Epoch time: 87.77 s 
2023-07-31 19:05:50.278609:  
2023-07-31 19:05:50.278715: Epoch 499 
2023-07-31 19:05:50.278826: Current learning rate: 0.00054 
2023-07-31 19:07:17.907545: train_loss -0.3491 
2023-07-31 19:07:17.907788: val_loss -0.3395 
2023-07-31 19:07:17.907895: Pseudo dice [0.8634] 
2023-07-31 19:07:17.907998: Epoch time: 87.63 s 
2023-07-31 19:07:19.264401:  
2023-07-31 19:07:19.264517: Epoch 500 
2023-07-31 19:07:19.264597: Current learning rate: 0.00054 
2023-07-31 19:08:47.046864: train_loss -0.3412 
2023-07-31 19:08:47.047015: val_loss -0.3305 
2023-07-31 19:08:47.047072: Pseudo dice [0.7917] 
2023-07-31 19:08:47.047127: Epoch time: 87.78 s 
2023-07-31 19:08:48.090879:  
2023-07-31 19:08:48.091192: Epoch 501 
2023-07-31 19:08:48.091395: Current learning rate: 0.00053 
2023-07-31 19:10:15.999242: train_loss -0.3175 
2023-07-31 19:10:15.999414: val_loss -0.3461 
2023-07-31 19:10:15.999474: Pseudo dice [0.8789] 
2023-07-31 19:10:15.999538: Epoch time: 87.91 s 
2023-07-31 19:10:17.029963:  
2023-07-31 19:10:17.030086: Epoch 502 
2023-07-31 19:10:17.030166: Current learning rate: 0.00053 
2023-07-31 19:11:25.803755: train_loss -0.3613 
2023-07-31 19:11:25.803915: val_loss -0.3047 
2023-07-31 19:11:25.803974: Pseudo dice [0.7032] 
2023-07-31 19:11:25.804029: Epoch time: 68.77 s 
2023-07-31 19:11:26.868232:  
2023-07-31 19:11:26.868346: Epoch 503 
2023-07-31 19:11:26.868542: Current learning rate: 0.00053 
2023-07-31 19:12:22.444594: train_loss -0.3118 
2023-07-31 19:12:22.444749: val_loss -0.316 
2023-07-31 19:12:22.444804: Pseudo dice [0.8125] 
2023-07-31 19:12:22.444857: Epoch time: 55.58 s 
2023-07-31 19:12:23.471548:  
2023-07-31 19:12:23.471678: Epoch 504 
2023-07-31 19:12:23.471757: Current learning rate: 0.00053 
2023-07-31 19:13:19.046509: train_loss -0.3383 
2023-07-31 19:13:19.046676: val_loss -0.33 
2023-07-31 19:13:19.046733: Pseudo dice [0.8137] 
2023-07-31 19:13:19.046787: Epoch time: 55.58 s 
2023-07-31 19:13:20.106393:  
2023-07-31 19:13:20.106498: Epoch 505 
2023-07-31 19:13:20.106574: Current learning rate: 0.00053 
2023-07-31 19:14:15.654409: train_loss -0.3622 
2023-07-31 19:14:15.654566: val_loss -0.3161 
2023-07-31 19:14:15.654626: Pseudo dice [0.7424] 
2023-07-31 19:14:15.654680: Epoch time: 55.55 s 
2023-07-31 19:14:16.688636:  
2023-07-31 19:14:16.688748: Epoch 506 
2023-07-31 19:14:16.688836: Current learning rate: 0.00053 
2023-07-31 19:15:12.207362: train_loss -0.3037 
2023-07-31 19:15:12.207644: val_loss -0.2991 
2023-07-31 19:15:12.207710: Pseudo dice [0.817] 
2023-07-31 19:15:12.207765: Epoch time: 55.52 s 
2023-07-31 19:15:13.257887:  
2023-07-31 19:15:13.257991: Epoch 507 
2023-07-31 19:15:13.258083: Current learning rate: 0.00053 
2023-07-31 19:16:08.845365: train_loss -0.3366 
2023-07-31 19:16:08.845549: val_loss -0.378 
2023-07-31 19:16:08.845608: Pseudo dice [0.8627] 
2023-07-31 19:16:08.845661: Epoch time: 55.59 s 
2023-07-31 19:16:09.905563:  
2023-07-31 19:16:09.905665: Epoch 508 
2023-07-31 19:16:09.905743: Current learning rate: 0.00053 
2023-07-31 19:17:05.507689: train_loss -0.3416 
2023-07-31 19:17:05.507852: val_loss -0.4202 
2023-07-31 19:17:05.507911: Pseudo dice [0.8207] 
2023-07-31 19:17:05.507965: Epoch time: 55.6 s 
2023-07-31 19:17:06.683882:  
2023-07-31 19:17:06.683992: Epoch 509 
2023-07-31 19:17:06.684073: Current learning rate: 0.00053 
2023-07-31 19:18:02.303870: train_loss -0.3599 
2023-07-31 19:18:02.304034: val_loss -0.3276 
2023-07-31 19:18:02.304096: Pseudo dice [0.7789] 
2023-07-31 19:18:02.304152: Epoch time: 55.62 s 
2023-07-31 19:18:03.351623:  
2023-07-31 19:18:03.351723: Epoch 510 
2023-07-31 19:18:03.351815: Current learning rate: 0.00053 
2023-07-31 19:18:59.918774: train_loss -0.3108 
2023-07-31 19:18:59.918935: val_loss -0.389 
2023-07-31 19:18:59.919010: Pseudo dice [0.8444] 
2023-07-31 19:18:59.919065: Epoch time: 56.57 s 
2023-07-31 19:19:01.015498:  
2023-07-31 19:19:01.015618: Epoch 511 
2023-07-31 19:19:01.015697: Current learning rate: 0.00053 
2023-07-31 19:20:30.344124: train_loss -0.335 
2023-07-31 19:20:30.344293: val_loss -0.2967 
2023-07-31 19:20:30.344354: Pseudo dice [0.8366] 
2023-07-31 19:20:30.344420: Epoch time: 89.33 s 
2023-07-31 19:20:31.408286:  
2023-07-31 19:20:31.408483: Epoch 512 
2023-07-31 19:20:31.408563: Current learning rate: 0.00052 
2023-07-31 19:21:59.169520: train_loss -0.3208 
2023-07-31 19:21:59.169719: val_loss -0.3218 
2023-07-31 19:21:59.169784: Pseudo dice [0.6873] 
2023-07-31 19:21:59.169846: Epoch time: 87.76 s 
2023-07-31 19:22:00.274541:  
2023-07-31 19:22:00.274666: Epoch 513 
2023-07-31 19:22:00.274748: Current learning rate: 0.00052 
2023-07-31 19:23:28.200292: train_loss -0.3402 
2023-07-31 19:23:28.200480: val_loss -0.3706 
2023-07-31 19:23:28.200545: Pseudo dice [0.7042] 
2023-07-31 19:23:28.200604: Epoch time: 87.93 s 
2023-07-31 19:23:29.267024:  
2023-07-31 19:23:29.267228: Epoch 514 
2023-07-31 19:23:29.267323: Current learning rate: 0.00052 
2023-07-31 19:24:57.310725: train_loss -0.3276 
2023-07-31 19:24:57.310906: val_loss -0.394 
2023-07-31 19:24:57.310973: Pseudo dice [0.7431] 
2023-07-31 19:24:57.311032: Epoch time: 88.04 s 
2023-07-31 19:24:58.522221:  
2023-07-31 19:24:58.522328: Epoch 515 
2023-07-31 19:24:58.522539: Current learning rate: 0.00052 
2023-07-31 19:26:26.085768: train_loss -0.3295 
2023-07-31 19:26:26.085946: val_loss -0.2671 
2023-07-31 19:26:26.086009: Pseudo dice [0.8425] 
2023-07-31 19:26:26.086070: Epoch time: 87.56 s 
2023-07-31 19:26:27.131653:  
2023-07-31 19:26:27.131938: Epoch 516 
2023-07-31 19:26:27.132085: Current learning rate: 0.00052 
2023-07-31 19:27:54.891209: train_loss -0.3662 
2023-07-31 19:27:54.891399: val_loss -0.3136 
2023-07-31 19:27:54.891465: Pseudo dice [0.8068] 
2023-07-31 19:27:54.891536: Epoch time: 87.76 s 
2023-07-31 19:27:55.956097:  
2023-07-31 19:27:55.956207: Epoch 517 
2023-07-31 19:27:55.956296: Current learning rate: 0.00052 
2023-07-31 19:29:23.859666: train_loss -0.3444 
2023-07-31 19:29:23.859844: val_loss -0.3458 
2023-07-31 19:29:23.859906: Pseudo dice [0.8051] 
2023-07-31 19:29:23.859968: Epoch time: 87.9 s 
2023-07-31 19:29:24.933165:  
2023-07-31 19:29:24.933266: Epoch 518 
2023-07-31 19:29:24.933359: Current learning rate: 0.00052 
2023-07-31 19:30:52.734257: train_loss -0.321 
2023-07-31 19:30:52.734421: val_loss -0.2693 
2023-07-31 19:30:52.734483: Pseudo dice [0.7643] 
2023-07-31 19:30:52.734539: Epoch time: 87.8 s 
2023-07-31 19:30:53.775895:  
2023-07-31 19:30:53.776000: Epoch 519 
2023-07-31 19:30:53.776077: Current learning rate: 0.00052 
2023-07-31 19:32:21.068238: train_loss -0.3615 
2023-07-31 19:32:21.068391: val_loss -0.2797 
2023-07-31 19:32:21.068451: Pseudo dice [0.7587] 
2023-07-31 19:32:21.068506: Epoch time: 87.29 s 
2023-07-31 19:32:22.329478:  
2023-07-31 19:32:22.329582: Epoch 520 
2023-07-31 19:32:22.329681: Current learning rate: 0.00052 
2023-07-31 19:33:50.712764: train_loss -0.3447 
2023-07-31 19:33:50.712920: val_loss -0.3271 
2023-07-31 19:33:50.712980: Pseudo dice [0.7636] 
2023-07-31 19:33:50.713036: Epoch time: 88.38 s 
2023-07-31 19:33:51.801758:  
2023-07-31 19:33:51.801873: Epoch 521 
2023-07-31 19:33:51.801949: Current learning rate: 0.00052 
2023-07-31 19:35:20.323545: train_loss -0.3777 
2023-07-31 19:35:20.323709: val_loss -0.2492 
2023-07-31 19:35:20.323771: Pseudo dice [0.6651] 
2023-07-31 19:35:20.323827: Epoch time: 88.52 s 
2023-07-31 19:35:21.432313:  
2023-07-31 19:35:21.432418: Epoch 522 
2023-07-31 19:35:21.432500: Current learning rate: 0.00051 
2023-07-31 19:36:49.425667: train_loss -0.3438 
2023-07-31 19:36:49.425848: val_loss -0.345 
2023-07-31 19:36:49.425908: Pseudo dice [0.7909] 
2023-07-31 19:36:49.425965: Epoch time: 87.99 s 
2023-07-31 19:36:50.460788:  
2023-07-31 19:36:50.461005: Epoch 523 
2023-07-31 19:36:50.461103: Current learning rate: 0.00051 
2023-07-31 19:38:18.575565: train_loss -0.3395 
2023-07-31 19:38:18.575721: val_loss -0.327 
2023-07-31 19:38:18.575780: Pseudo dice [0.7495] 
2023-07-31 19:38:18.575835: Epoch time: 88.12 s 
2023-07-31 19:38:19.614899:  
2023-07-31 19:38:19.615028: Epoch 524 
2023-07-31 19:38:19.615110: Current learning rate: 0.00051 
2023-07-31 19:39:47.859647: train_loss -0.3781 
2023-07-31 19:39:47.859810: val_loss -0.3274 
2023-07-31 19:39:47.859870: Pseudo dice [0.7986] 
2023-07-31 19:39:47.859925: Epoch time: 88.25 s 
2023-07-31 19:39:48.937252:  
2023-07-31 19:39:48.937488: Epoch 525 
2023-07-31 19:39:48.937574: Current learning rate: 0.00051 
2023-07-31 19:41:17.234812: train_loss -0.344 
2023-07-31 19:41:17.234982: val_loss -0.4102 
2023-07-31 19:41:17.235039: Pseudo dice [0.7912] 
2023-07-31 19:41:17.235094: Epoch time: 88.3 s 
2023-07-31 19:41:18.445428:  
2023-07-31 19:41:18.445552: Epoch 526 
2023-07-31 19:41:18.445634: Current learning rate: 0.00051 
2023-07-31 19:42:46.670856: train_loss -0.3251 
2023-07-31 19:42:46.671031: val_loss -0.3034 
2023-07-31 19:42:46.671096: Pseudo dice [0.7473] 
2023-07-31 19:42:46.671150: Epoch time: 88.23 s 
2023-07-31 19:42:47.730968:  
2023-07-31 19:42:47.731090: Epoch 527 
2023-07-31 19:42:47.731175: Current learning rate: 0.00051 
2023-07-31 19:44:14.414283: train_loss -0.36 
2023-07-31 19:44:14.414458: val_loss -0.407 
2023-07-31 19:44:14.414516: Pseudo dice [0.8228] 
2023-07-31 19:44:14.414590: Epoch time: 86.68 s 
2023-07-31 19:44:15.504774:  
2023-07-31 19:44:15.504892: Epoch 528 
2023-07-31 19:44:15.504988: Current learning rate: 0.00051 
2023-07-31 19:45:44.644456: train_loss -0.3176 
2023-07-31 19:45:44.644610: val_loss -0.415 
2023-07-31 19:45:44.644670: Pseudo dice [0.8379] 
2023-07-31 19:45:44.644724: Epoch time: 89.14 s 
2023-07-31 19:45:45.744322:  
2023-07-31 19:45:45.744700: Epoch 529 
2023-07-31 19:45:45.744792: Current learning rate: 0.00051 
2023-07-31 19:47:14.086341: train_loss -0.3624 
2023-07-31 19:47:14.086519: val_loss -0.3635 
2023-07-31 19:47:14.086581: Pseudo dice [0.8268] 
2023-07-31 19:47:14.086636: Epoch time: 88.34 s 
2023-07-31 19:47:15.185940:  
2023-07-31 19:47:15.186046: Epoch 530 
2023-07-31 19:47:15.186141: Current learning rate: 0.00051 
2023-07-31 19:48:43.232196: train_loss -0.3422 
2023-07-31 19:48:43.232358: val_loss -0.3461 
2023-07-31 19:48:43.232418: Pseudo dice [0.8637] 
2023-07-31 19:48:43.232473: Epoch time: 88.05 s 
2023-07-31 19:48:44.276112:  
2023-07-31 19:48:44.276212: Epoch 531 
2023-07-31 19:48:44.276288: Current learning rate: 0.00051 
2023-07-31 19:49:39.783184: train_loss -0.3177 
2023-07-31 19:49:39.783353: val_loss -0.3107 
2023-07-31 19:49:39.783411: Pseudo dice [0.7908] 
2023-07-31 19:49:39.783465: Epoch time: 55.51 s 
2023-07-31 19:49:40.988785:  
2023-07-31 19:49:40.988908: Epoch 532 
2023-07-31 19:49:40.989002: Current learning rate: 0.0005 
2023-07-31 19:50:36.646124: train_loss -0.3488 
2023-07-31 19:50:36.646289: val_loss -0.3141 
2023-07-31 19:50:36.646351: Pseudo dice [0.7539] 
2023-07-31 19:50:36.646406: Epoch time: 55.66 s 
2023-07-31 19:50:37.688891:  
2023-07-31 19:50:37.688994: Epoch 533 
2023-07-31 19:50:37.689085: Current learning rate: 0.0005 
2023-07-31 19:51:33.374992: train_loss -0.4019 
2023-07-31 19:51:33.375157: val_loss -0.2936 
2023-07-31 19:51:33.375219: Pseudo dice [0.7277] 
2023-07-31 19:51:33.375273: Epoch time: 55.69 s 
2023-07-31 19:51:34.405916:  
2023-07-31 19:51:34.406085: Epoch 534 
2023-07-31 19:51:34.406182: Current learning rate: 0.0005 
2023-07-31 19:52:30.014282: train_loss -0.3642 
2023-07-31 19:52:30.014460: val_loss -0.37 
2023-07-31 19:52:30.014525: Pseudo dice [0.8205] 
2023-07-31 19:52:30.014581: Epoch time: 55.61 s 
2023-07-31 19:52:31.039445:  
2023-07-31 19:52:31.039690: Epoch 535 
2023-07-31 19:52:31.039771: Current learning rate: 0.0005 
2023-07-31 19:53:26.632392: train_loss -0.3341 
2023-07-31 19:53:26.632545: val_loss -0.3387 
2023-07-31 19:53:26.632601: Pseudo dice [0.8803] 
2023-07-31 19:53:26.632655: Epoch time: 55.59 s 
2023-07-31 19:53:27.665837:  
2023-07-31 19:53:27.665938: Epoch 536 
2023-07-31 19:53:27.666030: Current learning rate: 0.0005 
2023-07-31 19:54:23.225018: train_loss -0.3386 
2023-07-31 19:54:23.225189: val_loss -0.4004 
2023-07-31 19:54:23.225251: Pseudo dice [0.8001] 
2023-07-31 19:54:23.225306: Epoch time: 55.56 s 
2023-07-31 19:54:24.285988:  
2023-07-31 19:54:24.286185: Epoch 537 
2023-07-31 19:54:24.286264: Current learning rate: 0.0005 
2023-07-31 19:55:19.928892: train_loss -0.345 
2023-07-31 19:55:19.929079: val_loss -0.3064 
2023-07-31 19:55:19.929139: Pseudo dice [0.8439] 
2023-07-31 19:55:19.929193: Epoch time: 55.64 s 
2023-07-31 19:55:21.161506:  
2023-07-31 19:55:21.161707: Epoch 538 
2023-07-31 19:55:21.161791: Current learning rate: 0.0005 
2023-07-31 19:56:16.760986: train_loss -0.3477 
2023-07-31 19:56:16.761143: val_loss -0.3164 
2023-07-31 19:56:16.761203: Pseudo dice [0.8553] 
2023-07-31 19:56:16.761259: Epoch time: 55.6 s 
2023-07-31 19:56:17.822568:  
2023-07-31 19:56:17.822963: Epoch 539 
2023-07-31 19:56:17.823047: Current learning rate: 0.0005 
2023-07-31 19:57:30.997480: train_loss -0.3313 
2023-07-31 19:57:30.997635: val_loss -0.3546 
2023-07-31 19:57:30.997709: Pseudo dice [0.8031] 
2023-07-31 19:57:30.997764: Epoch time: 73.18 s 
2023-07-31 19:57:32.038726:  
2023-07-31 19:57:32.038944: Epoch 540 
2023-07-31 19:57:32.039031: Current learning rate: 0.0005 
2023-07-31 19:59:00.371651: train_loss -0.3067 
2023-07-31 19:59:00.371815: val_loss -0.297 
2023-07-31 19:59:00.371874: Pseudo dice [0.8322] 
2023-07-31 19:59:00.371929: Epoch time: 88.33 s 
2023-07-31 19:59:01.448496:  
2023-07-31 19:59:01.448617: Epoch 541 
2023-07-31 19:59:01.448715: Current learning rate: 0.0005 
2023-07-31 20:00:29.809787: train_loss -0.3192 
2023-07-31 20:00:29.809939: val_loss -0.3072 
2023-07-31 20:00:29.810005: Pseudo dice [0.7274] 
2023-07-31 20:00:29.810059: Epoch time: 88.36 s 
2023-07-31 20:00:30.910974:  
2023-07-31 20:00:30.911094: Epoch 542 
2023-07-31 20:00:30.911173: Current learning rate: 0.0005 
2023-07-31 20:01:59.026143: train_loss -0.3356 
2023-07-31 20:01:59.026305: val_loss -0.3679 
2023-07-31 20:01:59.026362: Pseudo dice [0.767] 
2023-07-31 20:01:59.026428: Epoch time: 88.12 s 
2023-07-31 20:02:00.125651:  
2023-07-31 20:02:00.125982: Epoch 543 
2023-07-31 20:02:00.126067: Current learning rate: 0.00049 
2023-07-31 20:03:27.751439: train_loss -0.3416 
2023-07-31 20:03:27.751636: val_loss -0.3222 
2023-07-31 20:03:27.751699: Pseudo dice [0.7768] 
2023-07-31 20:03:27.751758: Epoch time: 87.63 s 
2023-07-31 20:03:28.999723:  
2023-07-31 20:03:28.999986: Epoch 544 
2023-07-31 20:03:29.000073: Current learning rate: 0.00049 
2023-07-31 20:04:55.933914: train_loss -0.3172 
2023-07-31 20:04:55.934067: val_loss -0.3758 
2023-07-31 20:04:55.934126: Pseudo dice [0.8029] 
2023-07-31 20:04:55.934180: Epoch time: 86.94 s 
2023-07-31 20:04:57.041316:  
2023-07-31 20:04:57.041696: Epoch 545 
2023-07-31 20:04:57.041861: Current learning rate: 0.00049 
2023-07-31 20:06:27.065207: train_loss -0.3344 
2023-07-31 20:06:27.065379: val_loss -0.3973 
2023-07-31 20:06:27.065450: Pseudo dice [0.8327] 
2023-07-31 20:06:27.065510: Epoch time: 90.02 s 
2023-07-31 20:06:28.103747:  
2023-07-31 20:06:28.103961: Epoch 546 
2023-07-31 20:06:28.104046: Current learning rate: 0.00049 
2023-07-31 20:07:58.067089: train_loss -0.3612 
2023-07-31 20:07:58.067259: val_loss -0.4123 
2023-07-31 20:07:58.067319: Pseudo dice [0.7905] 
2023-07-31 20:07:58.067374: Epoch time: 89.96 s 
2023-07-31 20:07:59.174028:  
2023-07-31 20:07:59.174349: Epoch 547 
2023-07-31 20:07:59.174497: Current learning rate: 0.00049 
2023-07-31 20:09:28.731843: train_loss -0.372 
2023-07-31 20:09:28.732002: val_loss -0.3456 
2023-07-31 20:09:28.732059: Pseudo dice [0.798] 
2023-07-31 20:09:28.732115: Epoch time: 89.56 s 
2023-07-31 20:09:29.793291:  
2023-07-31 20:09:29.793396: Epoch 548 
2023-07-31 20:09:29.793473: Current learning rate: 0.00049 
2023-07-31 20:10:59.496353: train_loss -0.3691 
2023-07-31 20:10:59.496510: val_loss -0.4115 
2023-07-31 20:10:59.496569: Pseudo dice [0.8459] 
2023-07-31 20:10:59.496627: Epoch time: 89.7 s 
2023-07-31 20:11:00.618407:  
2023-07-31 20:11:00.618508: Epoch 549 
2023-07-31 20:11:00.618603: Current learning rate: 0.00049 
2023-07-31 20:12:30.347248: train_loss -0.382 
2023-07-31 20:12:30.347410: val_loss -0.3386 
2023-07-31 20:12:30.347516: Pseudo dice [0.7734] 
2023-07-31 20:12:30.347579: Epoch time: 89.73 s 
2023-07-31 20:12:31.925207:  
2023-07-31 20:12:31.925343: Epoch 550 
2023-07-31 20:12:31.925440: Current learning rate: 0.00049 
2023-07-31 20:14:01.509970: train_loss -0.3275 
2023-07-31 20:14:01.510149: val_loss -0.3303 
2023-07-31 20:14:01.510232: Pseudo dice [0.8249] 
2023-07-31 20:14:01.510292: Epoch time: 89.59 s 
2023-07-31 20:14:02.590676:  
2023-07-31 20:14:02.590910: Epoch 551 
2023-07-31 20:14:02.590997: Current learning rate: 0.00049 
2023-07-31 20:15:32.853733: train_loss -0.3677 
2023-07-31 20:15:32.853888: val_loss -0.2749 
2023-07-31 20:15:32.853944: Pseudo dice [0.7681] 
2023-07-31 20:15:32.853998: Epoch time: 90.26 s 
2023-07-31 20:15:33.920319:  
2023-07-31 20:15:33.920430: Epoch 552 
2023-07-31 20:15:33.920510: Current learning rate: 0.00049 
2023-07-31 20:17:03.846757: train_loss -0.331 
2023-07-31 20:17:03.846915: val_loss -0.4315 
2023-07-31 20:17:03.846971: Pseudo dice [0.8164] 
2023-07-31 20:17:03.847028: Epoch time: 89.93 s 
2023-07-31 20:17:04.929448:  
2023-07-31 20:17:04.929694: Epoch 553 
2023-07-31 20:17:04.929792: Current learning rate: 0.00048 
2023-07-31 20:18:30.989989: train_loss -0.3598 
2023-07-31 20:18:30.990148: val_loss -0.3414 
2023-07-31 20:18:30.990207: Pseudo dice [0.8044] 
2023-07-31 20:18:30.990261: Epoch time: 86.06 s 
2023-07-31 20:18:32.028092:  
2023-07-31 20:18:32.028198: Epoch 554 
2023-07-31 20:18:32.028277: Current learning rate: 0.00048 
2023-07-31 20:19:36.974983: train_loss -0.3532 
2023-07-31 20:19:36.975136: val_loss -0.3312 
2023-07-31 20:19:36.975194: Pseudo dice [0.7963] 
2023-07-31 20:19:36.975247: Epoch time: 64.95 s 
2023-07-31 20:19:38.156488:  
2023-07-31 20:19:38.156588: Epoch 555 
2023-07-31 20:19:38.156671: Current learning rate: 0.00048 
2023-07-31 20:20:33.716393: train_loss -0.3247 
2023-07-31 20:20:33.716563: val_loss -0.3839 
2023-07-31 20:20:33.716625: Pseudo dice [0.8005] 
2023-07-31 20:20:33.716679: Epoch time: 55.56 s 
2023-07-31 20:20:34.746380:  
2023-07-31 20:20:34.746481: Epoch 556 
2023-07-31 20:20:34.746559: Current learning rate: 0.00048 
2023-07-31 20:21:30.361146: train_loss -0.3584 
2023-07-31 20:21:30.361322: val_loss -0.3471 
2023-07-31 20:21:30.361380: Pseudo dice [0.7973] 
2023-07-31 20:21:30.361435: Epoch time: 55.62 s 
2023-07-31 20:21:31.434945:  
2023-07-31 20:21:31.435049: Epoch 557 
2023-07-31 20:21:31.435125: Current learning rate: 0.00048 
2023-07-31 20:22:27.089512: train_loss -0.3481 
2023-07-31 20:22:27.089664: val_loss -0.2777 
2023-07-31 20:22:27.089719: Pseudo dice [0.8033] 
2023-07-31 20:22:27.089773: Epoch time: 55.66 s 
2023-07-31 20:22:28.121986:  
2023-07-31 20:22:28.122086: Epoch 558 
2023-07-31 20:22:28.122164: Current learning rate: 0.00048 
2023-07-31 20:23:23.691655: train_loss -0.3689 
2023-07-31 20:23:23.691891: val_loss -0.3237 
2023-07-31 20:23:23.691967: Pseudo dice [0.8154] 
2023-07-31 20:23:23.692034: Epoch time: 55.57 s 
2023-07-31 20:23:24.725823:  
2023-07-31 20:23:24.725925: Epoch 559 
2023-07-31 20:23:24.726004: Current learning rate: 0.00048 
2023-07-31 20:24:25.514798: train_loss -0.3469 
2023-07-31 20:24:25.514952: val_loss -0.4138 
2023-07-31 20:24:25.515011: Pseudo dice [0.8263] 
2023-07-31 20:24:25.515065: Epoch time: 60.79 s 
2023-07-31 20:24:26.627968:  
2023-07-31 20:24:26.628321: Epoch 560 
2023-07-31 20:24:26.628405: Current learning rate: 0.00048 
2023-07-31 20:25:56.997153: train_loss -0.3266 
2023-07-31 20:25:56.997334: val_loss -0.3546 
2023-07-31 20:25:56.997393: Pseudo dice [0.8549] 
2023-07-31 20:25:56.997448: Epoch time: 90.37 s 
2023-07-31 20:25:58.295802:  
2023-07-31 20:25:58.295998: Epoch 561 
2023-07-31 20:25:58.296083: Current learning rate: 0.00048 
2023-07-31 20:27:31.172192: train_loss -0.3853 
2023-07-31 20:27:31.172359: val_loss -0.3182 
2023-07-31 20:27:31.172421: Pseudo dice [0.7931] 
2023-07-31 20:27:31.172482: Epoch time: 92.88 s 
2023-07-31 20:27:32.234119:  
2023-07-31 20:27:32.234246: Epoch 562 
2023-07-31 20:27:32.234328: Current learning rate: 0.00048 
2023-07-31 20:29:05.035590: train_loss -0.3332 
2023-07-31 20:29:05.035757: val_loss -0.3514 
2023-07-31 20:29:05.035817: Pseudo dice [0.8479] 
2023-07-31 20:29:05.035872: Epoch time: 92.8 s 
2023-07-31 20:29:05.035918: Yayy! New best EMA pseudo Dice: 0.8121 
2023-07-31 20:29:06.470126:  
2023-07-31 20:29:06.470250: Epoch 563 
2023-07-31 20:29:06.470448: Current learning rate: 0.00047 
2023-07-31 20:30:38.845405: train_loss -0.3164 
2023-07-31 20:30:38.845581: val_loss -0.3186 
2023-07-31 20:30:38.845639: Pseudo dice [0.7726] 
2023-07-31 20:30:38.845695: Epoch time: 92.38 s 
2023-07-31 20:30:39.880731:  
2023-07-31 20:30:39.880852: Epoch 564 
2023-07-31 20:30:39.880934: Current learning rate: 0.00047 
2023-07-31 20:32:12.230490: train_loss -0.3083 
2023-07-31 20:32:12.230650: val_loss -0.4314 
2023-07-31 20:32:12.230707: Pseudo dice [0.8173] 
2023-07-31 20:32:12.230763: Epoch time: 92.35 s 
2023-07-31 20:32:13.327891:  
2023-07-31 20:32:13.327999: Epoch 565 
2023-07-31 20:32:13.328081: Current learning rate: 0.00047 
2023-07-31 20:33:46.214665: train_loss -0.3737 
2023-07-31 20:33:46.214817: val_loss -0.4132 
2023-07-31 20:33:46.214890: Pseudo dice [0.84] 
2023-07-31 20:33:46.214944: Epoch time: 92.89 s 
2023-07-31 20:33:46.214988: Yayy! New best EMA pseudo Dice: 0.8122 
2023-07-31 20:33:47.670964:  
2023-07-31 20:33:47.671197: Epoch 566 
2023-07-31 20:33:47.671302: Current learning rate: 0.00047 
2023-07-31 20:35:20.451143: train_loss -0.3329 
2023-07-31 20:35:20.451366: val_loss -0.3964 
2023-07-31 20:35:20.451472: Pseudo dice [0.7722] 
2023-07-31 20:35:20.451585: Epoch time: 92.78 s 
2023-07-31 20:35:21.693246:  
2023-07-31 20:35:21.693365: Epoch 567 
2023-07-31 20:35:21.693450: Current learning rate: 0.00047 
2023-07-31 20:36:54.580991: train_loss -0.3319 
2023-07-31 20:36:54.581148: val_loss -0.3918 
2023-07-31 20:36:54.581209: Pseudo dice [0.7536] 
2023-07-31 20:36:54.581273: Epoch time: 92.89 s 
2023-07-31 20:36:55.646653:  
2023-07-31 20:36:55.646757: Epoch 568 
2023-07-31 20:36:55.646852: Current learning rate: 0.00047 
2023-07-31 20:38:27.788511: train_loss -0.3667 
2023-07-31 20:38:27.788665: val_loss -0.3562 
2023-07-31 20:38:27.788729: Pseudo dice [0.8303] 
2023-07-31 20:38:27.788782: Epoch time: 92.14 s 
2023-07-31 20:38:28.837885:  
2023-07-31 20:38:28.838063: Epoch 569 
2023-07-31 20:38:28.838146: Current learning rate: 0.00047 
2023-07-31 20:39:50.870515: train_loss -0.3624 
2023-07-31 20:39:50.870687: val_loss -0.2788 
2023-07-31 20:39:50.870747: Pseudo dice [0.7846] 
2023-07-31 20:39:50.870800: Epoch time: 82.03 s 
2023-07-31 20:39:51.901539:  
2023-07-31 20:39:51.901639: Epoch 570 
2023-07-31 20:39:51.901730: Current learning rate: 0.00047 
2023-07-31 20:40:47.557415: train_loss -0.3126 
2023-07-31 20:40:47.557715: val_loss -0.3419 
2023-07-31 20:40:47.566039: Pseudo dice [0.7836] 
2023-07-31 20:40:47.566258: Epoch time: 55.66 s 
2023-07-31 20:40:48.633577:  
2023-07-31 20:40:48.633674: Epoch 571 
2023-07-31 20:40:48.633768: Current learning rate: 0.00047 
2023-07-31 20:41:44.412276: train_loss -0.3309 
2023-07-31 20:41:44.412433: val_loss -0.3232 
2023-07-31 20:41:44.412489: Pseudo dice [0.8765] 
2023-07-31 20:41:44.412543: Epoch time: 55.78 s 
2023-07-31 20:41:45.641685:  
2023-07-31 20:41:45.641800: Epoch 572 
2023-07-31 20:41:45.641890: Current learning rate: 0.00047 
2023-07-31 20:42:55.521504: train_loss -0.3327 
2023-07-31 20:42:55.521669: val_loss -0.4144 
2023-07-31 20:42:55.521725: Pseudo dice [0.8681] 
2023-07-31 20:42:55.521780: Epoch time: 69.88 s 
2023-07-31 20:42:55.521824: Yayy! New best EMA pseudo Dice: 0.8148 
2023-07-31 20:42:57.002318:  
2023-07-31 20:42:57.002451: Epoch 573 
2023-07-31 20:42:57.002531: Current learning rate: 0.00046 
2023-07-31 20:44:28.483765: train_loss -0.3289 
2023-07-31 20:44:28.483938: val_loss -0.3889 
2023-07-31 20:44:28.484001: Pseudo dice [0.809] 
2023-07-31 20:44:28.484209: Epoch time: 91.48 s 
2023-07-31 20:44:29.591242:  
2023-07-31 20:44:29.591354: Epoch 574 
2023-07-31 20:44:29.591457: Current learning rate: 0.00046 
2023-07-31 20:46:02.466292: train_loss -0.3163 
2023-07-31 20:46:02.466448: val_loss -0.3122 
2023-07-31 20:46:02.466504: Pseudo dice [0.7654] 
2023-07-31 20:46:02.466558: Epoch time: 92.88 s 
2023-07-31 20:46:03.551422:  
2023-07-31 20:46:03.551563: Epoch 575 
2023-07-31 20:46:03.551645: Current learning rate: 0.00046 
2023-07-31 20:47:36.697007: train_loss -0.315 
2023-07-31 20:47:36.697156: val_loss -0.3725 
2023-07-31 20:47:36.697215: Pseudo dice [0.7193] 
2023-07-31 20:47:36.697269: Epoch time: 93.15 s 
2023-07-31 20:47:37.846570:  
2023-07-31 20:47:37.846700: Epoch 576 
2023-07-31 20:47:37.846784: Current learning rate: 0.00046 
2023-07-31 20:49:10.659108: train_loss -0.2701 
2023-07-31 20:49:10.659277: val_loss -0.3844 
2023-07-31 20:49:10.659334: Pseudo dice [0.8488] 
2023-07-31 20:49:10.659388: Epoch time: 92.81 s 
2023-07-31 20:49:11.885928:  
2023-07-31 20:49:11.886054: Epoch 577 
2023-07-31 20:49:11.886150: Current learning rate: 0.00046 
2023-07-31 20:50:44.156094: train_loss -0.3406 
2023-07-31 20:50:44.156248: val_loss -0.3109 
2023-07-31 20:50:44.156307: Pseudo dice [0.7925] 
2023-07-31 20:50:44.156360: Epoch time: 92.27 s 
2023-07-31 20:50:45.214544:  
2023-07-31 20:50:45.214664: Epoch 578 
2023-07-31 20:50:45.214741: Current learning rate: 0.00046 
2023-07-31 20:52:17.813273: train_loss -0.352 
2023-07-31 20:52:17.813453: val_loss -0.3326 
2023-07-31 20:52:17.813518: Pseudo dice [0.9006] 
2023-07-31 20:52:17.813576: Epoch time: 92.6 s 
2023-07-31 20:52:18.957059:  
2023-07-31 20:52:18.957401: Epoch 579 
2023-07-31 20:52:18.957534: Current learning rate: 0.00046 
2023-07-31 20:53:51.650830: train_loss -0.2979 
2023-07-31 20:53:51.651130: val_loss -0.3394 
2023-07-31 20:53:51.651191: Pseudo dice [0.7624] 
2023-07-31 20:53:51.651247: Epoch time: 92.69 s 
2023-07-31 20:53:52.747495:  
2023-07-31 20:53:52.747645: Epoch 580 
2023-07-31 20:53:52.747724: Current learning rate: 0.00046 
2023-07-31 20:55:25.673917: train_loss -0.3366 
2023-07-31 20:55:25.674090: val_loss -0.4069 
2023-07-31 20:55:25.674148: Pseudo dice [0.843] 
2023-07-31 20:55:25.674204: Epoch time: 92.93 s 
2023-07-31 20:55:26.759834:  
2023-07-31 20:55:26.759974: Epoch 581 
2023-07-31 20:55:26.760064: Current learning rate: 0.00046 
2023-07-31 20:56:59.228044: train_loss -0.3533 
2023-07-31 20:56:59.228203: val_loss -0.3597 
2023-07-31 20:56:59.228259: Pseudo dice [0.7282] 
2023-07-31 20:56:59.228313: Epoch time: 92.47 s 
2023-07-31 20:57:00.322150:  
2023-07-31 20:57:00.322344: Epoch 582 
2023-07-31 20:57:00.322430: Current learning rate: 0.00046 
2023-07-31 20:58:27.138648: train_loss -0.3124 
2023-07-31 20:58:27.138829: val_loss -0.3386 
2023-07-31 20:58:27.138895: Pseudo dice [0.7516] 
2023-07-31 20:58:27.138948: Epoch time: 86.82 s 
2023-07-31 20:58:28.369726:  
2023-07-31 20:58:28.369841: Epoch 583 
2023-07-31 20:58:28.369936: Current learning rate: 0.00046 
2023-07-31 20:59:23.993918: train_loss -0.3275 
2023-07-31 20:59:23.994102: val_loss -0.3702 
2023-07-31 20:59:23.994822: Pseudo dice [0.8341] 
2023-07-31 20:59:23.994873: Epoch time: 55.62 s 
2023-07-31 20:59:25.061552:  
2023-07-31 20:59:25.061654: Epoch 584 
2023-07-31 20:59:25.061742: Current learning rate: 0.00045 
2023-07-31 21:00:20.789072: train_loss -0.3795 
2023-07-31 21:00:20.789236: val_loss -0.3709 
2023-07-31 21:00:20.789312: Pseudo dice [0.834] 
2023-07-31 21:00:20.789367: Epoch time: 55.73 s 
2023-07-31 21:00:21.848320:  
2023-07-31 21:00:21.848428: Epoch 585 
2023-07-31 21:00:21.848523: Current learning rate: 0.00045 
2023-07-31 21:01:25.467186: train_loss -0.3368 
2023-07-31 21:01:25.467381: val_loss -0.3176 
2023-07-31 21:01:25.475829: Pseudo dice [0.8657] 
2023-07-31 21:01:25.475984: Epoch time: 63.62 s 
2023-07-31 21:01:26.589928:  
2023-07-31 21:01:26.590034: Epoch 586 
2023-07-31 21:01:26.590129: Current learning rate: 0.00045 
2023-07-31 21:02:59.180740: train_loss -0.3315 
2023-07-31 21:02:59.180891: val_loss -0.4027 
2023-07-31 21:02:59.180948: Pseudo dice [0.6947] 
2023-07-31 21:02:59.181002: Epoch time: 92.59 s 
2023-07-31 21:03:00.249908:  
2023-07-31 21:03:00.250037: Epoch 587 
2023-07-31 21:03:00.250121: Current learning rate: 0.00045 
2023-07-31 21:04:33.511340: train_loss -0.3659 
2023-07-31 21:04:33.511506: val_loss -0.3789 
2023-07-31 21:04:33.511566: Pseudo dice [0.7845] 
2023-07-31 21:04:33.511624: Epoch time: 93.26 s 
2023-07-31 21:04:34.599886:  
2023-07-31 21:04:34.599995: Epoch 588 
2023-07-31 21:04:34.600070: Current learning rate: 0.00045 
2023-07-31 21:06:07.773252: train_loss -0.3394 
2023-07-31 21:06:07.773430: val_loss -0.2905 
2023-07-31 21:06:07.773508: Pseudo dice [0.657] 
2023-07-31 21:06:07.773566: Epoch time: 93.17 s 
2023-07-31 21:06:09.087508:  
2023-07-31 21:06:09.087646: Epoch 589 
2023-07-31 21:06:09.087724: Current learning rate: 0.00045 
2023-07-31 21:07:41.725533: train_loss -0.3196 
2023-07-31 21:07:41.725704: val_loss -0.2892 
2023-07-31 21:07:41.725762: Pseudo dice [0.7753] 
2023-07-31 21:07:41.725817: Epoch time: 92.64 s 
2023-07-31 21:07:42.849132:  
2023-07-31 21:07:42.849239: Epoch 590 
2023-07-31 21:07:42.849321: Current learning rate: 0.00045 
2023-07-31 21:09:15.574304: train_loss -0.3351 
2023-07-31 21:09:15.574454: val_loss -0.3189 
2023-07-31 21:09:15.574511: Pseudo dice [0.7537] 
2023-07-31 21:09:15.574564: Epoch time: 92.73 s 
2023-07-31 21:09:16.632988:  
2023-07-31 21:09:16.633102: Epoch 591 
2023-07-31 21:09:16.633214: Current learning rate: 0.00045 
2023-07-31 21:10:49.324515: train_loss -0.3614 
2023-07-31 21:10:49.324677: val_loss -0.3079 
2023-07-31 21:10:49.324735: Pseudo dice [0.8775] 
2023-07-31 21:10:49.324790: Epoch time: 92.69 s 
2023-07-31 21:10:50.381997:  
2023-07-31 21:10:50.382094: Epoch 592 
2023-07-31 21:10:50.382172: Current learning rate: 0.00045 
2023-07-31 21:12:23.555465: train_loss -0.3008 
2023-07-31 21:12:23.555616: val_loss -0.3546 
2023-07-31 21:12:23.555679: Pseudo dice [0.8182] 
2023-07-31 21:12:23.555735: Epoch time: 93.17 s 
2023-07-31 21:12:24.653357:  
2023-07-31 21:12:24.653483: Epoch 593 
2023-07-31 21:12:24.653561: Current learning rate: 0.00045 
2023-07-31 21:13:57.565276: train_loss -0.3356 
2023-07-31 21:13:57.565429: val_loss -0.3055 
2023-07-31 21:13:57.565502: Pseudo dice [0.8127] 
2023-07-31 21:13:57.565556: Epoch time: 92.91 s 
2023-07-31 21:13:58.714892:  
2023-07-31 21:13:58.714997: Epoch 594 
2023-07-31 21:13:58.715093: Current learning rate: 0.00044 
2023-07-31 21:15:31.426953: train_loss -0.3459 
2023-07-31 21:15:31.427136: val_loss -0.3476 
2023-07-31 21:15:31.427201: Pseudo dice [0.7439] 
2023-07-31 21:15:31.427261: Epoch time: 92.71 s 
2023-07-31 21:15:32.691710:  
2023-07-31 21:15:32.691829: Epoch 595 
2023-07-31 21:15:32.691924: Current learning rate: 0.00044 
2023-07-31 21:16:59.594750: train_loss -0.3806 
2023-07-31 21:16:59.594935: val_loss -0.2725 
2023-07-31 21:16:59.594995: Pseudo dice [0.7955] 
2023-07-31 21:16:59.595050: Epoch time: 86.9 s 
2023-07-31 21:17:00.658338:  
2023-07-31 21:17:00.658516: Epoch 596 
2023-07-31 21:17:00.658596: Current learning rate: 0.00044 
2023-07-31 21:17:56.129900: train_loss -0.371 
2023-07-31 21:17:56.130059: val_loss -0.3933 
2023-07-31 21:17:56.130115: Pseudo dice [0.8197] 
2023-07-31 21:17:56.130169: Epoch time: 55.47 s 
2023-07-31 21:17:57.177395:  
2023-07-31 21:17:57.177495: Epoch 597 
2023-07-31 21:17:57.177588: Current learning rate: 0.00044 
2023-07-31 21:18:52.769935: train_loss -0.3203 
2023-07-31 21:18:52.770110: val_loss -0.2904 
2023-07-31 21:18:52.770170: Pseudo dice [0.7359] 
2023-07-31 21:18:52.770225: Epoch time: 55.59 s 
2023-07-31 21:18:53.874825:  
2023-07-31 21:18:53.874935: Epoch 598 
2023-07-31 21:18:53.875028: Current learning rate: 0.00044 
2023-07-31 21:19:57.393028: train_loss -0.3029 
2023-07-31 21:19:57.393196: val_loss -0.4194 
2023-07-31 21:19:57.393273: Pseudo dice [0.8357] 
2023-07-31 21:19:57.393332: Epoch time: 63.52 s 
2023-07-31 21:19:58.485862:  
2023-07-31 21:19:58.485969: Epoch 599 
2023-07-31 21:19:58.486060: Current learning rate: 0.00044 
2023-07-31 21:21:30.927912: train_loss -0.3322 
2023-07-31 21:21:30.928105: val_loss -0.4077 
2023-07-31 21:21:30.928172: Pseudo dice [0.851] 
2023-07-31 21:21:30.928233: Epoch time: 92.44 s 
2023-07-31 21:21:32.513032:  
2023-07-31 21:21:32.513141: Epoch 600 
2023-07-31 21:21:32.513237: Current learning rate: 0.00044 
2023-07-31 21:23:05.028625: train_loss -0.3602 
2023-07-31 21:23:05.028780: val_loss -0.3175 
2023-07-31 21:23:05.029035: Pseudo dice [0.7582] 
2023-07-31 21:23:05.029093: Epoch time: 92.52 s 
2023-07-31 21:23:06.114331:  
2023-07-31 21:23:06.114458: Epoch 601 
2023-07-31 21:23:06.114538: Current learning rate: 0.00044 
2023-07-31 21:24:38.842078: train_loss -0.3204 
2023-07-31 21:24:38.842238: val_loss -0.3268 
2023-07-31 21:24:38.842298: Pseudo dice [0.8063] 
2023-07-31 21:24:38.842352: Epoch time: 92.73 s 
2023-07-31 21:24:39.925797:  
2023-07-31 21:24:39.925912: Epoch 602 
2023-07-31 21:24:39.926006: Current learning rate: 0.00044 
2023-07-31 21:26:12.558448: train_loss -0.3336 
2023-07-31 21:26:12.558705: val_loss -0.3362 
2023-07-31 21:26:12.558765: Pseudo dice [0.66] 
2023-07-31 21:26:12.558819: Epoch time: 92.63 s 
2023-07-31 21:26:13.620536:  
2023-07-31 21:26:13.620804: Epoch 603 
2023-07-31 21:26:13.620886: Current learning rate: 0.00044 
2023-07-31 21:27:46.751774: train_loss -0.3472 
2023-07-31 21:27:46.751933: val_loss -0.3596 
2023-07-31 21:27:46.751994: Pseudo dice [0.8164] 
2023-07-31 21:27:46.752049: Epoch time: 93.13 s 
2023-07-31 21:27:47.833035:  
2023-07-31 21:27:47.833154: Epoch 604 
2023-07-31 21:27:47.833237: Current learning rate: 0.00043 
2023-07-31 21:29:20.801032: train_loss -0.3506 
2023-07-31 21:29:20.801192: val_loss -0.3224 
2023-07-31 21:29:20.801248: Pseudo dice [0.7905] 
2023-07-31 21:29:20.801304: Epoch time: 92.97 s 
2023-07-31 21:29:21.908123:  
2023-07-31 21:29:21.908249: Epoch 605 
2023-07-31 21:29:21.908357: Current learning rate: 0.00043 
2023-07-31 21:30:55.125907: train_loss -0.33 
2023-07-31 21:30:55.126071: val_loss -0.3132 
2023-07-31 21:30:55.126130: Pseudo dice [0.8558] 
2023-07-31 21:30:55.126194: Epoch time: 93.22 s 
2023-07-31 21:30:56.468290:  
2023-07-31 21:30:56.468405: Epoch 606 
2023-07-31 21:30:56.468484: Current learning rate: 0.00043 
2023-07-31 21:32:29.053968: train_loss -0.3476 
2023-07-31 21:32:29.054149: val_loss -0.3748 
2023-07-31 21:32:29.054232: Pseudo dice [0.8083] 
2023-07-31 21:32:29.054292: Epoch time: 92.59 s 
2023-07-31 21:32:30.123433:  
2023-07-31 21:32:30.128640: Epoch 607 
2023-07-31 21:32:30.128739: Current learning rate: 0.00043 
2023-07-31 21:34:02.554710: train_loss -0.3524 
2023-07-31 21:34:02.554883: val_loss -0.3286 
2023-07-31 21:34:02.554943: Pseudo dice [0.8489] 
2023-07-31 21:34:02.554998: Epoch time: 92.43 s 
2023-07-31 21:34:03.614378:  
2023-07-31 21:34:03.614483: Epoch 608 
2023-07-31 21:34:03.614561: Current learning rate: 0.00043 
2023-07-31 21:35:30.674627: train_loss -0.3469 
2023-07-31 21:35:30.674786: val_loss -0.364 
2023-07-31 21:35:30.674842: Pseudo dice [0.8474] 
2023-07-31 21:35:30.674897: Epoch time: 87.06 s 
2023-07-31 21:35:31.798696:  
2023-07-31 21:35:31.798799: Epoch 609 
2023-07-31 21:35:31.798891: Current learning rate: 0.00043 
2023-07-31 21:36:27.307982: train_loss -0.3529 
2023-07-31 21:36:27.308240: val_loss -0.3977 
2023-07-31 21:36:27.308304: Pseudo dice [0.8089] 
2023-07-31 21:36:27.308360: Epoch time: 55.51 s 
2023-07-31 21:36:28.355388:  
2023-07-31 21:36:28.355488: Epoch 610 
2023-07-31 21:36:28.355596: Current learning rate: 0.00043 
2023-07-31 21:37:23.981267: train_loss -0.3096 
2023-07-31 21:37:23.981425: val_loss -0.3521 
2023-07-31 21:37:23.981481: Pseudo dice [0.7856] 
2023-07-31 21:37:23.981535: Epoch time: 55.63 s 
2023-07-31 21:37:25.191005:  
2023-07-31 21:37:25.191119: Epoch 611 
2023-07-31 21:37:25.191213: Current learning rate: 0.00043 
2023-07-31 21:38:29.220781: train_loss -0.3713 
2023-07-31 21:38:29.220940: val_loss -0.2975 
2023-07-31 21:38:29.221000: Pseudo dice [0.7606] 
2023-07-31 21:38:29.221054: Epoch time: 64.03 s 
2023-07-31 21:38:30.350246:  
2023-07-31 21:38:30.350384: Epoch 612 
2023-07-31 21:38:30.350483: Current learning rate: 0.00043 
2023-07-31 21:40:04.254898: train_loss -0.3235 
2023-07-31 21:40:04.255052: val_loss -0.2461 
2023-07-31 21:40:04.255110: Pseudo dice [0.7061] 
2023-07-31 21:40:04.255181: Epoch time: 93.91 s 
2023-07-31 21:40:05.394904:  
2023-07-31 21:40:05.395023: Epoch 613 
2023-07-31 21:40:05.395106: Current learning rate: 0.00043 
2023-07-31 21:41:39.697808: train_loss -0.3568 
2023-07-31 21:41:39.698055: val_loss -0.3185 
2023-07-31 21:41:39.698119: Pseudo dice [0.8683] 
2023-07-31 21:41:39.698175: Epoch time: 94.3 s 
2023-07-31 21:41:40.774941:  
2023-07-31 21:41:40.775231: Epoch 614 
2023-07-31 21:41:40.775316: Current learning rate: 0.00042 
2023-07-31 21:43:14.923466: train_loss -0.3574 
2023-07-31 21:43:14.923640: val_loss -0.2926 
2023-07-31 21:43:14.923700: Pseudo dice [0.8614] 
2023-07-31 21:43:14.923772: Epoch time: 94.15 s 
2023-07-31 21:43:16.047690:  
2023-07-31 21:43:16.047876: Epoch 615 
2023-07-31 21:43:16.047972: Current learning rate: 0.00042 
2023-07-31 21:44:50.269549: train_loss -0.3765 
2023-07-31 21:44:50.269708: val_loss -0.3758 
2023-07-31 21:44:50.278112: Pseudo dice [0.8162] 
2023-07-31 21:44:50.278338: Epoch time: 94.22 s 
2023-07-31 21:44:51.365354:  
2023-07-31 21:44:51.365574: Epoch 616 
2023-07-31 21:44:51.365664: Current learning rate: 0.00042 
2023-07-31 21:46:25.793265: train_loss -0.3286 
2023-07-31 21:46:25.793421: val_loss -0.3639 
2023-07-31 21:46:25.793481: Pseudo dice [0.7913] 
2023-07-31 21:46:25.793535: Epoch time: 94.43 s 
2023-07-31 21:46:27.089153:  
2023-07-31 21:46:27.089372: Epoch 617 
2023-07-31 21:46:27.089458: Current learning rate: 0.00042 
2023-07-31 21:48:01.283224: train_loss -0.3099 
2023-07-31 21:48:01.283387: val_loss -0.3711 
2023-07-31 21:48:01.283463: Pseudo dice [0.8592] 
2023-07-31 21:48:01.283527: Epoch time: 94.19 s 
2023-07-31 21:48:02.352497:  
2023-07-31 21:48:02.352604: Epoch 618 
2023-07-31 21:48:02.352680: Current learning rate: 0.00042 
2023-07-31 21:49:36.863701: train_loss -0.3836 
2023-07-31 21:49:36.863859: val_loss -0.3227 
2023-07-31 21:49:36.863916: Pseudo dice [0.8073] 
2023-07-31 21:49:36.863969: Epoch time: 94.51 s 
2023-07-31 21:49:37.955288:  
2023-07-31 21:49:37.955395: Epoch 619 
2023-07-31 21:49:37.955472: Current learning rate: 0.00042 
2023-07-31 21:51:12.310222: train_loss -0.3299 
2023-07-31 21:51:12.310397: val_loss -0.2609 
2023-07-31 21:51:12.310461: Pseudo dice [0.7828] 
2023-07-31 21:51:12.310515: Epoch time: 94.36 s 
2023-07-31 21:51:13.378559:  
2023-07-31 21:51:13.378677: Epoch 620 
2023-07-31 21:51:13.378759: Current learning rate: 0.00042 
2023-07-31 21:52:47.866945: train_loss -0.3694 
2023-07-31 21:52:47.867124: val_loss -0.3381 
2023-07-31 21:52:47.867182: Pseudo dice [0.8273] 
2023-07-31 21:52:47.867237: Epoch time: 94.49 s 
2023-07-31 21:52:48.996654:  
2023-07-31 21:52:48.996773: Epoch 621 
2023-07-31 21:52:48.996869: Current learning rate: 0.00042 
2023-07-31 21:54:23.415819: train_loss -0.3362 
2023-07-31 21:54:23.415974: val_loss -0.3726 
2023-07-31 21:54:23.416034: Pseudo dice [0.8186] 
2023-07-31 21:54:23.416086: Epoch time: 94.42 s 
2023-07-31 21:54:24.633929:  
2023-07-31 21:54:24.634166: Epoch 622 
2023-07-31 21:54:24.634252: Current learning rate: 0.00042 
2023-07-31 21:55:45.327198: train_loss -0.379 
2023-07-31 21:55:45.327370: val_loss -0.4404 
2023-07-31 21:55:45.327450: Pseudo dice [0.8568] 
2023-07-31 21:55:45.327516: Epoch time: 80.69 s 
2023-07-31 21:55:46.474235:  
2023-07-31 21:55:46.474340: Epoch 623 
2023-07-31 21:55:46.474436: Current learning rate: 0.00042 
2023-07-31 21:56:42.122405: train_loss -0.3612 
2023-07-31 21:56:42.122566: val_loss -0.3377 
2023-07-31 21:56:42.122629: Pseudo dice [0.8039] 
2023-07-31 21:56:42.122684: Epoch time: 55.65 s 
2023-07-31 21:56:43.216511:  
2023-07-31 21:56:43.216897: Epoch 624 
2023-07-31 21:56:43.216994: Current learning rate: 0.00041 
2023-07-31 21:57:38.857054: train_loss -0.3473 
2023-07-31 21:57:38.857225: val_loss -0.3835 
2023-07-31 21:57:38.857307: Pseudo dice [0.8582] 
2023-07-31 21:57:38.857368: Epoch time: 55.64 s 
2023-07-31 21:57:38.857415: Yayy! New best EMA pseudo Dice: 0.8177 
2023-07-31 21:57:40.275053:  
2023-07-31 21:57:40.275171: Epoch 625 
2023-07-31 21:57:40.275256: Current learning rate: 0.00041 
2023-07-31 21:58:35.853800: train_loss -0.3332 
2023-07-31 21:58:35.853966: val_loss -0.3439 
2023-07-31 21:58:35.854023: Pseudo dice [0.8437] 
2023-07-31 21:58:35.854079: Epoch time: 55.58 s 
2023-07-31 21:58:35.854124: Yayy! New best EMA pseudo Dice: 0.8203 
2023-07-31 21:58:37.309254:  
2023-07-31 21:58:37.309461: Epoch 626 
2023-07-31 21:58:37.309693: Current learning rate: 0.00041 
2023-07-31 21:59:32.923392: train_loss -0.3312 
2023-07-31 21:59:32.923726: val_loss -0.3848 
2023-07-31 21:59:32.923799: Pseudo dice [0.77] 
2023-07-31 21:59:32.923860: Epoch time: 55.61 s 
2023-07-31 21:59:34.139157:  
2023-07-31 21:59:34.139429: Epoch 627 
2023-07-31 21:59:34.139885: Current learning rate: 0.00041 
2023-07-31 22:00:29.788294: train_loss -0.3342 
2023-07-31 22:00:29.788450: val_loss -0.3347 
2023-07-31 22:00:29.788508: Pseudo dice [0.7632] 
2023-07-31 22:00:29.788563: Epoch time: 55.65 s 
2023-07-31 22:00:30.914055:  
2023-07-31 22:00:30.914154: Epoch 628 
2023-07-31 22:00:30.914265: Current learning rate: 0.00041 
2023-07-31 22:01:26.620312: train_loss -0.3514 
2023-07-31 22:01:26.620482: val_loss -0.2816 
2023-07-31 22:01:26.620541: Pseudo dice [0.7123] 
2023-07-31 22:01:26.620596: Epoch time: 55.71 s 
2023-07-31 22:01:27.694951:  
2023-07-31 22:01:27.695053: Epoch 629 
2023-07-31 22:01:27.695147: Current learning rate: 0.00041 
2023-07-31 22:02:23.382116: train_loss -0.3526 
2023-07-31 22:02:23.382272: val_loss -0.3482 
2023-07-31 22:02:23.382331: Pseudo dice [0.7749] 
2023-07-31 22:02:23.382385: Epoch time: 55.69 s 
2023-07-31 22:02:24.473229:  
2023-07-31 22:02:24.473361: Epoch 630 
2023-07-31 22:02:24.473454: Current learning rate: 0.00041 
2023-07-31 22:03:20.109005: train_loss -0.365 
2023-07-31 22:03:20.109170: val_loss -0.3658 
2023-07-31 22:03:20.109229: Pseudo dice [0.782] 
2023-07-31 22:03:20.109291: Epoch time: 55.64 s 
2023-07-31 22:03:21.175859:  
2023-07-31 22:03:21.175960: Epoch 631 
2023-07-31 22:03:21.176038: Current learning rate: 0.00041 
2023-07-31 22:04:16.783934: train_loss -0.3494 
2023-07-31 22:04:16.784100: val_loss -0.3775 
2023-07-31 22:04:16.784160: Pseudo dice [0.8219] 
2023-07-31 22:04:16.784214: Epoch time: 55.61 s 
2023-07-31 22:04:17.849677:  
2023-07-31 22:04:17.849917: Epoch 632 
2023-07-31 22:04:17.850014: Current learning rate: 0.00041 
2023-07-31 22:05:13.452116: train_loss -0.3484 
2023-07-31 22:05:13.452282: val_loss -0.4269 
2023-07-31 22:05:13.452339: Pseudo dice [0.8486] 
2023-07-31 22:05:13.452392: Epoch time: 55.6 s 
2023-07-31 22:05:14.755686:  
2023-07-31 22:05:14.755896: Epoch 633 
2023-07-31 22:05:14.755978: Current learning rate: 0.00041 
2023-07-31 22:06:10.373891: train_loss -0.3479 
2023-07-31 22:06:10.374056: val_loss -0.408 
2023-07-31 22:06:10.374115: Pseudo dice [0.8567] 
2023-07-31 22:06:10.374169: Epoch time: 55.62 s 
2023-07-31 22:06:11.437739:  
2023-07-31 22:06:11.437964: Epoch 634 
2023-07-31 22:06:11.438061: Current learning rate: 0.0004 
2023-07-31 22:07:07.033946: train_loss -0.3515 
2023-07-31 22:07:07.034115: val_loss -0.3831 
2023-07-31 22:07:07.034174: Pseudo dice [0.8372] 
2023-07-31 22:07:07.034230: Epoch time: 55.6 s 
2023-07-31 22:07:08.108174:  
2023-07-31 22:07:08.108398: Epoch 635 
2023-07-31 22:07:08.108479: Current learning rate: 0.0004 
2023-07-31 22:08:03.727845: train_loss -0.372 
2023-07-31 22:08:03.728010: val_loss -0.3204 
2023-07-31 22:08:03.728072: Pseudo dice [0.7641] 
2023-07-31 22:08:03.728128: Epoch time: 55.62 s 
2023-07-31 22:08:04.830544:  
2023-07-31 22:08:04.830751: Epoch 636 
2023-07-31 22:08:04.830836: Current learning rate: 0.0004 
2023-07-31 22:09:00.459419: train_loss -0.3574 
2023-07-31 22:09:00.459598: val_loss -0.327 
2023-07-31 22:09:00.459660: Pseudo dice [0.8169] 
2023-07-31 22:09:00.459714: Epoch time: 55.63 s 
2023-07-31 22:09:01.564099:  
2023-07-31 22:09:01.564201: Epoch 637 
2023-07-31 22:09:01.564295: Current learning rate: 0.0004 
2023-07-31 22:09:57.216596: train_loss -0.3832 
2023-07-31 22:09:57.216755: val_loss -0.3878 
2023-07-31 22:09:57.216813: Pseudo dice [0.8103] 
2023-07-31 22:09:57.216867: Epoch time: 55.65 s 
2023-07-31 22:09:58.491430:  
2023-07-31 22:09:58.491672: Epoch 638 
2023-07-31 22:09:58.491756: Current learning rate: 0.0004 
2023-07-31 22:10:54.099640: train_loss -0.3562 
2023-07-31 22:10:54.099804: val_loss -0.3833 
2023-07-31 22:10:54.099865: Pseudo dice [0.7941] 
2023-07-31 22:10:54.099920: Epoch time: 55.61 s 
2023-07-31 22:10:55.186959:  
2023-07-31 22:10:55.187061: Epoch 639 
2023-07-31 22:10:55.187139: Current learning rate: 0.0004 
2023-07-31 22:11:50.822118: train_loss -0.3454 
2023-07-31 22:11:50.822283: val_loss -0.3652 
2023-07-31 22:11:50.822339: Pseudo dice [0.9032] 
2023-07-31 22:11:50.822395: Epoch time: 55.64 s 
2023-07-31 22:11:51.888246:  
2023-07-31 22:11:51.888461: Epoch 640 
2023-07-31 22:11:51.888539: Current learning rate: 0.0004 
2023-07-31 22:12:47.584855: train_loss -0.3822 
2023-07-31 22:12:47.585014: val_loss -0.3032 
2023-07-31 22:12:47.585069: Pseudo dice [0.9052] 
2023-07-31 22:12:47.585122: Epoch time: 55.7 s 
2023-07-31 22:12:47.585167: Yayy! New best EMA pseudo Dice: 0.8254 
2023-07-31 22:12:49.021297:  
2023-07-31 22:12:49.021481: Epoch 641 
2023-07-31 22:12:49.021561: Current learning rate: 0.0004 
2023-07-31 22:13:44.656860: train_loss -0.3477 
2023-07-31 22:13:44.657017: val_loss -0.3016 
2023-07-31 22:13:44.657075: Pseudo dice [0.8231] 
2023-07-31 22:13:44.657128: Epoch time: 55.64 s 
2023-07-31 22:13:45.753249:  
2023-07-31 22:13:45.753351: Epoch 642 
2023-07-31 22:13:45.753446: Current learning rate: 0.0004 
2023-07-31 22:14:41.359069: train_loss -0.3647 
2023-07-31 22:14:41.359242: val_loss -0.4234 
2023-07-31 22:14:41.359301: Pseudo dice [0.8311] 
2023-07-31 22:14:41.359356: Epoch time: 55.61 s 
2023-07-31 22:14:41.359408: Yayy! New best EMA pseudo Dice: 0.8257 
2023-07-31 22:14:42.978273:  
2023-07-31 22:14:42.978384: Epoch 643 
2023-07-31 22:14:42.978468: Current learning rate: 0.0004 
2023-07-31 22:15:38.627069: train_loss -0.3445 
2023-07-31 22:15:38.627226: val_loss -0.3183 
2023-07-31 22:15:38.627285: Pseudo dice [0.7662] 
2023-07-31 22:15:38.627338: Epoch time: 55.65 s 
2023-07-31 22:15:39.683372:  
2023-07-31 22:15:39.683487: Epoch 644 
2023-07-31 22:15:39.683567: Current learning rate: 0.00039 
2023-07-31 22:16:35.328977: train_loss -0.3803 
2023-07-31 22:16:35.329166: val_loss -0.3481 
2023-07-31 22:16:35.329224: Pseudo dice [0.8007] 
2023-07-31 22:16:35.329279: Epoch time: 55.65 s 
2023-07-31 22:16:36.416973:  
2023-07-31 22:16:36.417074: Epoch 645 
2023-07-31 22:16:36.417167: Current learning rate: 0.00039 
2023-07-31 22:17:32.079021: train_loss -0.3359 
2023-07-31 22:17:32.079200: val_loss -0.3582 
2023-07-31 22:17:32.079260: Pseudo dice [0.807] 
2023-07-31 22:17:32.079315: Epoch time: 55.66 s 
2023-07-31 22:17:33.152066:  
2023-07-31 22:17:33.152166: Epoch 646 
2023-07-31 22:17:33.152258: Current learning rate: 0.00039 
2023-07-31 22:18:28.774311: train_loss -0.3481 
2023-07-31 22:18:28.774467: val_loss -0.4034 
2023-07-31 22:18:28.774540: Pseudo dice [0.777] 
2023-07-31 22:18:28.774594: Epoch time: 55.62 s 
2023-07-31 22:18:29.823287:  
2023-07-31 22:18:29.823382: Epoch 647 
2023-07-31 22:18:29.823471: Current learning rate: 0.00039 
2023-07-31 22:19:25.411461: train_loss -0.3185 
2023-07-31 22:19:25.411630: val_loss -0.3877 
2023-07-31 22:19:25.411689: Pseudo dice [0.9186] 
2023-07-31 22:19:25.411744: Epoch time: 55.59 s 
2023-07-31 22:19:26.514370:  
2023-07-31 22:19:26.514466: Epoch 648 
2023-07-31 22:19:26.514573: Current learning rate: 0.00039 
2023-07-31 22:20:22.140488: train_loss -0.3361 
2023-07-31 22:20:22.140641: val_loss -0.3163 
2023-07-31 22:20:22.140698: Pseudo dice [0.8266] 
2023-07-31 22:20:22.140751: Epoch time: 55.63 s 
2023-07-31 22:20:23.381686:  
2023-07-31 22:20:23.381796: Epoch 649 
2023-07-31 22:20:23.381891: Current learning rate: 0.00039 
2023-07-31 22:21:19.002905: train_loss -0.3515 
2023-07-31 22:21:19.003065: val_loss -0.4161 
2023-07-31 22:21:19.003122: Pseudo dice [0.8332] 
2023-07-31 22:21:19.003192: Epoch time: 55.62 s 
2023-07-31 22:21:20.426804:  
2023-07-31 22:21:20.426917: Epoch 650 
2023-07-31 22:21:20.426995: Current learning rate: 0.00039 
2023-07-31 22:22:16.026638: train_loss -0.367 
2023-07-31 22:22:16.026806: val_loss -0.3043 
2023-07-31 22:22:16.026881: Pseudo dice [0.8539] 
2023-07-31 22:22:16.026936: Epoch time: 55.6 s 
2023-07-31 22:22:16.026980: Yayy! New best EMA pseudo Dice: 0.8276 
2023-07-31 22:22:17.449650:  
2023-07-31 22:22:17.449864: Epoch 651 
2023-07-31 22:22:17.449950: Current learning rate: 0.00039 
2023-07-31 22:23:13.079216: train_loss -0.3562 
2023-07-31 22:23:13.079385: val_loss -0.402 
2023-07-31 22:23:13.079443: Pseudo dice [0.8305] 
2023-07-31 22:23:13.079508: Epoch time: 55.63 s 
2023-07-31 22:23:13.079556: Yayy! New best EMA pseudo Dice: 0.8279 
2023-07-31 22:23:14.566746:  
2023-07-31 22:23:14.566845: Epoch 652 
2023-07-31 22:23:14.566966: Current learning rate: 0.00039 
2023-07-31 22:24:10.161875: train_loss -0.3284 
2023-07-31 22:24:10.162059: val_loss -0.3591 
2023-07-31 22:24:10.162115: Pseudo dice [0.8229] 
2023-07-31 22:24:10.162169: Epoch time: 55.6 s 
2023-07-31 22:24:11.215372:  
2023-07-31 22:24:11.215468: Epoch 653 
2023-07-31 22:24:11.215565: Current learning rate: 0.00039 
2023-07-31 22:25:06.831902: train_loss -0.3419 
2023-07-31 22:25:06.832063: val_loss -0.3653 
2023-07-31 22:25:06.832119: Pseudo dice [0.7839] 
2023-07-31 22:25:06.832173: Epoch time: 55.62 s 
2023-07-31 22:25:08.081438:  
2023-07-31 22:25:08.081621: Epoch 654 
2023-07-31 22:25:08.081708: Current learning rate: 0.00038 
2023-07-31 22:26:03.625092: train_loss -0.3479 
2023-07-31 22:26:03.625260: val_loss -0.2941 
2023-07-31 22:26:03.625318: Pseudo dice [0.8129] 
2023-07-31 22:26:03.625372: Epoch time: 55.54 s 
2023-07-31 22:26:04.706104:  
2023-07-31 22:26:04.706300: Epoch 655 
2023-07-31 22:26:04.706378: Current learning rate: 0.00038 
2023-07-31 22:27:00.313046: train_loss -0.311 
2023-07-31 22:27:00.313235: val_loss -0.33 
2023-07-31 22:27:00.313296: Pseudo dice [0.8072] 
2023-07-31 22:27:00.313350: Epoch time: 55.61 s 
2023-07-31 22:27:01.365712:  
2023-07-31 22:27:01.365812: Epoch 656 
2023-07-31 22:27:01.365904: Current learning rate: 0.00038 
2023-07-31 22:27:57.010702: train_loss -0.3072 
2023-07-31 22:27:57.010897: val_loss -0.3697 
2023-07-31 22:27:57.010959: Pseudo dice [0.8407] 
2023-07-31 22:27:57.011014: Epoch time: 55.65 s 
2023-07-31 22:27:58.078851:  
2023-07-31 22:27:58.079027: Epoch 657 
2023-07-31 22:27:58.079124: Current learning rate: 0.00038 
2023-07-31 22:28:53.663550: train_loss -0.3478 
2023-07-31 22:28:53.663723: val_loss -0.3797 
2023-07-31 22:28:53.663792: Pseudo dice [0.8096] 
2023-07-31 22:28:53.663848: Epoch time: 55.59 s 
2023-07-31 22:28:54.719997:  
2023-07-31 22:28:54.720184: Epoch 658 
2023-07-31 22:28:54.720267: Current learning rate: 0.00038 
2023-07-31 22:29:50.197523: train_loss -0.3282 
2023-07-31 22:29:50.197680: val_loss -0.3228 
2023-07-31 22:29:50.197741: Pseudo dice [0.9051] 
2023-07-31 22:29:50.197795: Epoch time: 55.48 s 
2023-07-31 22:29:50.197838: Yayy! New best EMA pseudo Dice: 0.8296 
2023-07-31 22:29:51.776430:  
2023-07-31 22:29:51.776747: Epoch 659 
2023-07-31 22:29:51.776908: Current learning rate: 0.00038 
2023-07-31 22:30:47.343304: train_loss -0.3797 
2023-07-31 22:30:47.343473: val_loss -0.369 
2023-07-31 22:30:47.343549: Pseudo dice [0.8106] 
2023-07-31 22:30:47.343605: Epoch time: 55.57 s 
2023-07-31 22:30:48.436641:  
2023-07-31 22:30:48.436779: Epoch 660 
2023-07-31 22:30:48.436864: Current learning rate: 0.00038 
2023-07-31 22:31:44.017442: train_loss -0.358 
2023-07-31 22:31:44.017615: val_loss -0.3407 
2023-07-31 22:31:44.017689: Pseudo dice [0.8614] 
2023-07-31 22:31:44.017744: Epoch time: 55.58 s 
2023-07-31 22:31:44.017789: Yayy! New best EMA pseudo Dice: 0.8311 
2023-07-31 22:31:45.445986:  
2023-07-31 22:31:45.446115: Epoch 661 
2023-07-31 22:31:45.446207: Current learning rate: 0.00038 
2023-07-31 22:32:41.018423: train_loss -0.3665 
2023-07-31 22:32:41.018571: val_loss -0.3732 
2023-07-31 22:32:41.018629: Pseudo dice [0.7803] 
2023-07-31 22:32:41.018682: Epoch time: 55.57 s 
2023-07-31 22:32:42.089120:  
2023-07-31 22:32:42.089378: Epoch 662 
2023-07-31 22:32:42.089616: Current learning rate: 0.00038 
2023-07-31 22:33:37.663228: train_loss -0.3638 
2023-07-31 22:33:37.663386: val_loss -0.3552 
2023-07-31 22:33:37.663444: Pseudo dice [0.8221] 
2023-07-31 22:33:37.663508: Epoch time: 55.57 s 
2023-07-31 22:33:38.743948:  
2023-07-31 22:33:38.744047: Epoch 663 
2023-07-31 22:33:38.744142: Current learning rate: 0.00038 
2023-07-31 22:34:34.306643: train_loss -0.3605 
2023-07-31 22:34:34.306806: val_loss -0.3223 
2023-07-31 22:34:34.306868: Pseudo dice [0.8357] 
2023-07-31 22:34:34.306922: Epoch time: 55.56 s 
2023-07-31 22:34:35.351246:  
2023-07-31 22:34:35.351449: Epoch 664 
2023-07-31 22:34:35.351533: Current learning rate: 0.00037 
2023-07-31 22:35:30.900653: train_loss -0.3233 
2023-07-31 22:35:30.900849: val_loss -0.441 
2023-07-31 22:35:30.900933: Pseudo dice [0.8283] 
2023-07-31 22:35:30.901010: Epoch time: 55.55 s 
2023-07-31 22:35:32.123196:  
2023-07-31 22:35:32.123298: Epoch 665 
2023-07-31 22:35:32.123391: Current learning rate: 0.00037 
2023-07-31 22:36:27.704963: train_loss -0.3236 
2023-07-31 22:36:27.705139: val_loss -0.3465 
2023-07-31 22:36:27.705220: Pseudo dice [0.8198] 
2023-07-31 22:36:27.705287: Epoch time: 55.58 s 
2023-07-31 22:36:28.763181:  
2023-07-31 22:36:28.763285: Epoch 666 
2023-07-31 22:36:28.763393: Current learning rate: 0.00037 
2023-07-31 22:37:24.324345: train_loss -0.3779 
2023-07-31 22:37:24.324519: val_loss -0.3939 
2023-07-31 22:37:24.324598: Pseudo dice [0.8372] 
2023-07-31 22:37:24.324666: Epoch time: 55.56 s 
2023-07-31 22:37:25.397346:  
2023-07-31 22:37:25.397444: Epoch 667 
2023-07-31 22:37:25.397535: Current learning rate: 0.00037 
2023-07-31 22:38:20.950398: train_loss -0.3278 
2023-07-31 22:38:20.950587: val_loss -0.3227 
2023-07-31 22:38:20.950650: Pseudo dice [0.7587] 
2023-07-31 22:38:20.950719: Epoch time: 55.55 s 
2023-07-31 22:38:22.083068:  
2023-07-31 22:38:22.083169: Epoch 668 
2023-07-31 22:38:22.083277: Current learning rate: 0.00037 
2023-07-31 22:39:17.694600: train_loss -0.3352 
2023-07-31 22:39:17.694764: val_loss -0.372 
2023-07-31 22:39:17.694825: Pseudo dice [0.7915] 
2023-07-31 22:39:17.694883: Epoch time: 55.61 s 
2023-07-31 22:39:18.785266:  
2023-07-31 22:39:18.785363: Epoch 669 
2023-07-31 22:39:18.785456: Current learning rate: 0.00037 
2023-07-31 22:40:14.351874: train_loss -0.3739 
2023-07-31 22:40:14.352028: val_loss -0.3347 
2023-07-31 22:40:14.352084: Pseudo dice [0.7684] 
2023-07-31 22:40:14.352137: Epoch time: 55.57 s 
2023-07-31 22:40:15.566047:  
2023-07-31 22:40:15.566147: Epoch 670 
2023-07-31 22:40:15.566237: Current learning rate: 0.00037 
2023-07-31 22:41:11.147835: train_loss -0.3452 
2023-07-31 22:41:11.147995: val_loss -0.3476 
2023-07-31 22:41:11.148054: Pseudo dice [0.8187] 
2023-07-31 22:41:11.148108: Epoch time: 55.58 s 
2023-07-31 22:41:12.236143:  
2023-07-31 22:41:12.236250: Epoch 671 
2023-07-31 22:41:12.236341: Current learning rate: 0.00037 
2023-07-31 22:42:07.879066: train_loss -0.3696 
2023-07-31 22:42:07.879234: val_loss -0.3999 
2023-07-31 22:42:07.879311: Pseudo dice [0.8629] 
2023-07-31 22:42:07.879378: Epoch time: 55.64 s 
2023-07-31 22:42:08.978327:  
2023-07-31 22:42:08.978438: Epoch 672 
2023-07-31 22:42:08.978530: Current learning rate: 0.00037 
2023-07-31 22:43:04.611508: train_loss -0.3296 
2023-07-31 22:43:04.611675: val_loss -0.3389 
2023-07-31 22:43:04.611750: Pseudo dice [0.8395] 
2023-07-31 22:43:04.611817: Epoch time: 55.63 s 
2023-07-31 22:43:05.692363:  
2023-07-31 22:43:05.692466: Epoch 673 
2023-07-31 22:43:05.692543: Current learning rate: 0.00037 
2023-07-31 22:44:01.276561: train_loss -0.3646 
2023-07-31 22:44:01.276732: val_loss -0.3545 
2023-07-31 22:44:01.285158: Pseudo dice [0.7892] 
2023-07-31 22:44:01.285368: Epoch time: 55.58 s 
2023-07-31 22:44:02.386375:  
2023-07-31 22:44:02.386472: Epoch 674 
2023-07-31 22:44:02.386581: Current learning rate: 0.00036 
2023-07-31 22:44:57.980975: train_loss -0.357 
2023-07-31 22:44:57.981149: val_loss -0.3552 
2023-07-31 22:44:57.981231: Pseudo dice [0.8389] 
2023-07-31 22:44:57.981299: Epoch time: 55.6 s 
2023-07-31 22:44:59.197973:  
2023-07-31 22:44:59.198085: Epoch 675 
2023-07-31 22:44:59.198177: Current learning rate: 0.00036 
2023-07-31 22:45:54.740390: train_loss -0.3493 
2023-07-31 22:45:54.740555: val_loss -0.3723 
2023-07-31 22:45:54.740613: Pseudo dice [0.81] 
2023-07-31 22:45:54.740668: Epoch time: 55.54 s 
2023-07-31 22:45:55.810872:  
2023-07-31 22:45:55.810970: Epoch 676 
2023-07-31 22:45:55.811077: Current learning rate: 0.00036 
2023-07-31 22:46:51.405016: train_loss -0.3483 
2023-07-31 22:46:51.405182: val_loss -0.3912 
2023-07-31 22:46:51.405278: Pseudo dice [0.8522] 
2023-07-31 22:46:51.405345: Epoch time: 55.59 s 
2023-07-31 22:46:52.498678:  
2023-07-31 22:46:52.498774: Epoch 677 
2023-07-31 22:46:52.498883: Current learning rate: 0.00036 
2023-07-31 22:47:48.116368: train_loss -0.3767 
2023-07-31 22:47:48.116527: val_loss -0.3875 
2023-07-31 22:47:48.116585: Pseudo dice [0.8911] 
2023-07-31 22:47:48.116639: Epoch time: 55.62 s 
2023-07-31 22:47:49.182400:  
2023-07-31 22:47:49.182499: Epoch 678 
2023-07-31 22:47:49.182605: Current learning rate: 0.00036 
2023-07-31 22:48:44.828540: train_loss -0.3305 
2023-07-31 22:48:44.828729: val_loss -0.3609 
2023-07-31 22:48:44.828804: Pseudo dice [0.8716] 
2023-07-31 22:48:44.828871: Epoch time: 55.65 s 
2023-07-31 22:48:44.828928: Yayy! New best EMA pseudo Dice: 0.833 
2023-07-31 22:48:46.291686:  
2023-07-31 22:48:46.291787: Epoch 679 
2023-07-31 22:48:46.291863: Current learning rate: 0.00036 
2023-07-31 22:49:41.853253: train_loss -0.3464 
2023-07-31 22:49:41.853421: val_loss -0.387 
2023-07-31 22:49:41.853484: Pseudo dice [0.819] 
2023-07-31 22:49:41.853539: Epoch time: 55.56 s 
2023-07-31 22:49:42.920664:  
2023-07-31 22:49:42.920770: Epoch 680 
2023-07-31 22:49:42.920862: Current learning rate: 0.00036 
2023-07-31 22:50:38.501458: train_loss -0.3418 
2023-07-31 22:50:38.501634: val_loss -0.3854 
2023-07-31 22:50:38.501697: Pseudo dice [0.8442] 
2023-07-31 22:50:38.501754: Epoch time: 55.58 s 
2023-07-31 22:50:39.759287:  
2023-07-31 22:50:39.759395: Epoch 681 
2023-07-31 22:50:39.759473: Current learning rate: 0.00036 
2023-07-31 22:51:35.376684: train_loss -0.3257 
2023-07-31 22:51:35.376890: val_loss -0.3289 
2023-07-31 22:51:35.376952: Pseudo dice [0.8013] 
2023-07-31 22:51:35.377010: Epoch time: 55.62 s 
2023-07-31 22:51:36.477554:  
2023-07-31 22:51:36.477656: Epoch 682 
2023-07-31 22:51:36.477763: Current learning rate: 0.00036 
2023-07-31 22:52:32.111546: train_loss -0.3751 
2023-07-31 22:52:32.111717: val_loss -0.3492 
2023-07-31 22:52:32.111803: Pseudo dice [0.7821] 
2023-07-31 22:52:32.111870: Epoch time: 55.63 s 
2023-07-31 22:52:33.196199:  
2023-07-31 22:52:33.196322: Epoch 683 
2023-07-31 22:52:33.196400: Current learning rate: 0.00036 
2023-07-31 22:53:28.781484: train_loss -0.3598 
2023-07-31 22:53:28.781649: val_loss -0.4677 
2023-07-31 22:53:28.781708: Pseudo dice [0.8538] 
2023-07-31 22:53:28.781763: Epoch time: 55.59 s 
2023-07-31 22:53:29.868425:  
2023-07-31 22:53:29.868523: Epoch 684 
2023-07-31 22:53:29.868600: Current learning rate: 0.00035 
2023-07-31 22:54:25.507166: train_loss -0.3273 
2023-07-31 22:54:25.507338: val_loss -0.4436 
2023-07-31 22:54:25.507398: Pseudo dice [0.8286] 
2023-07-31 22:54:25.507454: Epoch time: 55.64 s 
2023-07-31 22:54:26.575072:  
2023-07-31 22:54:26.575168: Epoch 685 
2023-07-31 22:54:26.575259: Current learning rate: 0.00035 
2023-07-31 22:55:22.208330: train_loss -0.3295 
2023-07-31 22:55:22.208574: val_loss -0.2809 
2023-07-31 22:55:22.208632: Pseudo dice [0.8582] 
2023-07-31 22:55:22.208687: Epoch time: 55.63 s 
2023-07-31 22:55:23.421036:  
2023-07-31 22:55:23.421144: Epoch 686 
2023-07-31 22:55:23.421234: Current learning rate: 0.00035 
2023-07-31 22:56:19.027320: train_loss -0.3549 
2023-07-31 22:56:19.027497: val_loss -0.302 
2023-07-31 22:56:19.027563: Pseudo dice [0.7736] 
2023-07-31 22:56:19.027618: Epoch time: 55.61 s 
2023-07-31 22:56:20.115863:  
2023-07-31 22:56:20.116043: Epoch 687 
2023-07-31 22:56:20.116139: Current learning rate: 0.00035 
2023-07-31 22:57:15.702239: train_loss -0.3414 
2023-07-31 22:57:15.702403: val_loss -0.315 
2023-07-31 22:57:15.702480: Pseudo dice [0.7665] 
2023-07-31 22:57:15.702534: Epoch time: 55.59 s 
2023-07-31 22:57:16.771589:  
2023-07-31 22:57:16.771693: Epoch 688 
2023-07-31 22:57:16.771801: Current learning rate: 0.00035 
2023-07-31 22:58:12.359385: train_loss -0.3327 
2023-07-31 22:58:12.359557: val_loss -0.2808 
2023-07-31 22:58:12.359617: Pseudo dice [0.779] 
2023-07-31 22:58:12.359671: Epoch time: 55.59 s 
2023-07-31 22:58:13.423228:  
2023-07-31 22:58:13.423327: Epoch 689 
2023-07-31 22:58:13.423403: Current learning rate: 0.00035 
2023-07-31 22:59:09.015506: train_loss -0.3647 
2023-07-31 22:59:09.015796: val_loss -0.4716 
2023-07-31 22:59:09.015857: Pseudo dice [0.8678] 
2023-07-31 22:59:09.015915: Epoch time: 55.59 s 
2023-07-31 22:59:10.089025:  
2023-07-31 22:59:10.089126: Epoch 690 
2023-07-31 22:59:10.089219: Current learning rate: 0.00035 
2023-07-31 23:00:05.677570: train_loss -0.3949 
2023-07-31 23:00:05.677730: val_loss -0.3767 
2023-07-31 23:00:05.677788: Pseudo dice [0.8411] 
2023-07-31 23:00:05.677842: Epoch time: 55.59 s 
2023-07-31 23:00:06.746450:  
2023-07-31 23:00:06.746547: Epoch 691 
2023-07-31 23:00:06.746654: Current learning rate: 0.00035 
2023-07-31 23:01:02.335648: train_loss -0.3486 
2023-07-31 23:01:02.335801: val_loss -0.3322 
2023-07-31 23:01:02.335856: Pseudo dice [0.7932] 
2023-07-31 23:01:02.335909: Epoch time: 55.59 s 
2023-07-31 23:01:03.571389:  
2023-07-31 23:01:03.571509: Epoch 692 
2023-07-31 23:01:03.571606: Current learning rate: 0.00035 
2023-07-31 23:01:59.211206: train_loss -0.3542 
2023-07-31 23:01:59.211385: val_loss -0.3818 
2023-07-31 23:01:59.211444: Pseudo dice [0.9173] 
2023-07-31 23:01:59.211505: Epoch time: 55.64 s 
2023-07-31 23:02:00.285277:  
2023-07-31 23:02:00.285384: Epoch 693 
2023-07-31 23:02:00.285478: Current learning rate: 0.00035 
2023-07-31 23:02:55.935795: train_loss -0.348 
2023-07-31 23:02:55.935956: val_loss -0.3585 
2023-07-31 23:02:55.936016: Pseudo dice [0.8788] 
2023-07-31 23:02:55.936070: Epoch time: 55.65 s 
2023-07-31 23:02:55.936115: Yayy! New best EMA pseudo Dice: 0.8344 
2023-07-31 23:02:57.393326:  
2023-07-31 23:02:57.393430: Epoch 694 
2023-07-31 23:02:57.393540: Current learning rate: 0.00034 
2023-07-31 23:03:53.074758: train_loss -0.3472 
2023-07-31 23:03:53.074944: val_loss -0.4396 
2023-07-31 23:03:53.075004: Pseudo dice [0.8086] 
2023-07-31 23:03:53.075060: Epoch time: 55.68 s 
2023-07-31 23:03:54.173422:  
2023-07-31 23:03:54.173551: Epoch 695 
2023-07-31 23:03:54.173644: Current learning rate: 0.00034 
2023-07-31 23:04:49.808969: train_loss -0.3505 
2023-07-31 23:04:49.809136: val_loss -0.3332 
2023-07-31 23:04:49.809195: Pseudo dice [0.9127] 
2023-07-31 23:04:49.809252: Epoch time: 55.64 s 
2023-07-31 23:04:49.809296: Yayy! New best EMA pseudo Dice: 0.8399 
2023-07-31 23:04:51.296933:  
2023-07-31 23:04:51.297030: Epoch 696 
2023-07-31 23:04:51.297123: Current learning rate: 0.00034 
2023-07-31 23:05:46.913328: train_loss -0.3631 
2023-07-31 23:05:46.913509: val_loss -0.3743 
2023-07-31 23:05:46.913570: Pseudo dice [0.7867] 
2023-07-31 23:05:46.913624: Epoch time: 55.62 s 
2023-07-31 23:05:48.161170:  
2023-07-31 23:05:48.161395: Epoch 697 
2023-07-31 23:05:48.161497: Current learning rate: 0.00034 
2023-07-31 23:06:43.755341: train_loss -0.3301 
2023-07-31 23:06:43.755504: val_loss -0.2995 
2023-07-31 23:06:43.755564: Pseudo dice [0.7766] 
2023-07-31 23:06:43.755619: Epoch time: 55.59 s 
2023-07-31 23:06:44.849808:  
2023-07-31 23:06:44.849915: Epoch 698 
2023-07-31 23:06:44.850146: Current learning rate: 0.00034 
2023-07-31 23:07:40.407305: train_loss -0.311 
2023-07-31 23:07:40.407466: val_loss -0.3413 
2023-07-31 23:07:40.407537: Pseudo dice [0.8687] 
2023-07-31 23:07:40.407596: Epoch time: 55.56 s 
2023-07-31 23:07:41.512111:  
2023-07-31 23:07:41.512212: Epoch 699 
2023-07-31 23:07:41.512306: Current learning rate: 0.00034 
2023-07-31 23:08:37.070807: train_loss -0.3365 
2023-07-31 23:08:37.070977: val_loss -0.4011 
2023-07-31 23:08:37.071035: Pseudo dice [0.8586] 
2023-07-31 23:08:37.071096: Epoch time: 55.56 s 
2023-07-31 23:08:38.548719:  
2023-07-31 23:08:38.548946: Epoch 700 
2023-07-31 23:08:38.549030: Current learning rate: 0.00034 
2023-07-31 23:09:34.130766: train_loss -0.3678 
2023-07-31 23:09:34.130928: val_loss -0.3237 
2023-07-31 23:09:34.130985: Pseudo dice [0.7574] 
2023-07-31 23:09:34.131039: Epoch time: 55.58 s 
2023-07-31 23:09:35.196150:  
2023-07-31 23:09:35.196266: Epoch 701 
2023-07-31 23:09:35.196346: Current learning rate: 0.00034 
2023-07-31 23:10:30.731775: train_loss -0.322 
2023-07-31 23:10:30.731938: val_loss -0.352 
2023-07-31 23:10:30.731998: Pseudo dice [0.8263] 
2023-07-31 23:10:30.732053: Epoch time: 55.54 s 
2023-07-31 23:10:31.959558:  
2023-07-31 23:10:31.959664: Epoch 702 
2023-07-31 23:10:31.959743: Current learning rate: 0.00034 
2023-07-31 23:11:27.525094: train_loss -0.3577 
2023-07-31 23:11:27.525247: val_loss -0.3403 
2023-07-31 23:11:27.525304: Pseudo dice [0.8238] 
2023-07-31 23:11:27.525358: Epoch time: 55.57 s 
2023-07-31 23:11:28.635560:  
2023-07-31 23:11:28.635664: Epoch 703 
2023-07-31 23:11:28.635770: Current learning rate: 0.00034 
2023-07-31 23:12:24.192739: train_loss -0.341 
2023-07-31 23:12:24.192935: val_loss -0.3815 
2023-07-31 23:12:24.192996: Pseudo dice [0.8631] 
2023-07-31 23:12:24.193052: Epoch time: 55.56 s 
2023-07-31 23:12:25.264953:  
2023-07-31 23:12:25.265050: Epoch 704 
2023-07-31 23:12:25.265155: Current learning rate: 0.00033 
2023-07-31 23:13:20.851144: train_loss -0.3202 
2023-07-31 23:13:20.851300: val_loss -0.4014 
2023-07-31 23:13:20.851360: Pseudo dice [0.8746] 
2023-07-31 23:13:20.851414: Epoch time: 55.59 s 
2023-07-31 23:13:21.921474:  
2023-07-31 23:13:21.921599: Epoch 705 
2023-07-31 23:13:21.921694: Current learning rate: 0.00033 
2023-07-31 23:14:17.567302: train_loss -0.3564 
2023-07-31 23:14:17.567488: val_loss -0.4067 
2023-07-31 23:14:17.567549: Pseudo dice [0.7743] 
2023-07-31 23:14:17.567603: Epoch time: 55.65 s 
2023-07-31 23:14:18.637977:  
2023-07-31 23:14:18.638073: Epoch 706 
2023-07-31 23:14:18.638180: Current learning rate: 0.00033 
2023-07-31 23:15:14.248559: train_loss -0.356 
2023-07-31 23:15:14.248728: val_loss -0.3532 
2023-07-31 23:15:14.248784: Pseudo dice [0.8352] 
2023-07-31 23:15:14.248838: Epoch time: 55.61 s 
2023-07-31 23:15:15.330833:  
2023-07-31 23:15:15.331027: Epoch 707 
2023-07-31 23:15:15.331128: Current learning rate: 0.00033 
2023-07-31 23:16:10.954820: train_loss -0.3686 
2023-07-31 23:16:10.954978: val_loss -0.3272 
2023-07-31 23:16:10.955050: Pseudo dice [0.8121] 
2023-07-31 23:16:10.955104: Epoch time: 55.62 s 
2023-07-31 23:16:12.215318:  
2023-07-31 23:16:12.215534: Epoch 708 
2023-07-31 23:16:12.215720: Current learning rate: 0.00033 
2023-07-31 23:17:07.812661: train_loss -0.3701 
2023-07-31 23:17:07.812826: val_loss -0.323 
2023-07-31 23:17:07.812885: Pseudo dice [0.7952] 
2023-07-31 23:17:07.812940: Epoch time: 55.6 s 
2023-07-31 23:17:08.891686:  
2023-07-31 23:17:08.891925: Epoch 709 
2023-07-31 23:17:08.892088: Current learning rate: 0.00033 
2023-07-31 23:18:04.436318: train_loss -0.3246 
2023-07-31 23:18:04.436483: val_loss -0.4016 
2023-07-31 23:18:04.436542: Pseudo dice [0.8906] 
2023-07-31 23:18:04.436613: Epoch time: 55.55 s 
2023-07-31 23:18:05.528081:  
2023-07-31 23:18:05.528186: Epoch 710 
2023-07-31 23:18:05.528279: Current learning rate: 0.00033 
2023-07-31 23:19:01.107938: train_loss -0.3705 
2023-07-31 23:19:01.108100: val_loss -0.351 
2023-07-31 23:19:01.108162: Pseudo dice [0.8523] 
2023-07-31 23:19:01.108218: Epoch time: 55.58 s 
2023-07-31 23:19:02.209618:  
2023-07-31 23:19:02.209720: Epoch 711 
2023-07-31 23:19:02.209810: Current learning rate: 0.00033 
2023-07-31 23:19:57.762798: train_loss -0.3218 
2023-07-31 23:19:57.762979: val_loss -0.2475 
2023-07-31 23:19:57.763038: Pseudo dice [0.7513] 
2023-07-31 23:19:57.763093: Epoch time: 55.55 s 
2023-07-31 23:19:58.860847:  
2023-07-31 23:19:58.861036: Epoch 712 
2023-07-31 23:19:58.861116: Current learning rate: 0.00033 
2023-07-31 23:20:54.488477: train_loss -0.3736 
2023-07-31 23:20:54.488640: val_loss -0.3652 
2023-07-31 23:20:54.488698: Pseudo dice [0.8444] 
2023-07-31 23:20:54.488770: Epoch time: 55.63 s 
2023-07-31 23:20:55.559527:  
2023-07-31 23:20:55.559658: Epoch 713 
2023-07-31 23:20:55.559734: Current learning rate: 0.00033 
2023-07-31 23:21:51.279139: train_loss -0.3411 
2023-07-31 23:21:51.279304: val_loss -0.3854 
2023-07-31 23:21:51.279365: Pseudo dice [0.9111] 
2023-07-31 23:21:51.279419: Epoch time: 55.72 s 
2023-07-31 23:21:52.346527:  
2023-07-31 23:21:52.346629: Epoch 714 
2023-07-31 23:21:52.346720: Current learning rate: 0.00032 
2023-07-31 23:22:47.944455: train_loss -0.389 
2023-07-31 23:22:47.944619: val_loss -0.3386 
2023-07-31 23:22:47.944678: Pseudo dice [0.8107] 
2023-07-31 23:22:47.944732: Epoch time: 55.6 s 
2023-07-31 23:22:49.047261:  
2023-07-31 23:22:49.047363: Epoch 715 
2023-07-31 23:22:49.047443: Current learning rate: 0.00032 
2023-07-31 23:23:44.658593: train_loss -0.3728 
2023-07-31 23:23:44.658748: val_loss -0.3253 
2023-07-31 23:23:44.658811: Pseudo dice [0.8178] 
2023-07-31 23:23:44.658866: Epoch time: 55.61 s 
2023-07-31 23:23:45.789423:  
2023-07-31 23:23:45.789526: Epoch 716 
2023-07-31 23:23:45.789618: Current learning rate: 0.00032 
2023-07-31 23:24:41.400209: train_loss -0.3482 
2023-07-31 23:24:41.400371: val_loss -0.3952 
2023-07-31 23:24:41.400434: Pseudo dice [0.8258] 
2023-07-31 23:24:41.400490: Epoch time: 55.61 s 
2023-07-31 23:24:42.470572:  
2023-07-31 23:24:42.470693: Epoch 717 
2023-07-31 23:24:42.470770: Current learning rate: 0.00032 
2023-07-31 23:25:38.011234: train_loss -0.3822 
2023-07-31 23:25:38.011428: val_loss -0.3445 
2023-07-31 23:25:38.011499: Pseudo dice [0.8436] 
2023-07-31 23:25:38.011556: Epoch time: 55.54 s 
2023-07-31 23:25:39.096979:  
2023-07-31 23:25:39.097083: Epoch 718 
2023-07-31 23:25:39.097184: Current learning rate: 0.00032 
2023-07-31 23:26:34.724783: train_loss -0.3641 
2023-07-31 23:26:34.724944: val_loss -0.3164 
2023-07-31 23:26:34.725003: Pseudo dice [0.7519] 
2023-07-31 23:26:34.725059: Epoch time: 55.63 s 
2023-07-31 23:26:35.971626:  
2023-07-31 23:26:35.971732: Epoch 719 
2023-07-31 23:26:35.971809: Current learning rate: 0.00032 
2023-07-31 23:27:31.599405: train_loss -0.3537 
2023-07-31 23:27:31.599593: val_loss -0.3576 
2023-07-31 23:27:31.599654: Pseudo dice [0.8334] 
2023-07-31 23:27:31.599710: Epoch time: 55.63 s 
2023-07-31 23:27:32.693906:  
2023-07-31 23:27:32.694008: Epoch 720 
2023-07-31 23:27:32.694083: Current learning rate: 0.00032 
2023-07-31 23:28:28.319408: train_loss -0.314 
2023-07-31 23:28:28.319581: val_loss -0.3154 
2023-07-31 23:28:28.319642: Pseudo dice [0.8413] 
2023-07-31 23:28:28.319696: Epoch time: 55.63 s 
2023-07-31 23:28:29.408869:  
2023-07-31 23:28:29.408977: Epoch 721 
2023-07-31 23:28:29.409068: Current learning rate: 0.00032 
2023-07-31 23:29:24.984060: train_loss -0.3251 
2023-07-31 23:29:24.984222: val_loss -0.3054 
2023-07-31 23:29:24.992618: Pseudo dice [0.8667] 
2023-07-31 23:29:24.992745: Epoch time: 55.58 s 
2023-07-31 23:29:26.067058:  
2023-07-31 23:29:26.067158: Epoch 722 
2023-07-31 23:29:26.067234: Current learning rate: 0.00032 
2023-07-31 23:30:21.670141: train_loss -0.3844 
2023-07-31 23:30:21.670306: val_loss -0.3011 
2023-07-31 23:30:21.670365: Pseudo dice [0.8742] 
2023-07-31 23:30:21.670420: Epoch time: 55.6 s 
2023-07-31 23:30:22.747337:  
2023-07-31 23:30:22.747438: Epoch 723 
2023-07-31 23:30:22.747537: Current learning rate: 0.00031 
2023-07-31 23:31:18.307563: train_loss -0.331 
2023-07-31 23:31:18.307716: val_loss -0.3152 
2023-07-31 23:31:18.307773: Pseudo dice [0.7678] 
2023-07-31 23:31:18.307828: Epoch time: 55.56 s 
2023-07-31 23:31:19.534507:  
2023-07-31 23:31:19.534613: Epoch 724 
2023-07-31 23:31:19.534720: Current learning rate: 0.00031 
2023-07-31 23:32:15.106889: train_loss -0.3399 
2023-07-31 23:32:15.107067: val_loss -0.429 
2023-07-31 23:32:15.107125: Pseudo dice [0.9001] 
2023-07-31 23:32:15.107180: Epoch time: 55.57 s 
2023-07-31 23:32:16.178396:  
2023-07-31 23:32:16.178498: Epoch 725 
2023-07-31 23:32:16.178588: Current learning rate: 0.00031 
2023-07-31 23:33:11.766631: train_loss -0.3517 
2023-07-31 23:33:11.766797: val_loss -0.3814 
2023-07-31 23:33:11.766853: Pseudo dice [0.8548] 
2023-07-31 23:33:11.766908: Epoch time: 55.59 s 
2023-07-31 23:33:12.880209:  
2023-07-31 23:33:12.880313: Epoch 726 
2023-07-31 23:33:12.880407: Current learning rate: 0.00031 
2023-07-31 23:34:08.499915: train_loss -0.3478 
2023-07-31 23:34:08.500075: val_loss -0.3706 
2023-07-31 23:34:08.500134: Pseudo dice [0.8069] 
2023-07-31 23:34:08.500189: Epoch time: 55.62 s 
2023-07-31 23:34:09.569967:  
2023-07-31 23:34:09.570073: Epoch 727 
2023-07-31 23:34:09.570167: Current learning rate: 0.00031 
2023-07-31 23:35:05.157461: train_loss -0.383 
2023-07-31 23:35:05.157635: val_loss -0.3263 
2023-07-31 23:35:05.157691: Pseudo dice [0.7682] 
2023-07-31 23:35:05.157746: Epoch time: 55.59 s 
2023-07-31 23:35:06.225744:  
2023-07-31 23:35:06.225840: Epoch 728 
2023-07-31 23:35:06.225930: Current learning rate: 0.00031 
2023-07-31 23:36:01.808310: train_loss -0.3774 
2023-07-31 23:36:01.808478: val_loss -0.404 
2023-07-31 23:36:01.808538: Pseudo dice [0.8566] 
2023-07-31 23:36:01.808592: Epoch time: 55.58 s 
2023-07-31 23:36:03.101482:  
2023-07-31 23:36:03.101589: Epoch 729 
2023-07-31 23:36:03.101682: Current learning rate: 0.00031 
2023-07-31 23:36:58.630314: train_loss -0.3482 
2023-07-31 23:36:58.630466: val_loss -0.214 
2023-07-31 23:36:58.630525: Pseudo dice [0.774] 
2023-07-31 23:36:58.630579: Epoch time: 55.53 s 
2023-07-31 23:36:59.702111:  
2023-07-31 23:36:59.702228: Epoch 730 
2023-07-31 23:36:59.702306: Current learning rate: 0.00031 
2023-07-31 23:37:55.339005: train_loss -0.3608 
2023-07-31 23:37:55.339169: val_loss -0.5014 
2023-07-31 23:37:55.339226: Pseudo dice [0.8502] 
2023-07-31 23:37:55.339291: Epoch time: 55.64 s 
2023-07-31 23:37:56.497784:  
2023-07-31 23:37:56.497982: Epoch 731 
2023-07-31 23:37:56.498079: Current learning rate: 0.00031 
2023-07-31 23:38:52.142571: train_loss -0.3424 
2023-07-31 23:38:52.142747: val_loss -0.4091 
2023-07-31 23:38:52.142809: Pseudo dice [0.8356] 
2023-07-31 23:38:52.142864: Epoch time: 55.65 s 
2023-07-31 23:38:53.232806:  
2023-07-31 23:38:53.233015: Epoch 732 
2023-07-31 23:38:53.233098: Current learning rate: 0.00031 
2023-07-31 23:39:48.844145: train_loss -0.3725 
2023-07-31 23:39:48.844310: val_loss -0.3635 
2023-07-31 23:39:48.844380: Pseudo dice [0.8811] 
2023-07-31 23:39:48.844436: Epoch time: 55.61 s 
2023-07-31 23:39:49.947600:  
2023-07-31 23:39:49.947697: Epoch 733 
2023-07-31 23:39:49.947774: Current learning rate: 0.0003 
2023-07-31 23:40:45.543821: train_loss -0.3261 
2023-07-31 23:40:45.543983: val_loss -0.4107 
2023-07-31 23:40:45.544046: Pseudo dice [0.8905] 
2023-07-31 23:40:45.544099: Epoch time: 55.6 s 
2023-07-31 23:40:46.814664:  
2023-07-31 23:40:46.814775: Epoch 734 
2023-07-31 23:40:46.814865: Current learning rate: 0.0003 
2023-07-31 23:41:42.353766: train_loss -0.3686 
2023-07-31 23:41:42.353923: val_loss -0.3855 
2023-07-31 23:41:42.354002: Pseudo dice [0.8122] 
2023-07-31 23:41:42.354217: Epoch time: 55.54 s 
2023-07-31 23:41:43.465440:  
2023-07-31 23:41:43.465642: Epoch 735 
2023-07-31 23:41:43.465888: Current learning rate: 0.0003 
2023-07-31 23:42:39.066084: train_loss -0.323 
2023-07-31 23:42:39.066247: val_loss -0.3153 
2023-07-31 23:42:39.066306: Pseudo dice [0.8464] 
2023-07-31 23:42:39.066360: Epoch time: 55.6 s 
2023-07-31 23:42:40.169477:  
2023-07-31 23:42:40.169574: Epoch 736 
2023-07-31 23:42:40.169664: Current learning rate: 0.0003 
2023-07-31 23:43:35.722922: train_loss -0.3507 
2023-07-31 23:43:35.723089: val_loss -0.2767 
2023-07-31 23:43:35.723147: Pseudo dice [0.7988] 
2023-07-31 23:43:35.723201: Epoch time: 55.55 s 
2023-07-31 23:43:36.828264:  
2023-07-31 23:43:36.828368: Epoch 737 
2023-07-31 23:43:36.828442: Current learning rate: 0.0003 
2023-07-31 23:44:32.427150: train_loss -0.3378 
2023-07-31 23:44:32.427309: val_loss -0.4309 
2023-07-31 23:44:32.427384: Pseudo dice [0.8472] 
2023-07-31 23:44:32.427440: Epoch time: 55.6 s 
2023-07-31 23:44:33.504547:  
2023-07-31 23:44:33.504651: Epoch 738 
2023-07-31 23:44:33.504740: Current learning rate: 0.0003 
2023-07-31 23:45:29.062129: train_loss -0.359 
2023-07-31 23:45:29.062300: val_loss -0.3863 
2023-07-31 23:45:29.062356: Pseudo dice [0.8541] 
2023-07-31 23:45:29.062411: Epoch time: 55.56 s 
2023-07-31 23:45:30.140578:  
2023-07-31 23:45:30.140685: Epoch 739 
2023-07-31 23:45:30.140774: Current learning rate: 0.0003 
2023-07-31 23:46:25.758076: train_loss -0.3796 
2023-07-31 23:46:25.758230: val_loss -0.3401 
2023-07-31 23:46:25.758286: Pseudo dice [0.8417] 
2023-07-31 23:46:25.758339: Epoch time: 55.62 s 
2023-07-31 23:46:27.007767:  
2023-07-31 23:46:27.007886: Epoch 740 
2023-07-31 23:46:27.007965: Current learning rate: 0.0003 
2023-07-31 23:47:22.623719: train_loss -0.3646 
2023-07-31 23:47:22.623887: val_loss -0.368 
2023-07-31 23:47:22.623948: Pseudo dice [0.7862] 
2023-07-31 23:47:22.624002: Epoch time: 55.62 s 
2023-07-31 23:47:23.696187:  
2023-07-31 23:47:23.696300: Epoch 741 
2023-07-31 23:47:23.696375: Current learning rate: 0.0003 
2023-07-31 23:48:19.244083: train_loss -0.3285 
2023-07-31 23:48:19.244261: val_loss -0.2891 
2023-07-31 23:48:19.244320: Pseudo dice [0.7917] 
2023-07-31 23:48:19.244375: Epoch time: 55.55 s 
2023-07-31 23:48:20.325712:  
2023-07-31 23:48:20.325821: Epoch 742 
2023-07-31 23:48:20.325911: Current learning rate: 0.0003 
2023-07-31 23:49:15.834952: train_loss -0.3293 
2023-07-31 23:49:15.835123: val_loss -0.3459 
2023-07-31 23:49:15.835183: Pseudo dice [0.8001] 
2023-07-31 23:49:15.835237: Epoch time: 55.51 s 
2023-07-31 23:49:16.909310:  
2023-07-31 23:49:16.909420: Epoch 743 
2023-07-31 23:49:16.909511: Current learning rate: 0.00029 
2023-07-31 23:50:12.569944: train_loss -0.3585 
2023-07-31 23:50:12.570124: val_loss -0.3004 
2023-07-31 23:50:12.570195: Pseudo dice [0.853] 
2023-07-31 23:50:12.570251: Epoch time: 55.66 s 
2023-07-31 23:50:13.670312:  
2023-07-31 23:50:13.670413: Epoch 744 
2023-07-31 23:50:13.670503: Current learning rate: 0.00029 
2023-07-31 23:51:09.293491: train_loss -0.3553 
2023-07-31 23:51:09.293643: val_loss -0.3452 
2023-07-31 23:51:09.293718: Pseudo dice [0.7603] 
2023-07-31 23:51:09.293771: Epoch time: 55.62 s 
2023-07-31 23:51:10.513096:  
2023-07-31 23:51:10.513205: Epoch 745 
2023-07-31 23:51:10.513296: Current learning rate: 0.00029 
2023-07-31 23:52:06.150044: train_loss -0.3706 
2023-07-31 23:52:06.150210: val_loss -0.3125 
2023-07-31 23:52:06.150271: Pseudo dice [0.8802] 
2023-07-31 23:52:06.150327: Epoch time: 55.64 s 
2023-07-31 23:52:07.222232:  
2023-07-31 23:52:07.222334: Epoch 746 
2023-07-31 23:52:07.222427: Current learning rate: 0.00029 
2023-07-31 23:53:02.759110: train_loss -0.3886 
2023-07-31 23:53:02.759266: val_loss -0.4573 
2023-07-31 23:53:02.759321: Pseudo dice [0.8941] 
2023-07-31 23:53:02.759375: Epoch time: 55.54 s 
2023-07-31 23:53:03.884881:  
2023-07-31 23:53:03.884991: Epoch 747 
2023-07-31 23:53:03.885098: Current learning rate: 0.00029 
2023-07-31 23:53:59.479869: train_loss -0.3645 
2023-07-31 23:53:59.480034: val_loss -0.322 
2023-07-31 23:53:59.480094: Pseudo dice [0.9015] 
2023-07-31 23:53:59.480149: Epoch time: 55.6 s 
2023-07-31 23:53:59.480193: Yayy! New best EMA pseudo Dice: 0.8407 
2023-07-31 23:54:00.955382:  
2023-07-31 23:54:00.955731: Epoch 748 
2023-07-31 23:54:00.955987: Current learning rate: 0.00029 
2023-07-31 23:54:56.431978: train_loss -0.3694 
2023-07-31 23:54:56.432142: val_loss -0.3387 
2023-07-31 23:54:56.432202: Pseudo dice [0.8577] 
2023-07-31 23:54:56.432257: Epoch time: 55.48 s 
2023-07-31 23:54:56.432301: Yayy! New best EMA pseudo Dice: 0.8424 
2023-07-31 23:54:57.878742:  
2023-07-31 23:54:57.878943: Epoch 749 
2023-07-31 23:54:57.879026: Current learning rate: 0.00029 
2023-07-31 23:55:53.377275: train_loss -0.3197 
2023-07-31 23:55:53.377432: val_loss -0.3064 
2023-07-31 23:55:53.377488: Pseudo dice [0.8463] 
2023-07-31 23:55:53.377541: Epoch time: 55.5 s 
2023-07-31 23:55:53.737477: Yayy! New best EMA pseudo Dice: 0.8428 
2023-07-31 23:55:55.320652:  
2023-07-31 23:55:55.320762: Epoch 750 
2023-07-31 23:55:55.320842: Current learning rate: 0.00029 
2023-07-31 23:56:50.831607: train_loss -0.3221 
2023-07-31 23:56:50.831773: val_loss -0.3845 
2023-07-31 23:56:50.831830: Pseudo dice [0.8346] 
2023-07-31 23:56:50.831885: Epoch time: 55.51 s 
2023-07-31 23:56:51.932775:  
2023-07-31 23:56:51.932899: Epoch 751 
2023-07-31 23:56:51.932993: Current learning rate: 0.00029 
2023-07-31 23:57:47.506558: train_loss -0.366 
2023-07-31 23:57:47.506731: val_loss -0.498 
2023-07-31 23:57:47.506790: Pseudo dice [0.9123] 
2023-07-31 23:57:47.506845: Epoch time: 55.57 s 
2023-07-31 23:57:47.506888: Yayy! New best EMA pseudo Dice: 0.849 
2023-07-31 23:57:49.030454:  
2023-07-31 23:57:49.030566: Epoch 752 
2023-07-31 23:57:49.030645: Current learning rate: 0.00029 
2023-07-31 23:58:44.498199: train_loss -0.3376 
2023-07-31 23:58:44.498351: val_loss -0.399 
2023-07-31 23:58:44.498425: Pseudo dice [0.8378] 
2023-07-31 23:58:44.498479: Epoch time: 55.47 s 
2023-07-31 23:58:45.630871:  
2023-07-31 23:58:45.631194: Epoch 753 
2023-07-31 23:58:45.631334: Current learning rate: 0.00028 
2023-07-31 23:59:41.219027: train_loss -0.327 
2023-07-31 23:59:41.219202: val_loss -0.3111 
2023-07-31 23:59:41.219262: Pseudo dice [0.8574] 
2023-07-31 23:59:41.219315: Epoch time: 55.59 s 
2023-07-31 23:59:42.290344:  
2023-07-31 23:59:42.290444: Epoch 754 
2023-07-31 23:59:42.290535: Current learning rate: 0.00028 
2023-08-01 00:00:37.925492: train_loss -0.3289 
2023-08-01 00:00:37.925635: val_loss -0.3703 
2023-08-01 00:00:37.925692: Pseudo dice [0.7728] 
2023-08-01 00:00:37.925747: Epoch time: 55.64 s 
2023-08-01 00:00:39.160630:  
2023-08-01 00:00:39.160736: Epoch 755 
2023-08-01 00:00:39.160815: Current learning rate: 0.00028 
2023-08-01 00:01:34.757049: train_loss -0.336 
2023-08-01 00:01:34.757243: val_loss -0.4213 
2023-08-01 00:01:34.757309: Pseudo dice [0.8819] 
2023-08-01 00:01:34.757367: Epoch time: 55.6 s 
2023-08-01 00:01:35.836243:  
2023-08-01 00:01:35.836347: Epoch 756 
2023-08-01 00:01:35.836422: Current learning rate: 0.00028 
2023-08-01 00:02:31.415851: train_loss -0.3712 
2023-08-01 00:02:31.416127: val_loss -0.3564 
2023-08-01 00:02:31.416193: Pseudo dice [0.806] 
2023-08-01 00:02:31.416249: Epoch time: 55.58 s 
2023-08-01 00:02:32.553827:  
2023-08-01 00:02:32.553935: Epoch 757 
2023-08-01 00:02:32.554013: Current learning rate: 0.00028 
2023-08-01 00:03:28.154984: train_loss -0.3159 
2023-08-01 00:03:28.155352: val_loss -0.391 
2023-08-01 00:03:28.155460: Pseudo dice [0.9201] 
2023-08-01 00:03:28.155581: Epoch time: 55.6 s 
2023-08-01 00:03:28.155668: Yayy! New best EMA pseudo Dice: 0.8492 
2023-08-01 00:03:29.625180:  
2023-08-01 00:03:29.625285: Epoch 758 
2023-08-01 00:03:29.625363: Current learning rate: 0.00028 
2023-08-01 00:04:25.180862: train_loss -0.384 
2023-08-01 00:04:25.181019: val_loss -0.3644 
2023-08-01 00:04:25.181078: Pseudo dice [0.8126] 
2023-08-01 00:04:25.181133: Epoch time: 55.56 s 
2023-08-01 00:04:26.273985:  
2023-08-01 00:04:26.274084: Epoch 759 
2023-08-01 00:04:26.274173: Current learning rate: 0.00028 
2023-08-01 00:05:21.809787: train_loss -0.3611 
2023-08-01 00:05:21.809952: val_loss -0.4237 
2023-08-01 00:05:21.810014: Pseudo dice [0.8148] 
2023-08-01 00:05:21.810069: Epoch time: 55.54 s 
2023-08-01 00:05:23.035820:  
2023-08-01 00:05:23.035941: Epoch 760 
2023-08-01 00:05:23.036035: Current learning rate: 0.00028 
2023-08-01 00:06:18.639690: train_loss -0.324 
2023-08-01 00:06:18.639933: val_loss -0.3856 
2023-08-01 00:06:18.639992: Pseudo dice [0.8201] 
2023-08-01 00:06:18.640047: Epoch time: 55.6 s 
2023-08-01 00:06:19.724682:  
2023-08-01 00:06:19.724794: Epoch 761 
2023-08-01 00:06:19.724885: Current learning rate: 0.00028 
2023-08-01 00:07:15.312807: train_loss -0.3336 
2023-08-01 00:07:15.312970: val_loss -0.4324 
2023-08-01 00:07:15.313033: Pseudo dice [0.8894] 
2023-08-01 00:07:15.313089: Epoch time: 55.59 s 
2023-08-01 00:07:16.418734:  
2023-08-01 00:07:16.418837: Epoch 762 
2023-08-01 00:07:16.418927: Current learning rate: 0.00027 
2023-08-01 00:08:11.935386: train_loss -0.362 
2023-08-01 00:08:11.935566: val_loss -0.3909 
2023-08-01 00:08:11.935626: Pseudo dice [0.856] 
2023-08-01 00:08:11.935680: Epoch time: 55.52 s 
2023-08-01 00:08:13.039756:  
2023-08-01 00:08:13.039859: Epoch 763 
2023-08-01 00:08:13.039937: Current learning rate: 0.00027 
2023-08-01 00:09:08.550734: train_loss -0.3391 
2023-08-01 00:09:08.550895: val_loss -0.4145 
2023-08-01 00:09:08.550954: Pseudo dice [0.8975] 
2023-08-01 00:09:08.551012: Epoch time: 55.51 s 
2023-08-01 00:09:08.551063: Yayy! New best EMA pseudo Dice: 0.8514 
2023-08-01 00:09:10.046106:  
2023-08-01 00:09:10.046225: Epoch 764 
2023-08-01 00:09:10.046319: Current learning rate: 0.00027 
2023-08-01 00:10:05.551665: train_loss -0.3354 
2023-08-01 00:10:05.551823: val_loss -0.3615 
2023-08-01 00:10:05.551881: Pseudo dice [0.8224] 
2023-08-01 00:10:05.551941: Epoch time: 55.51 s 
2023-08-01 00:10:06.793586:  
2023-08-01 00:10:06.793705: Epoch 765 
2023-08-01 00:10:06.793784: Current learning rate: 0.00027 
2023-08-01 00:11:02.389602: train_loss -0.3502 
2023-08-01 00:11:02.389791: val_loss -0.3766 
2023-08-01 00:11:02.389850: Pseudo dice [0.8172] 
2023-08-01 00:11:02.389903: Epoch time: 55.6 s 
2023-08-01 00:11:03.518928:  
2023-08-01 00:11:03.519052: Epoch 766 
2023-08-01 00:11:03.519146: Current learning rate: 0.00027 
2023-08-01 00:11:59.123398: train_loss -0.3369 
2023-08-01 00:11:59.123568: val_loss -0.3624 
2023-08-01 00:11:59.123626: Pseudo dice [0.8449] 
2023-08-01 00:11:59.123680: Epoch time: 55.61 s 
2023-08-01 00:12:00.214774:  
2023-08-01 00:12:00.214891: Epoch 767 
2023-08-01 00:12:00.214983: Current learning rate: 0.00027 
2023-08-01 00:12:55.819945: train_loss -0.3602 
2023-08-01 00:12:55.820107: val_loss -0.3794 
2023-08-01 00:12:55.820168: Pseudo dice [0.8371] 
2023-08-01 00:12:55.820222: Epoch time: 55.61 s 
2023-08-01 00:12:56.934832:  
2023-08-01 00:12:56.934948: Epoch 768 
2023-08-01 00:12:56.935026: Current learning rate: 0.00027 
2023-08-01 00:13:52.548954: train_loss -0.3395 
2023-08-01 00:13:52.549129: val_loss -0.3402 
2023-08-01 00:13:52.549189: Pseudo dice [0.8871] 
2023-08-01 00:13:52.549244: Epoch time: 55.61 s 
2023-08-01 00:13:53.642099:  
2023-08-01 00:13:53.642202: Epoch 769 
2023-08-01 00:13:53.642308: Current learning rate: 0.00027 
2023-08-01 00:14:49.177064: train_loss -0.3788 
2023-08-01 00:14:49.177226: val_loss -0.3426 
2023-08-01 00:14:49.177283: Pseudo dice [0.8061] 
2023-08-01 00:14:49.177337: Epoch time: 55.54 s 
2023-08-01 00:14:50.416533:  
2023-08-01 00:14:50.416638: Epoch 770 
2023-08-01 00:14:50.416721: Current learning rate: 0.00027 
2023-08-01 00:15:46.048067: train_loss -0.3582 
2023-08-01 00:15:46.048245: val_loss -0.3789 
2023-08-01 00:15:46.048305: Pseudo dice [0.8479] 
2023-08-01 00:15:46.048359: Epoch time: 55.63 s 
2023-08-01 00:15:47.139201:  
2023-08-01 00:15:47.139304: Epoch 771 
2023-08-01 00:15:47.139396: Current learning rate: 0.00027 
2023-08-01 00:16:42.743042: train_loss -0.335 
2023-08-01 00:16:42.743200: val_loss -0.3482 
2023-08-01 00:16:42.743260: Pseudo dice [0.853] 
2023-08-01 00:16:42.743314: Epoch time: 55.6 s 
2023-08-01 00:16:43.880107:  
2023-08-01 00:16:43.880409: Epoch 772 
2023-08-01 00:16:43.880490: Current learning rate: 0.00026 
2023-08-01 00:17:39.555931: train_loss -0.3375 
2023-08-01 00:17:39.556097: val_loss -0.364 
2023-08-01 00:17:39.556154: Pseudo dice [0.7917] 
2023-08-01 00:17:39.556209: Epoch time: 55.68 s 
2023-08-01 00:17:40.652539:  
2023-08-01 00:17:40.652646: Epoch 773 
2023-08-01 00:17:40.652724: Current learning rate: 0.00026 
2023-08-01 00:18:36.314096: train_loss -0.3608 
2023-08-01 00:18:36.314256: val_loss -0.3671 
2023-08-01 00:18:36.314316: Pseudo dice [0.8107] 
2023-08-01 00:18:36.314386: Epoch time: 55.66 s 
2023-08-01 00:18:37.423692:  
2023-08-01 00:18:37.423793: Epoch 774 
2023-08-01 00:18:37.423883: Current learning rate: 0.00026 
2023-08-01 00:19:33.021731: train_loss -0.372 
2023-08-01 00:19:33.021897: val_loss -0.3294 
2023-08-01 00:19:33.021955: Pseudo dice [0.8371] 
2023-08-01 00:19:33.022008: Epoch time: 55.6 s 
2023-08-01 00:19:34.166235:  
2023-08-01 00:19:34.166336: Epoch 775 
2023-08-01 00:19:34.166446: Current learning rate: 0.00026 
2023-08-01 00:20:29.808337: train_loss -0.3635 
2023-08-01 00:20:29.808509: val_loss -0.3282 
2023-08-01 00:20:29.808567: Pseudo dice [0.8748] 
2023-08-01 00:20:29.808621: Epoch time: 55.64 s 
2023-08-01 00:20:31.134456:  
2023-08-01 00:20:31.134577: Epoch 776 
2023-08-01 00:20:31.134667: Current learning rate: 0.00026 
2023-08-01 00:21:26.705378: train_loss -0.3086 
2023-08-01 00:21:26.705534: val_loss -0.3457 
2023-08-01 00:21:26.705590: Pseudo dice [0.809] 
2023-08-01 00:21:26.705644: Epoch time: 55.57 s 
2023-08-01 00:21:27.797834:  
2023-08-01 00:21:27.797955: Epoch 777 
2023-08-01 00:21:27.798033: Current learning rate: 0.00026 
2023-08-01 00:22:23.424077: train_loss -0.3667 
2023-08-01 00:22:23.424239: val_loss -0.3321 
2023-08-01 00:22:23.424298: Pseudo dice [0.8446] 
2023-08-01 00:22:23.424352: Epoch time: 55.63 s 
2023-08-01 00:22:24.518743:  
2023-08-01 00:22:24.518845: Epoch 778 
2023-08-01 00:22:24.518938: Current learning rate: 0.00026 
2023-08-01 00:23:20.099975: train_loss -0.3271 
2023-08-01 00:23:20.100138: val_loss -0.3215 
2023-08-01 00:23:20.100195: Pseudo dice [0.8326] 
2023-08-01 00:23:20.100250: Epoch time: 55.58 s 
2023-08-01 00:23:21.212484:  
2023-08-01 00:23:21.212588: Epoch 779 
2023-08-01 00:23:21.212666: Current learning rate: 0.00026 
2023-08-01 00:24:16.819672: train_loss -0.3729 
2023-08-01 00:24:16.819832: val_loss -0.351 
2023-08-01 00:24:16.819891: Pseudo dice [0.8053] 
2023-08-01 00:24:16.819945: Epoch time: 55.61 s 
2023-08-01 00:24:17.910660:  
2023-08-01 00:24:17.910763: Epoch 780 
2023-08-01 00:24:17.910840: Current learning rate: 0.00026 
2023-08-01 00:25:13.474399: train_loss -0.3553 
2023-08-01 00:25:13.474563: val_loss -0.3418 
2023-08-01 00:25:13.474635: Pseudo dice [0.8104] 
2023-08-01 00:25:13.474692: Epoch time: 55.56 s 
2023-08-01 00:25:14.738644:  
2023-08-01 00:25:14.738750: Epoch 781 
2023-08-01 00:25:14.738842: Current learning rate: 0.00025 
2023-08-01 00:26:10.341632: train_loss -0.3531 
2023-08-01 00:26:10.341793: val_loss -0.3219 
2023-08-01 00:26:10.341854: Pseudo dice [0.7847] 
2023-08-01 00:26:10.341908: Epoch time: 55.6 s 
2023-08-01 00:26:11.428580:  
2023-08-01 00:26:11.428682: Epoch 782 
2023-08-01 00:26:11.428761: Current learning rate: 0.00025 
2023-08-01 00:27:07.057551: train_loss -0.3673 
2023-08-01 00:27:07.057707: val_loss -0.3789 
2023-08-01 00:27:07.057767: Pseudo dice [0.8619] 
2023-08-01 00:27:07.057821: Epoch time: 55.63 s 
2023-08-01 00:27:08.147017:  
2023-08-01 00:27:08.147114: Epoch 783 
2023-08-01 00:27:08.147203: Current learning rate: 0.00025 
2023-08-01 00:28:03.659220: train_loss -0.3415 
2023-08-01 00:28:03.659406: val_loss -0.3631 
2023-08-01 00:28:03.659465: Pseudo dice [0.83] 
2023-08-01 00:28:03.659529: Epoch time: 55.51 s 
2023-08-01 00:28:04.758553:  
2023-08-01 00:28:04.758653: Epoch 784 
2023-08-01 00:28:04.758760: Current learning rate: 0.00025 
2023-08-01 00:29:00.321620: train_loss -0.3557 
2023-08-01 00:29:00.321773: val_loss -0.3517 
2023-08-01 00:29:00.321831: Pseudo dice [0.8611] 
2023-08-01 00:29:00.321885: Epoch time: 55.56 s 
2023-08-01 00:29:01.423797:  
2023-08-01 00:29:01.423895: Epoch 785 
2023-08-01 00:29:01.423974: Current learning rate: 0.00025 
2023-08-01 00:29:56.917850: train_loss -0.3381 
2023-08-01 00:29:56.918012: val_loss -0.3944 
2023-08-01 00:29:56.918068: Pseudo dice [0.8383] 
2023-08-01 00:29:56.918122: Epoch time: 55.49 s 
2023-08-01 00:29:58.053703:  
2023-08-01 00:29:58.053800: Epoch 786 
2023-08-01 00:29:58.053893: Current learning rate: 0.00025 
2023-08-01 00:30:53.721410: train_loss -0.3693 
2023-08-01 00:30:53.721573: val_loss -0.3959 
2023-08-01 00:30:53.721634: Pseudo dice [0.7928] 
2023-08-01 00:30:53.721689: Epoch time: 55.67 s 
2023-08-01 00:30:54.803367:  
2023-08-01 00:30:54.803470: Epoch 787 
2023-08-01 00:30:54.803568: Current learning rate: 0.00025 
2023-08-01 00:31:50.444126: train_loss -0.3289 
2023-08-01 00:31:50.444282: val_loss -0.3283 
2023-08-01 00:31:50.444344: Pseudo dice [0.8752] 
2023-08-01 00:31:50.444399: Epoch time: 55.64 s 
2023-08-01 00:31:51.534119:  
2023-08-01 00:31:51.534237: Epoch 788 
2023-08-01 00:31:51.534328: Current learning rate: 0.00025 
2023-08-01 00:32:47.178082: train_loss -0.3422 
2023-08-01 00:32:47.178257: val_loss -0.3753 
2023-08-01 00:32:47.178317: Pseudo dice [0.8537] 
2023-08-01 00:32:47.178372: Epoch time: 55.64 s 
2023-08-01 00:32:48.290299:  
2023-08-01 00:32:48.290400: Epoch 789 
2023-08-01 00:32:48.290509: Current learning rate: 0.00025 
2023-08-01 00:33:43.904843: train_loss -0.3895 
2023-08-01 00:33:43.905002: val_loss -0.3729 
2023-08-01 00:33:43.905063: Pseudo dice [0.8377] 
2023-08-01 00:33:43.905117: Epoch time: 55.62 s 
2023-08-01 00:33:45.022386:  
2023-08-01 00:33:45.022489: Epoch 790 
2023-08-01 00:33:45.022582: Current learning rate: 0.00025 
2023-08-01 00:34:40.574468: train_loss -0.3682 
2023-08-01 00:34:40.574641: val_loss -0.3541 
2023-08-01 00:34:40.574703: Pseudo dice [0.8401] 
2023-08-01 00:34:40.574760: Epoch time: 55.55 s 
2023-08-01 00:34:41.820037:  
2023-08-01 00:34:41.820153: Epoch 791 
2023-08-01 00:34:41.820249: Current learning rate: 0.00024 
2023-08-01 00:35:37.467273: train_loss -0.3674 
2023-08-01 00:35:37.467453: val_loss -0.3867 
2023-08-01 00:35:37.467520: Pseudo dice [0.8041] 
2023-08-01 00:35:37.467577: Epoch time: 55.65 s 
2023-08-01 00:35:38.590330:  
2023-08-01 00:35:38.590437: Epoch 792 
2023-08-01 00:35:38.590544: Current learning rate: 0.00024 
2023-08-01 00:36:34.171467: train_loss -0.3206 
2023-08-01 00:36:34.171649: val_loss -0.3054 
2023-08-01 00:36:34.171708: Pseudo dice [0.8171] 
2023-08-01 00:36:34.171762: Epoch time: 55.58 s 
2023-08-01 00:36:35.290675:  
2023-08-01 00:36:35.290895: Epoch 793 
2023-08-01 00:36:35.291006: Current learning rate: 0.00024 
2023-08-01 00:37:30.896099: train_loss -0.3407 
2023-08-01 00:37:30.896255: val_loss -0.3558 
2023-08-01 00:37:30.896316: Pseudo dice [0.8623] 
2023-08-01 00:37:30.896371: Epoch time: 55.61 s 
2023-08-01 00:37:32.021544:  
2023-08-01 00:37:32.021645: Epoch 794 
2023-08-01 00:37:32.021752: Current learning rate: 0.00024 
2023-08-01 00:38:27.556305: train_loss -0.3366 
2023-08-01 00:38:27.556568: val_loss -0.2987 
2023-08-01 00:38:27.556633: Pseudo dice [0.8188] 
2023-08-01 00:38:27.556689: Epoch time: 55.54 s 
2023-08-01 00:38:28.651425:  
2023-08-01 00:38:28.651551: Epoch 795 
2023-08-01 00:38:28.651630: Current learning rate: 0.00024 
2023-08-01 00:39:24.243832: train_loss -0.3272 
2023-08-01 00:39:24.244112: val_loss -0.3675 
2023-08-01 00:39:24.252519: Pseudo dice [0.8555] 
2023-08-01 00:39:24.252658: Epoch time: 55.59 s 
2023-08-01 00:39:25.408140:  
2023-08-01 00:39:25.408239: Epoch 796 
2023-08-01 00:39:25.408316: Current learning rate: 0.00024 
2023-08-01 00:40:20.946686: train_loss -0.3314 
2023-08-01 00:40:20.946857: val_loss -0.3443 
2023-08-01 00:40:20.946918: Pseudo dice [0.9073] 
2023-08-01 00:40:20.946972: Epoch time: 55.54 s 
2023-08-01 00:40:22.222816:  
2023-08-01 00:40:22.222929: Epoch 797 
2023-08-01 00:40:22.223006: Current learning rate: 0.00024 
2023-08-01 00:41:17.805494: train_loss -0.3632 
2023-08-01 00:41:17.805676: val_loss -0.3373 
2023-08-01 00:41:17.805733: Pseudo dice [0.8664] 
2023-08-01 00:41:17.805787: Epoch time: 55.58 s 
2023-08-01 00:41:18.910764:  
2023-08-01 00:41:18.910880: Epoch 798 
2023-08-01 00:41:18.910957: Current learning rate: 0.00024 
2023-08-01 00:42:14.549891: train_loss -0.3753 
2023-08-01 00:42:14.550053: val_loss -0.3551 
2023-08-01 00:42:14.550110: Pseudo dice [0.8852] 
2023-08-01 00:42:14.550164: Epoch time: 55.64 s 
2023-08-01 00:42:15.641982:  
2023-08-01 00:42:15.642104: Epoch 799 
2023-08-01 00:42:15.642180: Current learning rate: 0.00024 
2023-08-01 00:43:11.196250: train_loss -0.3335 
2023-08-01 00:43:11.196411: val_loss -0.3154 
2023-08-01 00:43:11.196467: Pseudo dice [0.7906] 
2023-08-01 00:43:11.196522: Epoch time: 55.55 s 
2023-08-01 00:43:12.713639:  
2023-08-01 00:43:12.713745: Epoch 800 
2023-08-01 00:43:12.713837: Current learning rate: 0.00023 
2023-08-01 00:44:08.275121: train_loss -0.3477 
2023-08-01 00:44:08.275285: val_loss -0.4704 
2023-08-01 00:44:08.275359: Pseudo dice [0.8632] 
2023-08-01 00:44:08.275414: Epoch time: 55.56 s 
2023-08-01 00:44:09.412010:  
2023-08-01 00:44:09.412191: Epoch 801 
2023-08-01 00:44:09.412272: Current learning rate: 0.00023 
2023-08-01 00:45:05.074327: train_loss -0.3395 
2023-08-01 00:45:05.074504: val_loss -0.3652 
2023-08-01 00:45:05.074563: Pseudo dice [0.815] 
2023-08-01 00:45:05.074618: Epoch time: 55.66 s 
2023-08-01 00:45:06.346040:  
2023-08-01 00:45:06.346215: Epoch 802 
2023-08-01 00:45:06.346313: Current learning rate: 0.00023 
2023-08-01 00:46:01.936511: train_loss -0.3594 
2023-08-01 00:46:01.936668: val_loss -0.3479 
2023-08-01 00:46:01.936729: Pseudo dice [0.8384] 
2023-08-01 00:46:01.936784: Epoch time: 55.59 s 
2023-08-01 00:46:03.025957:  
2023-08-01 00:46:03.026063: Epoch 803 
2023-08-01 00:46:03.026154: Current learning rate: 0.00023 
2023-08-01 00:46:58.679977: train_loss -0.376 
2023-08-01 00:46:58.680144: val_loss -0.3894 
2023-08-01 00:46:58.680202: Pseudo dice [0.8452] 
2023-08-01 00:46:58.680257: Epoch time: 55.65 s 
2023-08-01 00:46:59.834274:  
2023-08-01 00:46:59.834404: Epoch 804 
2023-08-01 00:46:59.834481: Current learning rate: 0.00023 
2023-08-01 00:47:55.397576: train_loss -0.3371 
2023-08-01 00:47:55.397749: val_loss -0.3562 
2023-08-01 00:47:55.397807: Pseudo dice [0.8529] 
2023-08-01 00:47:55.397860: Epoch time: 55.56 s 
2023-08-01 00:47:56.492398:  
2023-08-01 00:47:56.492496: Epoch 805 
2023-08-01 00:47:56.492573: Current learning rate: 0.00023 
2023-08-01 00:48:52.064696: train_loss -0.3594 
2023-08-01 00:48:52.064863: val_loss -0.3629 
2023-08-01 00:48:52.064920: Pseudo dice [0.8079] 
2023-08-01 00:48:52.064973: Epoch time: 55.57 s 
2023-08-01 00:48:53.231596:  
2023-08-01 00:48:53.231704: Epoch 806 
2023-08-01 00:48:53.231800: Current learning rate: 0.00023 
2023-08-01 00:49:48.844781: train_loss -0.3303 
2023-08-01 00:49:48.844964: val_loss -0.4424 
2023-08-01 00:49:48.845023: Pseudo dice [0.8554] 
2023-08-01 00:49:48.845078: Epoch time: 55.61 s 
2023-08-01 00:49:50.094468:  
2023-08-01 00:49:50.094660: Epoch 807 
2023-08-01 00:49:50.094759: Current learning rate: 0.00023 
2023-08-01 00:50:45.702481: train_loss -0.3885 
2023-08-01 00:50:45.702650: val_loss -0.4073 
2023-08-01 00:50:45.702709: Pseudo dice [0.8184] 
2023-08-01 00:50:45.702763: Epoch time: 55.61 s 
2023-08-01 00:50:46.798801:  
2023-08-01 00:50:46.798903: Epoch 808 
2023-08-01 00:50:46.798997: Current learning rate: 0.00023 
2023-08-01 00:51:42.397594: train_loss -0.3851 
2023-08-01 00:51:42.397775: val_loss -0.2891 
2023-08-01 00:51:42.397836: Pseudo dice [0.8068] 
2023-08-01 00:51:42.397890: Epoch time: 55.6 s 
2023-08-01 00:51:43.496861:  
2023-08-01 00:51:43.496958: Epoch 809 
2023-08-01 00:51:43.497051: Current learning rate: 0.00023 
2023-08-01 00:52:39.060959: train_loss -0.3501 
2023-08-01 00:52:39.061125: val_loss -0.4143 
2023-08-01 00:52:39.061182: Pseudo dice [0.8356] 
2023-08-01 00:52:39.061237: Epoch time: 55.56 s 
2023-08-01 00:52:40.188417:  
2023-08-01 00:52:40.188787: Epoch 810 
2023-08-01 00:52:40.188874: Current learning rate: 0.00022 
2023-08-01 00:53:35.819973: train_loss -0.3779 
2023-08-01 00:53:35.820153: val_loss -0.3455 
2023-08-01 00:53:35.820211: Pseudo dice [0.792] 
2023-08-01 00:53:35.820267: Epoch time: 55.63 s 
2023-08-01 00:53:36.936995:  
2023-08-01 00:53:36.937094: Epoch 811 
2023-08-01 00:53:36.937186: Current learning rate: 0.00022 
2023-08-01 00:54:32.520480: train_loss -0.3583 
2023-08-01 00:54:32.520635: val_loss -0.3593 
2023-08-01 00:54:32.520696: Pseudo dice [0.824] 
2023-08-01 00:54:32.520750: Epoch time: 55.58 s 
2023-08-01 00:54:33.618036:  
2023-08-01 00:54:33.618140: Epoch 812 
2023-08-01 00:54:33.618233: Current learning rate: 0.00022 
2023-08-01 00:55:29.118246: train_loss -0.3399 
2023-08-01 00:55:29.118402: val_loss -0.3566 
2023-08-01 00:55:29.118464: Pseudo dice [0.8818] 
2023-08-01 00:55:29.118518: Epoch time: 55.5 s 
2023-08-01 00:55:30.218219:  
2023-08-01 00:55:30.218317: Epoch 813 
2023-08-01 00:55:30.218407: Current learning rate: 0.00022 
2023-08-01 00:56:25.808760: train_loss -0.3556 
2023-08-01 00:56:25.808918: val_loss -0.3651 
2023-08-01 00:56:25.808973: Pseudo dice [0.7866] 
2023-08-01 00:56:25.809029: Epoch time: 55.59 s 
2023-08-01 00:56:26.910222:  
2023-08-01 00:56:26.910321: Epoch 814 
2023-08-01 00:56:26.910414: Current learning rate: 0.00022 
2023-08-01 00:57:22.423359: train_loss -0.3877 
2023-08-01 00:57:22.423544: val_loss -0.3408 
2023-08-01 00:57:22.423607: Pseudo dice [0.8592] 
2023-08-01 00:57:22.423662: Epoch time: 55.51 s 
2023-08-01 00:57:23.544051:  
2023-08-01 00:57:23.544157: Epoch 815 
2023-08-01 00:57:23.544233: Current learning rate: 0.00022 
2023-08-01 00:58:19.090926: train_loss -0.3142 
2023-08-01 00:58:19.091099: val_loss -0.3585 
2023-08-01 00:58:19.091156: Pseudo dice [0.9271] 
2023-08-01 00:58:19.091211: Epoch time: 55.55 s 
2023-08-01 00:58:20.362982:  
2023-08-01 00:58:20.363100: Epoch 816 
2023-08-01 00:58:20.363193: Current learning rate: 0.00022 
2023-08-01 00:59:15.890403: train_loss -0.3687 
2023-08-01 00:59:15.890586: val_loss -0.3624 
2023-08-01 00:59:15.890649: Pseudo dice [0.915] 
2023-08-01 00:59:15.890705: Epoch time: 55.53 s 
2023-08-01 00:59:17.021949:  
2023-08-01 00:59:17.022054: Epoch 817 
2023-08-01 00:59:17.022162: Current learning rate: 0.00022 
2023-08-01 01:00:12.614094: train_loss -0.3385 
2023-08-01 01:00:12.614288: val_loss -0.3191 
2023-08-01 01:00:12.614352: Pseudo dice [0.8014] 
2023-08-01 01:00:12.614408: Epoch time: 55.59 s 
2023-08-01 01:00:13.743021:  
2023-08-01 01:00:13.743134: Epoch 818 
2023-08-01 01:00:13.743229: Current learning rate: 0.00022 
2023-08-01 01:01:09.272320: train_loss -0.3249 
2023-08-01 01:01:09.272496: val_loss -0.3303 
2023-08-01 01:01:09.280949: Pseudo dice [0.9044] 
2023-08-01 01:01:09.281100: Epoch time: 55.53 s 
2023-08-01 01:01:10.392468:  
2023-08-01 01:01:10.392576: Epoch 819 
2023-08-01 01:01:10.392652: Current learning rate: 0.00021 
2023-08-01 01:02:06.001665: train_loss -0.3511 
2023-08-01 01:02:06.001882: val_loss -0.3044 
2023-08-01 01:02:06.001983: Pseudo dice [0.8628] 
2023-08-01 01:02:06.002084: Epoch time: 55.61 s 
2023-08-01 01:02:06.002167: Yayy! New best EMA pseudo Dice: 0.8524 
2023-08-01 01:02:07.432612:  
2023-08-01 01:02:07.432722: Epoch 820 
2023-08-01 01:02:07.432798: Current learning rate: 0.00021 
2023-08-01 01:03:02.939765: train_loss -0.3431 
2023-08-01 01:03:02.939932: val_loss -0.2982 
2023-08-01 01:03:02.939992: Pseudo dice [0.8558] 
2023-08-01 01:03:02.940046: Epoch time: 55.51 s 
2023-08-01 01:03:02.940090: Yayy! New best EMA pseudo Dice: 0.8528 
2023-08-01 01:03:04.492810:  
2023-08-01 01:03:04.492929: Epoch 821 
2023-08-01 01:03:04.493036: Current learning rate: 0.00021 
2023-08-01 01:04:00.086264: train_loss -0.3253 
2023-08-01 01:04:00.086426: val_loss -0.3606 
2023-08-01 01:04:00.086485: Pseudo dice [0.8642] 
2023-08-01 01:04:00.086539: Epoch time: 55.59 s 
2023-08-01 01:04:00.086582: Yayy! New best EMA pseudo Dice: 0.8539 
2023-08-01 01:04:01.503021:  
2023-08-01 01:04:01.503125: Epoch 822 
2023-08-01 01:04:01.503218: Current learning rate: 0.00021 
2023-08-01 01:04:57.118013: train_loss -0.3776 
2023-08-01 01:04:57.118176: val_loss -0.386 
2023-08-01 01:04:57.118236: Pseudo dice [0.8586] 
2023-08-01 01:04:57.118291: Epoch time: 55.62 s 
2023-08-01 01:04:57.118334: Yayy! New best EMA pseudo Dice: 0.8544 
2023-08-01 01:04:58.544286:  
2023-08-01 01:04:58.544387: Epoch 823 
2023-08-01 01:04:58.544478: Current learning rate: 0.00021 
2023-08-01 01:05:54.082047: train_loss -0.33 
2023-08-01 01:05:54.082205: val_loss -0.42 
2023-08-01 01:05:54.082268: Pseudo dice [0.7995] 
2023-08-01 01:05:54.082322: Epoch time: 55.54 s 
2023-08-01 01:05:55.114695:  
2023-08-01 01:05:55.114791: Epoch 824 
2023-08-01 01:05:55.114899: Current learning rate: 0.00021 
2023-08-01 01:06:50.683106: train_loss -0.3293 
2023-08-01 01:06:50.683295: val_loss -0.3276 
2023-08-01 01:06:50.683355: Pseudo dice [0.8468] 
2023-08-01 01:06:50.683411: Epoch time: 55.57 s 
2023-08-01 01:06:51.711797:  
2023-08-01 01:06:51.711897: Epoch 825 
2023-08-01 01:06:51.711991: Current learning rate: 0.00021 
2023-08-01 01:07:47.276971: train_loss -0.3289 
2023-08-01 01:07:47.277143: val_loss -0.3032 
2023-08-01 01:07:47.277201: Pseudo dice [0.8217] 
2023-08-01 01:07:47.277256: Epoch time: 55.57 s 
2023-08-01 01:07:48.308400:  
2023-08-01 01:07:48.308497: Epoch 826 
2023-08-01 01:07:48.308591: Current learning rate: 0.00021 
2023-08-01 01:08:43.947350: train_loss -0.3561 
2023-08-01 01:08:43.947541: val_loss -0.3403 
2023-08-01 01:08:43.947605: Pseudo dice [0.8909] 
2023-08-01 01:08:43.947660: Epoch time: 55.64 s 
2023-08-01 01:08:45.176829:  
2023-08-01 01:08:45.176935: Epoch 827 
2023-08-01 01:08:45.177026: Current learning rate: 0.00021 
2023-08-01 01:09:40.796818: train_loss -0.3715 
2023-08-01 01:09:40.796993: val_loss -0.3681 
2023-08-01 01:09:40.797054: Pseudo dice [0.811] 
2023-08-01 01:09:40.797108: Epoch time: 55.62 s 
2023-08-01 01:09:41.828120:  
2023-08-01 01:09:41.828223: Epoch 828 
2023-08-01 01:09:41.828315: Current learning rate: 0.00021 
2023-08-01 01:10:37.529133: train_loss -0.3625 
2023-08-01 01:10:37.529296: val_loss -0.3045 
2023-08-01 01:10:37.529356: Pseudo dice [0.8354] 
2023-08-01 01:10:37.529411: Epoch time: 55.7 s 
2023-08-01 01:10:38.590697:  
2023-08-01 01:10:38.590801: Epoch 829 
2023-08-01 01:10:38.590909: Current learning rate: 0.0002 
2023-08-01 01:11:34.188164: train_loss -0.3488 
2023-08-01 01:11:34.188327: val_loss -0.4157 
2023-08-01 01:11:34.188383: Pseudo dice [0.8761] 
2023-08-01 01:11:34.188437: Epoch time: 55.6 s 
2023-08-01 01:11:35.219960:  
2023-08-01 01:11:35.220065: Epoch 830 
2023-08-01 01:11:35.220141: Current learning rate: 0.0002 
2023-08-01 01:12:30.785693: train_loss -0.3646 
2023-08-01 01:12:30.785890: val_loss -0.3831 
2023-08-01 01:12:30.794374: Pseudo dice [0.9095] 
2023-08-01 01:12:30.794631: Epoch time: 55.57 s 
2023-08-01 01:12:30.794774: Yayy! New best EMA pseudo Dice: 0.8546 
2023-08-01 01:12:32.226229:  
2023-08-01 01:12:32.226331: Epoch 831 
2023-08-01 01:12:32.226410: Current learning rate: 0.0002 
2023-08-01 01:13:27.783527: train_loss -0.3937 
2023-08-01 01:13:27.783704: val_loss -0.4015 
2023-08-01 01:13:27.783764: Pseudo dice [0.8603] 
2023-08-01 01:13:27.783836: Epoch time: 55.56 s 
2023-08-01 01:13:27.783885: Yayy! New best EMA pseudo Dice: 0.8551 
2023-08-01 01:13:29.351103:  
2023-08-01 01:13:29.351221: Epoch 832 
2023-08-01 01:13:29.351331: Current learning rate: 0.0002 
2023-08-01 01:14:24.870133: train_loss -0.3535 
2023-08-01 01:14:24.870296: val_loss -0.4143 
2023-08-01 01:14:24.870358: Pseudo dice [0.8593] 
2023-08-01 01:14:24.870414: Epoch time: 55.52 s 
2023-08-01 01:14:24.870458: Yayy! New best EMA pseudo Dice: 0.8556 
2023-08-01 01:14:26.263370:  
2023-08-01 01:14:26.263475: Epoch 833 
2023-08-01 01:14:26.263594: Current learning rate: 0.0002 
2023-08-01 01:15:21.794157: train_loss -0.3327 
2023-08-01 01:15:21.794340: val_loss -0.3734 
2023-08-01 01:15:21.794403: Pseudo dice [0.8306] 
2023-08-01 01:15:21.794459: Epoch time: 55.53 s 
2023-08-01 01:15:22.881470:  
2023-08-01 01:15:22.881688: Epoch 834 
2023-08-01 01:15:22.881770: Current learning rate: 0.0002 
2023-08-01 01:16:18.445960: train_loss -0.3832 
2023-08-01 01:16:18.446121: val_loss -0.3174 
2023-08-01 01:16:18.446194: Pseudo dice [0.732] 
2023-08-01 01:16:18.446249: Epoch time: 55.57 s 
2023-08-01 01:16:19.478385:  
2023-08-01 01:16:19.478485: Epoch 835 
2023-08-01 01:16:19.478595: Current learning rate: 0.0002 
2023-08-01 01:17:14.988445: train_loss -0.3183 
2023-08-01 01:17:14.988615: val_loss -0.3323 
2023-08-01 01:17:14.988673: Pseudo dice [0.84] 
2023-08-01 01:17:14.988728: Epoch time: 55.51 s 
2023-08-01 01:17:16.010377:  
2023-08-01 01:17:16.010578: Epoch 836 
2023-08-01 01:17:16.010674: Current learning rate: 0.0002 
2023-08-01 01:18:11.506396: train_loss -0.3148 
2023-08-01 01:18:11.506588: val_loss -0.343 
2023-08-01 01:18:11.506647: Pseudo dice [0.873] 
2023-08-01 01:18:11.506702: Epoch time: 55.5 s 
2023-08-01 01:18:12.538794:  
2023-08-01 01:18:12.538909: Epoch 837 
2023-08-01 01:18:12.538985: Current learning rate: 0.0002 
2023-08-01 01:19:08.085311: train_loss -0.3403 
2023-08-01 01:19:08.085476: val_loss -0.3198 
2023-08-01 01:19:08.085645: Pseudo dice [0.8548] 
2023-08-01 01:19:08.085702: Epoch time: 55.55 s 
2023-08-01 01:19:09.118035:  
2023-08-01 01:19:09.118139: Epoch 838 
2023-08-01 01:19:09.118229: Current learning rate: 0.00019 
2023-08-01 01:20:04.683848: train_loss -0.3741 
2023-08-01 01:20:04.684002: val_loss -0.4399 
2023-08-01 01:20:04.684062: Pseudo dice [0.8535] 
2023-08-01 01:20:04.684119: Epoch time: 55.57 s 
2023-08-01 01:20:05.754999:  
2023-08-01 01:20:05.755102: Epoch 839 
2023-08-01 01:20:05.755194: Current learning rate: 0.00019 
2023-08-01 01:21:01.221720: train_loss -0.3538 
2023-08-01 01:21:01.221896: val_loss -0.3655 
2023-08-01 01:21:01.221954: Pseudo dice [0.8801] 
2023-08-01 01:21:01.222010: Epoch time: 55.47 s 
2023-08-01 01:21:02.261697:  
2023-08-01 01:21:02.261798: Epoch 840 
2023-08-01 01:21:02.261892: Current learning rate: 0.00019 
2023-08-01 01:21:57.808527: train_loss -0.3486 
2023-08-01 01:21:57.808686: val_loss -0.3242 
2023-08-01 01:21:57.808742: Pseudo dice [0.7491] 
2023-08-01 01:21:57.808796: Epoch time: 55.55 s 
2023-08-01 01:21:58.859456:  
2023-08-01 01:21:58.859595: Epoch 841 
2023-08-01 01:21:58.859675: Current learning rate: 0.00019 
2023-08-01 01:22:54.402152: train_loss -0.3404 
2023-08-01 01:22:54.402309: val_loss -0.4022 
2023-08-01 01:22:54.402366: Pseudo dice [0.8808] 
2023-08-01 01:22:54.402421: Epoch time: 55.54 s 
2023-08-01 01:22:55.448018:  
2023-08-01 01:22:55.448416: Epoch 842 
2023-08-01 01:22:55.448572: Current learning rate: 0.00019 
2023-08-01 01:23:50.988904: train_loss -0.3471 
2023-08-01 01:23:50.989084: val_loss -0.3454 
2023-08-01 01:23:50.989145: Pseudo dice [0.8766] 
2023-08-01 01:23:50.989209: Epoch time: 55.54 s 
2023-08-01 01:23:52.171739:  
2023-08-01 01:23:52.171847: Epoch 843 
2023-08-01 01:23:52.171927: Current learning rate: 0.00019 
2023-08-01 01:24:47.722598: train_loss -0.3734 
2023-08-01 01:24:47.722767: val_loss -0.429 
2023-08-01 01:24:47.722831: Pseudo dice [0.8863] 
2023-08-01 01:24:47.722886: Epoch time: 55.55 s 
2023-08-01 01:24:48.756078:  
2023-08-01 01:24:48.756203: Epoch 844 
2023-08-01 01:24:48.756289: Current learning rate: 0.00019 
2023-08-01 01:25:44.322673: train_loss -0.3576 
2023-08-01 01:25:44.322831: val_loss -0.3803 
2023-08-01 01:25:44.322890: Pseudo dice [0.9115] 
2023-08-01 01:25:44.322944: Epoch time: 55.57 s 
2023-08-01 01:25:44.322989: Yayy! New best EMA pseudo Dice: 0.8568 
2023-08-01 01:25:45.776249:  
2023-08-01 01:25:45.776438: Epoch 845 
2023-08-01 01:25:45.776520: Current learning rate: 0.00019 
2023-08-01 01:26:41.328986: train_loss -0.3282 
2023-08-01 01:26:41.329162: val_loss -0.4027 
2023-08-01 01:26:41.329221: Pseudo dice [0.8254] 
2023-08-01 01:26:41.329274: Epoch time: 55.55 s 
2023-08-01 01:26:42.385056:  
2023-08-01 01:26:42.385157: Epoch 846 
2023-08-01 01:26:42.385234: Current learning rate: 0.00019 
2023-08-01 01:27:37.914973: train_loss -0.332 
2023-08-01 01:27:37.915128: val_loss -0.3687 
2023-08-01 01:27:37.915183: Pseudo dice [0.8478] 
2023-08-01 01:27:37.915237: Epoch time: 55.53 s 
2023-08-01 01:27:38.983700:  
2023-08-01 01:27:38.983798: Epoch 847 
2023-08-01 01:27:38.983891: Current learning rate: 0.00018 
2023-08-01 01:28:34.524513: train_loss -0.3619 
2023-08-01 01:28:34.524673: val_loss -0.3684 
2023-08-01 01:28:34.524734: Pseudo dice [0.8756] 
2023-08-01 01:28:34.524789: Epoch time: 55.54 s 
2023-08-01 01:28:35.749339:  
2023-08-01 01:28:35.749449: Epoch 848 
2023-08-01 01:28:35.749558: Current learning rate: 0.00018 
2023-08-01 01:29:31.248906: train_loss -0.3453 
2023-08-01 01:29:31.249081: val_loss -0.3788 
2023-08-01 01:29:31.249144: Pseudo dice [0.8613] 
2023-08-01 01:29:31.249211: Epoch time: 55.5 s 
2023-08-01 01:29:32.280499:  
2023-08-01 01:29:32.280603: Epoch 849 
2023-08-01 01:29:32.280697: Current learning rate: 0.00018 
2023-08-01 01:30:27.810472: train_loss -0.2985 
2023-08-01 01:30:27.810640: val_loss -0.2888 
2023-08-01 01:30:27.810697: Pseudo dice [0.7847] 
2023-08-01 01:30:27.810751: Epoch time: 55.53 s 
2023-08-01 01:30:29.200788:  
2023-08-01 01:30:29.200887: Epoch 850 
2023-08-01 01:30:29.200999: Current learning rate: 0.00018 
2023-08-01 01:31:24.722579: train_loss -0.3758 
2023-08-01 01:31:24.722748: val_loss -0.363 
2023-08-01 01:31:24.722809: Pseudo dice [0.8548] 
2023-08-01 01:31:24.722865: Epoch time: 55.52 s 
2023-08-01 01:31:25.744367:  
2023-08-01 01:31:25.744465: Epoch 851 
2023-08-01 01:31:25.744558: Current learning rate: 0.00018 
2023-08-01 01:32:21.211092: train_loss -0.3448 
2023-08-01 01:32:21.211285: val_loss -0.3324 
2023-08-01 01:32:21.211345: Pseudo dice [0.9061] 
2023-08-01 01:32:21.211400: Epoch time: 55.47 s 
2023-08-01 01:32:22.235194:  
2023-08-01 01:32:22.235292: Epoch 852 
2023-08-01 01:32:22.235399: Current learning rate: 0.00018 
2023-08-01 01:33:17.676846: train_loss -0.3242 
2023-08-01 01:33:17.677008: val_loss -0.3059 
2023-08-01 01:33:17.677068: Pseudo dice [0.7517] 
2023-08-01 01:33:17.677124: Epoch time: 55.44 s 
2023-08-01 01:33:18.750930:  
2023-08-01 01:33:18.751030: Epoch 853 
2023-08-01 01:33:18.751147: Current learning rate: 0.00018 
2023-08-01 01:34:14.290542: train_loss -0.3166 
2023-08-01 01:34:14.290696: val_loss -0.3368 
2023-08-01 01:34:14.290755: Pseudo dice [0.8177] 
2023-08-01 01:34:14.290809: Epoch time: 55.54 s 
2023-08-01 01:34:15.555656:  
2023-08-01 01:34:15.555779: Epoch 854 
2023-08-01 01:34:15.555864: Current learning rate: 0.00018 
2023-08-01 01:35:11.007339: train_loss -0.3586 
2023-08-01 01:35:11.007527: val_loss -0.3475 
2023-08-01 01:35:11.007637: Pseudo dice [0.8057] 
2023-08-01 01:35:11.007693: Epoch time: 55.45 s 
2023-08-01 01:35:12.033341:  
2023-08-01 01:35:12.033442: Epoch 855 
2023-08-01 01:35:12.033547: Current learning rate: 0.00018 
2023-08-01 01:36:07.602842: train_loss -0.3685 
2023-08-01 01:36:07.603015: val_loss -0.3122 
2023-08-01 01:36:07.603075: Pseudo dice [0.8368] 
2023-08-01 01:36:07.603130: Epoch time: 55.57 s 
2023-08-01 01:36:08.642830:  
2023-08-01 01:36:08.642934: Epoch 856 
2023-08-01 01:36:08.643030: Current learning rate: 0.00017 
2023-08-01 01:37:04.135630: train_loss -0.328 
2023-08-01 01:37:04.135795: val_loss -0.3463 
2023-08-01 01:37:04.135854: Pseudo dice [0.8021] 
2023-08-01 01:37:04.135907: Epoch time: 55.49 s 
2023-08-01 01:37:05.156303:  
2023-08-01 01:37:05.156408: Epoch 857 
2023-08-01 01:37:05.156486: Current learning rate: 0.00017 
2023-08-01 01:38:00.719858: train_loss -0.3258 
2023-08-01 01:38:00.720018: val_loss -0.4642 
2023-08-01 01:38:00.720081: Pseudo dice [0.8639] 
2023-08-01 01:38:00.720135: Epoch time: 55.56 s 
2023-08-01 01:38:01.791554:  
2023-08-01 01:38:01.791650: Epoch 858 
2023-08-01 01:38:01.791726: Current learning rate: 0.00017 
2023-08-01 01:38:57.294868: train_loss -0.3201 
2023-08-01 01:38:57.295026: val_loss -0.3214 
2023-08-01 01:38:57.295086: Pseudo dice [0.8272] 
2023-08-01 01:38:57.295141: Epoch time: 55.5 s 
2023-08-01 01:38:58.335747:  
2023-08-01 01:38:58.335844: Epoch 859 
2023-08-01 01:38:58.335920: Current learning rate: 0.00017 
2023-08-01 01:39:53.965291: train_loss -0.3419 
2023-08-01 01:39:53.965460: val_loss -0.4377 
2023-08-01 01:39:53.965520: Pseudo dice [0.8788] 
2023-08-01 01:39:53.965573: Epoch time: 55.63 s 
2023-08-01 01:39:54.999093:  
2023-08-01 01:39:54.999207: Epoch 860 
2023-08-01 01:39:54.999313: Current learning rate: 0.00017 
2023-08-01 01:40:50.542251: train_loss -0.3447 
2023-08-01 01:40:50.542403: val_loss -0.2945 
2023-08-01 01:40:50.542461: Pseudo dice [0.8657] 
2023-08-01 01:40:50.542516: Epoch time: 55.54 s 
2023-08-01 01:40:51.596760:  
2023-08-01 01:40:51.596870: Epoch 861 
2023-08-01 01:40:51.596961: Current learning rate: 0.00017 
2023-08-01 01:41:47.192949: train_loss -0.3317 
2023-08-01 01:41:47.193103: val_loss -0.3379 
2023-08-01 01:41:47.193161: Pseudo dice [0.8456] 
2023-08-01 01:41:47.193214: Epoch time: 55.6 s 
2023-08-01 01:41:48.239554:  
2023-08-01 01:41:48.239656: Epoch 862 
2023-08-01 01:41:48.239734: Current learning rate: 0.00017 
2023-08-01 01:42:43.746450: train_loss -0.3266 
2023-08-01 01:42:43.746755: val_loss -0.3389 
2023-08-01 01:42:43.746816: Pseudo dice [0.7916] 
2023-08-01 01:42:43.746871: Epoch time: 55.51 s 
2023-08-01 01:42:44.783952:  
2023-08-01 01:42:44.784054: Epoch 863 
2023-08-01 01:42:44.784148: Current learning rate: 0.00017 
2023-08-01 01:43:40.411439: train_loss -0.3508 
2023-08-01 01:43:40.411624: val_loss -0.4223 
2023-08-01 01:43:40.411685: Pseudo dice [0.8498] 
2023-08-01 01:43:40.411740: Epoch time: 55.63 s 
2023-08-01 01:43:41.430505:  
2023-08-01 01:43:41.430607: Epoch 864 
2023-08-01 01:43:41.430701: Current learning rate: 0.00017 
2023-08-01 01:44:37.051698: train_loss -0.349 
2023-08-01 01:44:37.051873: val_loss -0.3353 
2023-08-01 01:44:37.060203: Pseudo dice [0.7916] 
2023-08-01 01:44:37.060307: Epoch time: 55.62 s 
2023-08-01 01:44:38.256118:  
2023-08-01 01:44:38.256228: Epoch 865 
2023-08-01 01:44:38.256320: Current learning rate: 0.00016 
2023-08-01 01:45:33.864967: train_loss -0.3715 
2023-08-01 01:45:33.865151: val_loss -0.3694 
2023-08-01 01:45:33.865210: Pseudo dice [0.9353] 
2023-08-01 01:45:33.865265: Epoch time: 55.61 s 
2023-08-01 01:45:34.891648:  
2023-08-01 01:45:34.891753: Epoch 866 
2023-08-01 01:45:34.891847: Current learning rate: 0.00016 
2023-08-01 01:46:30.503570: train_loss -0.3394 
2023-08-01 01:46:30.503727: val_loss -0.3799 
2023-08-01 01:46:30.503784: Pseudo dice [0.8402] 
2023-08-01 01:46:30.503839: Epoch time: 55.61 s 
2023-08-01 01:46:31.527383:  
2023-08-01 01:46:31.527494: Epoch 867 
2023-08-01 01:46:31.527590: Current learning rate: 0.00016 
2023-08-01 01:47:27.089519: train_loss -0.3712 
2023-08-01 01:47:27.089686: val_loss -0.351 
2023-08-01 01:47:27.089747: Pseudo dice [0.8939] 
2023-08-01 01:47:27.089802: Epoch time: 55.56 s 
2023-08-01 01:47:28.140630:  
2023-08-01 01:47:28.140746: Epoch 868 
2023-08-01 01:47:28.140821: Current learning rate: 0.00016 
2023-08-01 01:48:23.718654: train_loss -0.3803 
2023-08-01 01:48:23.718811: val_loss -0.3883 
2023-08-01 01:48:23.718871: Pseudo dice [0.8515] 
2023-08-01 01:48:23.718925: Epoch time: 55.58 s 
2023-08-01 01:48:24.755770:  
2023-08-01 01:48:24.755876: Epoch 869 
2023-08-01 01:48:24.755953: Current learning rate: 0.00016 
2023-08-01 01:49:20.246022: train_loss -0.35 
2023-08-01 01:49:20.246187: val_loss -0.3236 
2023-08-01 01:49:20.246250: Pseudo dice [0.9061] 
2023-08-01 01:49:20.246304: Epoch time: 55.49 s 
2023-08-01 01:49:21.270360:  
2023-08-01 01:49:21.270459: Epoch 870 
2023-08-01 01:49:21.270549: Current learning rate: 0.00016 
2023-08-01 01:50:16.816662: train_loss -0.3551 
2023-08-01 01:50:16.816825: val_loss -0.3744 
2023-08-01 01:50:16.816884: Pseudo dice [0.8905] 
2023-08-01 01:50:16.816937: Epoch time: 55.55 s 
2023-08-01 01:50:16.816981: Yayy! New best EMA pseudo Dice: 0.8587 
2023-08-01 01:50:18.364650:  
2023-08-01 01:50:18.364757: Epoch 871 
2023-08-01 01:50:18.364838: Current learning rate: 0.00016 
2023-08-01 01:51:13.926582: train_loss -0.3596 
2023-08-01 01:51:13.926754: val_loss -0.3461 
2023-08-01 01:51:13.926816: Pseudo dice [0.8377] 
2023-08-01 01:51:13.926871: Epoch time: 55.56 s 
2023-08-01 01:51:14.947637:  
2023-08-01 01:51:14.947742: Epoch 872 
2023-08-01 01:51:14.947820: Current learning rate: 0.00016 
2023-08-01 01:52:10.563852: train_loss -0.378 
2023-08-01 01:52:10.564003: val_loss -0.2684 
2023-08-01 01:52:10.564061: Pseudo dice [0.8739] 
2023-08-01 01:52:10.564116: Epoch time: 55.62 s 
2023-08-01 01:52:11.612768:  
2023-08-01 01:52:11.612895: Epoch 873 
2023-08-01 01:52:11.612969: Current learning rate: 0.00016 
2023-08-01 01:53:07.157261: train_loss -0.3759 
2023-08-01 01:53:07.157421: val_loss -0.4112 
2023-08-01 01:53:07.157482: Pseudo dice [0.8508] 
2023-08-01 01:53:07.157537: Epoch time: 55.55 s 
2023-08-01 01:53:08.196046:  
2023-08-01 01:53:08.196148: Epoch 874 
2023-08-01 01:53:08.196226: Current learning rate: 0.00016 
2023-08-01 01:54:03.698734: train_loss -0.3289 
2023-08-01 01:54:03.698901: val_loss -0.3349 
2023-08-01 01:54:03.698960: Pseudo dice [0.8577] 
2023-08-01 01:54:03.699014: Epoch time: 55.5 s 
2023-08-01 01:54:04.759993:  
2023-08-01 01:54:04.760092: Epoch 875 
2023-08-01 01:54:04.760173: Current learning rate: 0.00015 
2023-08-01 01:55:00.289101: train_loss -0.3827 
2023-08-01 01:55:00.289290: val_loss -0.4354 
2023-08-01 01:55:00.289351: Pseudo dice [0.8603] 
2023-08-01 01:55:00.289405: Epoch time: 55.53 s 
2023-08-01 01:55:01.364160:  
2023-08-01 01:55:01.364262: Epoch 876 
2023-08-01 01:55:01.364356: Current learning rate: 0.00015 
2023-08-01 01:55:56.940935: train_loss -0.3629 
2023-08-01 01:55:56.941103: val_loss -0.3659 
2023-08-01 01:55:56.941403: Pseudo dice [0.8616] 
2023-08-01 01:55:56.941623: Epoch time: 55.58 s 
2023-08-01 01:55:58.174221:  
2023-08-01 01:55:58.174330: Epoch 877 
2023-08-01 01:55:58.174423: Current learning rate: 0.00015 
2023-08-01 01:56:53.768079: train_loss -0.3566 
2023-08-01 01:56:53.768246: val_loss -0.3626 
2023-08-01 01:56:53.768306: Pseudo dice [0.86] 
2023-08-01 01:56:53.768361: Epoch time: 55.59 s 
2023-08-01 01:56:54.809682:  
2023-08-01 01:56:54.809785: Epoch 878 
2023-08-01 01:56:54.809860: Current learning rate: 0.00015 
2023-08-01 01:57:50.409545: train_loss -0.3757 
2023-08-01 01:57:50.409747: val_loss -0.3387 
2023-08-01 01:57:50.409835: Pseudo dice [0.7808] 
2023-08-01 01:57:50.409920: Epoch time: 55.6 s 
2023-08-01 01:57:51.433328:  
2023-08-01 01:57:51.433422: Epoch 879 
2023-08-01 01:57:51.433515: Current learning rate: 0.00015 
2023-08-01 01:58:46.990929: train_loss -0.3908 
2023-08-01 01:58:46.991209: val_loss -0.3533 
2023-08-01 01:58:46.991268: Pseudo dice [0.8796] 
2023-08-01 01:58:46.991322: Epoch time: 55.56 s 
2023-08-01 01:58:48.011058:  
2023-08-01 01:58:48.011155: Epoch 880 
2023-08-01 01:58:48.011243: Current learning rate: 0.00015 
2023-08-01 01:59:43.655149: train_loss -0.346 
2023-08-01 01:59:43.655324: val_loss -0.4047 
2023-08-01 01:59:43.655394: Pseudo dice [0.7776] 
2023-08-01 01:59:43.655456: Epoch time: 55.64 s 
2023-08-01 01:59:44.732942:  
2023-08-01 01:59:44.733046: Epoch 881 
2023-08-01 01:59:44.733140: Current learning rate: 0.00015 
2023-08-01 02:00:40.262391: train_loss -0.3827 
2023-08-01 02:00:40.262556: val_loss -0.3496 
2023-08-01 02:00:40.262617: Pseudo dice [0.8631] 
2023-08-01 02:00:40.262672: Epoch time: 55.53 s 
2023-08-01 02:00:41.424053:  
2023-08-01 02:00:41.424158: Epoch 882 
2023-08-01 02:00:41.424233: Current learning rate: 0.00015 
2023-08-01 02:01:37.026254: train_loss -0.3874 
2023-08-01 02:01:37.026432: val_loss -0.377 
2023-08-01 02:01:37.034952: Pseudo dice [0.8432] 
2023-08-01 02:01:37.035209: Epoch time: 55.6 s 
2023-08-01 02:01:38.089271:  
2023-08-01 02:01:38.089370: Epoch 883 
2023-08-01 02:01:38.089460: Current learning rate: 0.00014 
2023-08-01 02:02:33.642903: train_loss -0.3341 
2023-08-01 02:02:33.643094: val_loss -0.4175 
2023-08-01 02:02:33.643157: Pseudo dice [0.9317] 
2023-08-01 02:02:33.643211: Epoch time: 55.55 s 
2023-08-01 02:02:34.664212:  
2023-08-01 02:02:34.664317: Epoch 884 
2023-08-01 02:02:34.664395: Current learning rate: 0.00014 
2023-08-01 02:03:30.258125: train_loss -0.354 
2023-08-01 02:03:30.258343: val_loss -0.3211 
2023-08-01 02:03:30.258440: Pseudo dice [0.8375] 
2023-08-01 02:03:30.258536: Epoch time: 55.59 s 
2023-08-01 02:03:31.300999:  
2023-08-01 02:03:31.301103: Epoch 885 
2023-08-01 02:03:31.301194: Current learning rate: 0.00014 
2023-08-01 02:04:26.894536: train_loss -0.3781 
2023-08-01 02:04:26.894703: val_loss -0.3608 
2023-08-01 02:04:26.894758: Pseudo dice [0.81] 
2023-08-01 02:04:26.894813: Epoch time: 55.59 s 
2023-08-01 02:04:27.914376:  
2023-08-01 02:04:27.914476: Epoch 886 
2023-08-01 02:04:27.914583: Current learning rate: 0.00014 
2023-08-01 02:05:23.491999: train_loss -0.3788 
2023-08-01 02:05:23.492167: val_loss -0.3406 
2023-08-01 02:05:23.492226: Pseudo dice [0.8353] 
2023-08-01 02:05:23.492280: Epoch time: 55.58 s 
2023-08-01 02:05:24.515392:  
2023-08-01 02:05:24.515498: Epoch 887 
2023-08-01 02:05:24.515594: Current learning rate: 0.00014 
2023-08-01 02:06:20.081090: train_loss -0.3641 
2023-08-01 02:06:20.081239: val_loss -0.3521 
2023-08-01 02:06:20.081292: Pseudo dice [0.9133] 
2023-08-01 02:06:20.081345: Epoch time: 55.57 s 
2023-08-01 02:06:21.259931:  
2023-08-01 02:06:21.260041: Epoch 888 
2023-08-01 02:06:21.260134: Current learning rate: 0.00014 
2023-08-01 02:07:16.745371: train_loss -0.3446 
2023-08-01 02:07:16.745646: val_loss -0.3012 
2023-08-01 02:07:16.745710: Pseudo dice [0.8382] 
2023-08-01 02:07:16.745767: Epoch time: 55.49 s 
2023-08-01 02:07:17.789675:  
2023-08-01 02:07:17.789773: Epoch 889 
2023-08-01 02:07:17.789863: Current learning rate: 0.00014 
2023-08-01 02:08:13.336253: train_loss -0.3394 
2023-08-01 02:08:13.336418: val_loss -0.366 
2023-08-01 02:08:13.336478: Pseudo dice [0.8705] 
2023-08-01 02:08:13.336544: Epoch time: 55.55 s 
2023-08-01 02:08:14.378609:  
2023-08-01 02:08:14.378708: Epoch 890 
2023-08-01 02:08:14.378814: Current learning rate: 0.00014 
2023-08-01 02:09:09.931881: train_loss -0.3468 
2023-08-01 02:09:09.932149: val_loss -0.3023 
2023-08-01 02:09:09.932227: Pseudo dice [0.8504] 
2023-08-01 02:09:09.932286: Epoch time: 55.55 s 
2023-08-01 02:09:10.957533:  
2023-08-01 02:09:10.957640: Epoch 891 
2023-08-01 02:09:10.957747: Current learning rate: 0.00014 
2023-08-01 02:10:06.524059: train_loss -0.3489 
2023-08-01 02:10:06.524220: val_loss -0.3044 
2023-08-01 02:10:06.524283: Pseudo dice [0.8226] 
2023-08-01 02:10:06.524338: Epoch time: 55.57 s 
2023-08-01 02:10:07.550001:  
2023-08-01 02:10:07.550102: Epoch 892 
2023-08-01 02:10:07.550192: Current learning rate: 0.00013 
2023-08-01 02:11:03.063020: train_loss -0.3785 
2023-08-01 02:11:03.063183: val_loss -0.378 
2023-08-01 02:11:03.063239: Pseudo dice [0.8705] 
2023-08-01 02:11:03.063293: Epoch time: 55.51 s 
2023-08-01 02:11:04.092761:  
2023-08-01 02:11:04.092869: Epoch 893 
2023-08-01 02:11:04.092975: Current learning rate: 0.00013 
2023-08-01 02:11:59.662518: train_loss -0.3463 
2023-08-01 02:11:59.662686: val_loss -0.3391 
2023-08-01 02:11:59.662749: Pseudo dice [0.7987] 
2023-08-01 02:11:59.662804: Epoch time: 55.57 s 
2023-08-01 02:12:00.845894:  
2023-08-01 02:12:00.846003: Epoch 894 
2023-08-01 02:12:00.846110: Current learning rate: 0.00013 
2023-08-01 02:12:56.351383: train_loss -0.348 
2023-08-01 02:12:56.351555: val_loss -0.34 
2023-08-01 02:12:56.351638: Pseudo dice [0.8244] 
2023-08-01 02:12:56.351698: Epoch time: 55.51 s 
2023-08-01 02:12:57.376669:  
2023-08-01 02:12:57.376802: Epoch 895 
2023-08-01 02:12:57.376878: Current learning rate: 0.00013 
2023-08-01 02:13:53.122737: train_loss -0.342 
2023-08-01 02:13:53.122899: val_loss -0.4536 
2023-08-01 02:13:53.122960: Pseudo dice [0.8618] 
2023-08-01 02:13:53.123015: Epoch time: 55.75 s 
2023-08-01 02:13:54.171367:  
2023-08-01 02:13:54.171733: Epoch 896 
2023-08-01 02:13:54.171819: Current learning rate: 0.00013 
2023-08-01 02:14:49.692528: train_loss -0.3212 
2023-08-01 02:14:49.692692: val_loss -0.3683 
2023-08-01 02:14:49.692754: Pseudo dice [0.8382] 
2023-08-01 02:14:49.692808: Epoch time: 55.52 s 
2023-08-01 02:14:50.746836:  
2023-08-01 02:14:50.747177: Epoch 897 
2023-08-01 02:14:50.747264: Current learning rate: 0.00013 
2023-08-01 02:15:46.286960: train_loss -0.3867 
2023-08-01 02:15:46.287130: val_loss -0.3594 
2023-08-01 02:15:46.287187: Pseudo dice [0.822] 
2023-08-01 02:15:46.287241: Epoch time: 55.54 s 
2023-08-01 02:15:47.337044:  
2023-08-01 02:15:47.337147: Epoch 898 
2023-08-01 02:15:47.337257: Current learning rate: 0.00013 
2023-08-01 02:16:42.902237: train_loss -0.3488 
2023-08-01 02:16:42.902397: val_loss -0.3285 
2023-08-01 02:16:42.902455: Pseudo dice [0.8535] 
2023-08-01 02:16:42.902510: Epoch time: 55.57 s 
2023-08-01 02:16:44.011375:  
2023-08-01 02:16:44.011473: Epoch 899 
2023-08-01 02:16:44.011577: Current learning rate: 0.00013 
2023-08-01 02:17:39.478010: train_loss -0.3678 
2023-08-01 02:17:39.478175: val_loss -0.3736 
2023-08-01 02:17:39.478236: Pseudo dice [0.8765] 
2023-08-01 02:17:39.478291: Epoch time: 55.47 s 
2023-08-01 02:17:41.009631:  
2023-08-01 02:17:41.009733: Epoch 900 
2023-08-01 02:17:41.009830: Current learning rate: 0.00013 
2023-08-01 02:18:36.542577: train_loss -0.3407 
2023-08-01 02:18:36.542737: val_loss -0.3773 
2023-08-01 02:18:36.542795: Pseudo dice [0.81] 
2023-08-01 02:18:36.542850: Epoch time: 55.53 s 
2023-08-01 02:18:37.597370:  
2023-08-01 02:18:37.597474: Epoch 901 
2023-08-01 02:18:37.597583: Current learning rate: 0.00012 
2023-08-01 02:19:33.050198: train_loss -0.3393 
2023-08-01 02:19:33.050382: val_loss -0.3509 
2023-08-01 02:19:33.050444: Pseudo dice [0.8628] 
2023-08-01 02:19:33.050498: Epoch time: 55.45 s 
2023-08-01 02:19:34.078483:  
2023-08-01 02:19:34.078781: Epoch 902 
2023-08-01 02:19:34.078881: Current learning rate: 0.00012 
2023-08-01 02:20:29.674855: train_loss -0.3391 
2023-08-01 02:20:29.675014: val_loss -0.3555 
2023-08-01 02:20:29.675069: Pseudo dice [0.8751] 
2023-08-01 02:20:29.675123: Epoch time: 55.6 s 
2023-08-01 02:20:30.696342:  
2023-08-01 02:20:30.696444: Epoch 903 
2023-08-01 02:20:30.696545: Current learning rate: 0.00012 
2023-08-01 02:21:26.200614: train_loss -0.3402 
2023-08-01 02:21:26.200808: val_loss -0.3436 
2023-08-01 02:21:26.200867: Pseudo dice [0.8168] 
2023-08-01 02:21:26.200923: Epoch time: 55.5 s 
2023-08-01 02:21:27.236519:  
2023-08-01 02:21:27.236617: Epoch 904 
2023-08-01 02:21:27.236710: Current learning rate: 0.00012 
2023-08-01 02:22:22.723178: train_loss -0.3579 
2023-08-01 02:22:22.723334: val_loss -0.3359 
2023-08-01 02:22:22.723391: Pseudo dice [0.8298] 
2023-08-01 02:22:22.723444: Epoch time: 55.49 s 
2023-08-01 02:22:23.751284:  
2023-08-01 02:22:23.751386: Epoch 905 
2023-08-01 02:22:23.751479: Current learning rate: 0.00012 
2023-08-01 02:23:19.283788: train_loss -0.3546 
2023-08-01 02:23:19.283945: val_loss -0.3449 
2023-08-01 02:23:19.284003: Pseudo dice [0.9052] 
2023-08-01 02:23:19.284057: Epoch time: 55.53 s 
2023-08-01 02:23:20.466060:  
2023-08-01 02:23:20.466174: Epoch 906 
2023-08-01 02:23:20.466280: Current learning rate: 0.00012 
2023-08-01 02:24:16.083478: train_loss -0.3582 
2023-08-01 02:24:16.083653: val_loss -0.4066 
2023-08-01 02:24:16.083710: Pseudo dice [0.8279] 
2023-08-01 02:24:16.083765: Epoch time: 55.62 s 
2023-08-01 02:24:17.117534:  
2023-08-01 02:24:17.117633: Epoch 907 
2023-08-01 02:24:17.117725: Current learning rate: 0.00012 
2023-08-01 02:25:12.693692: train_loss -0.3502 
2023-08-01 02:25:12.693867: val_loss -0.4318 
2023-08-01 02:25:12.693928: Pseudo dice [0.8977] 
2023-08-01 02:25:12.693983: Epoch time: 55.58 s 
2023-08-01 02:25:13.734623:  
2023-08-01 02:25:13.734729: Epoch 908 
2023-08-01 02:25:13.734822: Current learning rate: 0.00012 
2023-08-01 02:26:09.354456: train_loss -0.3423 
2023-08-01 02:26:09.354625: val_loss -0.343 
2023-08-01 02:26:09.354686: Pseudo dice [0.8613] 
2023-08-01 02:26:09.354741: Epoch time: 55.62 s 
2023-08-01 02:26:10.395589:  
2023-08-01 02:26:10.395690: Epoch 909 
2023-08-01 02:26:10.395783: Current learning rate: 0.00012 
2023-08-01 02:27:05.950454: train_loss -0.3808 
2023-08-01 02:27:05.950611: val_loss -0.375 
2023-08-01 02:27:05.950667: Pseudo dice [0.9466] 
2023-08-01 02:27:05.950722: Epoch time: 55.56 s 
2023-08-01 02:27:05.950766: Yayy! New best EMA pseudo Dice: 0.863 
2023-08-01 02:27:07.332909:  
2023-08-01 02:27:07.333015: Epoch 910 
2023-08-01 02:27:07.333091: Current learning rate: 0.00011 
2023-08-01 02:28:02.891498: train_loss -0.3761 
2023-08-01 02:28:02.891682: val_loss -0.3199 
2023-08-01 02:28:02.891743: Pseudo dice [0.8736] 
2023-08-01 02:28:02.891800: Epoch time: 55.56 s 
2023-08-01 02:28:02.891845: Yayy! New best EMA pseudo Dice: 0.8641 
2023-08-01 02:28:04.302104:  
2023-08-01 02:28:04.302212: Epoch 911 
2023-08-01 02:28:04.302307: Current learning rate: 0.00011 
2023-08-01 02:28:59.820284: train_loss -0.3573 
2023-08-01 02:28:59.820449: val_loss -0.4185 
2023-08-01 02:28:59.820508: Pseudo dice [0.8996] 
2023-08-01 02:28:59.820583: Epoch time: 55.52 s 
2023-08-01 02:28:59.820632: Yayy! New best EMA pseudo Dice: 0.8676 
2023-08-01 02:29:01.402799:  
2023-08-01 02:29:01.402906: Epoch 912 
2023-08-01 02:29:01.403001: Current learning rate: 0.00011 
2023-08-01 02:29:56.884761: train_loss -0.3537 
2023-08-01 02:29:56.884929: val_loss -0.4259 
2023-08-01 02:29:56.884987: Pseudo dice [0.8307] 
2023-08-01 02:29:56.885041: Epoch time: 55.48 s 
2023-08-01 02:29:57.908199:  
2023-08-01 02:29:57.908301: Epoch 913 
2023-08-01 02:29:57.908393: Current learning rate: 0.00011 
2023-08-01 02:30:53.376812: train_loss -0.3321 
2023-08-01 02:30:53.376990: val_loss -0.3258 
2023-08-01 02:30:53.377049: Pseudo dice [0.8566] 
2023-08-01 02:30:53.377104: Epoch time: 55.47 s 
2023-08-01 02:30:54.453817:  
2023-08-01 02:30:54.453917: Epoch 914 
2023-08-01 02:30:54.454006: Current learning rate: 0.00011 
2023-08-01 02:31:49.961639: train_loss -0.3733 
2023-08-01 02:31:49.961812: val_loss -0.32 
2023-08-01 02:31:49.961873: Pseudo dice [0.8515] 
2023-08-01 02:31:49.961927: Epoch time: 55.51 s 
2023-08-01 02:31:50.983099:  
2023-08-01 02:31:50.983196: Epoch 915 
2023-08-01 02:31:50.983305: Current learning rate: 0.00011 
2023-08-01 02:32:46.443515: train_loss -0.3284 
2023-08-01 02:32:46.443685: val_loss -0.3667 
2023-08-01 02:32:46.443743: Pseudo dice [0.878] 
2023-08-01 02:32:46.443799: Epoch time: 55.46 s 
2023-08-01 02:32:47.466260:  
2023-08-01 02:32:47.466364: Epoch 916 
2023-08-01 02:32:47.466456: Current learning rate: 0.00011 
2023-08-01 02:33:42.914905: train_loss -0.3428 
2023-08-01 02:33:42.915069: val_loss -0.309 
2023-08-01 02:33:42.915145: Pseudo dice [0.8572] 
2023-08-01 02:33:42.915200: Epoch time: 55.45 s 
2023-08-01 02:33:44.110907:  
2023-08-01 02:33:44.111007: Epoch 917 
2023-08-01 02:33:44.111091: Current learning rate: 0.00011 
2023-08-01 02:34:39.464648: train_loss -0.363 
2023-08-01 02:34:39.464816: val_loss -0.3356 
2023-08-01 02:34:39.464875: Pseudo dice [0.8535] 
2023-08-01 02:34:39.464930: Epoch time: 55.35 s 
2023-08-01 02:34:40.512520:  
2023-08-01 02:34:40.512625: Epoch 918 
2023-08-01 02:34:40.512701: Current learning rate: 0.00011 
2023-08-01 02:35:36.015809: train_loss -0.3258 
2023-08-01 02:35:36.015974: val_loss -0.4467 
2023-08-01 02:35:36.016034: Pseudo dice [0.9082] 
2023-08-01 02:35:36.016088: Epoch time: 55.5 s 
2023-08-01 02:35:37.045428:  
2023-08-01 02:35:37.045537: Epoch 919 
2023-08-01 02:35:37.045630: Current learning rate: 0.0001 
2023-08-01 02:36:32.428129: train_loss -0.3302 
2023-08-01 02:36:32.428291: val_loss -0.3717 
2023-08-01 02:36:32.428370: Pseudo dice [0.8574] 
2023-08-01 02:36:32.428430: Epoch time: 55.38 s 
2023-08-01 02:36:33.478637:  
2023-08-01 02:36:33.478736: Epoch 920 
2023-08-01 02:36:33.478842: Current learning rate: 0.0001 
2023-08-01 02:37:28.918095: train_loss -0.3643 
2023-08-01 02:37:28.918248: val_loss -0.4063 
2023-08-01 02:37:28.918307: Pseudo dice [0.8434] 
2023-08-01 02:37:28.918361: Epoch time: 55.44 s 
2023-08-01 02:37:29.975902:  
2023-08-01 02:37:29.976000: Epoch 921 
2023-08-01 02:37:29.976077: Current learning rate: 0.0001 
2023-08-01 02:38:25.429848: train_loss -0.3912 
2023-08-01 02:38:25.430039: val_loss -0.3726 
2023-08-01 02:38:25.430098: Pseudo dice [0.8121] 
2023-08-01 02:38:25.430153: Epoch time: 55.45 s 
2023-08-01 02:38:26.456155:  
2023-08-01 02:38:26.456257: Epoch 922 
2023-08-01 02:38:26.456335: Current learning rate: 0.0001 
2023-08-01 02:39:21.881329: train_loss -0.3508 
2023-08-01 02:39:21.881502: val_loss -0.3556 
2023-08-01 02:39:21.881562: Pseudo dice [0.8075] 
2023-08-01 02:39:21.881617: Epoch time: 55.43 s 
2023-08-01 02:39:23.065442:  
2023-08-01 02:39:23.065552: Epoch 923 
2023-08-01 02:39:23.065629: Current learning rate: 0.0001 
2023-08-01 02:40:18.396380: train_loss -0.3275 
2023-08-01 02:40:18.396547: val_loss -0.3701 
2023-08-01 02:40:18.396603: Pseudo dice [0.7962] 
2023-08-01 02:40:18.396657: Epoch time: 55.33 s 
2023-08-01 02:40:19.498825:  
2023-08-01 02:40:19.499318: Epoch 924 
2023-08-01 02:40:19.499548: Current learning rate: 0.0001 
2023-08-01 02:41:14.953139: train_loss -0.3656 
2023-08-01 02:41:14.953297: val_loss -0.3398 
2023-08-01 02:41:14.953374: Pseudo dice [0.79] 
2023-08-01 02:41:14.953429: Epoch time: 55.46 s 
2023-08-01 02:41:15.979307:  
2023-08-01 02:41:15.979411: Epoch 925 
2023-08-01 02:41:15.979511: Current learning rate: 0.0001 
2023-08-01 02:42:11.550507: train_loss -0.3433 
2023-08-01 02:42:11.550687: val_loss -0.3483 
2023-08-01 02:42:11.550747: Pseudo dice [0.8852] 
2023-08-01 02:42:11.550802: Epoch time: 55.57 s 
2023-08-01 02:42:12.594750:  
2023-08-01 02:42:12.594853: Epoch 926 
2023-08-01 02:42:12.594943: Current learning rate: 0.0001 
2023-08-01 02:43:08.176398: train_loss -0.3497 
2023-08-01 02:43:08.176565: val_loss -0.4294 
2023-08-01 02:43:08.176625: Pseudo dice [0.8329] 
2023-08-01 02:43:08.176678: Epoch time: 55.58 s 
2023-08-01 02:43:09.223107:  
2023-08-01 02:43:09.223204: Epoch 927 
2023-08-01 02:43:09.223312: Current learning rate: 9e-05 
2023-08-01 02:44:04.716838: train_loss -0.3744 
2023-08-01 02:44:04.716995: val_loss -0.376 
2023-08-01 02:44:04.717054: Pseudo dice [0.799] 
2023-08-01 02:44:04.717108: Epoch time: 55.49 s 
2023-08-01 02:44:05.924983:  
2023-08-01 02:44:05.925083: Epoch 928 
2023-08-01 02:44:05.925183: Current learning rate: 9e-05 
2023-08-01 02:45:01.484534: train_loss -0.3583 
2023-08-01 02:45:01.484694: val_loss -0.3503 
2023-08-01 02:45:01.484756: Pseudo dice [0.8789] 
2023-08-01 02:45:01.484812: Epoch time: 55.56 s 
2023-08-01 02:45:02.510854:  
2023-08-01 02:45:02.510967: Epoch 929 
2023-08-01 02:45:02.511059: Current learning rate: 9e-05 
2023-08-01 02:45:57.997418: train_loss -0.3392 
2023-08-01 02:45:57.997705: val_loss -0.3787 
2023-08-01 02:45:57.997771: Pseudo dice [0.8627] 
2023-08-01 02:45:57.997827: Epoch time: 55.49 s 
2023-08-01 02:45:59.025858:  
2023-08-01 02:45:59.025963: Epoch 930 
2023-08-01 02:45:59.026055: Current learning rate: 9e-05 
2023-08-01 02:46:54.479101: train_loss -0.3289 
2023-08-01 02:46:54.479260: val_loss -0.4195 
2023-08-01 02:46:54.479333: Pseudo dice [0.8601] 
2023-08-01 02:46:54.479388: Epoch time: 55.45 s 
2023-08-01 02:46:55.531092:  
2023-08-01 02:46:55.531202: Epoch 931 
2023-08-01 02:46:55.531295: Current learning rate: 9e-05 
2023-08-01 02:47:51.001071: train_loss -0.4006 
2023-08-01 02:47:51.001237: val_loss -0.3336 
2023-08-01 02:47:51.001294: Pseudo dice [0.8675] 
2023-08-01 02:47:51.001349: Epoch time: 55.47 s 
2023-08-01 02:47:52.029632:  
2023-08-01 02:47:52.029730: Epoch 932 
2023-08-01 02:47:52.029839: Current learning rate: 9e-05 
2023-08-01 02:48:47.539474: train_loss -0.3608 
2023-08-01 02:48:47.539797: val_loss -0.4337 
2023-08-01 02:48:47.539865: Pseudo dice [0.7917] 
2023-08-01 02:48:47.539922: Epoch time: 55.51 s 
2023-08-01 02:48:48.579500:  
2023-08-01 02:48:48.579616: Epoch 933 
2023-08-01 02:48:48.579691: Current learning rate: 9e-05 
2023-08-01 02:49:44.124799: train_loss -0.379 
2023-08-01 02:49:44.124969: val_loss -0.3609 
2023-08-01 02:49:44.125031: Pseudo dice [0.8259] 
2023-08-01 02:49:44.125085: Epoch time: 55.55 s 
2023-08-01 02:49:45.311568:  
2023-08-01 02:49:45.311671: Epoch 934 
2023-08-01 02:49:45.311765: Current learning rate: 9e-05 
2023-08-01 02:50:40.789776: train_loss -0.3572 
2023-08-01 02:50:40.789932: val_loss -0.4077 
2023-08-01 02:50:40.789992: Pseudo dice [0.8293] 
2023-08-01 02:50:40.790047: Epoch time: 55.48 s 
2023-08-01 02:50:41.867743:  
2023-08-01 02:50:41.867843: Epoch 935 
2023-08-01 02:50:41.867923: Current learning rate: 9e-05 
2023-08-01 02:51:37.377540: train_loss -0.358 
2023-08-01 02:51:37.377700: val_loss -0.4052 
2023-08-01 02:51:37.377758: Pseudo dice [0.8568] 
2023-08-01 02:51:37.377812: Epoch time: 55.51 s 
2023-08-01 02:51:38.423497:  
2023-08-01 02:51:38.423614: Epoch 936 
2023-08-01 02:51:38.423707: Current learning rate: 8e-05 
2023-08-01 02:52:33.893061: train_loss -0.3577 
2023-08-01 02:52:33.893253: val_loss -0.3478 
2023-08-01 02:52:33.893313: Pseudo dice [0.843] 
2023-08-01 02:52:33.893371: Epoch time: 55.47 s 
2023-08-01 02:52:34.915157:  
2023-08-01 02:52:34.915256: Epoch 937 
2023-08-01 02:52:34.915346: Current learning rate: 8e-05 
2023-08-01 02:53:30.442362: train_loss -0.3299 
2023-08-01 02:53:30.442527: val_loss -0.3272 
2023-08-01 02:53:30.442585: Pseudo dice [0.8596] 
2023-08-01 02:53:30.442640: Epoch time: 55.53 s 
2023-08-01 02:53:31.470677:  
2023-08-01 02:53:31.470779: Epoch 938 
2023-08-01 02:53:31.470872: Current learning rate: 8e-05 
2023-08-01 02:54:26.951544: train_loss -0.3699 
2023-08-01 02:54:26.951704: val_loss -0.388 
2023-08-01 02:54:26.951763: Pseudo dice [0.8529] 
2023-08-01 02:54:26.951818: Epoch time: 55.48 s 
2023-08-01 02:54:27.975331:  
2023-08-01 02:54:27.975429: Epoch 939 
2023-08-01 02:54:27.975528: Current learning rate: 8e-05 
2023-08-01 02:55:23.476895: train_loss -0.3703 
2023-08-01 02:55:23.477062: val_loss -0.3527 
2023-08-01 02:55:23.477118: Pseudo dice [0.8322] 
2023-08-01 02:55:23.477172: Epoch time: 55.5 s 
2023-08-01 02:55:24.684833:  
2023-08-01 02:55:24.685037: Epoch 940 
2023-08-01 02:55:24.685137: Current learning rate: 8e-05 
2023-08-01 02:56:20.215255: train_loss -0.3636 
2023-08-01 02:56:20.215422: val_loss -0.3523 
2023-08-01 02:56:20.215478: Pseudo dice [0.8638] 
2023-08-01 02:56:20.215546: Epoch time: 55.53 s 
2023-08-01 02:56:21.246303:  
2023-08-01 02:56:21.246407: Epoch 941 
2023-08-01 02:56:21.246499: Current learning rate: 8e-05 
2023-08-01 02:57:16.778458: train_loss -0.3645 
2023-08-01 02:57:16.778656: val_loss -0.3884 
2023-08-01 02:57:16.778731: Pseudo dice [0.9002] 
2023-08-01 02:57:16.778802: Epoch time: 55.53 s 
2023-08-01 02:57:17.808780:  
2023-08-01 02:57:17.808883: Epoch 942 
2023-08-01 02:57:17.808962: Current learning rate: 8e-05 
2023-08-01 02:58:13.321628: train_loss -0.3939 
2023-08-01 02:58:13.322042: val_loss -0.3909 
2023-08-01 02:58:13.322124: Pseudo dice [0.8051] 
2023-08-01 02:58:13.322180: Epoch time: 55.51 s 
2023-08-01 02:58:14.349638:  
2023-08-01 02:58:14.349734: Epoch 943 
2023-08-01 02:58:14.349828: Current learning rate: 8e-05 
2023-08-01 02:59:09.976594: train_loss -0.3543 
2023-08-01 02:59:09.976743: val_loss -0.4432 
2023-08-01 02:59:09.976802: Pseudo dice [0.8799] 
2023-08-01 02:59:09.976868: Epoch time: 55.63 s 
2023-08-01 02:59:11.042453:  
2023-08-01 02:59:11.042625: Epoch 944 
2023-08-01 02:59:11.042735: Current learning rate: 7e-05 
2023-08-01 03:00:06.580240: train_loss -0.356 
2023-08-01 03:00:06.580394: val_loss -0.4141 
2023-08-01 03:00:06.580453: Pseudo dice [0.831] 
2023-08-01 03:00:06.580507: Epoch time: 55.54 s 
2023-08-01 03:00:07.600085:  
2023-08-01 03:00:07.600183: Epoch 945 
2023-08-01 03:00:07.600274: Current learning rate: 7e-05 
2023-08-01 03:01:03.103723: train_loss -0.346 
2023-08-01 03:01:03.103886: val_loss -0.306 
2023-08-01 03:01:03.103948: Pseudo dice [0.8802] 
2023-08-01 03:01:03.104003: Epoch time: 55.5 s 
2023-08-01 03:01:04.280886:  
2023-08-01 03:01:04.281003: Epoch 946 
2023-08-01 03:01:04.281102: Current learning rate: 7e-05 
2023-08-01 03:01:59.854626: train_loss -0.3457 
2023-08-01 03:01:59.854786: val_loss -0.4827 
2023-08-01 03:01:59.854846: Pseudo dice [0.8119] 
2023-08-01 03:01:59.854902: Epoch time: 55.57 s 
2023-08-01 03:02:00.882669:  
2023-08-01 03:02:00.882781: Epoch 947 
2023-08-01 03:02:00.882889: Current learning rate: 7e-05 
2023-08-01 03:02:56.370969: train_loss -0.3592 
2023-08-01 03:02:56.371135: val_loss -0.3499 
2023-08-01 03:02:56.371195: Pseudo dice [0.8345] 
2023-08-01 03:02:56.371250: Epoch time: 55.49 s 
2023-08-01 03:02:57.394587:  
2023-08-01 03:02:57.394711: Epoch 948 
2023-08-01 03:02:57.394802: Current learning rate: 7e-05 
2023-08-01 03:03:52.882704: train_loss -0.3632 
2023-08-01 03:03:52.882885: val_loss -0.3266 
2023-08-01 03:03:52.882942: Pseudo dice [0.9006] 
2023-08-01 03:03:52.882996: Epoch time: 55.49 s 
2023-08-01 03:03:53.905215:  
2023-08-01 03:03:53.905317: Epoch 949 
2023-08-01 03:03:53.905409: Current learning rate: 7e-05 
2023-08-01 03:04:49.413023: train_loss -0.3815 
2023-08-01 03:04:49.413179: val_loss -0.349 
2023-08-01 03:04:49.413238: Pseudo dice [0.7804] 
2023-08-01 03:04:49.413294: Epoch time: 55.51 s 
2023-08-01 03:04:50.849048:  
2023-08-01 03:04:50.849150: Epoch 950 
2023-08-01 03:04:50.849258: Current learning rate: 7e-05 
2023-08-01 03:05:46.394078: train_loss -0.3517 
2023-08-01 03:05:46.394231: val_loss -0.3251 
2023-08-01 03:05:46.394289: Pseudo dice [0.8696] 
2023-08-01 03:05:46.394343: Epoch time: 55.55 s 
2023-08-01 03:05:47.435955:  
2023-08-01 03:05:47.436057: Epoch 951 
2023-08-01 03:05:47.436136: Current learning rate: 7e-05 
2023-08-01 03:06:42.976605: train_loss -0.3519 
2023-08-01 03:06:42.976805: val_loss -0.2971 
2023-08-01 03:06:42.976866: Pseudo dice [0.9127] 
2023-08-01 03:06:42.976921: Epoch time: 55.54 s 
2023-08-01 03:06:44.220995:  
2023-08-01 03:06:44.221249: Epoch 952 
2023-08-01 03:06:44.221334: Current learning rate: 7e-05 
2023-08-01 03:07:39.779287: train_loss -0.3404 
2023-08-01 03:07:39.779456: val_loss -0.3067 
2023-08-01 03:07:39.779530: Pseudo dice [0.909] 
2023-08-01 03:07:39.779585: Epoch time: 55.56 s 
2023-08-01 03:07:40.800620:  
2023-08-01 03:07:40.800724: Epoch 953 
2023-08-01 03:07:40.800801: Current learning rate: 6e-05 
2023-08-01 03:08:36.329088: train_loss -0.3595 
2023-08-01 03:08:36.329278: val_loss -0.2747 
2023-08-01 03:08:36.329337: Pseudo dice [0.8072] 
2023-08-01 03:08:36.329531: Epoch time: 55.53 s 
2023-08-01 03:08:37.377152:  
2023-08-01 03:08:37.377271: Epoch 954 
2023-08-01 03:08:37.377362: Current learning rate: 6e-05 
2023-08-01 03:09:32.931413: train_loss -0.3381 
2023-08-01 03:09:32.931907: val_loss -0.3696 
2023-08-01 03:09:32.932091: Pseudo dice [0.8626] 
2023-08-01 03:09:32.932242: Epoch time: 55.55 s 
2023-08-01 03:09:33.998875:  
2023-08-01 03:09:33.998978: Epoch 955 
2023-08-01 03:09:33.999072: Current learning rate: 6e-05 
2023-08-01 03:10:29.519430: train_loss -0.3481 
2023-08-01 03:10:29.519614: val_loss -0.3869 
2023-08-01 03:10:29.519674: Pseudo dice [0.8284] 
2023-08-01 03:10:29.519729: Epoch time: 55.52 s 
2023-08-01 03:10:30.593279:  
2023-08-01 03:10:30.593376: Epoch 956 
2023-08-01 03:10:30.593468: Current learning rate: 6e-05 
2023-08-01 03:11:26.111949: train_loss -0.3959 
2023-08-01 03:11:26.112118: val_loss -0.3809 
2023-08-01 03:11:26.112187: Pseudo dice [0.8113] 
2023-08-01 03:11:26.112243: Epoch time: 55.52 s 
2023-08-01 03:11:27.297505:  
2023-08-01 03:11:27.297614: Epoch 957 
2023-08-01 03:11:27.297723: Current learning rate: 6e-05 
2023-08-01 03:12:22.838052: train_loss -0.367 
2023-08-01 03:12:22.838236: val_loss -0.3873 
2023-08-01 03:12:22.838299: Pseudo dice [0.9247] 
2023-08-01 03:12:22.838354: Epoch time: 55.54 s 
2023-08-01 03:12:23.905666:  
2023-08-01 03:12:23.905772: Epoch 958 
2023-08-01 03:12:23.905865: Current learning rate: 6e-05 
2023-08-01 03:13:19.413941: train_loss -0.3234 
2023-08-01 03:13:19.414106: val_loss -0.3656 
2023-08-01 03:13:19.414165: Pseudo dice [0.8799] 
2023-08-01 03:13:19.414220: Epoch time: 55.51 s 
2023-08-01 03:13:20.450842:  
2023-08-01 03:13:20.450948: Epoch 959 
2023-08-01 03:13:20.451055: Current learning rate: 6e-05 
2023-08-01 03:14:15.995393: train_loss -0.3242 
2023-08-01 03:14:15.995564: val_loss -0.391 
2023-08-01 03:14:15.995624: Pseudo dice [0.8496] 
2023-08-01 03:14:15.995678: Epoch time: 55.55 s 
2023-08-01 03:14:17.077443:  
2023-08-01 03:14:17.077546: Epoch 960 
2023-08-01 03:14:17.077627: Current learning rate: 6e-05 
2023-08-01 03:15:12.664197: train_loss -0.3663 
2023-08-01 03:15:12.664369: val_loss -0.3907 
2023-08-01 03:15:12.664439: Pseudo dice [0.8855] 
2023-08-01 03:15:12.664505: Epoch time: 55.59 s 
2023-08-01 03:15:13.707806:  
2023-08-01 03:15:13.707909: Epoch 961 
2023-08-01 03:15:13.707986: Current learning rate: 5e-05 
2023-08-01 03:16:09.230457: train_loss -0.3741 
2023-08-01 03:16:09.230615: val_loss -0.3943 
2023-08-01 03:16:09.230690: Pseudo dice [0.8278] 
2023-08-01 03:16:09.230744: Epoch time: 55.52 s 
2023-08-01 03:16:10.274344:  
2023-08-01 03:16:10.274446: Epoch 962 
2023-08-01 03:16:10.274539: Current learning rate: 5e-05 
2023-08-01 03:17:05.668322: train_loss -0.3201 
2023-08-01 03:17:05.668479: val_loss -0.3687 
2023-08-01 03:17:05.668537: Pseudo dice [0.9303] 
2023-08-01 03:17:05.668590: Epoch time: 55.39 s 
2023-08-01 03:17:06.884014:  
2023-08-01 03:17:06.884119: Epoch 963 
2023-08-01 03:17:06.884216: Current learning rate: 5e-05 
2023-08-01 03:18:02.394830: train_loss -0.3648 
2023-08-01 03:18:02.395013: val_loss -0.3432 
2023-08-01 03:18:02.395071: Pseudo dice [0.8811] 
2023-08-01 03:18:02.395126: Epoch time: 55.51 s 
2023-08-01 03:18:03.437804:  
2023-08-01 03:18:03.437926: Epoch 964 
2023-08-01 03:18:03.438005: Current learning rate: 5e-05 
2023-08-01 03:18:58.917736: train_loss -0.3736 
2023-08-01 03:18:58.917920: val_loss -0.4473 
2023-08-01 03:18:58.917977: Pseudo dice [0.9212] 
2023-08-01 03:18:58.918031: Epoch time: 55.48 s 
2023-08-01 03:18:58.918075: Yayy! New best EMA pseudo Dice: 0.8714 
2023-08-01 03:19:00.344437:  
2023-08-01 03:19:00.344642: Epoch 965 
2023-08-01 03:19:00.344725: Current learning rate: 5e-05 
2023-08-01 03:19:55.801218: train_loss -0.3566 
2023-08-01 03:19:55.801412: val_loss -0.3426 
2023-08-01 03:19:55.801472: Pseudo dice [0.8149] 
2023-08-01 03:19:55.801528: Epoch time: 55.46 s 
2023-08-01 03:19:56.845963:  
2023-08-01 03:19:56.846062: Epoch 966 
2023-08-01 03:19:56.846155: Current learning rate: 5e-05 
2023-08-01 03:20:52.303742: train_loss -0.3299 
2023-08-01 03:20:52.303893: val_loss -0.3689 
2023-08-01 03:20:52.303952: Pseudo dice [0.8548] 
2023-08-01 03:20:52.304007: Epoch time: 55.46 s 
2023-08-01 03:20:53.558180:  
2023-08-01 03:20:53.558385: Epoch 967 
2023-08-01 03:20:53.558482: Current learning rate: 5e-05 
2023-08-01 03:21:49.102638: train_loss -0.3697 
2023-08-01 03:21:49.102815: val_loss -0.3496 
2023-08-01 03:21:49.102874: Pseudo dice [0.8116] 
2023-08-01 03:21:49.102929: Epoch time: 55.55 s 
2023-08-01 03:21:50.289291:  
2023-08-01 03:21:50.289404: Epoch 968 
2023-08-01 03:21:50.289482: Current learning rate: 5e-05 
2023-08-01 03:22:45.842606: train_loss -0.3468 
2023-08-01 03:22:45.842783: val_loss -0.3793 
2023-08-01 03:22:45.842842: Pseudo dice [0.8293] 
2023-08-01 03:22:45.842900: Epoch time: 55.55 s 
2023-08-01 03:22:46.935647:  
2023-08-01 03:22:46.935751: Epoch 969 
2023-08-01 03:22:46.935845: Current learning rate: 4e-05 
2023-08-01 03:23:42.440874: train_loss -0.3452 
2023-08-01 03:23:42.441165: val_loss -0.385 
2023-08-01 03:23:42.441230: Pseudo dice [0.8754] 
2023-08-01 03:23:42.441285: Epoch time: 55.51 s 
2023-08-01 03:23:43.516424:  
2023-08-01 03:23:43.516531: Epoch 970 
2023-08-01 03:23:43.516624: Current learning rate: 4e-05 
2023-08-01 03:24:38.989440: train_loss -0.353 
2023-08-01 03:24:38.989634: val_loss -0.3545 
2023-08-01 03:24:38.989691: Pseudo dice [0.8927] 
2023-08-01 03:24:38.989748: Epoch time: 55.47 s 
2023-08-01 03:24:40.035046:  
2023-08-01 03:24:40.035176: Epoch 971 
2023-08-01 03:24:40.035260: Current learning rate: 4e-05 
2023-08-01 03:25:35.631160: train_loss -0.3898 
2023-08-01 03:25:35.631354: val_loss -0.3999 
2023-08-01 03:25:35.631413: Pseudo dice [0.8949] 
2023-08-01 03:25:35.631468: Epoch time: 55.6 s 
2023-08-01 03:25:36.681992:  
2023-08-01 03:25:36.682088: Epoch 972 
2023-08-01 03:25:36.682182: Current learning rate: 4e-05 
2023-08-01 03:26:32.203666: train_loss -0.3971 
2023-08-01 03:26:32.203822: val_loss -0.3009 
2023-08-01 03:26:32.203882: Pseudo dice [0.8186] 
2023-08-01 03:26:32.203937: Epoch time: 55.52 s 
2023-08-01 03:26:33.278323:  
2023-08-01 03:26:33.278416: Epoch 973 
2023-08-01 03:26:33.278524: Current learning rate: 4e-05 
2023-08-01 03:27:28.819225: train_loss -0.3543 
2023-08-01 03:27:28.819403: val_loss -0.4222 
2023-08-01 03:27:28.819462: Pseudo dice [0.8375] 
2023-08-01 03:27:28.819531: Epoch time: 55.54 s 
2023-08-01 03:27:30.040862:  
2023-08-01 03:27:30.041178: Epoch 974 
2023-08-01 03:27:30.041260: Current learning rate: 4e-05 
2023-08-01 03:28:25.623806: train_loss -0.389 
2023-08-01 03:28:25.623970: val_loss -0.3915 
2023-08-01 03:28:25.624030: Pseudo dice [0.8855] 
2023-08-01 03:28:25.624084: Epoch time: 55.58 s 
2023-08-01 03:28:26.674582:  
2023-08-01 03:28:26.674694: Epoch 975 
2023-08-01 03:28:26.674787: Current learning rate: 4e-05 
2023-08-01 03:29:22.254933: train_loss -0.3362 
2023-08-01 03:29:22.255108: val_loss -0.341 
2023-08-01 03:29:22.255164: Pseudo dice [0.8429] 
2023-08-01 03:29:22.255219: Epoch time: 55.58 s 
2023-08-01 03:29:23.297901:  
2023-08-01 03:29:23.298012: Epoch 976 
2023-08-01 03:29:23.298091: Current learning rate: 3e-05 
2023-08-01 03:30:18.856634: train_loss -0.3407 
2023-08-01 03:30:18.856799: val_loss -0.4316 
2023-08-01 03:30:18.856864: Pseudo dice [0.9103] 
2023-08-01 03:30:18.856919: Epoch time: 55.56 s 
2023-08-01 03:30:19.909349:  
2023-08-01 03:30:19.909569: Epoch 977 
2023-08-01 03:30:19.909667: Current learning rate: 3e-05 
2023-08-01 03:31:15.388029: train_loss -0.3567 
2023-08-01 03:31:15.388195: val_loss -0.3132 
2023-08-01 03:31:15.388254: Pseudo dice [0.8872] 
2023-08-01 03:31:15.388309: Epoch time: 55.48 s 
2023-08-01 03:31:16.438826:  
2023-08-01 03:31:16.438931: Epoch 978 
2023-08-01 03:31:16.439023: Current learning rate: 3e-05 
2023-08-01 03:32:12.045636: train_loss -0.3647 
2023-08-01 03:32:12.045810: val_loss -0.3376 
2023-08-01 03:32:12.045871: Pseudo dice [0.8371] 
2023-08-01 03:32:12.045926: Epoch time: 55.61 s 
2023-08-01 03:32:13.116415:  
2023-08-01 03:32:13.116519: Epoch 979 
2023-08-01 03:32:13.116596: Current learning rate: 3e-05 
2023-08-01 03:33:08.647134: train_loss -0.3924 
2023-08-01 03:33:08.647321: val_loss -0.3821 
2023-08-01 03:33:08.647383: Pseudo dice [0.8259] 
2023-08-01 03:33:08.647438: Epoch time: 55.53 s 
2023-08-01 03:33:09.843299:  
2023-08-01 03:33:09.843424: Epoch 980 
2023-08-01 03:33:09.843533: Current learning rate: 3e-05 
2023-08-01 03:34:05.443440: train_loss -0.365 
2023-08-01 03:34:05.443615: val_loss -0.2985 
2023-08-01 03:34:05.443677: Pseudo dice [0.8482] 
2023-08-01 03:34:05.443732: Epoch time: 55.6 s 
2023-08-01 03:34:06.491443:  
2023-08-01 03:34:06.491567: Epoch 981 
2023-08-01 03:34:06.491661: Current learning rate: 3e-05 
2023-08-01 03:35:02.099228: train_loss -0.3599 
2023-08-01 03:35:02.099391: val_loss -0.3825 
2023-08-01 03:35:02.099472: Pseudo dice [0.8592] 
2023-08-01 03:35:02.099537: Epoch time: 55.61 s 
2023-08-01 03:35:03.172352:  
2023-08-01 03:35:03.172656: Epoch 982 
2023-08-01 03:35:03.172742: Current learning rate: 3e-05 
2023-08-01 03:35:58.761433: train_loss -0.3631 
2023-08-01 03:35:58.761604: val_loss -0.4102 
2023-08-01 03:35:58.761662: Pseudo dice [0.8818] 
2023-08-01 03:35:58.761716: Epoch time: 55.59 s 
2023-08-01 03:35:59.822935:  
2023-08-01 03:35:59.823037: Epoch 983 
2023-08-01 03:35:59.823147: Current learning rate: 3e-05 
2023-08-01 03:36:55.358318: train_loss -0.3491 
2023-08-01 03:36:55.358487: val_loss -0.406 
2023-08-01 03:36:55.358546: Pseudo dice [0.8807] 
2023-08-01 03:36:55.358600: Epoch time: 55.54 s 
2023-08-01 03:36:56.485009:  
2023-08-01 03:36:56.485112: Epoch 984 
2023-08-01 03:36:56.485184: Current learning rate: 2e-05 
2023-08-01 03:37:52.142826: train_loss -0.353 
2023-08-01 03:37:52.142989: val_loss -0.3315 
2023-08-01 03:37:52.143047: Pseudo dice [0.8542] 
2023-08-01 03:37:52.143101: Epoch time: 55.66 s 
2023-08-01 03:37:53.187230:  
2023-08-01 03:37:53.187346: Epoch 985 
2023-08-01 03:37:53.187425: Current learning rate: 2e-05 
2023-08-01 03:38:48.818367: train_loss -0.3568 
2023-08-01 03:38:48.818523: val_loss -0.4304 
2023-08-01 03:38:48.818582: Pseudo dice [0.7887] 
2023-08-01 03:38:48.818637: Epoch time: 55.63 s 
2023-08-01 03:38:50.030025:  
2023-08-01 03:38:50.030238: Epoch 986 
2023-08-01 03:38:50.030352: Current learning rate: 2e-05 
2023-08-01 03:39:45.627067: train_loss -0.3405 
2023-08-01 03:39:45.627297: val_loss -0.3398 
2023-08-01 03:39:45.627357: Pseudo dice [0.8789] 
2023-08-01 03:39:45.627411: Epoch time: 55.6 s 
2023-08-01 03:39:46.683741:  
2023-08-01 03:39:46.683846: Epoch 987 
2023-08-01 03:39:46.683926: Current learning rate: 2e-05 
2023-08-01 03:40:42.280068: train_loss -0.3614 
2023-08-01 03:40:42.280238: val_loss -0.3396 
2023-08-01 03:40:42.280301: Pseudo dice [0.8654] 
2023-08-01 03:40:42.280355: Epoch time: 55.6 s 
2023-08-01 03:40:43.327378:  
2023-08-01 03:40:43.327485: Epoch 988 
2023-08-01 03:40:43.327579: Current learning rate: 2e-05 
2023-08-01 03:41:38.907290: train_loss -0.3657 
2023-08-01 03:41:38.907453: val_loss -0.3778 
2023-08-01 03:41:38.907520: Pseudo dice [0.886] 
2023-08-01 03:41:38.907576: Epoch time: 55.58 s 
2023-08-01 03:41:39.983690:  
2023-08-01 03:41:39.983793: Epoch 989 
2023-08-01 03:41:39.983872: Current learning rate: 2e-05 
2023-08-01 03:42:35.537212: train_loss -0.3344 
2023-08-01 03:42:35.537376: val_loss -0.3858 
2023-08-01 03:42:35.537436: Pseudo dice [0.8611] 
2023-08-01 03:42:35.537490: Epoch time: 55.55 s 
2023-08-01 03:42:36.579277:  
2023-08-01 03:42:36.579383: Epoch 990 
2023-08-01 03:42:36.579477: Current learning rate: 2e-05 
2023-08-01 03:43:32.103950: train_loss -0.3339 
2023-08-01 03:43:32.104109: val_loss -0.3527 
2023-08-01 03:43:32.104170: Pseudo dice [0.8703] 
2023-08-01 03:43:32.104228: Epoch time: 55.53 s 
2023-08-01 03:43:33.164617:  
2023-08-01 03:43:33.164731: Epoch 991 
2023-08-01 03:43:33.164826: Current learning rate: 1e-05 
2023-08-01 03:44:28.775558: train_loss -0.3428 
2023-08-01 03:44:28.775721: val_loss -0.4103 
2023-08-01 03:44:28.775784: Pseudo dice [0.8168] 
2023-08-01 03:44:28.775839: Epoch time: 55.61 s 
2023-08-01 03:44:30.059011:  
2023-08-01 03:44:30.059111: Epoch 992 
2023-08-01 03:44:30.059204: Current learning rate: 1e-05 
2023-08-01 03:45:25.651002: train_loss -0.3244 
2023-08-01 03:45:25.651165: val_loss -0.3957 
2023-08-01 03:45:25.651240: Pseudo dice [0.8521] 
2023-08-01 03:45:25.651293: Epoch time: 55.59 s 
2023-08-01 03:45:26.737314:  
2023-08-01 03:45:26.737417: Epoch 993 
2023-08-01 03:45:26.737526: Current learning rate: 1e-05 
2023-08-01 03:46:22.323831: train_loss -0.3704 
2023-08-01 03:46:22.324001: val_loss -0.2864 
2023-08-01 03:46:22.324063: Pseudo dice [0.7832] 
2023-08-01 03:46:22.324119: Epoch time: 55.59 s 
2023-08-01 03:46:23.364244:  
2023-08-01 03:46:23.364340: Epoch 994 
2023-08-01 03:46:23.364434: Current learning rate: 1e-05 
2023-08-01 03:47:18.977117: train_loss -0.3753 
2023-08-01 03:47:18.977306: val_loss -0.3275 
2023-08-01 03:47:18.977363: Pseudo dice [0.8849] 
2023-08-01 03:47:18.977417: Epoch time: 55.61 s 
2023-08-01 03:47:20.023852:  
2023-08-01 03:47:20.023957: Epoch 995 
2023-08-01 03:47:20.024035: Current learning rate: 1e-05 
2023-08-01 03:48:15.479627: train_loss -0.3517 
2023-08-01 03:48:15.479778: val_loss -0.3596 
2023-08-01 03:48:15.479836: Pseudo dice [0.842] 
2023-08-01 03:48:15.479892: Epoch time: 55.46 s 
2023-08-01 03:48:16.531037:  
2023-08-01 03:48:16.531154: Epoch 996 
2023-08-01 03:48:16.531250: Current learning rate: 1e-05 
2023-08-01 03:49:12.022699: train_loss -0.381 
2023-08-01 03:49:12.022858: val_loss -0.3796 
2023-08-01 03:49:12.022918: Pseudo dice [0.8385] 
2023-08-01 03:49:12.022973: Epoch time: 55.49 s 
2023-08-01 03:49:13.209340:  
2023-08-01 03:49:13.209440: Epoch 997 
2023-08-01 03:49:13.209517: Current learning rate: 1e-05 
2023-08-01 03:50:08.757661: train_loss -0.3911 
2023-08-01 03:50:08.757923: val_loss -0.3569 
2023-08-01 03:50:08.757991: Pseudo dice [0.8242] 
2023-08-01 03:50:08.758047: Epoch time: 55.55 s 
2023-08-01 03:50:09.803708:  
2023-08-01 03:50:09.803814: Epoch 998 
2023-08-01 03:50:09.803891: Current learning rate: 0.0 
2023-08-01 03:51:05.332691: train_loss -0.3902 
2023-08-01 03:51:05.332866: val_loss -0.359 
2023-08-01 03:51:05.332942: Pseudo dice [0.8549] 
2023-08-01 03:51:05.332998: Epoch time: 55.53 s 
2023-08-01 03:51:06.439780:  
2023-08-01 03:51:06.439886: Epoch 999 
2023-08-01 03:51:06.439963: Current learning rate: 0.0 
2023-08-01 03:52:02.007439: train_loss -0.3725 
2023-08-01 03:52:02.007621: val_loss -0.3549 
2023-08-01 03:52:02.007686: Pseudo dice [0.8647] 
2023-08-01 03:52:02.007742: Epoch time: 55.57 s 
2023-08-01 03:52:03.743596: predicting LUNG1-001 
2023-08-01 03:52:07.242674: predicting LUNG1-002 
2023-08-01 03:52:10.212662: predicting LUNG1-003 
2023-08-01 03:52:13.199644: predicting LUNG1-004 
2023-08-01 03:52:16.174174: predicting LUNG1-005 
2023-08-01 03:52:19.160662: predicting LUNG1-006 
2023-08-01 03:52:22.111884: predicting LUNG1-007 
2023-08-01 03:52:25.088553: predicting LUNG1-008 
2023-08-01 03:52:28.052089: predicting LUNG1-009 
2023-08-01 03:52:31.010481: predicting LUNG1-010 
2023-08-01 03:52:33.991313: predicting LUNG1-011 
2023-08-01 03:52:37.932462: predicting LUNG1-012 
2023-08-01 03:52:41.890510: predicting LUNG1-013 
2023-08-01 03:52:44.869701: predicting LUNG1-014 
2023-08-01 03:52:47.857244: predicting LUNG1-015 
2023-08-01 03:52:50.814963: predicting LUNG1-016 
2023-08-01 03:52:53.783141: predicting LUNG1-017 
2023-08-01 03:52:56.740206: predicting LUNG1-018 
2023-08-01 03:52:59.708623: predicting LUNG1-019 
2023-08-01 03:53:02.667675: predicting LUNG1-020 
2023-08-01 03:53:05.651939: predicting LUNG1-021 
2023-08-01 03:53:08.632267: predicting LUNG1-022 
2023-08-01 03:53:11.601321: predicting LUNG1-023 
2023-08-01 03:53:14.568312: predicting LUNG1-024 
2023-08-01 03:53:17.552428: predicting LUNG1-025 
2023-08-01 03:53:19.543874: predicting LUNG1-026 
2023-08-01 03:53:22.502035: predicting LUNG1-027 
2023-08-01 03:53:26.925413: predicting LUNG1-028 
2023-08-01 03:53:29.918429: predicting LUNG1-029 
2023-08-01 03:53:31.911743: predicting LUNG1-030 
2023-08-01 03:53:34.864970: predicting LUNG1-031 
2023-08-01 03:53:37.833037: predicting LUNG1-032 
2023-08-01 03:53:42.250606: predicting LUNG1-033 
2023-08-01 03:53:46.682643: predicting LUNG1-034 
2023-08-01 03:53:49.687209: predicting LUNG1-035 
2023-08-01 03:53:52.641130: predicting LUNG1-036 
2023-08-01 03:53:55.609237: predicting LUNG1-037 
2023-08-01 03:53:58.573160: predicting LUNG1-038 
2023-08-01 03:54:00.563635: predicting LUNG1-039 
2023-08-01 03:54:03.516907: predicting LUNG1-040 
2023-08-01 03:54:05.504781: predicting LUNG1-041 
2023-08-01 03:54:07.476041: predicting LUNG1-042 
2023-08-01 03:54:10.439331: predicting LUNG1-043 
2023-08-01 03:54:13.388808: predicting LUNG1-044 
2023-08-01 03:54:15.377609: predicting LUNG1-045 
2023-08-01 03:54:17.350888: predicting LUNG1-046 
2023-08-01 03:54:20.295911: predicting LUNG1-047 
2023-08-01 03:54:23.262854: predicting LUNG1-048 
2023-08-01 03:54:25.237628: predicting LUNG1-049 
2023-08-01 03:54:28.204428: predicting LUNG1-050 
2023-08-01 03:54:31.167073: predicting LUNG1-051 
2023-08-01 03:54:35.579378: predicting LUNG1-052 
2023-08-01 03:54:38.528623: predicting LUNG1-053 
2023-08-01 03:54:41.476790: predicting LUNG1-054 
2023-08-01 03:54:44.420928: predicting LUNG1-055 
2023-08-01 03:54:47.384671: predicting LUNG1-056 
2023-08-01 03:54:49.356545: predicting LUNG1-057 
2023-08-01 03:54:52.318424: predicting LUNG1-058 
2023-08-01 03:54:56.743528: predicting LUNG1-059 
2023-08-01 03:54:59.718773: predicting LUNG1-060 
2023-08-01 03:55:03.653158: predicting LUNG1-061 
2023-08-01 03:55:06.630086: predicting LUNG1-062 
2023-08-01 03:55:08.605566: predicting LUNG1-063 
2023-08-01 03:55:10.575922: predicting LUNG1-064 
2023-08-01 03:55:13.517975: predicting LUNG1-065 
2023-08-01 03:55:15.522783: predicting LUNG1-066 
2023-08-01 03:55:18.477966: predicting LUNG1-067 
2023-08-01 03:55:21.438972: predicting LUNG1-068 
2023-08-01 03:55:24.386542: predicting LUNG1-069 
2023-08-01 03:55:27.345395: predicting LUNG1-070 
2023-08-01 03:55:30.294147: predicting LUNG1-071 
2023-08-01 03:55:33.244112: predicting LUNG1-072 
2023-08-01 03:55:36.191160: predicting LUNG1-073 
2023-08-01 03:55:39.140283: predicting LUNG1-074 
2023-08-01 03:55:42.102253: predicting LUNG1-075 
2023-08-01 03:55:44.072377: predicting LUNG1-076 
2023-08-01 03:55:47.034447: predicting LUNG1-077 
2023-08-01 03:55:49.989795: predicting LUNG1-078 
2023-08-01 03:55:52.948610: predicting LUNG1-079 
2023-08-01 03:55:55.912224: predicting LUNG1-080 
2023-08-01 03:55:58.870201: predicting LUNG1-081 
2023-08-01 03:56:03.279427: predicting LUNG1-082 
2023-08-01 03:56:06.249597: predicting LUNG1-083 
2023-08-01 03:56:10.667986: predicting LUNG1-084 
2023-08-01 03:56:12.666148: predicting LUNG1-085 
2023-08-01 03:56:14.649320: predicting LUNG1-086 
2023-08-01 03:56:17.593317: predicting LUNG1-087 
2023-08-01 03:56:20.557452: predicting LUNG1-088 
2023-08-01 03:56:24.976451: predicting LUNG1-089 
2023-08-01 03:56:26.977227: predicting LUNG1-090 
2023-08-01 03:56:31.376891: predicting LUNG1-091 
2023-08-01 03:56:33.362851: predicting LUNG1-092 
2023-08-01 03:56:36.319880: predicting LUNG1-093 
2023-08-01 03:56:39.272504: predicting LUNG1-094 
2023-08-01 03:56:41.241539: predicting LUNG1-095 
2023-08-01 03:56:43.211422: predicting LUNG1-096 
2023-08-01 03:56:46.169193: predicting LUNG1-097 
2023-08-01 03:56:49.139857: predicting LUNG1-098 
2023-08-01 03:56:52.103428: predicting LUNG1-099 
2023-08-01 03:56:55.065523: predicting LUNG1-100 
2023-08-01 03:56:58.031942: predicting LUNG1-101 
2023-08-01 03:57:00.003070: predicting LUNG1-102 
2023-08-01 03:57:02.959366: predicting LUNG1-103 
2023-08-01 03:57:05.902391: predicting LUNG1-104 
2023-08-01 03:57:08.844462: predicting LUNG1-105 
2023-08-01 03:57:10.816133: predicting LUNG1-106 
2023-08-01 03:57:13.772529: predicting LUNG1-107 
2023-08-01 03:57:16.730446: predicting LUNG1-108 
2023-08-01 03:57:19.671904: predicting LUNG1-109 
2023-08-01 03:57:22.614162: predicting LUNG1-110 
2023-08-01 03:57:24.597531: predicting LUNG1-111 
2023-08-01 03:57:27.555228: predicting LUNG1-112 
2023-08-01 03:57:30.500582: predicting LUNG1-113 
2023-08-01 03:57:33.469220: predicting LUNG1-114 
2023-08-01 03:57:36.424801: predicting LUNG1-115 
2023-08-01 03:57:39.362090: predicting LUNG1-116 
2023-08-01 03:57:42.308278: predicting LUNG1-117 
2023-08-01 03:57:45.273855: predicting LUNG1-118 
2023-08-01 03:57:48.227227: predicting LUNG1-119 
2023-08-01 03:57:50.222609: predicting LUNG1-120 
2023-08-01 03:57:53.174827: predicting LUNG1-121 
2023-08-01 03:57:56.126390: predicting LUNG1-122 
2023-08-01 03:57:59.079597: predicting LUNG1-123 
2023-08-01 03:58:02.031779: predicting LUNG1-124 
2023-08-01 03:58:04.971265: predicting LUNG1-125 
2023-08-01 03:58:07.909118: predicting LUNG1-126 
2023-08-01 03:58:10.858312: predicting LUNG1-127 
2023-08-01 03:58:12.839028: predicting LUNG1-129 
2023-08-01 03:58:15.775312: predicting LUNG1-130 
2023-08-01 03:58:18.713773: predicting LUNG1-131 
2023-08-01 03:58:21.663159: predicting LUNG1-132 
2023-08-01 03:58:24.599699: predicting LUNG1-133 
2023-08-01 03:58:27.550455: predicting LUNG1-134 
2023-08-01 03:58:30.488609: predicting LUNG1-135 
2023-08-01 03:58:33.433983: predicting LUNG1-136 
2023-08-01 03:58:36.387752: predicting LUNG1-137 
2023-08-01 03:58:39.322381: predicting LUNG1-138 
2023-08-01 03:58:41.298319: predicting LUNG1-139 
2023-08-01 03:58:44.243608: predicting LUNG1-140 
2023-08-01 03:58:46.221187: predicting LUNG1-141 
2023-08-01 03:58:48.193465: predicting LUNG1-142 
2023-08-01 03:58:51.139554: predicting LUNG1-143 
2023-08-01 03:58:53.116841: predicting LUNG1-144 
2023-08-01 03:58:56.062647: predicting LUNG1-145 
2023-08-01 03:58:58.995427: predicting LUNG1-146 
2023-08-01 03:59:01.941454: predicting LUNG1-147 
2023-08-01 03:59:04.883445: predicting LUNG1-148 
2023-08-01 03:59:07.825381: predicting LUNG1-149 
2023-08-01 03:59:10.771759: predicting LUNG1-150 
2023-08-01 03:59:15.160623: predicting LUNG1-151 
2023-08-01 03:59:19.569353: predicting LUNG1-152 
2023-08-01 03:59:23.958841: predicting LUNG1-153 
2023-08-01 03:59:24.969357: predicting LUNG1-154 
2023-08-01 03:59:27.892904: predicting LUNG1-155 
2023-08-01 03:59:29.867941: predicting LUNG1-156 
2023-08-01 03:59:32.808102: predicting LUNG1-157 
2023-08-01 03:59:35.737731: predicting LUNG1-158 
2023-08-01 03:59:38.663281: predicting LUNG1-159 
2023-08-01 03:59:41.600039: predicting LUNG1-160 
2023-08-01 03:59:45.991730: predicting LUNG1-161 
2023-08-01 03:59:50.405636: predicting LUNG1-162 
2023-08-01 03:59:53.357429: predicting LUNG1-163 
2023-08-01 03:59:55.317464: predicting LUNG1-164 
2023-08-01 03:59:58.254278: predicting LUNG1-165 
2023-08-01 04:00:00.226741: predicting LUNG1-166 
2023-08-01 04:00:03.149552: predicting LUNG1-167 
2023-08-01 04:00:06.089578: predicting LUNG1-168 
2023-08-01 04:00:09.012579: predicting LUNG1-169 
2023-08-01 04:00:11.939462: predicting LUNG1-170 
2023-08-01 04:00:14.879460: predicting LUNG1-171 
2023-08-01 04:00:17.827972: predicting LUNG1-172 
2023-08-01 04:00:19.785785: predicting LUNG1-173 
2023-08-01 04:00:22.706824: predicting LUNG1-174 
2023-08-01 04:00:25.641119: predicting LUNG1-175 
2023-08-01 04:00:28.573698: predicting LUNG1-176 
2023-08-01 04:00:30.545294: predicting LUNG1-177 
2023-08-01 04:00:32.510939: predicting LUNG1-178 
2023-08-01 04:00:35.443972: predicting LUNG1-179 
2023-08-01 04:00:38.365828: predicting LUNG1-180 
2023-08-01 04:00:41.291147: predicting LUNG1-181 
2023-08-01 04:00:44.216433: predicting LUNG1-182 
2023-08-01 04:00:47.178188: predicting LUNG1-183 
2023-08-01 04:00:50.114377: predicting LUNG1-184 
2023-08-01 04:00:54.496585: predicting LUNG1-185 
2023-08-01 04:00:57.442788: predicting LUNG1-186 
2023-08-01 04:01:00.379290: predicting LUNG1-187 
2023-08-01 04:01:02.334587: predicting LUNG1-188 
2023-08-01 04:01:05.266923: predicting LUNG1-189 
2023-08-01 04:01:08.186426: predicting LUNG1-190 
2023-08-01 04:01:11.121350: predicting LUNG1-191 
2023-08-01 04:01:14.042311: predicting LUNG1-192 
2023-08-01 04:01:16.977481: predicting LUNG1-193 
2023-08-01 04:01:19.908261: predicting LUNG1-194 
2023-08-01 04:01:22.826496: predicting LUNG1-195 
2023-08-01 04:01:24.793255: predicting LUNG1-196 
2023-08-01 04:01:26.745675: predicting LUNG1-197 
2023-08-01 04:01:28.709540: predicting LUNG1-198 
2023-08-01 04:01:31.632362: predicting LUNG1-199 
2023-08-01 04:01:34.563637: predicting LUNG1-200 
2023-08-01 04:01:37.481754: predicting LUNG1-201 
2023-08-01 04:01:40.427512: predicting LUNG1-202 
2023-08-01 04:01:42.402085: predicting LUNG1-203 
2023-08-01 04:01:45.329276: predicting LUNG1-204 
2023-08-01 04:01:48.250998: predicting LUNG1-205 
2023-08-01 04:01:51.168680: predicting LUNG1-206 
2023-08-01 04:01:54.082716: predicting LUNG1-207 
2023-08-01 04:01:57.013112: predicting LUNG1-208 
2023-08-01 04:01:59.953748: predicting LUNG1-209 
2023-08-01 04:02:04.331011: predicting LUNG1-210 
2023-08-01 04:02:08.743588: predicting LUNG1-211 
2023-08-01 04:02:11.679769: predicting LUNG1-212 
2023-08-01 04:02:14.597321: predicting LUNG1-213 
2023-08-01 04:02:16.563902: predicting LUNG1-214 
2023-08-01 04:02:19.491994: predicting LUNG1-215 
2023-08-01 04:02:20.978948: predicting LUNG1-216 
2023-08-01 04:02:23.904479: predicting LUNG1-217 
2023-08-01 04:02:25.872331: predicting LUNG1-218 
2023-08-01 04:02:27.834240: predicting LUNG1-219 
2023-08-01 04:02:29.779471: predicting LUNG1-220 
2023-08-01 04:02:31.752485: predicting LUNG1-221 
2023-08-01 04:02:34.678258: predicting LUNG1-222 
2023-08-01 04:02:37.598179: predicting LUNG1-223 
2023-08-01 04:02:39.551102: predicting LUNG1-224 
2023-08-01 04:02:41.502547: predicting LUNG1-225 
2023-08-01 04:02:44.430807: predicting LUNG1-226 
2023-08-01 04:02:47.358706: predicting LUNG1-227 
2023-08-01 04:02:50.274281: predicting LUNG1-228 
2023-08-01 04:02:52.238919: predicting LUNG1-229 
2023-08-01 04:02:55.168211: predicting LUNG1-230 
2023-08-01 04:02:58.096457: predicting LUNG1-231 
2023-08-01 04:03:00.046726: predicting LUNG1-232 
2023-08-01 04:03:02.974210: predicting LUNG1-233 
2023-08-01 04:03:05.903664: predicting LUNG1-234 
2023-08-01 04:03:07.870476: predicting LUNG1-235 
2023-08-01 04:03:09.833657: predicting LUNG1-236 
2023-08-01 04:03:11.782709: predicting LUNG1-237 
2023-08-01 04:03:14.712586: predicting LUNG1-238 
2023-08-01 04:03:17.642211: predicting LUNG1-239 
2023-08-01 04:03:20.569330: predicting LUNG1-240 
2023-08-01 04:03:23.496618: predicting LUNG1-241 
2023-08-01 04:03:26.449109: predicting LUNG1-242 
2023-08-01 04:03:29.375732: predicting LUNG1-243 
2023-08-01 04:03:32.288076: predicting LUNG1-244 
2023-08-01 04:03:35.199376: predicting LUNG1-245 
2023-08-01 04:03:38.125004: predicting LUNG1-246 
2023-08-01 04:03:40.075012: predicting LUNG1-247 
2023-08-01 04:03:42.038300: predicting LUNG1-248 
2023-08-01 04:03:43.986640: predicting LUNG1-249 
2023-08-01 04:03:46.911687: predicting LUNG1-250 
2023-08-01 04:03:49.825487: predicting LUNG1-251 
2023-08-01 04:03:51.777872: predicting LUNG1-252 
2023-08-01 04:03:54.702648: predicting LUNG1-253 
2023-08-01 04:03:59.072310: predicting LUNG1-254 
2023-08-01 04:04:01.027018: predicting LUNG1-255 
2023-08-01 04:04:03.951102: predicting LUNG1-256 
2023-08-01 04:04:05.925333: predicting LUNG1-257 
2023-08-01 04:04:08.846174: predicting LUNG1-258 
2023-08-01 04:04:11.765597: predicting LUNG1-259 
2023-08-01 04:04:13.716514: predicting LUNG1-260 
2023-08-01 04:04:16.643328: predicting LUNG1-261 
2023-08-01 04:04:18.620923: predicting LUNG1-262 
2023-08-01 04:04:20.581969: predicting LUNG1-263 
2023-08-01 04:04:23.505134: predicting LUNG1-264 
2023-08-01 04:04:26.443718: predicting LUNG1-265 
2023-08-01 04:04:30.813936: predicting LUNG1-266 
2023-08-01 04:04:33.752070: predicting LUNG1-267 
2023-08-01 04:04:36.668677: predicting LUNG1-268 
2023-08-01 04:04:41.048810: predicting LUNG1-269 
2023-08-01 04:04:43.990070: predicting LUNG1-270 
2023-08-01 04:04:46.903837: predicting LUNG1-271 
2023-08-01 04:04:50.790108: predicting LUNG1-272 
2023-08-01 04:04:53.726000: predicting LUNG1-273 
2023-08-01 04:04:58.086472: predicting LUNG1-274 
2023-08-01 04:05:01.026000: predicting LUNG1-275 
2023-08-01 04:05:03.939854: predicting LUNG1-276 
2023-08-01 04:05:06.867272: predicting LUNG1-277 
2023-08-01 04:05:08.815129: predicting LUNG1-278 
2023-08-01 04:05:11.727109: predicting LUNG1-279 
2023-08-01 04:05:14.677928: predicting LUNG1-280 
2023-08-01 04:05:17.621894: predicting LUNG1-281 
2023-08-01 04:05:20.536066: predicting LUNG1-282 
2023-08-01 04:05:23.451973: predicting LUNG1-283 
2023-08-01 04:05:25.402550: predicting LUNG1-284 
2023-08-01 04:05:28.329831: predicting LUNG1-285 
2023-08-01 04:05:31.271983: predicting LUNG1-286 
2023-08-01 04:05:34.199090: predicting LUNG1-287 
2023-08-01 04:05:36.163087: predicting LUNG1-288 
2023-08-01 04:05:39.074225: predicting LUNG1-289 
2023-08-01 04:05:41.997784: predicting LUNG1-290 
2023-08-01 04:05:44.910902: predicting LUNG1-291 
2023-08-01 04:05:47.835402: predicting LUNG1-292 
2023-08-01 04:05:50.750140: predicting LUNG1-293 
2023-08-01 04:05:53.665000: predicting LUNG1-294 
2023-08-01 04:05:56.594433: predicting LUNG1-295 
2023-08-01 04:05:59.520345: predicting LUNG1-296 
2023-08-01 04:06:02.440000: predicting LUNG1-297 
2023-08-01 04:06:05.356158: predicting LUNG1-298 
2023-08-01 04:06:08.292469: predicting LUNG1-299 
2023-08-01 04:06:11.206683: predicting LUNG1-300 
2023-08-01 04:06:15.580509: predicting LUNG1-301 
2023-08-01 04:06:18.522735: predicting LUNG1-302 
2023-08-01 04:06:21.450227: predicting LUNG1-303 
2023-08-01 04:06:25.849869: predicting LUNG1-304 
2023-08-01 04:06:26.841866: predicting LUNG1-305 
2023-08-01 04:06:28.312062: predicting LUNG1-306 
2023-08-01 04:06:30.260336: predicting LUNG1-307 
2023-08-01 04:06:32.223648: predicting LUNG1-308 
2023-08-01 04:06:35.149759: predicting LUNG1-309 
2023-08-01 04:06:38.060295: predicting LUNG1-310 
2023-08-01 04:06:40.035612: predicting LUNG1-311 
2023-08-01 04:06:44.387135: predicting LUNG1-312 
2023-08-01 04:06:48.765738: predicting LUNG1-313 
2023-08-01 04:06:51.702565: predicting LUNG1-314 
2023-08-01 04:06:53.172713: predicting LUNG1-315 
2023-08-01 04:06:55.134627: predicting LUNG1-316 
2023-08-01 04:06:57.097416: predicting LUNG1-317 
2023-08-01 04:07:00.011742: predicting LUNG1-318 
2023-08-01 04:07:02.937127: predicting LUNG1-319 
2023-08-01 04:07:05.857861: predicting LUNG1-320 
2023-08-01 04:07:08.768516: predicting LUNG1-321 
2023-08-01 04:07:13.151376: predicting LUNG1-322 
2023-08-01 04:07:17.513628: predicting LUNG1-323 
2023-08-01 04:07:20.450702: predicting LUNG1-324 
2023-08-01 04:07:22.413021: predicting LUNG1-325 
2023-08-01 04:07:25.345882: predicting LUNG1-326 
2023-08-01 04:07:28.302956: predicting LUNG1-327 
2023-08-01 04:07:30.252483: predicting LUNG1-328 
2023-08-01 04:07:34.619478: predicting LUNG1-329 
2023-08-01 04:07:36.608901: predicting LUNG1-330 
2023-08-01 04:07:39.534966: predicting LUNG1-331 
2023-08-01 04:07:42.457311: predicting LUNG1-332 
2023-08-01 04:07:46.828001: predicting LUNG1-333 
2023-08-01 04:07:49.781095: predicting LUNG1-334 
2023-08-01 04:07:51.733178: predicting LUNG1-335 
2023-08-01 04:07:54.644774: predicting LUNG1-336 
2023-08-01 04:07:57.573561: predicting LUNG1-337 
2023-08-01 04:07:59.522386: predicting LUNG1-338 
2023-08-01 04:08:02.449634: predicting LUNG1-339 
2023-08-01 04:08:06.840122: predicting LUNG1-340 
2023-08-01 04:08:09.793324: predicting LUNG1-341 
2023-08-01 04:08:12.707789: predicting LUNG1-342 
2023-08-01 04:08:14.657127: predicting LUNG1-343 
2023-08-01 04:08:17.572187: predicting LUNG1-344 
2023-08-01 04:08:20.485695: predicting LUNG1-345 
2023-08-01 04:08:23.421665: predicting LUNG1-346 
2023-08-01 04:08:25.374163: predicting LUNG1-347 
2023-08-01 04:08:27.334178: predicting LUNG1-348 
2023-08-01 04:08:30.259274: predicting LUNG1-349 
2023-08-01 04:08:33.171847: predicting LUNG1-350 
2023-08-01 04:08:34.184250: predicting LUNG1-351 
2023-08-01 04:08:36.133833: predicting LUNG1-352 
2023-08-01 04:08:39.046009: predicting LUNG1-353 
2023-08-01 04:08:41.986933: predicting LUNG1-354 
2023-08-01 04:08:43.937844: predicting LUNG1-355 
2023-08-01 04:08:45.888112: predicting LUNG1-356 
2023-08-01 04:08:48.812458: predicting LUNG1-357 
2023-08-01 04:08:51.740427: predicting LUNG1-358 
2023-08-01 04:08:53.704405: predicting LUNG1-359 
2023-08-01 04:08:55.670328: predicting LUNG1-360 
2023-08-01 04:08:58.594118: predicting LUNG1-361 
2023-08-01 04:09:01.510411: predicting LUNG1-362 
2023-08-01 04:09:04.451362: predicting LUNG1-363 
2023-08-01 04:09:07.379421: predicting LUNG1-364 
2023-08-01 04:09:09.329810: predicting LUNG1-365 
2023-08-01 04:09:12.255915: predicting LUNG1-366 
2023-08-01 04:09:15.168418: predicting LUNG1-367 
2023-08-01 04:09:20.967597: predicting LUNG1-368 
2023-08-01 04:09:23.907228: predicting LUNG1-369 
2023-08-01 04:09:25.887580: predicting LUNG1-370 
2023-08-01 04:09:30.257493: predicting LUNG1-371 
2023-08-01 04:09:33.222858: predicting LUNG1-372 
2023-08-01 04:09:35.173678: predicting LUNG1-373 
2023-08-01 04:09:38.085158: predicting LUNG1-374 
2023-08-01 04:09:41.978550: predicting LUNG1-375 
2023-08-01 04:09:43.958685: predicting LUNG1-376 
2023-08-01 04:09:46.871211: predicting LUNG1-377 
2023-08-01 04:09:51.238742: predicting LUNG1-378 
2023-08-01 04:09:54.176634: predicting LUNG1-379 
2023-08-01 04:09:56.141909: predicting LUNG1-380 
2023-08-01 04:09:59.064252: predicting LUNG1-381 
2023-08-01 04:10:01.030617: predicting LUNG1-382 
2023-08-01 04:10:03.953393: predicting LUNG1-383 
2023-08-01 04:10:09.782832: predicting LUNG1-384 
2023-08-01 04:10:12.723319: predicting LUNG1-385 
2023-08-01 04:10:15.637234: predicting LUNG1-386 
2023-08-01 04:10:18.567630: predicting LUNG1-387 
2023-08-01 04:10:20.514283: predicting LUNG1-388 
2023-08-01 04:10:23.438508: predicting LUNG1-389 
2023-08-01 04:10:26.377535: predicting LUNG1-390 
2023-08-01 04:10:30.732362: predicting LUNG1-391 
2023-08-01 04:10:33.670255: predicting LUNG1-392 
2023-08-01 04:10:36.588229: predicting LUNG1-393 
2023-08-01 04:10:40.961847: predicting LUNG1-394 
2023-08-01 04:10:43.914551: predicting LUNG1-395 
2023-08-01 04:10:46.840024: predicting LUNG1-396 
2023-08-01 04:10:48.786141: predicting LUNG1-397 
2023-08-01 04:10:50.748345: predicting LUNG1-398 
2023-08-01 04:10:53.658976: predicting LUNG1-399 
2023-08-01 04:10:55.632944: predicting LUNG1-400 
2023-08-01 04:10:58.555245: predicting LUNG1-401 
2023-08-01 04:11:02.924725: predicting LUNG1-402 
2023-08-01 04:11:07.337814: predicting LUNG1-403 
2023-08-01 04:11:09.340175: predicting LUNG1-404 
2023-08-01 04:11:12.252704: predicting LUNG1-405 
2023-08-01 04:11:15.190312: predicting LUNG1-406 
2023-08-01 04:11:18.103073: predicting LUNG1-407 
2023-08-01 04:11:21.020869: predicting LUNG1-408 
2023-08-01 04:11:22.984715: predicting LUNG1-409 
2023-08-01 04:11:25.897950: predicting LUNG1-410 
2023-08-01 04:11:28.839589: predicting LUNG1-411 
2023-08-01 04:11:31.766799: predicting LUNG1-412 
2023-08-01 04:11:36.124332: predicting LUNG1-413 
2023-08-01 04:11:38.095364: predicting LUNG1-414 
2023-08-01 04:11:41.005659: predicting LUNG1-415 
2023-08-01 04:11:43.929440: predicting LUNG1-416 
2023-08-01 04:11:46.852210: predicting LUNG1-417 
2023-08-01 04:11:49.788245: predicting LUNG1-418 
2023-08-01 04:11:52.725210: predicting LUNG1-419 
2023-08-01 04:11:55.638148: predicting LUNG1-420 
2023-08-01 04:11:58.576068: predicting LUNG1-421 
2023-08-01 04:12:00.538846: predicting LUNG1-422 
2023-08-01 04:12:03.461849: predicting MED_LYMPH_001 
2023-08-01 04:12:07.828262: predicting MED_LYMPH_002 
2023-08-01 04:12:10.772625: predicting MED_LYMPH_003 
2023-08-01 04:12:15.143606: predicting MED_LYMPH_004 
2023-08-01 04:12:18.087369: predicting MED_LYMPH_005 
2023-08-01 04:12:21.032290: predicting MED_LYMPH_006 
2023-08-01 04:12:23.967422: predicting MED_LYMPH_007 
2023-08-01 04:12:25.932176: predicting MED_LYMPH_008 
2023-08-01 04:12:30.307508: predicting MED_LYMPH_009 
2023-08-01 04:12:34.695184: predicting MED_LYMPH_010 
2023-08-01 04:12:36.674355: predicting MED_LYMPH_011 
2023-08-01 04:12:39.601275: predicting MED_LYMPH_012 
2023-08-01 04:12:41.551563: predicting MED_LYMPH_013 
2023-08-01 04:12:44.482173: predicting MED_LYMPH_014 
2023-08-01 04:12:46.450202: predicting MED_LYMPH_015 
2023-08-01 04:12:49.375785: predicting MED_LYMPH_016 
2023-08-01 04:12:52.307860: predicting MED_LYMPH_017 
2023-08-01 04:12:54.270480: predicting MED_LYMPH_018 
2023-08-01 04:12:57.203884: predicting MED_LYMPH_019 
2023-08-01 04:13:00.143711: predicting MED_LYMPH_020 
2023-08-01 04:13:03.073506: predicting MED_LYMPH_021 
2023-08-01 04:13:05.039145: predicting MED_LYMPH_022 
2023-08-01 04:13:07.971823: predicting MED_LYMPH_023 
2023-08-01 04:13:10.902727: predicting MED_LYMPH_024 
2023-08-01 04:13:15.279475: predicting MED_LYMPH_025 
2023-08-01 04:13:19.681347: predicting MED_LYMPH_026 
2023-08-01 04:13:22.625483: predicting MED_LYMPH_027 
2023-08-01 04:13:27.029143: predicting MED_LYMPH_028 
2023-08-01 04:13:29.949049: predicting MED_LYMPH_029 
2023-08-01 04:13:32.879187: predicting MED_LYMPH_030 
2023-08-01 04:13:34.848149: predicting MED_LYMPH_031 
2023-08-01 04:13:36.813722: predicting MED_LYMPH_032 
2023-08-01 04:13:39.730856: predicting MED_LYMPH_033 
2023-08-01 04:13:41.686523: predicting MED_LYMPH_034 
2023-08-01 04:13:44.602055: predicting MED_LYMPH_035 
2023-08-01 04:13:47.523043: predicting MED_LYMPH_036 
2023-08-01 04:13:49.502572: predicting MED_LYMPH_037 
2023-08-01 04:13:52.432622: predicting MED_LYMPH_038 
2023-08-01 04:13:55.350308: predicting MED_LYMPH_039 
2023-08-01 04:13:56.344254: predicting MED_LYMPH_040 
2023-08-01 04:13:58.295368: predicting MED_LYMPH_041 
2023-08-01 04:14:01.230384: predicting MED_LYMPH_042 
2023-08-01 04:14:04.150756: predicting MED_LYMPH_043 
2023-08-01 04:14:05.637839: predicting MED_LYMPH_044 
2023-08-01 04:14:07.604269: predicting MED_LYMPH_045 
2023-08-01 04:14:09.556331: predicting MED_LYMPH_046 
2023-08-01 04:14:15.371626: predicting MED_LYMPH_047 
2023-08-01 04:14:19.762947: predicting MED_LYMPH_048 
2023-08-01 04:14:21.776476: predicting MED_LYMPH_049 
2023-08-01 04:14:23.728359: predicting MED_LYMPH_050 
2023-08-01 04:14:28.109762: predicting MED_LYMPH_051 
2023-08-01 04:14:30.081584: predicting MED_LYMPH_052 
2023-08-01 04:14:33.000362: predicting MED_LYMPH_053 
2023-08-01 04:14:37.380159: predicting MED_LYMPH_054 
2023-08-01 04:14:39.354986: predicting MED_LYMPH_055 
2023-08-01 04:14:43.730068: predicting MED_LYMPH_056 
2023-08-01 04:14:50.281161: predicting MED_LYMPH_057 
2023-08-01 04:14:56.851401: predicting MED_LYMPH_058 
2023-08-01 04:14:59.842698: predicting MED_LYMPH_059 
2023-08-01 04:15:01.801571: predicting MED_LYMPH_060 
2023-08-01 04:15:04.737708: predicting MED_LYMPH_061 
2023-08-01 04:15:07.678376: predicting MED_LYMPH_062 
2023-08-01 04:15:12.076969: predicting MED_LYMPH_063 
2023-08-01 04:15:15.026514: predicting MED_LYMPH_064 
2023-08-01 04:15:17.944731: predicting MED_LYMPH_065 
2023-08-01 04:15:20.889204: predicting MED_LYMPH_066 
2023-08-01 04:15:22.845633: predicting MED_LYMPH_067 
2023-08-01 04:15:25.767822: predicting MED_LYMPH_068 
2023-08-01 04:15:28.702673: predicting MED_LYMPH_069 
2023-08-01 04:15:33.086597: predicting MED_LYMPH_070 
2023-08-01 04:15:35.066453: predicting MED_LYMPH_071 
2023-08-01 04:15:41.598680: predicting MED_LYMPH_072 
2023-08-01 04:15:44.546880: predicting MED_LYMPH_073 
2023-08-01 04:15:47.466689: predicting MED_LYMPH_074 
2023-08-01 04:15:50.425953: predicting MED_LYMPH_075 
2023-08-01 04:15:53.346378: predicting MED_LYMPH_076 
2023-08-01 04:15:55.317241: predicting MED_LYMPH_077 
2023-08-01 04:15:58.250667: predicting MED_LYMPH_078 
2023-08-01 04:16:01.174586: predicting MED_LYMPH_079 
2023-08-01 04:16:04.109411: predicting MED_LYMPH_080 
2023-08-01 04:16:06.062878: predicting MED_LYMPH_081 
2023-08-01 04:16:08.033008: predicting MED_LYMPH_082 
2023-08-01 04:16:10.965075: predicting MED_LYMPH_083 
2023-08-01 04:16:13.886830: predicting MED_LYMPH_084 
2023-08-01 04:16:16.833173: predicting MED_LYMPH_085 
2023-08-01 04:16:19.756967: predicting MED_LYMPH_086 
2023-08-01 04:16:26.306165: predicting MED_LYMPH_087 
2023-08-01 04:16:30.718192: predicting MED_LYMPH_088 
2023-08-01 04:16:33.649854: predicting MED_LYMPH_089 
2023-08-01 04:16:35.629460: predicting MED_LYMPH_090 
2023-08-01 04:16:37.595559: predicting R01-001 
2023-08-01 04:16:39.564622: predicting R01-002 
2023-08-01 04:16:42.500876: predicting R01-004 
2023-08-01 04:16:46.884519: predicting R01-005 
2023-08-01 04:16:49.823327: predicting R01-006 
2023-08-01 04:16:55.653529: predicting R01-007 
2023-08-01 04:17:00.034507: predicting R01-008 
2023-08-01 04:17:02.977773: predicting R01-010 
2023-08-01 04:17:05.923529: predicting R01-011 
2023-08-01 04:17:07.900516: predicting R01-012 
2023-08-01 04:17:10.834150: predicting R01-013 
2023-08-01 04:17:13.756946: predicting R01-014 
2023-08-01 04:17:15.730409: predicting R01-015 
2023-08-01 04:17:20.107028: predicting R01-016 
2023-08-01 04:17:23.065212: predicting R01-017 
2023-08-01 04:17:26.001269: predicting R01-018 
2023-08-01 04:17:28.921093: predicting R01-019 
2023-08-01 04:17:33.309347: predicting R01-020 
2023-08-01 04:17:36.271987: predicting R01-021 
2023-08-01 04:17:38.245342: predicting R01-022 
2023-08-01 04:17:41.162673: predicting R01-023 
2023-08-01 04:17:44.081845: predicting R01-024 
2023-08-01 04:17:47.003950: predicting R01-025 
2023-08-01 04:17:49.959191: predicting R01-026 
2023-08-01 04:17:54.330963: predicting R01-027 
2023-08-01 04:17:57.279758: predicting R01-028 
2023-08-01 04:18:03.848178: predicting R01-029 
2023-08-01 04:18:08.250566: predicting R01-030 
2023-08-01 04:18:11.197894: predicting R01-031 
2023-08-01 04:18:14.152135: predicting R01-032 
2023-08-01 04:18:18.520520: predicting R01-033 
2023-08-01 04:18:21.474419: predicting R01-034 
2023-08-01 04:18:24.409593: predicting R01-035 
2023-08-01 04:18:28.781054: predicting R01-036 
2023-08-01 04:18:33.179874: predicting R01-037 
2023-08-01 04:18:36.126604: predicting R01-038 
2023-08-01 04:18:40.517033: predicting R01-039 
2023-08-01 04:18:44.889493: predicting R01-040 
2023-08-01 04:18:51.489648: predicting R01-041 
2023-08-01 04:18:54.442578: predicting R01-042 
2023-08-01 04:18:57.365150: predicting R01-043 
2023-08-01 04:18:59.332408: predicting R01-044 
2023-08-01 04:19:02.256604: predicting R01-045 
2023-08-01 04:19:04.218709: predicting R01-046 
2023-08-01 04:19:07.155488: predicting R01-047 
2023-08-01 04:19:10.112231: predicting R01-048 
2023-08-01 04:19:13.056609: predicting R01-049 
2023-08-01 04:19:15.998590: predicting R01-050 
2023-08-01 04:19:17.968331: predicting R01-051 
2023-08-01 04:19:20.891180: predicting R01-052 
2023-08-01 04:19:23.813128: predicting R01-053 
2023-08-01 04:19:25.786747: predicting R01-054 
2023-08-01 04:19:28.717416: predicting R01-055 
2023-08-01 04:19:31.641786: predicting R01-056 
2023-08-01 04:19:34.590193: predicting R01-057 
2023-08-01 04:19:37.538052: predicting R01-058 
2023-08-01 04:19:40.501815: predicting R01-059 
2023-08-01 04:19:42.473502: predicting R01-060 
2023-08-01 04:19:45.390319: predicting R01-061 
2023-08-01 04:19:48.308152: predicting R01-062 
2023-08-01 04:19:51.229373: predicting R01-063 
2023-08-01 04:19:55.618364: predicting R01-064 
2023-08-01 04:19:58.578769: predicting R01-065 
2023-08-01 04:20:02.467293: predicting R01-066 
2023-08-01 04:20:05.401661: predicting R01-067 
2023-08-01 04:20:08.355244: predicting R01-068 
2023-08-01 04:20:12.746384: predicting R01-069 
2023-08-01 04:20:15.710644: predicting R01-070 
2023-08-01 04:20:18.634544: predicting R01-071 
2023-08-01 04:20:23.018934: predicting R01-072 
2023-08-01 04:20:27.401136: predicting R01-073 
2023-08-01 04:20:30.349349: predicting R01-074 
2023-08-01 04:20:33.306453: predicting R01-075 
2023-08-01 04:20:37.679917: predicting R01-076 
2023-08-01 04:20:42.088899: predicting R01-077 
2023-08-01 04:20:44.072883: predicting R01-078 
2023-08-01 04:20:46.040632: predicting R01-079 
2023-08-01 04:20:48.967299: predicting R01-080 
2023-08-01 04:20:53.356170: predicting R01-081 
2023-08-01 04:20:55.342247: predicting R01-082 
2023-08-01 04:20:58.279279: predicting R01-083 
2023-08-01 04:21:02.682172: predicting R01-084 
2023-08-01 04:21:05.641236: predicting R01-085 
2023-08-01 04:21:08.593463: predicting R01-086 
2023-08-01 04:21:11.548725: predicting R01-087 
2023-08-01 04:21:14.483672: predicting R01-088 
2023-08-01 04:21:18.870438: predicting R01-089 
2023-08-01 04:21:21.821964: predicting R01-090 
2023-08-01 04:21:24.746903: predicting R01-091 
2023-08-01 04:21:26.715054: predicting R01-092 
2023-08-01 04:21:29.649073: predicting R01-093 
2023-08-01 04:21:34.052282: predicting R01-094 
2023-08-01 04:21:37.007184: predicting R01-095 
2023-08-01 04:21:40.923683: predicting R01-096 
2023-08-01 04:21:46.792099: predicting R01-097 
2023-08-01 04:21:49.765665: predicting R01-098 
2023-08-01 04:21:51.753007: predicting R01-099 
2023-08-01 04:21:53.708034: predicting R01-100 
2023-08-01 04:21:55.682204: predicting R01-101 
2023-08-01 04:21:58.604210: predicting R01-102 
2023-08-01 04:22:01.541301: predicting R01-103 
2023-08-01 04:22:04.486837: predicting R01-104 
2023-08-01 04:22:07.440558: predicting R01-105 
2023-08-01 04:22:10.388154: predicting R01-106 
2023-08-01 04:22:14.760823: predicting R01-107 
2023-08-01 04:22:16.757878: predicting R01-108 
2023-08-01 04:22:19.678310: predicting R01-109 
2023-08-01 04:22:22.628504: predicting R01-110 
2023-08-01 04:22:27.029232: predicting R01-111 
2023-08-01 04:22:31.425990: predicting R01-112 
2023-08-01 04:22:37.280921: predicting R01-113 
2023-08-01 04:22:40.234254: predicting R01-114 
2023-08-01 04:22:44.629626: predicting R01-115 
2023-08-01 04:22:47.579341: predicting R01-116 
2023-08-01 04:22:50.505395: predicting R01-117 
2023-08-01 04:22:53.427372: predicting R01-118 
2023-08-01 04:22:57.330194: predicting R01-119 
2023-08-01 04:23:01.728679: predicting R01-120 
2023-08-01 04:23:04.677298: predicting R01-121 
2023-08-01 04:23:07.627067: predicting R01-122 
2023-08-01 04:23:10.580282: predicting R01-123 
2023-08-01 04:23:16.430070: predicting R01-124 
2023-08-01 04:23:20.840913: predicting R01-125 
2023-08-01 04:23:23.810826: predicting R01-126 
2023-08-01 04:23:28.179550: predicting R01-127 
2023-08-01 04:23:31.133728: predicting R01-128 
2023-08-01 04:23:34.072891: predicting R01-129 
2023-08-01 04:23:38.458155: predicting R01-130 
2023-08-01 04:23:41.422587: predicting R01-131 
2023-08-01 04:23:44.372844: predicting R01-132 
2023-08-01 04:23:47.293598: predicting R01-133 
2023-08-01 04:23:50.228549: predicting R01-134 
2023-08-01 04:23:53.173498: predicting R01-135 
2023-08-01 04:23:56.111841: predicting R01-136 
2023-08-01 04:23:58.067752: predicting R01-137 
2023-08-01 04:24:01.003124: predicting R01-138 
2023-08-01 04:24:03.933718: predicting R01-139 
2023-08-01 04:24:06.866585: predicting R01-140 
2023-08-01 04:24:08.838197: predicting R01-141 
2023-08-01 04:24:11.775434: predicting R01-142 
2023-08-01 04:24:13.744334: predicting R01-144 
2023-08-01 04:24:16.681088: predicting R01-145 
2023-08-01 04:24:21.054608: predicting R01-146 
2023-08-01 04:24:22.061031: predicting interobs05 
2023-08-01 04:24:25.002612: predicting interobs06 
2023-08-01 04:24:27.963893: predicting interobs08 
2023-08-01 04:24:32.329205: predicting interobs10 
2023-08-01 04:24:34.309771: predicting interobs11 
2023-08-01 04:24:37.249637: predicting interobs12 
2023-08-01 04:24:40.185366: predicting interobs13 
2023-08-01 04:24:42.152516: predicting interobs14 
2023-08-01 04:24:45.088611: predicting interobs15 
2023-08-01 04:24:48.010070: predicting interobs18 
2023-08-01 04:24:50.961349: predicting interobs19 
2023-08-01 04:24:54.858737: predicting interobs20 
2023-08-01 04:24:57.799633: predicting interobs21 
2023-08-01 04:25:00.719732: predicting interobs22 
2023-08-01 04:25:03.667409: predicting interobs27 
2023-08-01 04:25:05.621335: predicting interobs28 
2023-08-01 04:25:07.588804: predicting interobs29 
2023-08-01 04:25:10.507261: predicting interobs31 
2023-08-01 04:25:13.438461: predicting interobs32 
2023-08-01 04:25:16.391991: predicting interobs33 
2023-08-01 04:25:19.326668: predicting interobs34 
2023-08-01 04:25:22.260339: predicting lnq2023-train-0005 
2023-08-01 04:25:25.180712: predicting lnq2023-train-0006 
2023-08-01 04:25:27.150435: predicting lnq2023-train-0009 
2023-08-01 04:25:29.102732: predicting lnq2023-train-0012 
2023-08-01 04:25:31.071929: predicting lnq2023-train-0017 
2023-08-01 04:25:34.001227: predicting lnq2023-train-0021 
2023-08-01 04:25:36.919027: predicting lnq2023-train-0023 
2023-08-01 04:25:39.839902: predicting lnq2023-train-0024 
2023-08-01 04:25:42.759796: predicting lnq2023-train-0026 
2023-08-01 04:25:44.723839: predicting lnq2023-train-0029 
2023-08-01 04:25:49.087611: predicting lnq2023-train-0032 
2023-08-01 04:25:51.052184: predicting lnq2023-train-0033 
2023-08-01 04:25:53.972564: predicting lnq2023-train-0034 
2023-08-01 04:25:55.927651: predicting lnq2023-train-0035 
2023-08-01 04:26:00.308165: predicting lnq2023-train-0040 
2023-08-01 04:26:04.702890: predicting lnq2023-train-0042 
2023-08-01 04:26:06.675051: predicting lnq2023-train-0044 
2023-08-01 04:26:08.627883: predicting lnq2023-train-0048 
2023-08-01 04:26:10.601082: predicting lnq2023-train-0050 
2023-08-01 04:26:14.962606: predicting lnq2023-train-0052 
2023-08-01 04:26:17.914227: predicting lnq2023-train-0053 
2023-08-01 04:26:20.858746: predicting lnq2023-train-0054 
2023-08-01 04:26:23.790925: predicting lnq2023-train-0055 
2023-08-01 04:26:25.777373: predicting lnq2023-train-0057 
2023-08-01 04:26:28.703487: predicting lnq2023-train-0058 
2023-08-01 04:26:31.624092: predicting lnq2023-train-0064 
2023-08-01 04:26:34.542382: predicting lnq2023-train-0068 
2023-08-01 04:26:41.092625: predicting lnq2023-train-0069 
2023-08-01 04:26:44.049262: predicting lnq2023-train-0074 
2023-08-01 04:26:46.000875: predicting lnq2023-train-0076 
2023-08-01 04:26:52.557005: predicting lnq2023-train-0078 
2023-08-01 04:26:55.514208: predicting lnq2023-train-0088 
2023-08-01 04:26:57.465287: predicting lnq2023-train-0092 
2023-08-01 04:26:59.430999: predicting lnq2023-train-0093 
2023-08-01 04:27:01.398736: predicting lnq2023-train-0101 
2023-08-01 04:27:04.316958: predicting lnq2023-train-0102 
2023-08-01 04:27:07.235233: predicting lnq2023-train-0109 
2023-08-01 04:27:11.609658: predicting lnq2023-train-0110 
2023-08-01 04:27:14.550425: predicting lnq2023-train-0111 
2023-08-01 04:27:16.523300: predicting lnq2023-train-0113 
2023-08-01 04:27:20.893556: predicting lnq2023-train-0115 
2023-08-01 04:27:22.889615: predicting lnq2023-train-0116 
2023-08-01 04:27:27.264347: predicting lnq2023-train-0117 
2023-08-01 04:27:30.205649: predicting lnq2023-train-0119 
2023-08-01 04:27:33.143584: predicting lnq2023-train-0125 
2023-08-01 04:27:35.100683: predicting lnq2023-train-0126 
2023-08-01 04:27:38.032330: predicting lnq2023-train-0129 
2023-08-01 04:27:39.998096: predicting lnq2023-train-0131 
2023-08-01 04:27:42.911894: predicting lnq2023-train-0136 
2023-08-01 04:27:45.825671: predicting lnq2023-train-0149 
2023-08-01 04:27:52.386421: predicting lnq2023-train-0150 
2023-08-01 04:27:56.778471: predicting lnq2023-train-0152 
2023-08-01 04:27:59.715743: predicting lnq2023-train-0155 
2023-08-01 04:28:02.646894: predicting lnq2023-train-0158 
2023-08-01 04:28:04.631666: predicting lnq2023-train-0159 
2023-08-01 04:28:08.992530: predicting lnq2023-train-0160 
2023-08-01 04:28:10.988791: predicting lnq2023-train-0164 
2023-08-01 04:28:15.367833: predicting lnq2023-train-0165 
2023-08-01 04:28:18.307609: predicting lnq2023-train-0166 
2023-08-01 04:28:21.236161: predicting lnq2023-train-0170 
2023-08-01 04:28:24.176586: predicting lnq2023-train-0171 
2023-08-01 04:28:27.121957: predicting lnq2023-train-0177 
2023-08-01 04:28:30.066822: predicting lnq2023-train-0178 
2023-08-01 04:28:32.992322: predicting lnq2023-train-0182 
2023-08-01 04:28:35.921544: predicting lnq2023-train-0183 
2023-08-01 04:28:38.839047: predicting lnq2023-train-0187 
2023-08-01 04:28:41.756705: predicting lnq2023-train-0189 
2023-08-01 04:28:43.711328: predicting lnq2023-train-0191 
2023-08-01 04:28:48.079355: predicting lnq2023-train-0193 
2023-08-01 04:28:51.022331: predicting lnq2023-train-0194 
2023-08-01 04:28:53.961250: predicting lnq2023-train-0197 
2023-08-01 04:28:56.892159: predicting lnq2023-train-0199 
2023-08-01 04:28:59.825897: predicting lnq2023-train-0202 
2023-08-01 04:29:02.745052: predicting lnq2023-train-0203 
2023-08-01 04:29:04.714952: predicting lnq2023-train-0204 
2023-08-01 04:29:07.630977: predicting lnq2023-train-0216 
2023-08-01 04:29:10.575685: predicting lnq2023-train-0219 
2023-08-01 04:29:12.553790: predicting lnq2023-train-0222 
2023-08-01 04:29:15.486912: predicting lnq2023-train-0223 
2023-08-01 04:29:18.419783: predicting lnq2023-train-0225 
2023-08-01 04:29:20.377734: predicting lnq2023-train-0227 
2023-08-01 04:29:22.344052: predicting lnq2023-train-0229 
2023-08-01 04:29:24.295098: predicting lnq2023-train-0232 
2023-08-01 04:29:27.222403: predicting lnq2023-train-0236 
2023-08-01 04:29:30.161399: predicting lnq2023-train-0238 
2023-08-01 04:29:32.114507: predicting lnq2023-train-0240 
2023-08-01 04:29:36.493313: predicting lnq2023-train-0244 
2023-08-01 04:29:39.453577: predicting lnq2023-train-0247 
2023-08-01 04:29:41.406073: predicting lnq2023-train-0250 
2023-08-01 04:29:44.332912: predicting lnq2023-train-0259 
2023-08-01 04:29:47.248540: predicting lnq2023-train-0267 
2023-08-01 04:29:49.229326: predicting lnq2023-train-0269 
2023-08-01 04:29:52.147220: predicting lnq2023-train-0270 
2023-08-01 04:29:54.112062: predicting lnq2023-train-0271 
2023-08-01 04:29:58.484432: predicting lnq2023-train-0273 
2023-08-01 04:30:00.467967: predicting lnq2023-train-0278 
2023-08-01 04:30:03.385111: predicting lnq2023-train-0279 
2023-08-01 04:30:05.336714: predicting lnq2023-train-0281 
2023-08-01 04:30:08.268235: predicting lnq2023-train-0282 
2023-08-01 04:30:10.242052: predicting lnq2023-train-0283 
2023-08-01 04:30:13.173695: predicting lnq2023-train-0287 
2023-08-01 04:30:17.562282: predicting lnq2023-train-0288 
2023-08-01 04:30:24.137192: predicting lnq2023-train-0295 
2023-08-01 04:30:27.097362: predicting lnq2023-train-0296 
2023-08-01 04:30:30.038379: predicting lnq2023-train-0297 
2023-08-01 04:30:31.509150: predicting lnq2023-train-0301 
2023-08-01 04:30:34.435281: predicting lnq2023-train-0302 
2023-08-01 04:30:38.800623: predicting lnq2023-train-0304 
2023-08-01 04:30:43.190745: predicting lnq2023-train-0308 
2023-08-01 04:30:45.166737: predicting lnq2023-train-0313 
2023-08-01 04:30:48.079202: predicting lnq2023-train-0315 
2023-08-01 04:30:50.998764: predicting lnq2023-train-0317 
2023-08-01 04:30:55.385643: predicting lnq2023-train-0320 
2023-08-01 04:30:58.326434: predicting lnq2023-train-0322 
2023-08-01 04:31:01.243400: predicting lnq2023-train-0327 
2023-08-01 04:31:05.618706: predicting lnq2023-train-0328 
2023-08-01 04:31:07.626844: predicting lnq2023-train-0329 
2023-08-01 04:31:10.551945: predicting lnq2023-train-0331 
2023-08-01 04:31:14.924203: predicting lnq2023-train-0333 
2023-08-01 04:31:17.890337: predicting lnq2023-train-0334 
2023-08-01 04:31:20.833064: predicting lnq2023-train-0338 
2023-08-01 04:31:23.761963: predicting lnq2023-train-0343 
2023-08-01 04:31:28.135810: predicting lnq2023-train-0348 
2023-08-01 04:31:30.135427: predicting lnq2023-train-0354 
2023-08-01 04:31:33.047859: predicting lnq2023-train-0356 
2023-08-01 04:31:35.965705: predicting lnq2023-train-0357 
2023-08-01 04:31:37.941141: predicting lnq2023-train-0364 
2023-08-01 04:31:40.873122: predicting lnq2023-train-0368 
2023-08-01 04:31:43.791667: predicting lnq2023-train-0376 
2023-08-01 04:31:46.724454: predicting lnq2023-train-0380 
2023-08-01 04:31:51.147294: predicting lnq2023-train-0384 
2023-08-01 04:31:54.090876: predicting lnq2023-train-0385 
2023-08-01 04:31:57.036033: predicting lnq2023-train-0386 
2023-08-01 04:31:59.006253: predicting lnq2023-train-0392 
2023-08-01 04:32:01.924378: predicting lnq2023-train-0394 
2023-08-01 04:32:04.853655: predicting lnq2023-train-0395 
2023-08-01 04:32:07.780570: predicting lnq2023-train-0396 
2023-08-01 04:32:09.735378: predicting lnq2023-train-0401 
2023-08-01 04:32:12.661965: predicting lnq2023-train-0402 
2023-08-01 04:32:15.581297: predicting lnq2023-train-0406 
2023-08-01 04:32:18.512453: predicting lnq2023-train-0411 
2023-08-01 04:32:21.432127: predicting lnq2023-train-0415 
2023-08-01 04:32:25.809918: predicting lnq2023-train-0417 
2023-08-01 04:32:32.366410: predicting lnq2023-train-0418 
2023-08-01 04:32:35.326184: predicting lnq2023-train-0419 
2023-08-01 04:32:39.703499: predicting lnq2023-train-0421 
2023-08-01 04:32:42.650704: predicting lnq2023-train-0423 
2023-08-01 04:32:45.571994: predicting lnq2023-train-0424 
2023-08-01 04:32:47.543285: predicting lnq2023-train-0428 
2023-08-01 04:32:49.508030: predicting lnq2023-train-0431 
2023-08-01 04:32:51.460786: predicting lnq2023-train-0436 
2023-08-01 04:32:54.388157: predicting lnq2023-train-0437 
2023-08-01 04:32:57.306629: predicting lnq2023-train-0440 
2023-08-01 04:33:03.859928: predicting lnq2023-train-0441 
2023-08-01 04:33:08.254576: predicting lnq2023-train-0444 
2023-08-01 04:33:10.211362: predicting lnq2023-train-0445 
2023-08-01 04:33:13.136603: predicting lnq2023-train-0446 
2023-08-01 04:33:16.064858: predicting lnq2023-train-0448 
2023-08-01 04:33:18.031286: predicting lnq2023-train-0449 
2023-08-01 04:33:19.993499: predicting lnq2023-train-0450 
2023-08-01 04:33:22.922678: predicting lnq2023-train-0456 
2023-08-01 04:33:27.283875: predicting lnq2023-train-0459 
2023-08-01 04:33:30.222830: predicting lnq2023-train-0463 
2023-08-01 04:33:33.156686: predicting lnq2023-train-0466 
2023-08-01 04:33:36.073108: predicting lnq2023-train-0468 
2023-08-01 04:33:39.006759: predicting lnq2023-train-0469 
2023-08-01 04:33:43.377565: predicting lnq2023-train-0470 
2023-08-01 04:33:47.773849: predicting lnq2023-train-0474 
2023-08-01 04:33:54.336747: predicting lnq2023-train-0475 
2023-08-01 04:33:57.298666: predicting lnq2023-train-0480 
2023-08-01 04:34:00.213712: predicting lnq2023-train-0481 
2023-08-01 04:34:03.131575: predicting lnq2023-train-0482 
2023-08-01 04:34:06.073787: predicting lnq2023-train-0487 
2023-08-01 04:34:08.986094: predicting lnq2023-train-0489 
2023-08-01 04:34:10.966716: predicting lnq2023-train-0491 
2023-08-01 04:34:15.346618: predicting lnq2023-train-0493 
2023-08-01 04:34:18.287970: predicting lnq2023-train-0496 
2023-08-01 04:34:20.262224: predicting lnq2023-train-0499 
2023-08-01 04:34:23.189306: predicting lnq2023-train-0504 
2023-08-01 04:34:27.562350: predicting lnq2023-train-0506 
2023-08-01 04:34:30.527242: predicting lnq2023-train-0509 
2023-08-01 04:34:34.894965: predicting lnq2023-train-0512 
2023-08-01 04:34:36.895372: predicting lnq2023-train-0514 
2023-08-01 04:34:41.268653: predicting lnq2023-train-0515 
2023-08-01 04:34:44.211508: predicting lnq2023-train-0518 
2023-08-01 04:34:46.164005: predicting lnq2023-train-0519 
2023-08-01 04:34:49.093313: predicting lnq2023-train-0522 
2023-08-01 04:34:55.651839: predicting lnq2023-train-0531 
2023-08-01 04:34:58.596620: predicting lnq2023-train-0532 
2023-08-01 04:35:01.516805: predicting lnq2023-train-0545 
2023-08-01 04:35:05.414407: predicting lnq2023-train-0546 
2023-08-01 04:35:07.409057: predicting lnq2023-train-0547 
2023-08-01 04:35:10.326170: predicting lnq2023-train-0548 
2023-08-01 04:35:13.263472: predicting lnq2023-train-0551 
2023-08-01 04:35:16.190995: predicting lnq2023-train-0552 
2023-08-01 04:35:19.104826: predicting lnq2023-train-0553 
2023-08-01 04:35:22.035005: predicting lnq2023-train-0554 
2023-08-01 04:35:24.952195: predicting lnq2023-train-0556 
2023-08-01 04:35:26.903962: predicting lnq2023-train-0558 
2023-08-01 04:35:28.870604: predicting lnq2023-train-0567 
2023-08-01 04:35:30.832825: predicting lnq2023-train-0573 
2023-08-01 04:35:35.205249: predicting lnq2023-train-0577 
2023-08-01 04:35:37.186617: predicting lnq2023-train-0582 
2023-08-01 04:35:39.150282: predicting lnq2023-train-0586 
2023-08-01 04:35:43.527589: predicting lnq2023-train-0596 
2023-08-01 04:35:47.918203: predicting lnq2023-train-0601 
2023-08-01 04:35:50.863743: predicting lnq2023-train-0604 
2023-08-01 04:35:53.782034: predicting lnq2023-train-0605 
2023-08-01 04:35:56.725445: predicting lnq2023-train-0607 
2023-08-01 04:35:58.690788: predicting lnq2023-train-0610 
2023-08-01 04:35:59.679862: predicting lnq2023-train-0611 
2023-08-01 04:36:02.593798: predicting lnq2023-train-0614 
2023-08-01 04:36:05.527032: predicting lnq2023-train-0615 
2023-08-01 04:36:08.471806: predicting lnq2023-train-0616 
2023-08-01 04:36:11.409231: predicting lnq2023-train-0618 
2023-08-01 04:36:13.376055: predicting lnq2023-train-0622 
2023-08-01 04:36:17.736717: predicting lnq2023-train-0626 
2023-08-01 04:36:20.681933: predicting lnq2023-train-0628 
2023-08-01 04:36:22.658363: predicting lnq2023-train-0638 
2023-08-01 04:36:24.609370: predicting lnq2023-train-0645 
2023-08-01 04:36:26.573700: predicting lnq2023-train-0646 
2023-08-01 04:36:30.929114: predicting lnq2023-train-0648 
2023-08-01 04:36:35.317118: predicting lnq2023-train-0649 
2023-08-01 04:36:38.262731: predicting lnq2023-train-0651 
2023-08-01 04:36:41.178555: predicting lnq2023-train-0655 
2023-08-01 04:36:43.134117: predicting lnq2023-train-0656 
2023-08-01 04:36:45.084044: predicting lnq2023-train-0657 
2023-08-01 04:36:48.024327: predicting lnq2023-train-0658 
2023-08-01 04:36:50.939991: predicting lnq2023-train-0659 
2023-08-01 04:36:53.856924: predicting lnq2023-train-0662 
2023-08-01 04:36:55.810561: predicting lnq2023-train-0663 
2023-08-01 04:36:58.737043: predicting lnq2023-train-0668 
2023-08-01 04:37:01.670184: predicting lnq2023-train-0669 
2023-08-01 04:37:03.636776: predicting lnq2023-train-0671 
2023-08-01 04:37:06.552707: predicting lnq2023-train-0679 
2023-08-01 04:37:09.480073: predicting lnq2023-train-0682 
2023-08-01 04:37:12.398790: predicting lnq2023-train-0683 
2023-08-01 04:37:15.329942: predicting lnq2023-train-0685 
2023-08-01 04:37:17.286615: predicting lnq2023-train-0688 
2023-08-01 04:37:19.238006: predicting lnq2023-train-0690 
2023-08-01 04:37:22.166414: predicting lnq2023-train-0691 
2023-08-01 04:37:25.099422: predicting lnq2023-train-0695 
2023-08-01 04:37:30.912936: predicting lnq2023-train-0697 
2023-08-01 04:37:32.901197: predicting lnq2023-train-0700 
2023-08-01 04:37:34.852466: predicting lnq2023-train-0702 
2023-08-01 04:37:37.781833: predicting lnq2023-train-0704 
2023-08-01 04:37:44.304685: predicting lnq2023-train-0707 
2023-08-01 04:37:46.302208: predicting lnq2023-train-0708 
2023-08-01 04:37:49.215379: predicting lnq2023-train-0709 
2023-08-01 04:37:52.158105: predicting lnq2023-train-0715 
2023-08-01 04:37:55.089812: predicting lnq2023-train-0717 
2023-08-01 04:37:58.007839: predicting lnq2023-train-0720 
2023-08-01 04:38:00.942819: predicting lnq2023-train-0727 
2023-08-01 04:38:03.873104: predicting lnq2023-train-0731 
2023-08-01 04:38:06.794916: predicting lnq2023-train-0732 
2023-08-01 04:38:09.710994: predicting lnq2023-train-0737 
2023-08-01 04:38:12.630627: predicting lnq2023-train-0738 
2023-08-01 04:38:15.549277: predicting lnq2023-train-0740 
2023-08-01 04:38:17.513029: predicting lnq2023-train-0742 
2023-08-01 04:38:20.427153: predicting lnq2023-train-0748 
2023-08-01 04:38:23.344514: predicting lnq2023-train-0749 
2023-08-01 04:38:32.067815: predicting lnq2023-train-0752 
2023-08-01 04:38:34.057301: predicting lnq2023-train-0754 
2023-08-01 04:38:38.431641: predicting lnq2023-train-0758 
2023-08-01 04:38:40.390199: predicting lnq2023-train-0761 
2023-08-01 04:38:42.355250: predicting lnq2023-train-0764 
2023-08-01 04:38:45.270139: predicting lnq2023-train-0765 
2023-08-01 04:38:48.184952: predicting lnq2023-train-0766 
2023-08-01 04:38:50.152917: predicting lnq2023-train-0767 
2023-08-01 04:38:52.102371: predicting lnq2023-train-0768 
2023-08-01 04:38:54.055344: predicting lnq2023-train-0769 
2023-08-01 04:38:56.974250: predicting lnq2023-train-0772 
2023-08-01 04:38:59.905347: predicting lnq2023-train-0773 
2023-08-01 04:39:01.874695: predicting lnq2023-train-0774 
2023-08-01 04:39:06.247864: predicting lnq2023-train-0775 
2023-08-01 04:39:09.217908: predicting lnq2023-train-0782 
2023-08-01 04:39:12.137251: predicting lnq2023-train-0784 
2023-08-01 04:39:18.659328: predicting lnq2023-train-0786 
2023-08-01 04:39:21.627857: predicting lnq2023-train-0788 
2023-08-01 04:39:24.560827: predicting lnq2023-train-0790 
2023-08-01 04:39:27.477317: predicting lnq2023-train-0792 
2023-08-01 04:39:29.444006: predicting lnq2023-train-0793 
2023-08-01 04:39:35.984302: predicting lnq2023-train-0796 
2023-08-01 04:39:38.930353: predicting lnq2023-train-0798 
2023-08-01 04:39:41.868522: predicting lnq2023-train-0799 
2023-08-01 04:39:43.822118: predicting lnq2023-train-0800 
2023-08-01 04:39:45.776258: predicting lnq2023-train-0803 
2023-08-01 04:39:48.705782: predicting lnq2023-train-0804 
2023-08-01 04:39:49.709010: predicting lnq2023-train-0817 
2023-08-01 04:39:51.675551: predicting lnq2023-train-0818 
2023-08-01 04:39:54.588697: predicting lnq2023-train-0820 
2023-08-01 04:39:57.524586: predicting lnq2023-train-0823 
2023-08-01 04:39:59.484345: predicting lnq2023-train-0825 
2023-08-01 04:40:02.421413: predicting lnq2023-train-0826 
2023-08-01 04:40:04.404184: predicting lnq2023-train-0827 
2023-08-01 04:40:07.336113: predicting lnq2023-train-0831 
2023-08-01 04:40:09.289626: predicting lnq2023-train-0833 
2023-08-01 04:40:12.204631: predicting lnq2023-train-0838 
2023-08-01 04:40:15.137959: predicting lnq2023-train-0847 
2023-08-01 04:40:17.090271: predicting lnq2023-train-0849 
2023-08-01 04:40:21.467556: predicting lnq2023-train-0854 
2023-08-01 04:40:24.436134: predicting lnq2023-train-0856 
2023-08-01 04:40:27.371193: predicting lnq2023-train-0858 
2023-08-01 04:40:27.637716: predicting lnq2023-train-0860 
2023-08-01 04:40:30.547116: predicting lnq2023-train-0863 
2023-08-01 04:40:32.033873: predicting lnq2023-train-0864 
2023-08-01 04:40:34.945673: predicting lnq2023-train-0865 
2023-08-01 04:40:37.892773: predicting lnq2023-train-0866 
2023-08-01 04:40:40.803933: predicting lnq2023-train-0868 
2023-08-01 04:40:43.716539: predicting lnq2023-train-0869 
2023-08-01 04:40:46.666405: predicting lnq2023-train-0874 
2023-08-01 04:40:48.618664: predicting lnq2023-train-0880 
2023-08-01 04:40:50.568188: predicting lnq2023-train-0883 
2023-08-01 04:40:52.517500: predicting lnq2023-train-0885 
2023-08-01 04:40:55.444259: predicting lnq2023-train-0895 
2023-08-01 04:40:57.399860: predicting lnq2023-train-0902 
2023-08-01 04:40:59.356059: predicting lnq2023-train-0903 
2023-08-01 04:41:02.287698: predicting lnq2023-train-0906 
2023-08-01 04:41:04.244820: predicting lnq2023-train-0909 
2023-08-01 04:41:07.172477: predicting lnq2023-train-0911 
2023-08-01 04:41:10.087667: predicting lnq2023-train-0922 
2023-08-01 04:41:13.011245: predicting lnq2023-train-0926 
2023-08-01 04:41:15.925709: predicting lnq2023-train-0927 
2023-08-01 04:41:17.891464: predicting lnq2023-train-0931 
2023-08-01 04:41:20.806900: predicting lnq2023-train-0932 
2023-08-01 04:41:23.731091: predicting lnq2023-train-0933 
2023-08-01 04:41:26.651089: predicting lnq2023-train-0934 
2023-08-01 04:41:29.577515: predicting lnq2023-train-0935 
2023-08-01 04:41:32.497093: predicting lnq2023-train-0938 
2023-08-01 04:41:35.437856: predicting lnq2023-train-0941 
2023-08-01 04:41:38.364544: predicting lnq2023-train-0943 
2023-08-01 04:41:41.294752: predicting lnq2023-train-0944 
2023-08-01 04:41:44.220711: predicting lnq2023-train-0945 
2023-08-01 04:41:47.160719: predicting lnq2023-train-0949 
2023-08-01 04:41:50.100666: predicting lnq2023-train-0951 
2023-08-01 04:41:53.027446: predicting lnq2023-train-0952 
2023-08-01 04:41:55.967817: predicting lnq2023-train-0954 
2023-08-01 04:41:56.974258: predicting lnq2023-train-0955 
2023-08-01 04:41:58.927163: predicting lnq2023-train-0958 
2023-08-01 04:42:00.409466: predicting lnq2023-train-0962 
2023-08-01 04:42:03.321146: predicting lnq2023-train-0967 
2023-08-01 04:42:07.704574: predicting lnq2023-train-0969 
2023-08-01 04:42:10.671438: predicting lnq2023-train-0972 
2023-08-01 04:42:15.032707: predicting lnq2023-train-0974 
2023-08-01 04:42:16.999142: predicting lnq2023-train-0977 
2023-08-01 04:42:19.913477: predicting lnq2023-train-0979 
2023-08-01 04:42:25.744049: predicting lnq2023-train-0980 
2023-08-01 04:42:27.731879: predicting lnq2023-train-0982 
2023-08-01 04:42:30.646998: predicting lnq2023-train-0985 
2023-08-01 04:42:35.024821: predicting lnq2023-train-0986 
2023-08-01 04:42:37.967287: predicting lnq2023-train-0989 
2023-08-01 04:42:42.326088: predicting lnq2023-train-0992 
2023-08-01 04:42:44.309347: predicting lnq2023-train-0993 
2023-08-01 04:42:47.238685: predicting lnq2023-train-0995 
2023-08-01 04:42:49.211729: predicting lnq2023-train-0997 
2023-08-01 04:42:52.142353: predicting lnq2023-train-1002 
2023-08-01 04:42:54.091852: predicting lnq2023-train-1007 
2023-08-01 04:42:56.044218: predicting lnq2023-train-1012 
2023-08-01 04:42:56.305059: predicting lnq2023-train-1013 
2023-08-01 04:42:58.248594: predicting lnq2023-train-1017 
2023-08-01 04:43:02.605219: predicting lnq2023-train-1018 
2023-08-01 04:43:05.537663: predicting lnq2023-train-1019 
2023-08-01 04:43:12.059777: predicting lnq2023-train-1020 
2023-08-01 04:43:15.017731: predicting lnq2023-train-1022 
2023-08-01 04:43:16.969923: predicting lnq2023-train-1023 
2023-08-01 04:43:18.931545: predicting lnq2023-train-1034 
2023-08-01 04:43:23.285019: predicting lnq2023-train-1042 
2023-08-01 04:43:25.264294: predicting lnq2023-train-1044 
2023-08-01 04:43:28.189098: predicting lnq2023-train-1045 
2023-08-01 04:43:31.103818: predicting lnq2023-train-1047 
2023-08-01 04:43:34.028929: predicting lnq2023-train-1051 
2023-08-01 04:43:35.981384: predicting lnq2023-train-1057 
2023-08-01 04:43:39.866430: predicting lnq2023-train-1060 
2023-08-01 04:43:41.818533: predicting lnq2023-train-1062 
2023-08-01 04:43:44.726974: predicting lnq2023-train-1064 
2023-08-01 04:43:49.082340: predicting lnq2023-train-1065 
2023-08-01 04:43:51.045203: predicting lnq2023-train-1067 
2023-08-01 04:43:55.427264: predicting lnq2023-train-1071 
2023-08-01 04:43:58.370114: predicting lnq2023-train-1072 
2023-08-01 04:44:01.287958: predicting lnq2023-train-1076 
2023-08-01 04:44:04.216326: predicting lnq2023-train-1077 
2023-08-01 04:44:07.133959: predicting lnq2023-train-1081 
2023-08-01 04:44:09.099034: predicting lnq2023-train-1082 
2023-08-01 04:44:11.063907: predicting lnq2023-train-1084 
2023-08-01 04:44:13.976359: predicting lnq2023-train-1088 
2023-08-01 04:44:15.945499: predicting lnq2023-train-1090 
2023-08-01 04:44:17.898068: predicting lnq2023-train-1091 
2023-08-01 04:44:19.852669: predicting lnq2023-train-1092 
2023-08-01 04:44:24.210261: predicting lnq2023-train-1093 
2023-08-01 04:44:26.214842: predicting lnq2023-train-1096 
2023-08-01 04:44:30.576065: predicting lnq2023-train-1097 
2023-08-01 04:44:33.519712: predicting lnq2023-train-1098 
2023-08-01 04:44:36.468766: predicting lnq2023-train-1100 
2023-08-01 04:45:10.871111: Validation complete 
2023-08-01 04:45:10.871197: Mean Validation Dice:  0.6419215219591331 
