
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 224], 'median_image_size_in_voxels': [85.0, 209.0, 296.0], 'spacing': [3.0, 0.9335939884185791, 0.9335939884185791], 'normalization_schemes': ['Clip_Normalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [4, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset029_all_at_once', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.9335939884185791, 0.9335939884185791], 'original_median_shape_after_transp': [88, 222, 313], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 8913.0, 'mean': -123.09001922607422, 'median': -25.0, 'min': -3024.0, 'percentile_00_5': -1022.0, 'percentile_99_5': 463.0, 'std': 332.416259765625}}} 
 
2023-08-07 10:28:23.401483: unpacking dataset... 
2023-08-07 10:28:25.521945: unpacking done... 
2023-08-07 10:28:25.522965: do_dummy_2d_data_aug: True 
2023-08-07 10:28:25.537284: Unable to plot network architecture: 
2023-08-07 10:28:25.537347: No module named 'hiddenlayer' 
2023-08-07 10:28:25.541706:  
2023-08-07 10:28:25.541771: Epoch 0 
2023-08-07 10:28:25.541853: Current learning rate: 0.001 
2023-08-07 10:29:34.863055: train_loss 0.1207 
2023-08-07 10:29:34.863251: val_loss -0.0005 
2023-08-07 10:29:34.863314: Pseudo dice [0.0] 
2023-08-07 10:29:34.863372: Epoch time: 69.32 s 
2023-08-07 10:29:34.863411: Yayy! New best EMA pseudo Dice: 0.0 
2023-08-07 10:29:36.124932:  
2023-08-07 10:29:36.125024: Epoch 1 
2023-08-07 10:29:36.125112: Current learning rate: 0.001 
2023-08-07 10:30:39.613799: train_loss -0.0063 
2023-08-07 10:30:39.613958: val_loss -0.015 
2023-08-07 10:30:39.614014: Pseudo dice [0.0] 
2023-08-07 10:30:39.614064: Epoch time: 63.49 s 
2023-08-07 10:30:40.577521:  
2023-08-07 10:30:40.577638: Epoch 2 
2023-08-07 10:30:40.577713: Current learning rate: 0.001 
2023-08-07 10:31:44.033186: train_loss -0.0169 
2023-08-07 10:31:44.033337: val_loss -0.0251 
2023-08-07 10:31:44.033389: Pseudo dice [0.0] 
2023-08-07 10:31:44.033441: Epoch time: 63.46 s 
2023-08-07 10:31:45.067434:  
2023-08-07 10:31:45.067531: Epoch 3 
2023-08-07 10:31:45.067624: Current learning rate: 0.001 
2023-08-07 10:32:48.759997: train_loss -0.0734 
2023-08-07 10:32:48.760159: val_loss -0.0645 
2023-08-07 10:32:48.760212: Pseudo dice [0.1306] 
2023-08-07 10:32:48.760265: Epoch time: 63.69 s 
2023-08-07 10:32:48.760305: Yayy! New best EMA pseudo Dice: 0.0131 
2023-08-07 10:32:50.155866:  
2023-08-07 10:32:50.155978: Epoch 4 
2023-08-07 10:32:50.156060: Current learning rate: 0.001 
2023-08-07 10:33:53.853415: train_loss -0.0942 
2023-08-07 10:33:53.853565: val_loss -0.0924 
2023-08-07 10:33:53.853617: Pseudo dice [0.2178] 
2023-08-07 10:33:53.853669: Epoch time: 63.7 s 
2023-08-07 10:33:53.853711: Yayy! New best EMA pseudo Dice: 0.0335 
2023-08-07 10:33:55.248438:  
2023-08-07 10:33:55.248538: Epoch 5 
2023-08-07 10:33:55.248615: Current learning rate: 0.001 
2023-08-07 10:34:58.918229: train_loss -0.1127 
2023-08-07 10:34:58.918379: val_loss -0.1079 
2023-08-07 10:34:58.918434: Pseudo dice [0.2616] 
2023-08-07 10:34:58.918484: Epoch time: 63.67 s 
2023-08-07 10:34:58.918525: Yayy! New best EMA pseudo Dice: 0.0563 
2023-08-07 10:35:00.408083:  
2023-08-07 10:35:00.408184: Epoch 6 
2023-08-07 10:35:00.408258: Current learning rate: 0.001 
2023-08-07 10:36:04.175638: train_loss -0.1184 
2023-08-07 10:36:04.175786: val_loss -0.138 
2023-08-07 10:36:04.175837: Pseudo dice [0.2646] 
2023-08-07 10:36:04.175887: Epoch time: 63.77 s 
2023-08-07 10:36:04.175925: Yayy! New best EMA pseudo Dice: 0.0772 
2023-08-07 10:36:05.510901:  
2023-08-07 10:36:05.511000: Epoch 7 
2023-08-07 10:36:05.511091: Current learning rate: 0.001 
2023-08-07 10:37:09.584529: train_loss -0.1549 
2023-08-07 10:37:09.584671: val_loss -0.1826 
2023-08-07 10:37:09.584725: Pseudo dice [0.3183] 
2023-08-07 10:37:09.584774: Epoch time: 64.07 s 
2023-08-07 10:37:09.584814: Yayy! New best EMA pseudo Dice: 0.1013 
2023-08-07 10:37:10.908759:  
2023-08-07 10:37:10.908936: Epoch 8 
2023-08-07 10:37:10.909012: Current learning rate: 0.001 
2023-08-07 10:38:15.105846: train_loss -0.1917 
2023-08-07 10:38:15.106001: val_loss -0.1664 
2023-08-07 10:38:15.106056: Pseudo dice [0.2693] 
2023-08-07 10:38:15.106107: Epoch time: 64.2 s 
2023-08-07 10:38:15.106148: Yayy! New best EMA pseudo Dice: 0.1181 
2023-08-07 10:38:16.517376:  
2023-08-07 10:38:16.517479: Epoch 9 
2023-08-07 10:38:16.517636: Current learning rate: 0.001 
2023-08-07 10:39:20.814180: train_loss -0.1447 
2023-08-07 10:39:20.814324: val_loss -0.2235 
2023-08-07 10:39:20.814377: Pseudo dice [0.3158] 
2023-08-07 10:39:20.814445: Epoch time: 64.3 s 
2023-08-07 10:39:20.814485: Yayy! New best EMA pseudo Dice: 0.1379 
2023-08-07 10:39:22.125834:  
2023-08-07 10:39:22.126045: Epoch 10 
2023-08-07 10:39:22.126138: Current learning rate: 0.001 
2023-08-07 10:40:25.514005: train_loss -0.1722 
2023-08-07 10:40:25.514152: val_loss -0.1534 
2023-08-07 10:40:25.514201: Pseudo dice [0.2608] 
2023-08-07 10:40:25.514251: Epoch time: 63.39 s 
2023-08-07 10:40:25.514292: Yayy! New best EMA pseudo Dice: 0.1502 
2023-08-07 10:40:26.915048:  
2023-08-07 10:40:26.915242: Epoch 11 
2023-08-07 10:40:26.915338: Current learning rate: 0.001 
2023-08-07 10:41:30.130973: train_loss -0.1697 
2023-08-07 10:41:30.131125: val_loss -0.1717 
2023-08-07 10:41:30.131180: Pseudo dice [0.3183] 
2023-08-07 10:41:30.131231: Epoch time: 63.22 s 
2023-08-07 10:41:30.131272: Yayy! New best EMA pseudo Dice: 0.167 
2023-08-07 10:41:31.445722:  
2023-08-07 10:41:31.445819: Epoch 12 
2023-08-07 10:41:31.445908: Current learning rate: 0.00099 
2023-08-07 10:42:34.709533: train_loss -0.2115 
2023-08-07 10:42:34.709702: val_loss -0.1916 
2023-08-07 10:42:34.709755: Pseudo dice [0.314] 
2023-08-07 10:42:34.709805: Epoch time: 63.26 s 
2023-08-07 10:42:34.709845: Yayy! New best EMA pseudo Dice: 0.1817 
2023-08-07 10:42:35.989704:  
2023-08-07 10:42:35.989801: Epoch 13 
2023-08-07 10:42:35.989876: Current learning rate: 0.00099 
2023-08-07 10:43:39.439335: train_loss -0.2103 
2023-08-07 10:43:39.439484: val_loss -0.2295 
2023-08-07 10:43:39.439539: Pseudo dice [0.3128] 
2023-08-07 10:43:39.439600: Epoch time: 63.45 s 
2023-08-07 10:43:39.439641: Yayy! New best EMA pseudo Dice: 0.1948 
2023-08-07 10:43:40.752519:  
2023-08-07 10:43:40.752729: Epoch 14 
2023-08-07 10:43:40.752808: Current learning rate: 0.00099 
2023-08-07 10:44:44.005245: train_loss -0.2039 
2023-08-07 10:44:44.005393: val_loss -0.2152 
2023-08-07 10:44:44.005441: Pseudo dice [0.3499] 
2023-08-07 10:44:44.005507: Epoch time: 63.25 s 
2023-08-07 10:44:44.005556: Yayy! New best EMA pseudo Dice: 0.2103 
2023-08-07 10:44:45.332828:  
2023-08-07 10:44:45.332928: Epoch 15 
2023-08-07 10:44:45.333091: Current learning rate: 0.00099 
2023-08-07 10:45:48.716685: train_loss -0.1974 
2023-08-07 10:45:48.716834: val_loss -0.1955 
2023-08-07 10:45:48.716886: Pseudo dice [0.3762] 
2023-08-07 10:45:48.716936: Epoch time: 63.38 s 
2023-08-07 10:45:48.716976: Yayy! New best EMA pseudo Dice: 0.2269 
2023-08-07 10:45:50.152270:  
2023-08-07 10:45:50.152517: Epoch 16 
2023-08-07 10:45:50.152732: Current learning rate: 0.00099 
2023-08-07 10:46:53.540586: train_loss -0.204 
2023-08-07 10:46:53.540735: val_loss -0.1929 
2023-08-07 10:46:53.540785: Pseudo dice [0.2754] 
2023-08-07 10:46:53.540835: Epoch time: 63.39 s 
2023-08-07 10:46:53.540874: Yayy! New best EMA pseudo Dice: 0.2317 
2023-08-07 10:46:54.920134:  
2023-08-07 10:46:54.920231: Epoch 17 
2023-08-07 10:46:54.920306: Current learning rate: 0.00099 
2023-08-07 10:47:58.206066: train_loss -0.1876 
2023-08-07 10:47:58.206229: val_loss -0.2023 
2023-08-07 10:47:58.214663: Pseudo dice [0.4133] 
2023-08-07 10:47:58.214881: Epoch time: 63.29 s 
2023-08-07 10:47:58.215014: Yayy! New best EMA pseudo Dice: 0.2499 
2023-08-07 10:47:59.578839:  
2023-08-07 10:47:59.578934: Epoch 18 
2023-08-07 10:47:59.579007: Current learning rate: 0.00099 
2023-08-07 10:49:03.108180: train_loss -0.2334 
2023-08-07 10:49:03.108321: val_loss -0.1956 
2023-08-07 10:49:03.108373: Pseudo dice [0.3194] 
2023-08-07 10:49:03.108423: Epoch time: 63.53 s 
2023-08-07 10:49:03.108464: Yayy! New best EMA pseudo Dice: 0.2569 
2023-08-07 10:49:04.467666:  
2023-08-07 10:49:04.467769: Epoch 19 
2023-08-07 10:49:04.467841: Current learning rate: 0.00099 
2023-08-07 10:50:08.043320: train_loss -0.2386 
2023-08-07 10:50:08.043481: val_loss -0.2196 
2023-08-07 10:50:08.043534: Pseudo dice [0.3548] 
2023-08-07 10:50:08.043613: Epoch time: 63.58 s 
2023-08-07 10:50:08.043655: Yayy! New best EMA pseudo Dice: 0.2666 
2023-08-07 10:50:09.399602:  
2023-08-07 10:50:09.399700: Epoch 20 
2023-08-07 10:50:09.399789: Current learning rate: 0.00099 
2023-08-07 10:51:12.826216: train_loss -0.2034 
2023-08-07 10:51:12.826364: val_loss -0.1983 
2023-08-07 10:51:12.826431: Pseudo dice [0.3083] 
2023-08-07 10:51:12.826482: Epoch time: 63.43 s 
2023-08-07 10:51:12.826522: Yayy! New best EMA pseudo Dice: 0.2708 
2023-08-07 10:51:14.310751:  
2023-08-07 10:51:14.310860: Epoch 21 
2023-08-07 10:51:14.310952: Current learning rate: 0.00099 
2023-08-07 10:52:17.833052: train_loss -0.2213 
2023-08-07 10:52:17.833212: val_loss -0.2539 
2023-08-07 10:52:17.833264: Pseudo dice [0.383] 
2023-08-07 10:52:17.833313: Epoch time: 63.52 s 
2023-08-07 10:52:17.833352: Yayy! New best EMA pseudo Dice: 0.282 
2023-08-07 10:52:19.117495:  
2023-08-07 10:52:19.117588: Epoch 22 
2023-08-07 10:52:19.117662: Current learning rate: 0.00099 
2023-08-07 10:53:22.599456: train_loss -0.2128 
2023-08-07 10:53:22.599636: val_loss -0.2582 
2023-08-07 10:53:22.599691: Pseudo dice [0.3891] 
2023-08-07 10:53:22.599742: Epoch time: 63.48 s 
2023-08-07 10:53:22.599783: Yayy! New best EMA pseudo Dice: 0.2927 
2023-08-07 10:53:23.989248:  
2023-08-07 10:53:23.989349: Epoch 23 
2023-08-07 10:53:23.989453: Current learning rate: 0.00099 
2023-08-07 10:54:27.341863: train_loss -0.2547 
2023-08-07 10:54:27.342035: val_loss -0.2066 
2023-08-07 10:54:27.342088: Pseudo dice [0.4008] 
2023-08-07 10:54:27.342138: Epoch time: 63.35 s 
2023-08-07 10:54:27.342176: Yayy! New best EMA pseudo Dice: 0.3035 
2023-08-07 10:54:28.629514:  
2023-08-07 10:54:28.629717: Epoch 24 
2023-08-07 10:54:28.629791: Current learning rate: 0.00099 
2023-08-07 10:55:31.833619: train_loss -0.2417 
2023-08-07 10:55:31.833768: val_loss -0.2215 
2023-08-07 10:55:31.833822: Pseudo dice [0.2684] 
2023-08-07 10:55:31.833890: Epoch time: 63.2 s 
2023-08-07 10:55:32.809459:  
2023-08-07 10:55:32.809566: Epoch 25 
2023-08-07 10:55:32.809656: Current learning rate: 0.00099 
2023-08-07 10:56:36.040759: train_loss -0.2324 
2023-08-07 10:56:36.040948: val_loss -0.221 
2023-08-07 10:56:36.041005: Pseudo dice [0.3351] 
2023-08-07 10:56:36.041057: Epoch time: 63.23 s 
2023-08-07 10:56:37.114350:  
2023-08-07 10:56:37.114450: Epoch 26 
2023-08-07 10:56:37.114529: Current learning rate: 0.00099 
2023-08-07 10:57:40.579864: train_loss -0.2124 
2023-08-07 10:57:40.580016: val_loss -0.2862 
2023-08-07 10:57:40.580069: Pseudo dice [0.4099] 
2023-08-07 10:57:40.580120: Epoch time: 63.47 s 
2023-08-07 10:57:40.580160: Yayy! New best EMA pseudo Dice: 0.3142 
2023-08-07 10:57:41.883000:  
2023-08-07 10:57:41.883207: Epoch 27 
2023-08-07 10:57:41.883298: Current learning rate: 0.00099 
2023-08-07 10:58:45.299949: train_loss -0.2309 
2023-08-07 10:58:45.300095: val_loss -0.2753 
2023-08-07 10:58:45.300146: Pseudo dice [0.392] 
2023-08-07 10:58:45.300196: Epoch time: 63.42 s 
2023-08-07 10:58:45.300235: Yayy! New best EMA pseudo Dice: 0.3219 
2023-08-07 10:58:46.617913:  
2023-08-07 10:58:46.618138: Epoch 28 
2023-08-07 10:58:46.618233: Current learning rate: 0.00099 
2023-08-07 10:59:50.110485: train_loss -0.2622 
2023-08-07 10:59:50.110641: val_loss -0.2113 
2023-08-07 10:59:50.110694: Pseudo dice [0.3633] 
2023-08-07 10:59:50.110748: Epoch time: 63.49 s 
2023-08-07 10:59:50.110788: Yayy! New best EMA pseudo Dice: 0.3261 
2023-08-07 10:59:51.426504:  
2023-08-07 10:59:51.426603: Epoch 29 
2023-08-07 10:59:51.426677: Current learning rate: 0.00099 
2023-08-07 11:00:54.971828: train_loss -0.2456 
2023-08-07 11:00:54.972081: val_loss -0.2611 
2023-08-07 11:00:54.972138: Pseudo dice [0.4805] 
2023-08-07 11:00:54.972191: Epoch time: 63.55 s 
2023-08-07 11:00:54.972232: Yayy! New best EMA pseudo Dice: 0.3415 
2023-08-07 11:00:56.321597:  
2023-08-07 11:00:56.321689: Epoch 30 
2023-08-07 11:00:56.321765: Current learning rate: 0.00099 
2023-08-07 11:01:59.680045: train_loss -0.2671 
2023-08-07 11:01:59.680201: val_loss -0.2381 
2023-08-07 11:01:59.680259: Pseudo dice [0.3482] 
2023-08-07 11:01:59.680314: Epoch time: 63.36 s 
2023-08-07 11:01:59.680358: Yayy! New best EMA pseudo Dice: 0.3422 
2023-08-07 11:02:01.056527:  
2023-08-07 11:02:01.056624: Epoch 31 
2023-08-07 11:02:01.056698: Current learning rate: 0.00099 
2023-08-07 11:03:04.261861: train_loss -0.2603 
2023-08-07 11:03:04.262035: val_loss -0.237 
2023-08-07 11:03:04.262089: Pseudo dice [0.4907] 
2023-08-07 11:03:04.262140: Epoch time: 63.21 s 
2023-08-07 11:03:04.262180: Yayy! New best EMA pseudo Dice: 0.357 
2023-08-07 11:03:05.726038:  
2023-08-07 11:03:05.726146: Epoch 32 
2023-08-07 11:03:05.726234: Current learning rate: 0.00099 
2023-08-07 11:04:09.048981: train_loss -0.2547 
2023-08-07 11:04:09.049148: val_loss -0.2084 
2023-08-07 11:04:09.049201: Pseudo dice [0.3815] 
2023-08-07 11:04:09.049252: Epoch time: 63.32 s 
2023-08-07 11:04:09.049292: Yayy! New best EMA pseudo Dice: 0.3595 
2023-08-07 11:04:10.409594:  
2023-08-07 11:04:10.409795: Epoch 33 
2023-08-07 11:04:10.409873: Current learning rate: 0.00099 
2023-08-07 11:05:13.853322: train_loss -0.2293 
2023-08-07 11:05:13.853463: val_loss -0.2641 
2023-08-07 11:05:13.853515: Pseudo dice [0.4966] 
2023-08-07 11:05:13.853580: Epoch time: 63.44 s 
2023-08-07 11:05:13.853620: Yayy! New best EMA pseudo Dice: 0.3732 
2023-08-07 11:05:15.210762:  
2023-08-07 11:05:15.210858: Epoch 34 
2023-08-07 11:05:15.210974: Current learning rate: 0.00098 
2023-08-07 11:06:18.571302: train_loss -0.2375 
2023-08-07 11:06:18.571446: val_loss -0.2378 
2023-08-07 11:06:18.571513: Pseudo dice [0.423] 
2023-08-07 11:06:18.571573: Epoch time: 63.36 s 
2023-08-07 11:06:18.571618: Yayy! New best EMA pseudo Dice: 0.3782 
2023-08-07 11:06:19.926488:  
2023-08-07 11:06:19.926688: Epoch 35 
2023-08-07 11:06:19.926791: Current learning rate: 0.00098 
2023-08-07 11:07:23.391348: train_loss -0.2534 
2023-08-07 11:07:23.391514: val_loss -0.2463 
2023-08-07 11:07:23.391577: Pseudo dice [0.4753] 
2023-08-07 11:07:23.391632: Epoch time: 63.47 s 
2023-08-07 11:07:23.391672: Yayy! New best EMA pseudo Dice: 0.3879 
2023-08-07 11:07:24.843796:  
2023-08-07 11:07:24.843900: Epoch 36 
2023-08-07 11:07:24.843996: Current learning rate: 0.00098 
2023-08-07 11:08:28.374640: train_loss -0.2819 
2023-08-07 11:08:28.374785: val_loss -0.2826 
2023-08-07 11:08:28.374836: Pseudo dice [0.5153] 
2023-08-07 11:08:28.374911: Epoch time: 63.53 s 
2023-08-07 11:08:28.374953: Yayy! New best EMA pseudo Dice: 0.4006 
2023-08-07 11:08:29.721471:  
2023-08-07 11:08:29.721569: Epoch 37 
2023-08-07 11:08:29.721657: Current learning rate: 0.00098 
2023-08-07 11:09:33.195281: train_loss -0.2577 
2023-08-07 11:09:33.195420: val_loss -0.2133 
2023-08-07 11:09:33.195471: Pseudo dice [0.4363] 
2023-08-07 11:09:33.195536: Epoch time: 63.47 s 
2023-08-07 11:09:33.195586: Yayy! New best EMA pseudo Dice: 0.4042 
2023-08-07 11:09:34.527607:  
2023-08-07 11:09:34.527801: Epoch 38 
2023-08-07 11:09:34.527877: Current learning rate: 0.00098 
2023-08-07 11:10:38.037308: train_loss -0.2567 
2023-08-07 11:10:38.037462: val_loss -0.2094 
2023-08-07 11:10:38.037516: Pseudo dice [0.4834] 
2023-08-07 11:10:38.037567: Epoch time: 63.51 s 
2023-08-07 11:10:38.037606: Yayy! New best EMA pseudo Dice: 0.4121 
2023-08-07 11:10:39.372319:  
2023-08-07 11:10:39.372416: Epoch 39 
2023-08-07 11:10:39.372488: Current learning rate: 0.00098 
2023-08-07 11:11:42.796195: train_loss -0.2329 
2023-08-07 11:11:42.796347: val_loss -0.2663 
2023-08-07 11:11:42.796399: Pseudo dice [0.4738] 
2023-08-07 11:11:42.796574: Epoch time: 63.42 s 
2023-08-07 11:11:42.796620: Yayy! New best EMA pseudo Dice: 0.4183 
2023-08-07 11:11:44.134198:  
2023-08-07 11:11:44.134293: Epoch 40 
2023-08-07 11:11:44.134382: Current learning rate: 0.00098 
2023-08-07 11:12:47.570309: train_loss -0.262 
2023-08-07 11:12:47.570459: val_loss -0.2624 
2023-08-07 11:12:47.570508: Pseudo dice [0.4593] 
2023-08-07 11:12:47.570574: Epoch time: 63.44 s 
2023-08-07 11:12:47.570615: Yayy! New best EMA pseudo Dice: 0.4224 
2023-08-07 11:12:49.101780:  
2023-08-07 11:12:49.101881: Epoch 41 
2023-08-07 11:12:49.101956: Current learning rate: 0.00098 
2023-08-07 11:13:52.592429: train_loss -0.246 
2023-08-07 11:13:52.592576: val_loss -0.2196 
2023-08-07 11:13:52.592630: Pseudo dice [0.4065] 
2023-08-07 11:13:52.592680: Epoch time: 63.49 s 
2023-08-07 11:13:53.532299:  
2023-08-07 11:13:53.532479: Epoch 42 
2023-08-07 11:13:53.532556: Current learning rate: 0.00098 
2023-08-07 11:14:56.970300: train_loss -0.2788 
2023-08-07 11:14:56.970446: val_loss -0.2942 
2023-08-07 11:14:56.970497: Pseudo dice [0.4683] 
2023-08-07 11:14:56.970546: Epoch time: 63.44 s 
2023-08-07 11:14:56.970584: Yayy! New best EMA pseudo Dice: 0.4256 
2023-08-07 11:14:58.298573:  
2023-08-07 11:14:58.298671: Epoch 43 
2023-08-07 11:14:58.298760: Current learning rate: 0.00098 
2023-08-07 11:16:01.706498: train_loss -0.2646 
2023-08-07 11:16:01.706658: val_loss -0.2474 
2023-08-07 11:16:01.706712: Pseudo dice [0.5259] 
2023-08-07 11:16:01.706764: Epoch time: 63.41 s 
2023-08-07 11:16:01.706804: Yayy! New best EMA pseudo Dice: 0.4356 
2023-08-07 11:16:03.000129:  
2023-08-07 11:16:03.000226: Epoch 44 
2023-08-07 11:16:03.000301: Current learning rate: 0.00098 
2023-08-07 11:17:06.185753: train_loss -0.2388 
2023-08-07 11:17:06.185906: val_loss -0.2562 
2023-08-07 11:17:06.185958: Pseudo dice [0.5931] 
2023-08-07 11:17:06.186008: Epoch time: 63.19 s 
2023-08-07 11:17:06.186048: Yayy! New best EMA pseudo Dice: 0.4513 
2023-08-07 11:17:07.497058:  
2023-08-07 11:17:07.497266: Epoch 45 
2023-08-07 11:17:07.497346: Current learning rate: 0.00098 
2023-08-07 11:18:10.948551: train_loss -0.2602 
2023-08-07 11:18:10.948704: val_loss -0.2442 
2023-08-07 11:18:10.948757: Pseudo dice [0.6227] 
2023-08-07 11:18:10.948806: Epoch time: 63.45 s 
2023-08-07 11:18:10.948847: Yayy! New best EMA pseudo Dice: 0.4685 
2023-08-07 11:18:12.224187:  
2023-08-07 11:18:12.224288: Epoch 46 
2023-08-07 11:18:12.224361: Current learning rate: 0.00098 
2023-08-07 11:19:15.570577: train_loss -0.2325 
2023-08-07 11:19:15.570748: val_loss -0.2966 
2023-08-07 11:19:15.570803: Pseudo dice [0.5259] 
2023-08-07 11:19:15.570856: Epoch time: 63.35 s 
2023-08-07 11:19:15.570896: Yayy! New best EMA pseudo Dice: 0.4742 
2023-08-07 11:19:17.044847:  
2023-08-07 11:19:17.045039: Epoch 47 
2023-08-07 11:19:17.045120: Current learning rate: 0.00098 
2023-08-07 11:20:20.575733: train_loss -0.2647 
2023-08-07 11:20:20.575891: val_loss -0.2503 
2023-08-07 11:20:20.575946: Pseudo dice [0.455] 
2023-08-07 11:20:20.575997: Epoch time: 63.53 s 
2023-08-07 11:20:21.499456:  
2023-08-07 11:20:21.499566: Epoch 48 
2023-08-07 11:20:21.499672: Current learning rate: 0.00098 
2023-08-07 11:21:25.128732: train_loss -0.2822 
2023-08-07 11:21:25.128957: val_loss -0.3138 
2023-08-07 11:21:25.129012: Pseudo dice [0.6212] 
2023-08-07 11:21:25.129062: Epoch time: 63.63 s 
2023-08-07 11:21:25.129102: Yayy! New best EMA pseudo Dice: 0.4872 
2023-08-07 11:21:26.431508:  
2023-08-07 11:21:26.431636: Epoch 49 
2023-08-07 11:21:26.431712: Current learning rate: 0.00098 
2023-08-07 11:22:29.906304: train_loss -0.3065 
2023-08-07 11:22:29.906467: val_loss -0.337 
2023-08-07 11:22:29.906521: Pseudo dice [0.5398] 
2023-08-07 11:22:29.906573: Epoch time: 63.48 s 
2023-08-07 11:22:30.127938: Yayy! New best EMA pseudo Dice: 0.4925 
2023-08-07 11:22:31.395432:  
2023-08-07 11:22:31.395665: Epoch 50 
2023-08-07 11:22:31.395774: Current learning rate: 0.00098 
2023-08-07 11:23:34.870961: train_loss -0.2699 
2023-08-07 11:23:34.871129: val_loss -0.278 
2023-08-07 11:23:34.871183: Pseudo dice [0.4247] 
2023-08-07 11:23:34.871234: Epoch time: 63.48 s 
2023-08-07 11:23:35.831769:  
2023-08-07 11:23:35.831868: Epoch 51 
2023-08-07 11:23:35.831957: Current learning rate: 0.00098 
2023-08-07 11:24:39.056891: train_loss -0.2671 
2023-08-07 11:24:39.057045: val_loss -0.2841 
2023-08-07 11:24:39.057097: Pseudo dice [0.6347] 
2023-08-07 11:24:39.057164: Epoch time: 63.23 s 
2023-08-07 11:24:39.057205: Yayy! New best EMA pseudo Dice: 0.5006 
2023-08-07 11:24:40.486664:  
2023-08-07 11:24:40.486880: Epoch 52 
2023-08-07 11:24:40.486975: Current learning rate: 0.00098 
2023-08-07 11:25:44.018955: train_loss -0.2663 
2023-08-07 11:25:44.019118: val_loss -0.2258 
2023-08-07 11:25:44.019173: Pseudo dice [0.4601] 
2023-08-07 11:25:44.019240: Epoch time: 63.53 s 
2023-08-07 11:25:44.962803:  
2023-08-07 11:25:44.962906: Epoch 53 
2023-08-07 11:25:44.962994: Current learning rate: 0.00098 
2023-08-07 11:26:48.375811: train_loss -0.2445 
2023-08-07 11:26:48.375973: val_loss -0.2527 
2023-08-07 11:26:48.376027: Pseudo dice [0.525] 
2023-08-07 11:26:48.376078: Epoch time: 63.41 s 
2023-08-07 11:26:49.321244:  
2023-08-07 11:26:49.321340: Epoch 54 
2023-08-07 11:26:49.321427: Current learning rate: 0.00098 
2023-08-07 11:27:52.917960: train_loss -0.3017 
2023-08-07 11:27:52.918205: val_loss -0.3288 
2023-08-07 11:27:52.918262: Pseudo dice [0.5496] 
2023-08-07 11:27:52.918313: Epoch time: 63.6 s 
2023-08-07 11:27:52.918352: Yayy! New best EMA pseudo Dice: 0.5044 
2023-08-07 11:27:54.219057:  
2023-08-07 11:27:54.219172: Epoch 55 
2023-08-07 11:27:54.219247: Current learning rate: 0.00098 
2023-08-07 11:28:57.735526: train_loss -0.2732 
2023-08-07 11:28:57.735779: val_loss -0.3257 
2023-08-07 11:28:57.735836: Pseudo dice [0.6176] 
2023-08-07 11:28:57.735889: Epoch time: 63.52 s 
2023-08-07 11:28:57.735929: Yayy! New best EMA pseudo Dice: 0.5157 
2023-08-07 11:28:59.054087:  
2023-08-07 11:28:59.054183: Epoch 56 
2023-08-07 11:28:59.054256: Current learning rate: 0.00097 
2023-08-07 11:30:02.600757: train_loss -0.2458 
2023-08-07 11:30:02.600906: val_loss -0.3593 
2023-08-07 11:30:02.600973: Pseudo dice [0.6592] 
2023-08-07 11:30:02.601024: Epoch time: 63.55 s 
2023-08-07 11:30:02.601064: Yayy! New best EMA pseudo Dice: 0.5301 
2023-08-07 11:30:04.092728:  
2023-08-07 11:30:04.092961: Epoch 57 
2023-08-07 11:30:04.093053: Current learning rate: 0.00097 
2023-08-07 11:31:07.808425: train_loss -0.2696 
2023-08-07 11:31:07.808578: val_loss -0.2627 
2023-08-07 11:31:07.808635: Pseudo dice [0.6461] 
2023-08-07 11:31:07.808687: Epoch time: 63.72 s 
2023-08-07 11:31:07.808727: Yayy! New best EMA pseudo Dice: 0.5417 
2023-08-07 11:31:09.135530:  
2023-08-07 11:31:09.135741: Epoch 58 
2023-08-07 11:31:09.135840: Current learning rate: 0.00097 
2023-08-07 11:32:12.692924: train_loss -0.2887 
2023-08-07 11:32:12.693072: val_loss -0.3075 
2023-08-07 11:32:12.693127: Pseudo dice [0.5678] 
2023-08-07 11:32:12.693177: Epoch time: 63.56 s 
2023-08-07 11:32:12.693217: Yayy! New best EMA pseudo Dice: 0.5443 
2023-08-07 11:32:14.002434:  
2023-08-07 11:32:14.002532: Epoch 59 
2023-08-07 11:32:14.002605: Current learning rate: 0.00097 
2023-08-07 11:33:17.627238: train_loss -0.2355 
2023-08-07 11:33:17.627381: val_loss -0.2843 
2023-08-07 11:33:17.627432: Pseudo dice [0.3861] 
2023-08-07 11:33:17.627498: Epoch time: 63.63 s 
2023-08-07 11:33:18.595576:  
2023-08-07 11:33:18.595690: Epoch 60 
2023-08-07 11:33:18.595766: Current learning rate: 0.00097 
2023-08-07 11:34:22.059781: train_loss -0.2745 
2023-08-07 11:34:22.059924: val_loss -0.2498 
2023-08-07 11:34:22.059976: Pseudo dice [0.4107] 
2023-08-07 11:34:22.060027: Epoch time: 63.46 s 
2023-08-07 11:34:23.021458:  
2023-08-07 11:34:23.021682: Epoch 61 
2023-08-07 11:34:23.021763: Current learning rate: 0.00097 
2023-08-07 11:35:26.483078: train_loss -0.2577 
2023-08-07 11:35:26.483225: val_loss -0.2691 
2023-08-07 11:35:26.483276: Pseudo dice [0.6361] 
2023-08-07 11:35:26.483342: Epoch time: 63.46 s 
2023-08-07 11:35:27.477687:  
2023-08-07 11:35:27.477898: Epoch 62 
2023-08-07 11:35:27.477981: Current learning rate: 0.00097 
2023-08-07 11:36:31.118095: train_loss -0.2775 
2023-08-07 11:36:31.118243: val_loss -0.2702 
2023-08-07 11:36:31.118295: Pseudo dice [0.4996] 
2023-08-07 11:36:31.118346: Epoch time: 63.64 s 
2023-08-07 11:36:32.315433:  
2023-08-07 11:36:32.315531: Epoch 63 
2023-08-07 11:36:32.315639: Current learning rate: 0.00097 
2023-08-07 11:37:36.227682: train_loss -0.2896 
2023-08-07 11:37:36.227840: val_loss -0.2473 
2023-08-07 11:37:36.227895: Pseudo dice [0.5759] 
2023-08-07 11:37:36.227946: Epoch time: 63.91 s 
2023-08-07 11:37:37.201339:  
2023-08-07 11:37:37.201434: Epoch 64 
2023-08-07 11:37:37.201505: Current learning rate: 0.00097 
2023-08-07 11:38:41.020293: train_loss -0.3001 
2023-08-07 11:38:41.020443: val_loss -0.2359 
2023-08-07 11:38:41.020493: Pseudo dice [0.4446] 
2023-08-07 11:38:41.020544: Epoch time: 63.82 s 
2023-08-07 11:38:41.986845:  
2023-08-07 11:38:41.986942: Epoch 65 
2023-08-07 11:38:41.987017: Current learning rate: 0.00097 
2023-08-07 11:39:45.654024: train_loss -0.2705 
2023-08-07 11:39:45.654186: val_loss -0.2775 
2023-08-07 11:39:45.654238: Pseudo dice [0.5598] 
2023-08-07 11:39:45.654289: Epoch time: 63.67 s 
2023-08-07 11:39:46.625972:  
2023-08-07 11:39:46.626177: Epoch 66 
2023-08-07 11:39:46.626267: Current learning rate: 0.00097 
2023-08-07 11:40:50.185375: train_loss -0.2825 
2023-08-07 11:40:50.185533: val_loss -0.3104 
2023-08-07 11:40:50.185585: Pseudo dice [0.5988] 
2023-08-07 11:40:50.185635: Epoch time: 63.56 s 
2023-08-07 11:40:51.181831:  
2023-08-07 11:40:51.181925: Epoch 67 
2023-08-07 11:40:51.182039: Current learning rate: 0.00097 
2023-08-07 11:41:54.832816: train_loss -0.2875 
2023-08-07 11:41:54.832971: val_loss -0.3272 
2023-08-07 11:41:54.833022: Pseudo dice [0.71] 
2023-08-07 11:41:54.833074: Epoch time: 63.65 s 
2023-08-07 11:41:54.833115: Yayy! New best EMA pseudo Dice: 0.5509 
2023-08-07 11:41:56.301056:  
2023-08-07 11:41:56.301157: Epoch 68 
2023-08-07 11:41:56.301248: Current learning rate: 0.00097 
2023-08-07 11:43:00.037887: train_loss -0.306 
2023-08-07 11:43:00.038037: val_loss -0.3279 
2023-08-07 11:43:00.038088: Pseudo dice [0.5221] 
2023-08-07 11:43:00.038137: Epoch time: 63.74 s 
2023-08-07 11:43:01.076589:  
2023-08-07 11:43:01.076686: Epoch 69 
2023-08-07 11:43:01.076773: Current learning rate: 0.00097 
2023-08-07 11:44:04.840066: train_loss -0.2598 
2023-08-07 11:44:04.840224: val_loss -0.3391 
2023-08-07 11:44:04.840278: Pseudo dice [0.5836] 
2023-08-07 11:44:04.840329: Epoch time: 63.76 s 
2023-08-07 11:44:04.840370: Yayy! New best EMA pseudo Dice: 0.5516 
2023-08-07 11:44:06.175408:  
2023-08-07 11:44:06.175509: Epoch 70 
2023-08-07 11:44:06.175605: Current learning rate: 0.00097 
2023-08-07 11:45:09.826435: train_loss -0.2541 
2023-08-07 11:45:09.826592: val_loss -0.2955 
2023-08-07 11:45:09.826648: Pseudo dice [0.5989] 
2023-08-07 11:45:09.826699: Epoch time: 63.65 s 
2023-08-07 11:45:09.826740: Yayy! New best EMA pseudo Dice: 0.5563 
2023-08-07 11:45:11.179981:  
2023-08-07 11:45:11.180079: Epoch 71 
2023-08-07 11:45:11.180155: Current learning rate: 0.00097 
2023-08-07 11:46:14.651189: train_loss -0.2651 
2023-08-07 11:46:14.651346: val_loss -0.3087 
2023-08-07 11:46:14.651399: Pseudo dice [0.575] 
2023-08-07 11:46:14.651466: Epoch time: 63.47 s 
2023-08-07 11:46:14.651507: Yayy! New best EMA pseudo Dice: 0.5582 
2023-08-07 11:46:15.984381:  
2023-08-07 11:46:15.984477: Epoch 72 
2023-08-07 11:46:15.984552: Current learning rate: 0.00097 
2023-08-07 11:47:19.546635: train_loss -0.2493 
2023-08-07 11:47:19.546791: val_loss -0.2847 
2023-08-07 11:47:19.546864: Pseudo dice [0.605] 
2023-08-07 11:47:19.546917: Epoch time: 63.56 s 
2023-08-07 11:47:19.546957: Yayy! New best EMA pseudo Dice: 0.5628 
2023-08-07 11:47:21.053716:  
2023-08-07 11:47:21.053816: Epoch 73 
2023-08-07 11:47:21.053887: Current learning rate: 0.00097 
2023-08-07 11:48:24.781168: train_loss -0.281 
2023-08-07 11:48:24.781321: val_loss -0.2962 
2023-08-07 11:48:24.781374: Pseudo dice [0.6582] 
2023-08-07 11:48:24.781422: Epoch time: 63.73 s 
2023-08-07 11:48:24.781463: Yayy! New best EMA pseudo Dice: 0.5724 
2023-08-07 11:48:26.172811:  
2023-08-07 11:48:26.172922: Epoch 74 
2023-08-07 11:48:26.173012: Current learning rate: 0.00097 
2023-08-07 11:49:29.977228: train_loss -0.2809 
2023-08-07 11:49:29.977372: val_loss -0.3164 
2023-08-07 11:49:29.977426: Pseudo dice [0.5731] 
2023-08-07 11:49:29.977478: Epoch time: 63.81 s 
2023-08-07 11:49:29.977518: Yayy! New best EMA pseudo Dice: 0.5725 
2023-08-07 11:49:31.340405:  
2023-08-07 11:49:31.340604: Epoch 75 
2023-08-07 11:49:31.340682: Current learning rate: 0.00097 
2023-08-07 11:50:34.840928: train_loss -0.2659 
2023-08-07 11:50:34.841069: val_loss -0.3135 
2023-08-07 11:50:34.841121: Pseudo dice [0.5905] 
2023-08-07 11:50:34.841171: Epoch time: 63.5 s 
2023-08-07 11:50:34.841212: Yayy! New best EMA pseudo Dice: 0.5743 
2023-08-07 11:50:36.229643:  
2023-08-07 11:50:36.229845: Epoch 76 
2023-08-07 11:50:36.229939: Current learning rate: 0.00097 
2023-08-07 11:51:39.953021: train_loss -0.2626 
2023-08-07 11:51:39.953187: val_loss -0.2637 
2023-08-07 11:51:39.953240: Pseudo dice [0.597] 
2023-08-07 11:51:39.953291: Epoch time: 63.72 s 
2023-08-07 11:51:39.953331: Yayy! New best EMA pseudo Dice: 0.5765 
2023-08-07 11:51:41.342169:  
2023-08-07 11:51:41.342267: Epoch 77 
2023-08-07 11:51:41.342341: Current learning rate: 0.00097 
2023-08-07 11:52:44.808601: train_loss -0.3141 
2023-08-07 11:52:44.808750: val_loss -0.2364 
2023-08-07 11:52:44.808802: Pseudo dice [0.6098] 
2023-08-07 11:52:44.808852: Epoch time: 63.47 s 
2023-08-07 11:52:44.808892: Yayy! New best EMA pseudo Dice: 0.5799 
2023-08-07 11:52:46.333168:  
2023-08-07 11:52:46.333275: Epoch 78 
2023-08-07 11:52:46.333352: Current learning rate: 0.00096 
2023-08-07 11:53:49.989512: train_loss -0.2828 
2023-08-07 11:53:49.989666: val_loss -0.2675 
2023-08-07 11:53:49.989721: Pseudo dice [0.5493] 
2023-08-07 11:53:49.989772: Epoch time: 63.66 s 
2023-08-07 11:53:51.023850:  
2023-08-07 11:53:51.023948: Epoch 79 
2023-08-07 11:53:51.024036: Current learning rate: 0.00096 
2023-08-07 11:54:54.570885: train_loss -0.2497 
2023-08-07 11:54:54.571036: val_loss -0.2567 
2023-08-07 11:54:54.571091: Pseudo dice [0.5741] 
2023-08-07 11:54:54.571142: Epoch time: 63.55 s 
2023-08-07 11:54:55.574330:  
2023-08-07 11:54:55.574512: Epoch 80 
2023-08-07 11:54:55.574608: Current learning rate: 0.00096 
2023-08-07 11:55:59.471700: train_loss -0.2603 
2023-08-07 11:55:59.471985: val_loss -0.4121 
2023-08-07 11:55:59.472126: Pseudo dice [0.7386] 
2023-08-07 11:55:59.472280: Epoch time: 63.9 s 
2023-08-07 11:55:59.472381: Yayy! New best EMA pseudo Dice: 0.5927 
2023-08-07 11:56:00.899379:  
2023-08-07 11:56:00.899481: Epoch 81 
2023-08-07 11:56:00.899568: Current learning rate: 0.00096 
2023-08-07 11:57:04.419494: train_loss -0.2913 
2023-08-07 11:57:04.419681: val_loss -0.3128 
2023-08-07 11:57:04.419734: Pseudo dice [0.5777] 
2023-08-07 11:57:04.419784: Epoch time: 63.52 s 
2023-08-07 11:57:05.426438:  
2023-08-07 11:57:05.426537: Epoch 82 
2023-08-07 11:57:05.426626: Current learning rate: 0.00096 
2023-08-07 11:58:09.208997: train_loss -0.2891 
2023-08-07 11:58:09.209158: val_loss -0.3123 
2023-08-07 11:58:09.209225: Pseudo dice [0.6121] 
2023-08-07 11:58:09.209276: Epoch time: 63.78 s 
2023-08-07 11:58:09.209316: Yayy! New best EMA pseudo Dice: 0.5933 
2023-08-07 11:58:10.737949:  
2023-08-07 11:58:10.738059: Epoch 83 
2023-08-07 11:58:10.738161: Current learning rate: 0.00096 
2023-08-07 11:59:14.674747: train_loss -0.2821 
2023-08-07 11:59:14.674897: val_loss -0.2745 
2023-08-07 11:59:14.674968: Pseudo dice [0.6408] 
2023-08-07 11:59:14.675019: Epoch time: 63.94 s 
2023-08-07 11:59:14.675060: Yayy! New best EMA pseudo Dice: 0.5981 
2023-08-07 11:59:16.014359:  
2023-08-07 11:59:16.014472: Epoch 84 
2023-08-07 11:59:16.014562: Current learning rate: 0.00096 
2023-08-07 12:00:19.791055: train_loss -0.2827 
2023-08-07 12:00:19.791497: val_loss -0.3271 
2023-08-07 12:00:19.791584: Pseudo dice [0.544] 
2023-08-07 12:00:19.791640: Epoch time: 63.78 s 
2023-08-07 12:00:20.743938:  
2023-08-07 12:00:20.744044: Epoch 85 
2023-08-07 12:00:20.744121: Current learning rate: 0.00096 
2023-08-07 12:01:24.629528: train_loss -0.3327 
2023-08-07 12:01:24.629713: val_loss -0.2862 
2023-08-07 12:01:24.629766: Pseudo dice [0.6242] 
2023-08-07 12:01:24.629817: Epoch time: 63.89 s 
2023-08-07 12:01:25.603643:  
2023-08-07 12:01:25.603742: Epoch 86 
2023-08-07 12:01:25.603831: Current learning rate: 0.00096 
2023-08-07 12:02:29.358883: train_loss -0.2732 
2023-08-07 12:02:29.359036: val_loss -0.3432 
2023-08-07 12:02:29.359088: Pseudo dice [0.5339] 
2023-08-07 12:02:29.359158: Epoch time: 63.76 s 
2023-08-07 12:02:30.367624:  
2023-08-07 12:02:30.367717: Epoch 87 
2023-08-07 12:02:30.367793: Current learning rate: 0.00096 
2023-08-07 12:03:34.136648: train_loss -0.2724 
2023-08-07 12:03:34.136795: val_loss -0.3387 
2023-08-07 12:03:34.136848: Pseudo dice [0.6535] 
2023-08-07 12:03:34.136900: Epoch time: 63.77 s 
2023-08-07 12:03:35.095342:  
2023-08-07 12:03:35.095434: Epoch 88 
2023-08-07 12:03:35.095506: Current learning rate: 0.00096 
2023-08-07 12:04:38.735897: train_loss -0.3146 
2023-08-07 12:04:38.736040: val_loss -0.2306 
2023-08-07 12:04:38.736091: Pseudo dice [0.5879] 
2023-08-07 12:04:38.736140: Epoch time: 63.64 s 
2023-08-07 12:04:39.895927:  
2023-08-07 12:04:39.896036: Epoch 89 
2023-08-07 12:04:39.896124: Current learning rate: 0.00096 
2023-08-07 12:05:43.640484: train_loss -0.2827 
2023-08-07 12:05:43.640630: val_loss -0.3193 
2023-08-07 12:05:43.640684: Pseudo dice [0.6735] 
2023-08-07 12:05:43.640737: Epoch time: 63.75 s 
2023-08-07 12:05:43.640777: Yayy! New best EMA pseudo Dice: 0.603 
2023-08-07 12:05:44.957881:  
2023-08-07 12:05:44.957984: Epoch 90 
2023-08-07 12:05:44.958070: Current learning rate: 0.00096 
2023-08-07 12:06:48.697248: train_loss -0.2576 
2023-08-07 12:06:48.697407: val_loss -0.3523 
2023-08-07 12:06:48.697462: Pseudo dice [0.6426] 
2023-08-07 12:06:48.697530: Epoch time: 63.74 s 
2023-08-07 12:06:48.697571: Yayy! New best EMA pseudo Dice: 0.607 
2023-08-07 12:06:49.996949:  
2023-08-07 12:06:49.997206: Epoch 91 
2023-08-07 12:06:49.997365: Current learning rate: 0.00096 
2023-08-07 12:07:53.869095: train_loss -0.3175 
2023-08-07 12:07:53.869241: val_loss -0.3189 
2023-08-07 12:07:53.869294: Pseudo dice [0.6541] 
2023-08-07 12:07:53.869363: Epoch time: 63.87 s 
2023-08-07 12:07:53.869403: Yayy! New best EMA pseudo Dice: 0.6117 
2023-08-07 12:07:55.237323:  
2023-08-07 12:07:55.237418: Epoch 92 
2023-08-07 12:07:55.237493: Current learning rate: 0.00096 
2023-08-07 12:08:58.925725: train_loss -0.2849 
2023-08-07 12:08:58.925900: val_loss -0.2301 
2023-08-07 12:08:58.925955: Pseudo dice [0.5487] 
2023-08-07 12:08:58.926007: Epoch time: 63.69 s 
2023-08-07 12:08:59.861336:  
2023-08-07 12:08:59.861437: Epoch 93 
2023-08-07 12:08:59.861524: Current learning rate: 0.00096 
2023-08-07 12:10:03.712879: train_loss -0.3109 
2023-08-07 12:10:03.713033: val_loss -0.3775 
2023-08-07 12:10:03.713084: Pseudo dice [0.688] 
2023-08-07 12:10:03.713134: Epoch time: 63.85 s 
2023-08-07 12:10:03.713175: Yayy! New best EMA pseudo Dice: 0.6137 
2023-08-07 12:10:05.019538:  
2023-08-07 12:10:05.019657: Epoch 94 
2023-08-07 12:10:05.019837: Current learning rate: 0.00096 
2023-08-07 12:11:08.665512: train_loss -0.2921 
2023-08-07 12:11:08.665656: val_loss -0.3846 
2023-08-07 12:11:08.665725: Pseudo dice [0.7696] 
2023-08-07 12:11:08.665773: Epoch time: 63.65 s 
2023-08-07 12:11:08.665812: Yayy! New best EMA pseudo Dice: 0.6293 
2023-08-07 12:11:10.084777:  
2023-08-07 12:11:10.084883: Epoch 95 
2023-08-07 12:11:10.084975: Current learning rate: 0.00096 
2023-08-07 12:12:13.881320: train_loss -0.2721 
2023-08-07 12:12:13.881478: val_loss -0.276 
2023-08-07 12:12:13.881531: Pseudo dice [0.5635] 
2023-08-07 12:12:13.881581: Epoch time: 63.8 s 
2023-08-07 12:12:14.855226:  
2023-08-07 12:12:14.855506: Epoch 96 
2023-08-07 12:12:14.855701: Current learning rate: 0.00096 
2023-08-07 12:13:18.480397: train_loss -0.2766 
2023-08-07 12:13:18.480542: val_loss -0.3252 
2023-08-07 12:13:18.480593: Pseudo dice [0.5413] 
2023-08-07 12:13:18.480644: Epoch time: 63.63 s 
2023-08-07 12:13:19.464617:  
2023-08-07 12:13:19.464722: Epoch 97 
2023-08-07 12:13:19.464822: Current learning rate: 0.00096 
2023-08-07 12:14:23.267670: train_loss -0.2862 
2023-08-07 12:14:23.267828: val_loss -0.2909 
2023-08-07 12:14:23.267882: Pseudo dice [0.6011] 
2023-08-07 12:14:23.267933: Epoch time: 63.8 s 
2023-08-07 12:14:24.228631:  
2023-08-07 12:14:24.228733: Epoch 98 
2023-08-07 12:14:24.228820: Current learning rate: 0.00096 
2023-08-07 12:15:27.882830: train_loss -0.2932 
2023-08-07 12:15:27.882985: val_loss -0.3178 
2023-08-07 12:15:27.883054: Pseudo dice [0.5958] 
2023-08-07 12:15:27.883104: Epoch time: 63.65 s 
2023-08-07 12:15:28.864973:  
2023-08-07 12:15:28.865070: Epoch 99 
2023-08-07 12:15:28.865244: Current learning rate: 0.00096 
2023-08-07 12:16:32.310747: train_loss -0.317 
2023-08-07 12:16:32.310904: val_loss -0.2589 
2023-08-07 12:16:32.310954: Pseudo dice [0.5477] 
2023-08-07 12:16:32.311020: Epoch time: 63.45 s 
2023-08-07 12:16:33.756833:  
2023-08-07 12:16:33.756932: Epoch 100 
2023-08-07 12:16:33.757006: Current learning rate: 0.00095 
2023-08-07 12:17:37.620280: train_loss -0.2977 
2023-08-07 12:17:37.620435: val_loss -0.297 
2023-08-07 12:17:37.620489: Pseudo dice [0.6078] 
2023-08-07 12:17:37.620542: Epoch time: 63.86 s 
2023-08-07 12:17:38.610971:  
2023-08-07 12:17:38.611081: Epoch 101 
2023-08-07 12:17:38.611171: Current learning rate: 0.00095 
2023-08-07 12:18:42.492718: train_loss -0.307 
2023-08-07 12:18:42.492864: val_loss -0.3426 
2023-08-07 12:18:42.492914: Pseudo dice [0.5691] 
2023-08-07 12:18:42.492964: Epoch time: 63.88 s 
2023-08-07 12:18:43.470149:  
2023-08-07 12:18:43.470255: Epoch 102 
2023-08-07 12:18:43.470330: Current learning rate: 0.00095 
2023-08-07 12:19:47.197415: train_loss -0.2422 
2023-08-07 12:19:47.197560: val_loss -0.2366 
2023-08-07 12:19:47.197609: Pseudo dice [0.6015] 
2023-08-07 12:19:47.197675: Epoch time: 63.73 s 
2023-08-07 12:19:48.183487:  
2023-08-07 12:19:48.183587: Epoch 103 
2023-08-07 12:19:48.183676: Current learning rate: 0.00095 
2023-08-07 12:20:52.010001: train_loss -0.2883 
2023-08-07 12:20:52.010150: val_loss -0.2368 
2023-08-07 12:20:52.010202: Pseudo dice [0.6494] 
2023-08-07 12:20:52.010268: Epoch time: 63.83 s 
2023-08-07 12:20:53.035720:  
2023-08-07 12:20:53.035939: Epoch 104 
2023-08-07 12:20:53.036015: Current learning rate: 0.00095 
2023-08-07 12:21:56.623988: train_loss -0.3016 
2023-08-07 12:21:56.624138: val_loss -0.2979 
2023-08-07 12:21:56.624190: Pseudo dice [0.6345] 
2023-08-07 12:21:56.624241: Epoch time: 63.59 s 
2023-08-07 12:21:57.645611:  
2023-08-07 12:21:57.645708: Epoch 105 
2023-08-07 12:21:57.645786: Current learning rate: 0.00095 
2023-08-07 12:23:01.212812: train_loss -0.3117 
2023-08-07 12:23:01.212977: val_loss -0.2769 
2023-08-07 12:23:01.213030: Pseudo dice [0.6703] 
2023-08-07 12:23:01.213081: Epoch time: 63.57 s 
2023-08-07 12:23:02.373455:  
2023-08-07 12:23:02.373559: Epoch 106 
2023-08-07 12:23:02.373638: Current learning rate: 0.00095 
2023-08-07 12:24:06.350656: train_loss -0.3033 
2023-08-07 12:24:06.351610: val_loss -0.288 
2023-08-07 12:24:06.351701: Pseudo dice [0.6452] 
2023-08-07 12:24:06.351748: Epoch time: 63.98 s 
2023-08-07 12:24:07.316643:  
2023-08-07 12:24:07.316750: Epoch 107 
2023-08-07 12:24:07.316825: Current learning rate: 0.00095 
2023-08-07 12:25:10.881813: train_loss -0.3068 
2023-08-07 12:25:10.882073: val_loss -0.3353 
2023-08-07 12:25:10.882127: Pseudo dice [0.7088] 
2023-08-07 12:25:10.882178: Epoch time: 63.57 s 
2023-08-07 12:25:11.882973:  
2023-08-07 12:25:11.883174: Epoch 108 
2023-08-07 12:25:11.883250: Current learning rate: 0.00095 
2023-08-07 12:26:15.671541: train_loss -0.2588 
2023-08-07 12:26:15.671704: val_loss -0.3422 
2023-08-07 12:26:15.671753: Pseudo dice [0.7681] 
2023-08-07 12:26:15.671804: Epoch time: 63.79 s 
2023-08-07 12:26:15.671844: Yayy! New best EMA pseudo Dice: 0.6415 
2023-08-07 12:26:17.023227:  
2023-08-07 12:26:17.023327: Epoch 109 
2023-08-07 12:26:17.023416: Current learning rate: 0.00095 
2023-08-07 12:27:20.567026: train_loss -0.2435 
2023-08-07 12:27:20.567183: val_loss -0.2438 
2023-08-07 12:27:20.567234: Pseudo dice [0.6145] 
2023-08-07 12:27:20.567286: Epoch time: 63.54 s 
2023-08-07 12:27:21.537213:  
2023-08-07 12:27:21.537307: Epoch 110 
2023-08-07 12:27:21.537382: Current learning rate: 0.00095 
2023-08-07 12:28:25.308799: train_loss -0.2792 
2023-08-07 12:28:25.308948: val_loss -0.3341 
2023-08-07 12:28:25.308999: Pseudo dice [0.7508] 
2023-08-07 12:28:25.309049: Epoch time: 63.77 s 
2023-08-07 12:28:25.309089: Yayy! New best EMA pseudo Dice: 0.65 
2023-08-07 12:28:26.769172:  
2023-08-07 12:28:26.769483: Epoch 111 
2023-08-07 12:28:26.769648: Current learning rate: 0.00095 
2023-08-07 12:29:30.439235: train_loss -0.2953 
2023-08-07 12:29:30.439382: val_loss -0.3302 
2023-08-07 12:29:30.439434: Pseudo dice [0.6908] 
2023-08-07 12:29:30.439484: Epoch time: 63.67 s 
2023-08-07 12:29:30.439525: Yayy! New best EMA pseudo Dice: 0.6541 
2023-08-07 12:29:31.796061:  
2023-08-07 12:29:31.796172: Epoch 112 
2023-08-07 12:29:31.796252: Current learning rate: 0.00095 
2023-08-07 12:30:35.449074: train_loss -0.3138 
2023-08-07 12:30:35.449324: val_loss -0.2522 
2023-08-07 12:30:35.449380: Pseudo dice [0.6887] 
2023-08-07 12:30:35.449431: Epoch time: 63.65 s 
2023-08-07 12:30:35.449472: Yayy! New best EMA pseudo Dice: 0.6575 
2023-08-07 12:30:36.791339:  
2023-08-07 12:30:36.791443: Epoch 113 
2023-08-07 12:30:36.791516: Current learning rate: 0.00095 
2023-08-07 12:31:40.637450: train_loss -0.2918 
2023-08-07 12:31:40.637603: val_loss -0.3418 
2023-08-07 12:31:40.637652: Pseudo dice [0.7162] 
2023-08-07 12:31:40.637719: Epoch time: 63.85 s 
2023-08-07 12:31:40.637758: Yayy! New best EMA pseudo Dice: 0.6634 
2023-08-07 12:31:41.982666:  
2023-08-07 12:31:41.982895: Epoch 114 
2023-08-07 12:31:41.982974: Current learning rate: 0.00095 
2023-08-07 12:32:45.525835: train_loss -0.3252 
2023-08-07 12:32:45.526115: val_loss -0.2959 
2023-08-07 12:32:45.526176: Pseudo dice [0.58] 
2023-08-07 12:32:45.526228: Epoch time: 63.54 s 
2023-08-07 12:32:46.504221:  
2023-08-07 12:32:46.504324: Epoch 115 
2023-08-07 12:32:46.504416: Current learning rate: 0.00095 
2023-08-07 12:33:50.261930: train_loss -0.2978 
2023-08-07 12:33:50.262077: val_loss -0.2501 
2023-08-07 12:33:50.262131: Pseudo dice [0.6465] 
2023-08-07 12:33:50.262181: Epoch time: 63.76 s 
2023-08-07 12:33:51.393336:  
2023-08-07 12:33:51.393444: Epoch 116 
2023-08-07 12:33:51.393535: Current learning rate: 0.00095 
2023-08-07 12:34:55.119826: train_loss -0.2818 
2023-08-07 12:34:55.119983: val_loss -0.3027 
2023-08-07 12:34:55.120039: Pseudo dice [0.6779] 
2023-08-07 12:34:55.120090: Epoch time: 63.73 s 
2023-08-07 12:34:56.152545:  
2023-08-07 12:34:56.152649: Epoch 117 
2023-08-07 12:34:56.152727: Current learning rate: 0.00095 
2023-08-07 12:35:59.840020: train_loss -0.3067 
2023-08-07 12:35:59.840177: val_loss -0.2986 
2023-08-07 12:35:59.840230: Pseudo dice [0.6118] 
2023-08-07 12:35:59.840281: Epoch time: 63.69 s 
2023-08-07 12:36:00.821256:  
2023-08-07 12:36:00.821353: Epoch 118 
2023-08-07 12:36:00.821427: Current learning rate: 0.00095 
2023-08-07 12:37:04.527510: train_loss -0.3011 
2023-08-07 12:37:04.527700: val_loss -0.338 
2023-08-07 12:37:04.527754: Pseudo dice [0.7349] 
2023-08-07 12:37:04.527805: Epoch time: 63.71 s 
2023-08-07 12:37:05.511539:  
2023-08-07 12:37:05.511647: Epoch 119 
2023-08-07 12:37:05.511735: Current learning rate: 0.00095 
2023-08-07 12:38:09.208481: train_loss -0.2911 
2023-08-07 12:38:09.208629: val_loss -0.3297 
2023-08-07 12:38:09.208683: Pseudo dice [0.6946] 
2023-08-07 12:38:09.208732: Epoch time: 63.7 s 
2023-08-07 12:38:09.208771: Yayy! New best EMA pseudo Dice: 0.6638 
2023-08-07 12:38:10.530556:  
2023-08-07 12:38:10.530659: Epoch 120 
2023-08-07 12:38:10.530749: Current learning rate: 0.00095 
2023-08-07 12:39:14.430599: train_loss -0.3069 
2023-08-07 12:39:14.430747: val_loss -0.2919 
2023-08-07 12:39:14.430795: Pseudo dice [0.7093] 
2023-08-07 12:39:14.430862: Epoch time: 63.9 s 
2023-08-07 12:39:14.430902: Yayy! New best EMA pseudo Dice: 0.6683 
2023-08-07 12:39:15.943015:  
2023-08-07 12:39:15.943225: Epoch 121 
2023-08-07 12:39:15.943321: Current learning rate: 0.00095 
2023-08-07 12:40:19.901441: train_loss -0.2955 
2023-08-07 12:40:19.901588: val_loss -0.3145 
2023-08-07 12:40:19.901642: Pseudo dice [0.5839] 
2023-08-07 12:40:19.901693: Epoch time: 63.96 s 
2023-08-07 12:40:20.889681:  
2023-08-07 12:40:20.889867: Epoch 122 
2023-08-07 12:40:20.889960: Current learning rate: 0.00094 
2023-08-07 12:41:24.609635: train_loss -0.3035 
2023-08-07 12:41:24.609783: val_loss -0.3272 
2023-08-07 12:41:24.609833: Pseudo dice [0.6986] 
2023-08-07 12:41:24.609900: Epoch time: 63.72 s 
2023-08-07 12:41:25.594740:  
2023-08-07 12:41:25.594842: Epoch 123 
2023-08-07 12:41:25.594931: Current learning rate: 0.00094 
2023-08-07 12:42:29.268599: train_loss -0.3128 
2023-08-07 12:42:29.268747: val_loss -0.2454 
2023-08-07 12:42:29.268807: Pseudo dice [0.568] 
2023-08-07 12:42:29.268856: Epoch time: 63.67 s 
2023-08-07 12:42:30.243551:  
2023-08-07 12:42:30.243652: Epoch 124 
2023-08-07 12:42:30.243726: Current learning rate: 0.00094 
2023-08-07 12:43:33.890615: train_loss -0.3118 
2023-08-07 12:43:33.890776: val_loss -0.2804 
2023-08-07 12:43:33.890847: Pseudo dice [0.5536] 
2023-08-07 12:43:33.890900: Epoch time: 63.65 s 
2023-08-07 12:43:34.868024:  
2023-08-07 12:43:34.868280: Epoch 125 
2023-08-07 12:43:34.868438: Current learning rate: 0.00094 
2023-08-07 12:44:38.534788: train_loss -0.2946 
2023-08-07 12:44:38.534944: val_loss -0.2774 
2023-08-07 12:44:38.534997: Pseudo dice [0.8277] 
2023-08-07 12:44:38.535048: Epoch time: 63.67 s 
2023-08-07 12:44:39.536501:  
2023-08-07 12:44:39.536599: Epoch 126 
2023-08-07 12:44:39.536671: Current learning rate: 0.00094 
2023-08-07 12:45:43.554072: train_loss -0.2747 
2023-08-07 12:45:43.554399: val_loss -0.3184 
2023-08-07 12:45:43.554489: Pseudo dice [0.627] 
2023-08-07 12:45:43.554542: Epoch time: 64.02 s 
2023-08-07 12:45:44.685228:  
2023-08-07 12:45:44.685486: Epoch 127 
2023-08-07 12:45:44.685635: Current learning rate: 0.00094 
2023-08-07 12:46:48.446240: train_loss -0.3043 
2023-08-07 12:46:48.446387: val_loss -0.2835 
2023-08-07 12:46:48.446457: Pseudo dice [0.5645] 
2023-08-07 12:46:48.446507: Epoch time: 63.76 s 
2023-08-07 12:46:49.452762:  
2023-08-07 12:46:49.452887: Epoch 128 
2023-08-07 12:46:49.453117: Current learning rate: 0.00094 
2023-08-07 12:47:53.107581: train_loss -0.3156 
2023-08-07 12:47:53.107728: val_loss -0.301 
2023-08-07 12:47:53.107779: Pseudo dice [0.588] 
2023-08-07 12:47:53.107828: Epoch time: 63.66 s 
2023-08-07 12:47:54.120811:  
2023-08-07 12:47:54.120909: Epoch 129 
2023-08-07 12:47:54.121003: Current learning rate: 0.00094 
2023-08-07 12:48:58.107055: train_loss -0.2956 
2023-08-07 12:48:58.107203: val_loss -0.2875 
2023-08-07 12:48:58.107254: Pseudo dice [0.7306] 
2023-08-07 12:48:58.107320: Epoch time: 63.99 s 
2023-08-07 12:48:59.111220:  
2023-08-07 12:48:59.111330: Epoch 130 
2023-08-07 12:48:59.111401: Current learning rate: 0.00094 
2023-08-07 12:50:02.981713: train_loss -0.3132 
2023-08-07 12:50:02.981860: val_loss -0.3063 
2023-08-07 12:50:02.981912: Pseudo dice [0.6636] 
2023-08-07 12:50:02.981982: Epoch time: 63.87 s 
2023-08-07 12:50:03.982836:  
2023-08-07 12:50:03.982931: Epoch 131 
2023-08-07 12:50:03.983001: Current learning rate: 0.00094 
2023-08-07 12:51:07.792585: train_loss -0.3293 
2023-08-07 12:51:07.792748: val_loss -0.2868 
2023-08-07 12:51:07.792811: Pseudo dice [0.7134] 
2023-08-07 12:51:07.792862: Epoch time: 63.81 s 
2023-08-07 12:51:08.932920:  
2023-08-07 12:51:08.933023: Epoch 132 
2023-08-07 12:51:08.933112: Current learning rate: 0.00094 
2023-08-07 12:52:12.770331: train_loss -0.2822 
2023-08-07 12:52:12.770478: val_loss -0.3017 
2023-08-07 12:52:12.770527: Pseudo dice [0.6604] 
2023-08-07 12:52:12.770592: Epoch time: 63.84 s 
2023-08-07 12:52:13.743459:  
2023-08-07 12:52:13.743566: Epoch 133 
2023-08-07 12:52:13.743655: Current learning rate: 0.00094 
2023-08-07 12:53:17.238612: train_loss -0.2611 
2023-08-07 12:53:17.238914: val_loss -0.2747 
2023-08-07 12:53:17.247194: Pseudo dice [0.5877] 
2023-08-07 12:53:17.247307: Epoch time: 63.5 s 
2023-08-07 12:53:18.244064:  
2023-08-07 12:53:18.244167: Epoch 134 
2023-08-07 12:53:18.244243: Current learning rate: 0.00094 
2023-08-07 12:54:22.014045: train_loss -0.3194 
2023-08-07 12:54:22.014189: val_loss -0.2907 
2023-08-07 12:54:22.014256: Pseudo dice [0.7142] 
2023-08-07 12:54:22.014306: Epoch time: 63.77 s 
2023-08-07 12:54:23.018322:  
2023-08-07 12:54:23.018502: Epoch 135 
2023-08-07 12:54:23.018597: Current learning rate: 0.00094 
2023-08-07 12:55:26.932716: train_loss -0.3248 
2023-08-07 12:55:26.932869: val_loss -0.2466 
2023-08-07 12:55:26.932918: Pseudo dice [0.6173] 
2023-08-07 12:55:26.932984: Epoch time: 63.92 s 
2023-08-07 12:55:27.962268:  
2023-08-07 12:55:27.962365: Epoch 136 
2023-08-07 12:55:27.962455: Current learning rate: 0.00094 
2023-08-07 12:56:31.745236: train_loss -0.3341 
2023-08-07 12:56:31.745378: val_loss -0.3113 
2023-08-07 12:56:31.745426: Pseudo dice [0.698] 
2023-08-07 12:56:31.745492: Epoch time: 63.78 s 
2023-08-07 12:56:32.734179:  
2023-08-07 12:56:32.734272: Epoch 137 
2023-08-07 12:56:32.734346: Current learning rate: 0.00094 
2023-08-07 12:57:36.697922: train_loss -0.2781 
2023-08-07 12:57:36.698069: val_loss -0.2892 
2023-08-07 12:57:36.698137: Pseudo dice [0.6747] 
2023-08-07 12:57:36.698188: Epoch time: 63.96 s 
2023-08-07 12:57:37.692500:  
2023-08-07 12:57:37.692609: Epoch 138 
2023-08-07 12:57:37.692698: Current learning rate: 0.00094 
2023-08-07 12:58:41.623922: train_loss -0.3199 
2023-08-07 12:58:41.624068: val_loss -0.3637 
2023-08-07 12:58:41.624119: Pseudo dice [0.6803] 
2023-08-07 12:58:41.624168: Epoch time: 63.93 s 
2023-08-07 12:58:42.636231:  
2023-08-07 12:58:42.636342: Epoch 139 
2023-08-07 12:58:42.636416: Current learning rate: 0.00094 
2023-08-07 12:59:46.396695: train_loss -0.3276 
2023-08-07 12:59:46.396839: val_loss -0.2642 
2023-08-07 12:59:46.396890: Pseudo dice [0.5833] 
2023-08-07 12:59:46.396939: Epoch time: 63.76 s 
2023-08-07 12:59:47.390743:  
2023-08-07 12:59:47.390921: Epoch 140 
2023-08-07 12:59:47.391002: Current learning rate: 0.00094 
2023-08-07 13:00:51.162588: train_loss -0.3057 
2023-08-07 13:00:51.162735: val_loss -0.3077 
2023-08-07 13:00:51.162804: Pseudo dice [0.5955] 
2023-08-07 13:00:51.162855: Epoch time: 63.77 s 
2023-08-07 13:00:52.156217:  
2023-08-07 13:00:52.156316: Epoch 141 
2023-08-07 13:00:52.156386: Current learning rate: 0.00094 
2023-08-07 13:01:55.935382: train_loss -0.3224 
2023-08-07 13:01:55.935548: val_loss -0.2843 
2023-08-07 13:01:55.935620: Pseudo dice [0.5129] 
2023-08-07 13:01:55.935671: Epoch time: 63.78 s 
2023-08-07 13:01:56.946718:  
2023-08-07 13:01:56.946812: Epoch 142 
2023-08-07 13:01:56.946882: Current learning rate: 0.00094 
2023-08-07 13:03:00.799017: train_loss -0.3075 
2023-08-07 13:03:00.799157: val_loss -0.3277 
2023-08-07 13:03:00.799206: Pseudo dice [0.6551] 
2023-08-07 13:03:00.799270: Epoch time: 63.85 s 
2023-08-07 13:03:01.954829:  
2023-08-07 13:03:01.954943: Epoch 143 
2023-08-07 13:03:01.955019: Current learning rate: 0.00094 
2023-08-07 13:04:05.818283: train_loss -0.2866 
2023-08-07 13:04:05.818429: val_loss -0.2665 
2023-08-07 13:04:05.818498: Pseudo dice [0.6951] 
2023-08-07 13:04:05.818547: Epoch time: 63.86 s 
2023-08-07 13:04:06.874660:  
2023-08-07 13:04:06.874947: Epoch 144 
2023-08-07 13:04:06.875111: Current learning rate: 0.00093 
2023-08-07 13:05:10.596005: train_loss -0.3166 
2023-08-07 13:05:10.596156: val_loss -0.285 
2023-08-07 13:05:10.596207: Pseudo dice [0.7063] 
2023-08-07 13:05:10.596257: Epoch time: 63.72 s 
2023-08-07 13:05:11.589820:  
2023-08-07 13:05:11.589920: Epoch 145 
2023-08-07 13:05:11.590005: Current learning rate: 0.00093 
2023-08-07 13:06:15.299808: train_loss -0.3116 
2023-08-07 13:06:15.299957: val_loss -0.2502 
2023-08-07 13:06:15.300010: Pseudo dice [0.5548] 
2023-08-07 13:06:15.300061: Epoch time: 63.71 s 
2023-08-07 13:06:16.318165:  
2023-08-07 13:06:16.318263: Epoch 146 
2023-08-07 13:06:16.318354: Current learning rate: 0.00093 
2023-08-07 13:07:20.132653: train_loss -0.3056 
2023-08-07 13:07:20.132805: val_loss -0.2237 
2023-08-07 13:07:20.132861: Pseudo dice [0.5783] 
2023-08-07 13:07:20.132910: Epoch time: 63.82 s 
2023-08-07 13:07:21.149758:  
2023-08-07 13:07:21.149854: Epoch 147 
2023-08-07 13:07:21.149943: Current learning rate: 0.00093 
2023-08-07 13:08:24.815714: train_loss -0.2956 
2023-08-07 13:08:24.815861: val_loss -0.2956 
2023-08-07 13:08:24.815916: Pseudo dice [0.7606] 
2023-08-07 13:08:24.815970: Epoch time: 63.67 s 
2023-08-07 13:08:25.977926:  
2023-08-07 13:08:25.978014: Epoch 148 
2023-08-07 13:08:25.978106: Current learning rate: 0.00093 
2023-08-07 13:09:29.763885: train_loss -0.304 
2023-08-07 13:09:29.764075: val_loss -0.3024 
2023-08-07 13:09:29.764128: Pseudo dice [0.7061] 
2023-08-07 13:09:29.764179: Epoch time: 63.79 s 
2023-08-07 13:09:30.757319:  
2023-08-07 13:09:30.757418: Epoch 149 
2023-08-07 13:09:30.757491: Current learning rate: 0.00093 
2023-08-07 13:10:34.619514: train_loss -0.3124 
2023-08-07 13:10:34.619694: val_loss -0.3783 
2023-08-07 13:10:34.619746: Pseudo dice [0.7079] 
2023-08-07 13:10:34.619795: Epoch time: 63.86 s 
2023-08-07 13:10:35.984588:  
2023-08-07 13:10:35.984766: Epoch 150 
2023-08-07 13:10:35.984843: Current learning rate: 0.00093 
2023-08-07 13:11:39.822783: train_loss -0.2685 
2023-08-07 13:11:39.822942: val_loss -0.3157 
2023-08-07 13:11:39.822992: Pseudo dice [0.6247] 
2023-08-07 13:11:39.823060: Epoch time: 63.84 s 
2023-08-07 13:11:40.816258:  
2023-08-07 13:11:40.816360: Epoch 151 
2023-08-07 13:11:40.816431: Current learning rate: 0.00093 
2023-08-07 13:12:44.542106: train_loss -0.3009 
2023-08-07 13:12:44.542259: val_loss -0.2943 
2023-08-07 13:12:44.542331: Pseudo dice [0.5276] 
2023-08-07 13:12:44.542382: Epoch time: 63.73 s 
2023-08-07 13:12:45.571473:  
2023-08-07 13:12:45.571843: Epoch 152 
2023-08-07 13:12:45.572054: Current learning rate: 0.00093 
2023-08-07 13:13:49.403007: train_loss -0.2883 
2023-08-07 13:13:49.403156: val_loss -0.2414 
2023-08-07 13:13:49.403204: Pseudo dice [0.7474] 
2023-08-07 13:13:49.403270: Epoch time: 63.83 s 
2023-08-07 13:13:50.568150:  
2023-08-07 13:13:50.568340: Epoch 153 
2023-08-07 13:13:50.568436: Current learning rate: 0.00093 
2023-08-07 13:14:54.386848: train_loss -0.3017 
2023-08-07 13:14:54.387000: val_loss -0.2888 
2023-08-07 13:14:54.387049: Pseudo dice [0.7045] 
2023-08-07 13:14:54.387098: Epoch time: 63.82 s 
2023-08-07 13:14:55.432728:  
2023-08-07 13:14:55.432857: Epoch 154 
2023-08-07 13:14:55.432944: Current learning rate: 0.00093 
2023-08-07 13:15:59.074843: train_loss -0.3523 
2023-08-07 13:15:59.074987: val_loss -0.2995 
2023-08-07 13:15:59.075046: Pseudo dice [0.5995] 
2023-08-07 13:15:59.075112: Epoch time: 63.64 s 
2023-08-07 13:16:00.094997:  
2023-08-07 13:16:00.095241: Epoch 155 
2023-08-07 13:16:00.095429: Current learning rate: 0.00093 
2023-08-07 13:17:03.692718: train_loss -0.2997 
2023-08-07 13:17:03.692893: val_loss -0.2958 
2023-08-07 13:17:03.692945: Pseudo dice [0.6636] 
2023-08-07 13:17:03.692994: Epoch time: 63.6 s 
2023-08-07 13:17:04.717619:  
2023-08-07 13:17:04.717746: Epoch 156 
2023-08-07 13:17:04.717820: Current learning rate: 0.00093 
2023-08-07 13:18:08.412521: train_loss -0.2871 
2023-08-07 13:18:08.412675: val_loss -0.2853 
2023-08-07 13:18:08.412818: Pseudo dice [0.6724] 
2023-08-07 13:18:08.412909: Epoch time: 63.7 s 
2023-08-07 13:18:09.427024:  
2023-08-07 13:18:09.427237: Epoch 157 
2023-08-07 13:18:09.427313: Current learning rate: 0.00093 
2023-08-07 13:19:13.285911: train_loss -0.3005 
2023-08-07 13:19:13.286083: val_loss -0.3139 
2023-08-07 13:19:13.286152: Pseudo dice [0.6298] 
2023-08-07 13:19:13.286203: Epoch time: 63.86 s 
2023-08-07 13:19:14.454391:  
2023-08-07 13:19:14.454499: Epoch 158 
2023-08-07 13:19:14.454603: Current learning rate: 0.00093 
2023-08-07 13:20:18.307369: train_loss -0.335 
2023-08-07 13:20:18.307523: val_loss -0.3367 
2023-08-07 13:20:18.307601: Pseudo dice [0.7555] 
2023-08-07 13:20:18.307653: Epoch time: 63.85 s 
2023-08-07 13:20:19.356885:  
2023-08-07 13:20:19.356982: Epoch 159 
2023-08-07 13:20:19.357070: Current learning rate: 0.00093 
2023-08-07 13:21:23.045994: train_loss -0.2702 
2023-08-07 13:21:23.046143: val_loss -0.3531 
2023-08-07 13:21:23.046190: Pseudo dice [0.7266] 
2023-08-07 13:21:23.046255: Epoch time: 63.69 s 
2023-08-07 13:21:23.046294: Yayy! New best EMA pseudo Dice: 0.6691 
2023-08-07 13:21:24.396537:  
2023-08-07 13:21:24.396641: Epoch 160 
2023-08-07 13:21:24.396715: Current learning rate: 0.00093 
2023-08-07 13:22:27.963692: train_loss -0.2735 
2023-08-07 13:22:27.963841: val_loss -0.3204 
2023-08-07 13:22:27.963895: Pseudo dice [0.7529] 
2023-08-07 13:22:27.963945: Epoch time: 63.57 s 
2023-08-07 13:22:27.963985: Yayy! New best EMA pseudo Dice: 0.6775 
2023-08-07 13:22:29.331360:  
2023-08-07 13:22:29.331455: Epoch 161 
2023-08-07 13:22:29.331529: Current learning rate: 0.00093 
2023-08-07 13:23:33.151065: train_loss -0.3029 
2023-08-07 13:23:33.151212: val_loss -0.3541 
2023-08-07 13:23:33.151262: Pseudo dice [0.7011] 
2023-08-07 13:23:33.151312: Epoch time: 63.82 s 
2023-08-07 13:23:33.151351: Yayy! New best EMA pseudo Dice: 0.6798 
2023-08-07 13:23:34.550743:  
2023-08-07 13:23:34.550842: Epoch 162 
2023-08-07 13:23:34.550933: Current learning rate: 0.00093 
2023-08-07 13:24:38.304559: train_loss -0.3246 
2023-08-07 13:24:38.304706: val_loss -0.3499 
2023-08-07 13:24:38.304760: Pseudo dice [0.555] 
2023-08-07 13:24:38.304811: Epoch time: 63.75 s 
2023-08-07 13:24:39.482826:  
2023-08-07 13:24:39.483038: Epoch 163 
2023-08-07 13:24:39.483115: Current learning rate: 0.00093 
2023-08-07 13:25:43.412774: train_loss -0.3202 
2023-08-07 13:25:43.412924: val_loss -0.3164 
2023-08-07 13:25:43.412976: Pseudo dice [0.7163] 
2023-08-07 13:25:43.413027: Epoch time: 63.93 s 
2023-08-07 13:25:44.416489:  
2023-08-07 13:25:44.416707: Epoch 164 
2023-08-07 13:25:44.416826: Current learning rate: 0.00093 
2023-08-07 13:26:48.082769: train_loss -0.3281 
2023-08-07 13:26:48.082934: val_loss -0.2432 
2023-08-07 13:26:48.082988: Pseudo dice [0.643] 
2023-08-07 13:26:48.083040: Epoch time: 63.67 s 
2023-08-07 13:26:49.061657:  
2023-08-07 13:26:49.061750: Epoch 165 
2023-08-07 13:26:49.061819: Current learning rate: 0.00093 
2023-08-07 13:27:52.917113: train_loss -0.3075 
2023-08-07 13:27:52.917285: val_loss -0.3334 
2023-08-07 13:27:52.917338: Pseudo dice [0.6341] 
2023-08-07 13:27:52.917390: Epoch time: 63.86 s 
2023-08-07 13:27:53.899996:  
2023-08-07 13:27:53.900090: Epoch 166 
2023-08-07 13:27:53.900164: Current learning rate: 0.00092 
2023-08-07 13:28:57.509900: train_loss -0.2898 
2023-08-07 13:28:57.510053: val_loss -0.3092 
2023-08-07 13:28:57.510104: Pseudo dice [0.6987] 
2023-08-07 13:28:57.510163: Epoch time: 63.61 s 
2023-08-07 13:28:58.495421:  
2023-08-07 13:28:58.495679: Epoch 167 
2023-08-07 13:28:58.495936: Current learning rate: 0.00092 
2023-08-07 13:30:02.179307: train_loss -0.3053 
2023-08-07 13:30:02.179460: val_loss -0.3354 
2023-08-07 13:30:02.179511: Pseudo dice [0.76] 
2023-08-07 13:30:02.179585: Epoch time: 63.68 s 
2023-08-07 13:30:03.334002:  
2023-08-07 13:30:03.334108: Epoch 168 
2023-08-07 13:30:03.334180: Current learning rate: 0.00092 
2023-08-07 13:31:07.083532: train_loss -0.3266 
2023-08-07 13:31:07.083710: val_loss -0.2957 
2023-08-07 13:31:07.083761: Pseudo dice [0.6132] 
2023-08-07 13:31:07.083813: Epoch time: 63.75 s 
2023-08-07 13:31:08.080020:  
2023-08-07 13:31:08.080120: Epoch 169 
2023-08-07 13:31:08.080234: Current learning rate: 0.00092 
2023-08-07 13:32:11.775152: train_loss -0.3302 
2023-08-07 13:32:11.775301: val_loss -0.3644 
2023-08-07 13:32:11.775354: Pseudo dice [0.7082] 
2023-08-07 13:32:11.775404: Epoch time: 63.7 s 
2023-08-07 13:32:12.779311:  
2023-08-07 13:32:12.779676: Epoch 170 
2023-08-07 13:32:12.779843: Current learning rate: 0.00092 
2023-08-07 13:33:16.281659: train_loss -0.3182 
2023-08-07 13:33:16.281808: val_loss -0.3153 
2023-08-07 13:33:16.281858: Pseudo dice [0.7167] 
2023-08-07 13:33:16.281909: Epoch time: 63.5 s 
2023-08-07 13:33:17.282250:  
2023-08-07 13:33:17.282347: Epoch 171 
2023-08-07 13:33:17.282433: Current learning rate: 0.00092 
2023-08-07 13:34:21.092695: train_loss -0.2941 
2023-08-07 13:34:21.092860: val_loss -0.3193 
2023-08-07 13:34:21.092928: Pseudo dice [0.6637] 
2023-08-07 13:34:21.092979: Epoch time: 63.81 s 
2023-08-07 13:34:22.119940:  
2023-08-07 13:34:22.120031: Epoch 172 
2023-08-07 13:34:22.120116: Current learning rate: 0.00092 
2023-08-07 13:35:25.751426: train_loss -0.2927 
2023-08-07 13:35:25.751576: val_loss -0.3641 
2023-08-07 13:35:25.751644: Pseudo dice [0.7003] 
2023-08-07 13:35:25.751694: Epoch time: 63.63 s 
2023-08-07 13:35:25.751735: Yayy! New best EMA pseudo Dice: 0.6801 
2023-08-07 13:35:27.297693:  
2023-08-07 13:35:27.297794: Epoch 173 
2023-08-07 13:35:27.297867: Current learning rate: 0.00092 
2023-08-07 13:36:30.851660: train_loss -0.3283 
2023-08-07 13:36:30.851817: val_loss -0.3817 
2023-08-07 13:36:30.851868: Pseudo dice [0.7881] 
2023-08-07 13:36:30.851920: Epoch time: 63.55 s 
2023-08-07 13:36:30.851960: Yayy! New best EMA pseudo Dice: 0.6909 
2023-08-07 13:36:32.243945:  
2023-08-07 13:36:32.244146: Epoch 174 
2023-08-07 13:36:32.244222: Current learning rate: 0.00092 
2023-08-07 13:37:35.965835: train_loss -0.3263 
2023-08-07 13:37:35.965982: val_loss -0.3186 
2023-08-07 13:37:35.966031: Pseudo dice [0.7363] 
2023-08-07 13:37:35.966098: Epoch time: 63.72 s 
2023-08-07 13:37:35.966137: Yayy! New best EMA pseudo Dice: 0.6955 
2023-08-07 13:37:37.326926:  
2023-08-07 13:37:37.327027: Epoch 175 
2023-08-07 13:37:37.327100: Current learning rate: 0.00092 
2023-08-07 13:38:40.968331: train_loss -0.3359 
2023-08-07 13:38:40.968477: val_loss -0.3146 
2023-08-07 13:38:40.968528: Pseudo dice [0.7877] 
2023-08-07 13:38:40.968579: Epoch time: 63.64 s 
2023-08-07 13:38:40.968619: Yayy! New best EMA pseudo Dice: 0.7047 
2023-08-07 13:38:42.323927:  
2023-08-07 13:38:42.324138: Epoch 176 
2023-08-07 13:38:42.324217: Current learning rate: 0.00092 
2023-08-07 13:39:45.960032: train_loss -0.2859 
2023-08-07 13:39:45.960183: val_loss -0.2841 
2023-08-07 13:39:45.960234: Pseudo dice [0.4323] 
2023-08-07 13:39:45.960285: Epoch time: 63.64 s 
2023-08-07 13:39:47.094665:  
2023-08-07 13:39:47.094764: Epoch 177 
2023-08-07 13:39:47.094835: Current learning rate: 0.00092 
2023-08-07 13:40:50.601380: train_loss -0.3373 
2023-08-07 13:40:50.601555: val_loss -0.3369 
2023-08-07 13:40:50.601609: Pseudo dice [0.7725] 
2023-08-07 13:40:50.601659: Epoch time: 63.51 s 
2023-08-07 13:40:51.600482:  
2023-08-07 13:40:51.600583: Epoch 178 
2023-08-07 13:40:51.600683: Current learning rate: 0.00092 
2023-08-07 13:41:55.076247: train_loss -0.3229 
2023-08-07 13:41:55.076538: val_loss -0.3265 
2023-08-07 13:41:55.076602: Pseudo dice [0.6583] 
2023-08-07 13:41:55.076654: Epoch time: 63.48 s 
2023-08-07 13:41:56.109416:  
2023-08-07 13:41:56.109512: Epoch 179 
2023-08-07 13:41:56.109583: Current learning rate: 0.00092 
2023-08-07 13:42:59.680941: train_loss -0.3132 
2023-08-07 13:42:59.681091: val_loss -0.3883 
2023-08-07 13:42:59.681143: Pseudo dice [0.6969] 
2023-08-07 13:42:59.681195: Epoch time: 63.57 s 
2023-08-07 13:43:00.735754:  
2023-08-07 13:43:00.736083: Epoch 180 
2023-08-07 13:43:00.736161: Current learning rate: 0.00092 
2023-08-07 13:44:04.358366: train_loss -0.3079 
2023-08-07 13:44:04.358648: val_loss -0.3176 
2023-08-07 13:44:04.358701: Pseudo dice [0.6904] 
2023-08-07 13:44:04.358753: Epoch time: 63.62 s 
2023-08-07 13:44:05.358058:  
2023-08-07 13:44:05.358152: Epoch 181 
2023-08-07 13:44:05.358225: Current learning rate: 0.00092 
2023-08-07 13:45:08.785414: train_loss -0.3125 
2023-08-07 13:45:08.785573: val_loss -0.3785 
2023-08-07 13:45:08.785626: Pseudo dice [0.767] 
2023-08-07 13:45:08.785677: Epoch time: 63.43 s 
2023-08-07 13:45:09.797591:  
2023-08-07 13:45:09.797688: Epoch 182 
2023-08-07 13:45:09.797776: Current learning rate: 0.00092 
2023-08-07 13:46:13.434937: train_loss -0.2938 
2023-08-07 13:46:13.435086: val_loss -0.3746 
2023-08-07 13:46:13.435153: Pseudo dice [0.8104] 
2023-08-07 13:46:13.435203: Epoch time: 63.64 s 
2023-08-07 13:46:13.435245: Yayy! New best EMA pseudo Dice: 0.7056 
2023-08-07 13:46:14.921779:  
2023-08-07 13:46:14.921888: Epoch 183 
2023-08-07 13:46:14.921959: Current learning rate: 0.00092 
2023-08-07 13:47:18.512616: train_loss -0.3191 
2023-08-07 13:47:18.512800: val_loss -0.2747 
2023-08-07 13:47:18.512854: Pseudo dice [0.7833] 
2023-08-07 13:47:18.512905: Epoch time: 63.59 s 
2023-08-07 13:47:18.512946: Yayy! New best EMA pseudo Dice: 0.7134 
2023-08-07 13:47:19.899326:  
2023-08-07 13:47:19.899570: Epoch 184 
2023-08-07 13:47:19.899665: Current learning rate: 0.00092 
2023-08-07 13:48:23.493184: train_loss -0.3088 
2023-08-07 13:48:23.493334: val_loss -0.3059 
2023-08-07 13:48:23.493385: Pseudo dice [0.7361] 
2023-08-07 13:48:23.493436: Epoch time: 63.59 s 
2023-08-07 13:48:23.493477: Yayy! New best EMA pseudo Dice: 0.7157 
2023-08-07 13:48:24.823109:  
2023-08-07 13:48:24.823298: Epoch 185 
2023-08-07 13:48:24.823376: Current learning rate: 0.00092 
2023-08-07 13:49:28.242452: train_loss -0.3257 
2023-08-07 13:49:28.242625: val_loss -0.3482 
2023-08-07 13:49:28.242678: Pseudo dice [0.8304] 
2023-08-07 13:49:28.242728: Epoch time: 63.42 s 
2023-08-07 13:49:28.242771: Yayy! New best EMA pseudo Dice: 0.7271 
2023-08-07 13:49:29.594790:  
2023-08-07 13:49:29.594902: Epoch 186 
2023-08-07 13:49:29.595074: Current learning rate: 0.00092 
2023-08-07 13:50:33.125261: train_loss -0.3084 
2023-08-07 13:50:33.125417: val_loss -0.2865 
2023-08-07 13:50:33.125469: Pseudo dice [0.6041] 
2023-08-07 13:50:33.125519: Epoch time: 63.53 s 
2023-08-07 13:50:34.134162:  
2023-08-07 13:50:34.134257: Epoch 187 
2023-08-07 13:50:34.134371: Current learning rate: 0.00092 
2023-08-07 13:51:37.487922: train_loss -0.3284 
2023-08-07 13:51:37.488086: val_loss -0.3063 
2023-08-07 13:51:37.488142: Pseudo dice [0.8084] 
2023-08-07 13:51:37.488194: Epoch time: 63.35 s 
2023-08-07 13:51:38.711252:  
2023-08-07 13:51:38.711355: Epoch 188 
2023-08-07 13:51:38.711431: Current learning rate: 0.00091 
2023-08-07 13:52:42.306832: train_loss -0.337 
2023-08-07 13:52:42.306991: val_loss -0.3486 
2023-08-07 13:52:42.307043: Pseudo dice [0.6369] 
2023-08-07 13:52:42.307095: Epoch time: 63.6 s 
2023-08-07 13:52:43.326408:  
2023-08-07 13:52:43.326504: Epoch 189 
2023-08-07 13:52:43.326573: Current learning rate: 0.00091 
2023-08-07 13:53:46.819450: train_loss -0.3133 
2023-08-07 13:53:46.819612: val_loss -0.3413 
2023-08-07 13:53:46.819681: Pseudo dice [0.607] 
2023-08-07 13:53:46.819731: Epoch time: 63.49 s 
2023-08-07 13:53:47.837499:  
2023-08-07 13:53:47.837601: Epoch 190 
2023-08-07 13:53:47.837689: Current learning rate: 0.00091 
2023-08-07 13:54:51.157536: train_loss -0.3145 
2023-08-07 13:54:51.157695: val_loss -0.2776 
2023-08-07 13:54:51.157761: Pseudo dice [0.7644] 
2023-08-07 13:54:51.157812: Epoch time: 63.32 s 
2023-08-07 13:54:52.176598:  
2023-08-07 13:54:52.176777: Epoch 191 
2023-08-07 13:54:52.176852: Current learning rate: 0.00091 
2023-08-07 13:55:55.646309: train_loss -0.3281 
2023-08-07 13:55:55.646458: val_loss -0.3767 
2023-08-07 13:55:55.646508: Pseudo dice [0.605] 
2023-08-07 13:55:55.646575: Epoch time: 63.47 s 
2023-08-07 13:55:56.688904:  
2023-08-07 13:55:56.689008: Epoch 192 
2023-08-07 13:55:56.689080: Current learning rate: 0.00091 
2023-08-07 13:56:59.921234: train_loss -0.2762 
2023-08-07 13:56:59.921398: val_loss -0.2947 
2023-08-07 13:56:59.921448: Pseudo dice [0.7084] 
2023-08-07 13:56:59.921498: Epoch time: 63.23 s 
2023-08-07 13:57:01.084342:  
2023-08-07 13:57:01.084447: Epoch 193 
2023-08-07 13:57:01.084523: Current learning rate: 0.00091 
2023-08-07 13:58:04.537865: train_loss -0.3639 
2023-08-07 13:58:04.538048: val_loss -0.3418 
2023-08-07 13:58:04.538100: Pseudo dice [0.7488] 
2023-08-07 13:58:04.538152: Epoch time: 63.45 s 
2023-08-07 13:58:05.577150:  
2023-08-07 13:58:05.577254: Epoch 194 
2023-08-07 13:58:05.577346: Current learning rate: 0.00091 
2023-08-07 13:59:09.247400: train_loss -0.3359 
2023-08-07 13:59:09.247577: val_loss -0.284 
2023-08-07 13:59:09.247634: Pseudo dice [0.7126] 
2023-08-07 13:59:09.247687: Epoch time: 63.67 s 
2023-08-07 13:59:10.260045:  
2023-08-07 13:59:10.260250: Epoch 195 
2023-08-07 13:59:10.260331: Current learning rate: 0.00091 
2023-08-07 14:00:13.795450: train_loss -0.3018 
2023-08-07 14:00:13.795756: val_loss -0.295 
2023-08-07 14:00:13.795813: Pseudo dice [0.6907] 
2023-08-07 14:00:13.795866: Epoch time: 63.54 s 
2023-08-07 14:00:14.806162:  
2023-08-07 14:00:14.806368: Epoch 196 
2023-08-07 14:00:14.806448: Current learning rate: 0.00091 
2023-08-07 14:01:18.141660: train_loss -0.2881 
2023-08-07 14:01:18.141810: val_loss -0.3669 
2023-08-07 14:01:18.141878: Pseudo dice [0.7696] 
2023-08-07 14:01:18.141929: Epoch time: 63.34 s 
2023-08-07 14:01:19.202399:  
2023-08-07 14:01:19.202503: Epoch 197 
2023-08-07 14:01:19.202616: Current learning rate: 0.00091 
2023-08-07 14:02:22.493648: train_loss -0.2953 
2023-08-07 14:02:22.493802: val_loss -0.3127 
2023-08-07 14:02:22.493856: Pseudo dice [0.7397] 
2023-08-07 14:02:22.493911: Epoch time: 63.29 s 
2023-08-07 14:02:23.506607:  
2023-08-07 14:02:23.506773: Epoch 198 
2023-08-07 14:02:23.506847: Current learning rate: 0.00091 
2023-08-07 14:03:26.883640: train_loss -0.3144 
2023-08-07 14:03:26.883799: val_loss -0.3561 
2023-08-07 14:03:26.883854: Pseudo dice [0.7208] 
2023-08-07 14:03:26.883904: Epoch time: 63.38 s 
2023-08-07 14:03:28.069522:  
2023-08-07 14:03:28.069620: Epoch 199 
2023-08-07 14:03:28.069710: Current learning rate: 0.00091 
2023-08-07 14:04:31.504440: train_loss -0.296 
2023-08-07 14:04:31.504594: val_loss -0.2952 
2023-08-07 14:04:31.504648: Pseudo dice [0.7643] 
2023-08-07 14:04:31.504699: Epoch time: 63.44 s 
2023-08-07 14:04:32.854288:  
2023-08-07 14:04:32.854385: Epoch 200 
2023-08-07 14:04:32.854475: Current learning rate: 0.00091 
2023-08-07 14:05:36.166833: train_loss -0.2852 
2023-08-07 14:05:36.166993: val_loss -0.2932 
2023-08-07 14:05:36.167047: Pseudo dice [0.6413] 
2023-08-07 14:05:36.167101: Epoch time: 63.31 s 
2023-08-07 14:05:37.197550:  
2023-08-07 14:05:37.197645: Epoch 201 
2023-08-07 14:05:37.197733: Current learning rate: 0.00091 
2023-08-07 14:06:40.522775: train_loss -0.2808 
2023-08-07 14:06:40.522919: val_loss -0.3096 
2023-08-07 14:06:40.522986: Pseudo dice [0.7011] 
2023-08-07 14:06:40.523037: Epoch time: 63.33 s 
2023-08-07 14:06:41.533955:  
2023-08-07 14:06:41.534052: Epoch 202 
2023-08-07 14:06:41.534138: Current learning rate: 0.00091 
2023-08-07 14:07:45.141734: train_loss -0.334 
2023-08-07 14:07:45.141917: val_loss -0.2836 
2023-08-07 14:07:45.141970: Pseudo dice [0.7315] 
2023-08-07 14:07:45.142021: Epoch time: 63.61 s 
2023-08-07 14:07:46.183088:  
2023-08-07 14:07:46.183177: Epoch 203 
2023-08-07 14:07:46.183248: Current learning rate: 0.00091 
2023-08-07 14:08:49.691031: train_loss -0.31 
2023-08-07 14:08:49.691190: val_loss -0.3275 
2023-08-07 14:08:49.691269: Pseudo dice [0.7872] 
2023-08-07 14:08:49.691320: Epoch time: 63.51 s 
2023-08-07 14:08:50.879871:  
2023-08-07 14:08:50.879972: Epoch 204 
2023-08-07 14:08:50.880052: Current learning rate: 0.00091 
2023-08-07 14:09:54.376071: train_loss -0.3466 
2023-08-07 14:09:54.376221: val_loss -0.3664 
2023-08-07 14:09:54.376282: Pseudo dice [0.7122] 
2023-08-07 14:09:54.376332: Epoch time: 63.5 s 
2023-08-07 14:09:55.386695:  
2023-08-07 14:09:55.386796: Epoch 205 
2023-08-07 14:09:55.386885: Current learning rate: 0.00091 
2023-08-07 14:10:58.672750: train_loss -0.3085 
2023-08-07 14:10:58.672906: val_loss -0.2943 
2023-08-07 14:10:58.672955: Pseudo dice [0.7172] 
2023-08-07 14:10:58.673022: Epoch time: 63.29 s 
2023-08-07 14:10:59.678782:  
2023-08-07 14:10:59.679038: Epoch 206 
2023-08-07 14:10:59.679261: Current learning rate: 0.00091 
2023-08-07 14:12:03.277304: train_loss -0.3155 
2023-08-07 14:12:03.277446: val_loss -0.3649 
2023-08-07 14:12:03.277497: Pseudo dice [0.7759] 
2023-08-07 14:12:03.277575: Epoch time: 63.6 s 
2023-08-07 14:12:04.218139:  
2023-08-07 14:12:04.218232: Epoch 207 
2023-08-07 14:12:04.218304: Current learning rate: 0.00091 
2023-08-07 14:13:07.759595: train_loss -0.3311 
2023-08-07 14:13:07.759756: val_loss -0.3053 
2023-08-07 14:13:07.759810: Pseudo dice [0.7341] 
2023-08-07 14:13:07.759862: Epoch time: 63.54 s 
2023-08-07 14:13:08.740010:  
2023-08-07 14:13:08.740188: Epoch 208 
2023-08-07 14:13:08.740281: Current learning rate: 0.00091 
2023-08-07 14:14:12.324151: train_loss -0.3105 
2023-08-07 14:14:12.324304: val_loss -0.3013 
2023-08-07 14:14:12.324358: Pseudo dice [0.8031] 
2023-08-07 14:14:12.324411: Epoch time: 63.58 s 
2023-08-07 14:14:12.324452: Yayy! New best EMA pseudo Dice: 0.7336 
2023-08-07 14:14:13.649038:  
2023-08-07 14:14:13.649273: Epoch 209 
2023-08-07 14:14:13.649373: Current learning rate: 0.00091 
2023-08-07 14:15:17.091867: train_loss -0.3373 
2023-08-07 14:15:17.092014: val_loss -0.3902 
2023-08-07 14:15:17.092067: Pseudo dice [0.8005] 
2023-08-07 14:15:17.092117: Epoch time: 63.44 s 
2023-08-07 14:15:17.092158: Yayy! New best EMA pseudo Dice: 0.7403 
2023-08-07 14:15:18.543828:  
2023-08-07 14:15:18.543935: Epoch 210 
2023-08-07 14:15:18.544008: Current learning rate: 0.0009 
2023-08-07 14:16:22.051346: train_loss -0.328 
2023-08-07 14:16:22.051628: val_loss -0.3578 
2023-08-07 14:16:22.051683: Pseudo dice [0.743] 
2023-08-07 14:16:22.051734: Epoch time: 63.51 s 
2023-08-07 14:16:22.051776: Yayy! New best EMA pseudo Dice: 0.7405 
2023-08-07 14:16:23.341575:  
2023-08-07 14:16:23.341677: Epoch 211 
2023-08-07 14:16:23.341766: Current learning rate: 0.0009 
2023-08-07 14:17:26.613882: train_loss -0.3263 
2023-08-07 14:17:26.614032: val_loss -0.3267 
2023-08-07 14:17:26.614082: Pseudo dice [0.738] 
2023-08-07 14:17:26.614149: Epoch time: 63.27 s 
2023-08-07 14:17:27.557344:  
2023-08-07 14:17:27.557531: Epoch 212 
2023-08-07 14:17:27.557608: Current learning rate: 0.0009 
2023-08-07 14:18:30.989331: train_loss -0.3467 
2023-08-07 14:18:30.989494: val_loss -0.286 
2023-08-07 14:18:30.989547: Pseudo dice [0.6283] 
2023-08-07 14:18:30.989599: Epoch time: 63.43 s 
2023-08-07 14:18:31.954665:  
2023-08-07 14:18:31.954944: Epoch 213 
2023-08-07 14:18:31.955270: Current learning rate: 0.0009 
2023-08-07 14:19:35.492378: train_loss -0.3029 
2023-08-07 14:19:35.492531: val_loss -0.3769 
2023-08-07 14:19:35.492584: Pseudo dice [0.7243] 
2023-08-07 14:19:35.492633: Epoch time: 63.54 s 
2023-08-07 14:19:36.461350:  
2023-08-07 14:19:36.461445: Epoch 214 
2023-08-07 14:19:36.461529: Current learning rate: 0.0009 
2023-08-07 14:20:39.829356: train_loss -0.3093 
2023-08-07 14:20:39.829509: val_loss -0.3053 
2023-08-07 14:20:39.829563: Pseudo dice [0.601] 
2023-08-07 14:20:39.829613: Epoch time: 63.37 s 
2023-08-07 14:20:40.953283:  
2023-08-07 14:20:40.953489: Epoch 215 
2023-08-07 14:20:40.953596: Current learning rate: 0.0009 
2023-08-07 14:21:44.521636: train_loss -0.3241 
2023-08-07 14:21:44.521814: val_loss -0.3055 
2023-08-07 14:21:44.521867: Pseudo dice [0.6384] 
2023-08-07 14:21:44.521917: Epoch time: 63.57 s 
2023-08-07 14:21:45.469832:  
2023-08-07 14:21:45.470032: Epoch 216 
2023-08-07 14:21:45.470124: Current learning rate: 0.0009 
2023-08-07 14:22:48.920305: train_loss -0.3452 
2023-08-07 14:22:48.920455: val_loss -0.2997 
2023-08-07 14:22:48.920508: Pseudo dice [0.6417] 
2023-08-07 14:22:48.920559: Epoch time: 63.45 s 
2023-08-07 14:22:49.869703:  
2023-08-07 14:22:49.869938: Epoch 217 
2023-08-07 14:22:49.870145: Current learning rate: 0.0009 
2023-08-07 14:23:53.263919: train_loss -0.3304 
2023-08-07 14:23:53.264074: val_loss -0.3289 
2023-08-07 14:23:53.264127: Pseudo dice [0.7243] 
2023-08-07 14:23:53.264177: Epoch time: 63.39 s 
2023-08-07 14:23:54.246325:  
2023-08-07 14:23:54.246527: Epoch 218 
2023-08-07 14:23:54.246603: Current learning rate: 0.0009 
2023-08-07 14:24:57.467788: train_loss -0.305 
2023-08-07 14:24:57.467945: val_loss -0.267 
2023-08-07 14:24:57.468000: Pseudo dice [0.6899] 
2023-08-07 14:24:57.468052: Epoch time: 63.22 s 
2023-08-07 14:24:58.429089:  
2023-08-07 14:24:58.429206: Epoch 219 
2023-08-07 14:24:58.429296: Current learning rate: 0.0009 
2023-08-07 14:26:01.887347: train_loss -0.3365 
2023-08-07 14:26:01.887492: val_loss -0.2805 
2023-08-07 14:26:01.887546: Pseudo dice [0.5986] 
2023-08-07 14:26:01.887623: Epoch time: 63.46 s 
2023-08-07 14:26:02.845925:  
2023-08-07 14:26:02.846021: Epoch 220 
2023-08-07 14:26:02.846094: Current learning rate: 0.0009 
2023-08-07 14:27:06.311341: train_loss -0.3214 
2023-08-07 14:27:06.311498: val_loss -0.3267 
2023-08-07 14:27:06.311574: Pseudo dice [0.7192] 
2023-08-07 14:27:06.311627: Epoch time: 63.47 s 
2023-08-07 14:27:07.409592:  
2023-08-07 14:27:07.409753: Epoch 221 
2023-08-07 14:27:07.409921: Current learning rate: 0.0009 
2023-08-07 14:28:10.972647: train_loss -0.3097 
2023-08-07 14:28:10.972809: val_loss -0.2621 
2023-08-07 14:28:10.972858: Pseudo dice [0.7019] 
2023-08-07 14:28:10.972924: Epoch time: 63.56 s 
2023-08-07 14:28:11.954731:  
2023-08-07 14:28:11.954840: Epoch 222 
2023-08-07 14:28:11.954926: Current learning rate: 0.0009 
2023-08-07 14:29:15.452959: train_loss -0.3199 
2023-08-07 14:29:15.453106: val_loss -0.3846 
2023-08-07 14:29:15.453155: Pseudo dice [0.8627] 
2023-08-07 14:29:15.453206: Epoch time: 63.5 s 
2023-08-07 14:29:16.422803:  
2023-08-07 14:29:16.422902: Epoch 223 
2023-08-07 14:29:16.422973: Current learning rate: 0.0009 
2023-08-07 14:30:19.771530: train_loss -0.3048 
2023-08-07 14:30:19.771698: val_loss -0.3103 
2023-08-07 14:30:19.771751: Pseudo dice [0.7581] 
2023-08-07 14:30:19.771804: Epoch time: 63.35 s 
2023-08-07 14:30:20.716257:  
2023-08-07 14:30:20.716355: Epoch 224 
2023-08-07 14:30:20.716431: Current learning rate: 0.0009 
2023-08-07 14:31:24.230659: train_loss -0.3265 
2023-08-07 14:31:24.230808: val_loss -0.3296 
2023-08-07 14:31:24.230877: Pseudo dice [0.7105] 
2023-08-07 14:31:24.230927: Epoch time: 63.52 s 
2023-08-07 14:31:25.199004:  
2023-08-07 14:31:25.199115: Epoch 225 
2023-08-07 14:31:25.199185: Current learning rate: 0.0009 
2023-08-07 14:32:28.682372: train_loss -0.3163 
2023-08-07 14:32:28.682524: val_loss -0.2457 
2023-08-07 14:32:28.682575: Pseudo dice [0.6864] 
2023-08-07 14:32:28.682626: Epoch time: 63.48 s 
2023-08-07 14:32:29.629602:  
2023-08-07 14:32:29.629695: Epoch 226 
2023-08-07 14:32:29.629768: Current learning rate: 0.0009 
2023-08-07 14:33:32.922274: train_loss -0.3354 
2023-08-07 14:33:32.922420: val_loss -0.3565 
2023-08-07 14:33:32.922472: Pseudo dice [0.7462] 
2023-08-07 14:33:32.922522: Epoch time: 63.29 s 
2023-08-07 14:33:34.066862:  
2023-08-07 14:33:34.066969: Epoch 227 
2023-08-07 14:33:34.067044: Current learning rate: 0.0009 
2023-08-07 14:34:37.398223: train_loss -0.3292 
2023-08-07 14:34:37.398367: val_loss -0.4063 
2023-08-07 14:34:37.398422: Pseudo dice [0.7664] 
2023-08-07 14:34:37.398472: Epoch time: 63.33 s 
2023-08-07 14:34:38.352286:  
2023-08-07 14:34:38.352497: Epoch 228 
2023-08-07 14:34:38.352580: Current learning rate: 0.0009 
2023-08-07 14:35:41.937048: train_loss -0.3021 
2023-08-07 14:35:41.937201: val_loss -0.3214 
2023-08-07 14:35:41.937280: Pseudo dice [0.7379] 
2023-08-07 14:35:41.937332: Epoch time: 63.59 s 
2023-08-07 14:35:42.922396:  
2023-08-07 14:35:42.922497: Epoch 229 
2023-08-07 14:35:42.922569: Current learning rate: 0.0009 
2023-08-07 14:36:46.362525: train_loss -0.312 
2023-08-07 14:36:46.362676: val_loss -0.374 
2023-08-07 14:36:46.362744: Pseudo dice [0.7813] 
2023-08-07 14:36:46.362795: Epoch time: 63.44 s 
2023-08-07 14:36:47.335448:  
2023-08-07 14:36:47.335729: Epoch 230 
2023-08-07 14:36:47.335967: Current learning rate: 0.0009 
2023-08-07 14:37:50.806211: train_loss -0.312 
2023-08-07 14:37:50.806358: val_loss -0.2687 
2023-08-07 14:37:50.806425: Pseudo dice [0.6952] 
2023-08-07 14:37:50.806476: Epoch time: 63.47 s 
2023-08-07 14:37:51.773182:  
2023-08-07 14:37:51.773276: Epoch 231 
2023-08-07 14:37:51.773365: Current learning rate: 0.0009 
2023-08-07 14:38:55.301182: train_loss -0.2957 
2023-08-07 14:38:55.301338: val_loss -0.3036 
2023-08-07 14:38:55.301390: Pseudo dice [0.7672] 
2023-08-07 14:38:55.301439: Epoch time: 63.53 s 
2023-08-07 14:38:56.257006:  
2023-08-07 14:38:56.257097: Epoch 232 
2023-08-07 14:38:56.257183: Current learning rate: 0.00089 
2023-08-07 14:39:59.801693: train_loss -0.347 
2023-08-07 14:39:59.801836: val_loss -0.3827 
2023-08-07 14:39:59.801888: Pseudo dice [0.7745] 
2023-08-07 14:39:59.801956: Epoch time: 63.55 s 
2023-08-07 14:40:00.956570:  
2023-08-07 14:40:00.956690: Epoch 233 
2023-08-07 14:40:00.956765: Current learning rate: 0.00089 
2023-08-07 14:41:04.640832: train_loss -0.344 
2023-08-07 14:41:04.640996: val_loss -0.2711 
2023-08-07 14:41:04.641050: Pseudo dice [0.6253] 
2023-08-07 14:41:04.641101: Epoch time: 63.68 s 
2023-08-07 14:41:05.596421:  
2023-08-07 14:41:05.596642: Epoch 234 
2023-08-07 14:41:05.596722: Current learning rate: 0.00089 
2023-08-07 14:42:09.095781: train_loss -0.2706 
2023-08-07 14:42:09.095930: val_loss -0.2429 
2023-08-07 14:42:09.095984: Pseudo dice [0.7011] 
2023-08-07 14:42:09.096034: Epoch time: 63.5 s 
2023-08-07 14:42:10.053985:  
2023-08-07 14:42:10.054091: Epoch 235 
2023-08-07 14:42:10.054163: Current learning rate: 0.00089 
2023-08-07 14:43:13.313756: train_loss -0.3122 
2023-08-07 14:43:13.313914: val_loss -0.2833 
2023-08-07 14:43:13.313967: Pseudo dice [0.5019] 
2023-08-07 14:43:13.314037: Epoch time: 63.26 s 
2023-08-07 14:43:14.267304:  
2023-08-07 14:43:14.267514: Epoch 236 
2023-08-07 14:43:14.267611: Current learning rate: 0.00089 
2023-08-07 14:44:17.674148: train_loss -0.3034 
2023-08-07 14:44:17.674298: val_loss -0.3633 
2023-08-07 14:44:17.674350: Pseudo dice [0.7328] 
2023-08-07 14:44:17.674401: Epoch time: 63.41 s 
2023-08-07 14:44:18.634587:  
2023-08-07 14:44:18.634936: Epoch 237 
2023-08-07 14:44:18.635017: Current learning rate: 0.00089 
2023-08-07 14:45:22.131122: train_loss -0.3173 
2023-08-07 14:45:22.131278: val_loss -0.2708 
2023-08-07 14:45:22.131346: Pseudo dice [0.5639] 
2023-08-07 14:45:22.131397: Epoch time: 63.5 s 
2023-08-07 14:45:23.090845:  
2023-08-07 14:45:23.090944: Epoch 238 
2023-08-07 14:45:23.091016: Current learning rate: 0.00089 
2023-08-07 14:46:26.559668: train_loss -0.3184 
2023-08-07 14:46:26.559816: val_loss -0.2929 
2023-08-07 14:46:26.559871: Pseudo dice [0.7135] 
2023-08-07 14:46:26.559922: Epoch time: 63.47 s 
2023-08-07 14:46:27.662945:  
2023-08-07 14:46:27.663154: Epoch 239 
2023-08-07 14:46:27.663248: Current learning rate: 0.00089 
2023-08-07 14:47:31.163772: train_loss -0.3041 
2023-08-07 14:47:31.163923: val_loss -0.3995 
2023-08-07 14:47:31.163975: Pseudo dice [0.7518] 
2023-08-07 14:47:31.164025: Epoch time: 63.5 s 
2023-08-07 14:47:32.131431:  
2023-08-07 14:47:32.131528: Epoch 240 
2023-08-07 14:47:32.131621: Current learning rate: 0.00089 
2023-08-07 14:48:35.682824: train_loss -0.2886 
2023-08-07 14:48:35.682989: val_loss -0.3308 
2023-08-07 14:48:35.683055: Pseudo dice [0.7829] 
2023-08-07 14:48:35.683119: Epoch time: 63.55 s 
2023-08-07 14:48:36.668876:  
2023-08-07 14:48:36.669101: Epoch 241 
2023-08-07 14:48:36.669180: Current learning rate: 0.00089 
2023-08-07 14:49:40.286139: train_loss -0.3438 
2023-08-07 14:49:40.286296: val_loss -0.3673 
2023-08-07 14:49:40.286363: Pseudo dice [0.7286] 
2023-08-07 14:49:40.286414: Epoch time: 63.62 s 
2023-08-07 14:49:41.275808:  
2023-08-07 14:49:41.275902: Epoch 242 
2023-08-07 14:49:41.275980: Current learning rate: 0.00089 
2023-08-07 14:50:44.795331: train_loss -0.3325 
2023-08-07 14:50:44.795613: val_loss -0.2895 
2023-08-07 14:50:44.795670: Pseudo dice [0.6985] 
2023-08-07 14:50:44.795722: Epoch time: 63.52 s 
2023-08-07 14:50:45.762018:  
2023-08-07 14:50:45.762117: Epoch 243 
2023-08-07 14:50:45.762188: Current learning rate: 0.00089 
2023-08-07 14:51:49.197733: train_loss -0.3328 
2023-08-07 14:51:49.197871: val_loss -0.3443 
2023-08-07 14:51:49.197921: Pseudo dice [0.7178] 
2023-08-07 14:51:49.197988: Epoch time: 63.44 s 
2023-08-07 14:51:50.196732:  
2023-08-07 14:51:50.196826: Epoch 244 
2023-08-07 14:51:50.196899: Current learning rate: 0.00089 
2023-08-07 14:52:53.791549: train_loss -0.3019 
2023-08-07 14:52:53.791731: val_loss -0.3376 
2023-08-07 14:52:53.791783: Pseudo dice [0.6995] 
2023-08-07 14:52:53.791834: Epoch time: 63.6 s 
2023-08-07 14:52:54.958479:  
2023-08-07 14:52:54.958688: Epoch 245 
2023-08-07 14:52:54.958769: Current learning rate: 0.00089 
2023-08-07 14:53:58.368206: train_loss -0.3107 
2023-08-07 14:53:58.368360: val_loss -0.3856 
2023-08-07 14:53:58.368412: Pseudo dice [0.6948] 
2023-08-07 14:53:58.368462: Epoch time: 63.41 s 
2023-08-07 14:53:59.334875:  
2023-08-07 14:53:59.334974: Epoch 246 
2023-08-07 14:53:59.335061: Current learning rate: 0.00089 
2023-08-07 14:55:02.845826: train_loss -0.3305 
2023-08-07 14:55:02.845998: val_loss -0.3129 
2023-08-07 14:55:02.846056: Pseudo dice [0.7002] 
2023-08-07 14:55:02.846108: Epoch time: 63.51 s 
2023-08-07 14:55:03.873602:  
2023-08-07 14:55:03.873692: Epoch 247 
2023-08-07 14:55:03.873762: Current learning rate: 0.00089 
2023-08-07 14:56:07.356762: train_loss -0.3264 
2023-08-07 14:56:07.356912: val_loss -0.2848 
2023-08-07 14:56:07.356965: Pseudo dice [0.7386] 
2023-08-07 14:56:07.357016: Epoch time: 63.48 s 
2023-08-07 14:56:08.337499:  
2023-08-07 14:56:08.337677: Epoch 248 
2023-08-07 14:56:08.337751: Current learning rate: 0.00089 
2023-08-07 14:57:11.692801: train_loss -0.3023 
2023-08-07 14:57:11.692950: val_loss -0.2917 
2023-08-07 14:57:11.693007: Pseudo dice [0.5659] 
2023-08-07 14:57:11.693060: Epoch time: 63.36 s 
2023-08-07 14:57:12.671304:  
2023-08-07 14:57:12.671406: Epoch 249 
2023-08-07 14:57:12.671496: Current learning rate: 0.00089 
2023-08-07 14:58:16.280465: train_loss -0.3087 
2023-08-07 14:58:16.280674: val_loss -0.3585 
2023-08-07 14:58:16.280766: Pseudo dice [0.7657] 
2023-08-07 14:58:16.280855: Epoch time: 63.61 s 
2023-08-07 14:58:17.649742:  
2023-08-07 14:58:17.649836: Epoch 250 
2023-08-07 14:58:17.649907: Current learning rate: 0.00089 
2023-08-07 14:59:21.166751: train_loss -0.3138 
2023-08-07 14:59:21.166901: val_loss -0.2985 
2023-08-07 14:59:21.166959: Pseudo dice [0.7491] 
2023-08-07 14:59:21.167146: Epoch time: 63.52 s 
2023-08-07 14:59:22.314389:  
2023-08-07 14:59:22.314499: Epoch 251 
2023-08-07 14:59:22.314573: Current learning rate: 0.00089 
2023-08-07 15:00:25.829101: train_loss -0.2962 
2023-08-07 15:00:25.829268: val_loss -0.3293 
2023-08-07 15:00:25.829320: Pseudo dice [0.6629] 
2023-08-07 15:00:25.829370: Epoch time: 63.52 s 
2023-08-07 15:00:26.802050:  
2023-08-07 15:00:26.802248: Epoch 252 
2023-08-07 15:00:26.802323: Current learning rate: 0.00089 
2023-08-07 15:01:30.188423: train_loss -0.3519 
2023-08-07 15:01:30.188572: val_loss -0.3122 
2023-08-07 15:01:30.188623: Pseudo dice [0.7886] 
2023-08-07 15:01:30.188673: Epoch time: 63.39 s 
2023-08-07 15:01:31.182629:  
2023-08-07 15:01:31.182725: Epoch 253 
2023-08-07 15:01:31.182796: Current learning rate: 0.00089 
2023-08-07 15:02:34.509813: train_loss -0.3428 
2023-08-07 15:02:34.509964: val_loss -0.2881 
2023-08-07 15:02:34.510041: Pseudo dice [0.6246] 
2023-08-07 15:02:34.510094: Epoch time: 63.33 s 
2023-08-07 15:02:35.509277:  
2023-08-07 15:02:35.509369: Epoch 254 
2023-08-07 15:02:35.509443: Current learning rate: 0.00088 
2023-08-07 15:03:38.823145: train_loss -0.292 
2023-08-07 15:03:38.823308: val_loss -0.2702 
2023-08-07 15:03:38.823361: Pseudo dice [0.6843] 
2023-08-07 15:03:38.823413: Epoch time: 63.31 s 
2023-08-07 15:03:39.796475:  
2023-08-07 15:03:39.796575: Epoch 255 
2023-08-07 15:03:39.796649: Current learning rate: 0.00088 
2023-08-07 15:04:43.065230: train_loss -0.275 
2023-08-07 15:04:43.065409: val_loss -0.3634 
2023-08-07 15:04:43.065474: Pseudo dice [0.82] 
2023-08-07 15:04:43.065575: Epoch time: 63.27 s 
2023-08-07 15:04:44.227850:  
2023-08-07 15:04:44.228185: Epoch 256 
2023-08-07 15:04:44.228348: Current learning rate: 0.00088 
2023-08-07 15:05:47.694682: train_loss -0.3414 
2023-08-07 15:05:47.694841: val_loss -0.3423 
2023-08-07 15:05:47.694899: Pseudo dice [0.7354] 
2023-08-07 15:05:47.694951: Epoch time: 63.47 s 
2023-08-07 15:05:48.677250:  
2023-08-07 15:05:48.677462: Epoch 257 
2023-08-07 15:05:48.677539: Current learning rate: 0.00088 
2023-08-07 15:06:52.209565: train_loss -0.3035 
2023-08-07 15:06:52.209743: val_loss -0.384 
2023-08-07 15:06:52.209805: Pseudo dice [0.7903] 
2023-08-07 15:06:52.209871: Epoch time: 63.53 s 
2023-08-07 15:06:53.187363:  
2023-08-07 15:06:53.187459: Epoch 258 
2023-08-07 15:06:53.187547: Current learning rate: 0.00088 
2023-08-07 15:07:56.523329: train_loss -0.3026 
2023-08-07 15:07:56.523482: val_loss -0.3345 
2023-08-07 15:07:56.523532: Pseudo dice [0.8048] 
2023-08-07 15:07:56.523594: Epoch time: 63.34 s 
2023-08-07 15:07:57.496413:  
2023-08-07 15:07:57.496589: Epoch 259 
2023-08-07 15:07:57.496667: Current learning rate: 0.00088 
2023-08-07 15:09:00.798412: train_loss -0.3154 
2023-08-07 15:09:00.798582: val_loss -0.3243 
2023-08-07 15:09:00.798638: Pseudo dice [0.7683] 
2023-08-07 15:09:00.798690: Epoch time: 63.3 s 
2023-08-07 15:09:01.778044:  
2023-08-07 15:09:01.778139: Epoch 260 
2023-08-07 15:09:01.778252: Current learning rate: 0.00088 
2023-08-07 15:10:05.318697: train_loss -0.3598 
2023-08-07 15:10:05.318902: val_loss -0.2969 
2023-08-07 15:10:05.318955: Pseudo dice [0.808] 
2023-08-07 15:10:05.319006: Epoch time: 63.54 s 
2023-08-07 15:10:05.319048: Yayy! New best EMA pseudo Dice: 0.7416 
2023-08-07 15:10:06.654753:  
2023-08-07 15:10:06.655024: Epoch 261 
2023-08-07 15:10:06.655210: Current learning rate: 0.00088 
2023-08-07 15:11:10.144550: train_loss -0.327 
2023-08-07 15:11:10.144703: val_loss -0.3273 
2023-08-07 15:11:10.144753: Pseudo dice [0.754] 
2023-08-07 15:11:10.144804: Epoch time: 63.49 s 
2023-08-07 15:11:10.144844: Yayy! New best EMA pseudo Dice: 0.7428 
2023-08-07 15:11:11.625771:  
2023-08-07 15:11:11.625878: Epoch 262 
2023-08-07 15:11:11.625952: Current learning rate: 0.00088 
2023-08-07 15:12:14.844376: train_loss -0.3305 
2023-08-07 15:12:14.844528: val_loss -0.3826 
2023-08-07 15:12:14.844582: Pseudo dice [0.7882] 
2023-08-07 15:12:14.844634: Epoch time: 63.22 s 
2023-08-07 15:12:14.844673: Yayy! New best EMA pseudo Dice: 0.7474 
2023-08-07 15:12:16.193209:  
2023-08-07 15:12:16.193303: Epoch 263 
2023-08-07 15:12:16.193375: Current learning rate: 0.00088 
2023-08-07 15:13:19.673629: train_loss -0.3236 
2023-08-07 15:13:19.673776: val_loss -0.3081 
2023-08-07 15:13:19.673828: Pseudo dice [0.7232] 
2023-08-07 15:13:19.673896: Epoch time: 63.48 s 
2023-08-07 15:13:20.656874:  
2023-08-07 15:13:20.656986: Epoch 264 
2023-08-07 15:13:20.657061: Current learning rate: 0.00088 
2023-08-07 15:14:24.048908: train_loss -0.2969 
2023-08-07 15:14:24.049128: val_loss -0.3367 
2023-08-07 15:14:24.049181: Pseudo dice [0.7538] 
2023-08-07 15:14:24.049232: Epoch time: 63.39 s 
2023-08-07 15:14:25.025623:  
2023-08-07 15:14:25.025713: Epoch 265 
2023-08-07 15:14:25.025783: Current learning rate: 0.00088 
2023-08-07 15:15:28.589232: train_loss -0.3134 
2023-08-07 15:15:28.589386: val_loss -0.2962 
2023-08-07 15:15:28.589437: Pseudo dice [0.7227] 
2023-08-07 15:15:28.589498: Epoch time: 63.56 s 
2023-08-07 15:15:29.565089:  
2023-08-07 15:15:29.565184: Epoch 266 
2023-08-07 15:15:29.565258: Current learning rate: 0.00088 
2023-08-07 15:16:32.909940: train_loss -0.3555 
2023-08-07 15:16:32.910100: val_loss -0.3467 
2023-08-07 15:16:32.910153: Pseudo dice [0.7355] 
2023-08-07 15:16:32.910203: Epoch time: 63.35 s 
2023-08-07 15:16:34.043344:  
2023-08-07 15:16:34.043542: Epoch 267 
2023-08-07 15:16:34.043627: Current learning rate: 0.00088 
2023-08-07 15:17:37.480159: train_loss -0.328 
2023-08-07 15:17:37.480439: val_loss -0.2419 
2023-08-07 15:17:37.480581: Pseudo dice [0.7827] 
2023-08-07 15:17:37.480729: Epoch time: 63.44 s 
2023-08-07 15:17:38.498434:  
2023-08-07 15:17:38.498524: Epoch 268 
2023-08-07 15:17:38.498595: Current learning rate: 0.00088 
2023-08-07 15:18:42.116776: train_loss -0.3271 
2023-08-07 15:18:42.116925: val_loss -0.3321 
2023-08-07 15:18:42.116975: Pseudo dice [0.6527] 
2023-08-07 15:18:42.117025: Epoch time: 63.62 s 
2023-08-07 15:18:43.095820:  
2023-08-07 15:18:43.095918: Epoch 269 
2023-08-07 15:18:43.096009: Current learning rate: 0.00088 
2023-08-07 15:19:46.476995: train_loss -0.3333 
2023-08-07 15:19:46.477189: val_loss -0.346 
2023-08-07 15:19:46.477242: Pseudo dice [0.7473] 
2023-08-07 15:19:46.477291: Epoch time: 63.38 s 
2023-08-07 15:19:47.455930:  
2023-08-07 15:19:47.456028: Epoch 270 
2023-08-07 15:19:47.456115: Current learning rate: 0.00088 
2023-08-07 15:20:50.778116: train_loss -0.3053 
2023-08-07 15:20:50.778277: val_loss -0.295 
2023-08-07 15:20:50.778371: Pseudo dice [0.6808] 
2023-08-07 15:20:50.778423: Epoch time: 63.32 s 
2023-08-07 15:20:51.752116:  
2023-08-07 15:20:51.752216: Epoch 271 
2023-08-07 15:20:51.752292: Current learning rate: 0.00088 
2023-08-07 15:21:55.183944: train_loss -0.3403 
2023-08-07 15:21:55.184093: val_loss -0.3263 
2023-08-07 15:21:55.184144: Pseudo dice [0.8121] 
2023-08-07 15:21:55.184195: Epoch time: 63.43 s 
2023-08-07 15:21:56.169074:  
2023-08-07 15:21:56.169172: Epoch 272 
2023-08-07 15:21:56.169247: Current learning rate: 0.00088 
2023-08-07 15:22:59.628712: train_loss -0.3271 
2023-08-07 15:22:59.628861: val_loss -0.3048 
2023-08-07 15:22:59.628910: Pseudo dice [0.7284] 
2023-08-07 15:22:59.628959: Epoch time: 63.46 s 
2023-08-07 15:23:00.607775:  
2023-08-07 15:23:00.607994: Epoch 273 
2023-08-07 15:23:00.608070: Current learning rate: 0.00088 
2023-08-07 15:24:04.014453: train_loss -0.3164 
2023-08-07 15:24:04.014603: val_loss -0.2843 
2023-08-07 15:24:04.014656: Pseudo dice [0.7334] 
2023-08-07 15:24:04.014722: Epoch time: 63.41 s 
2023-08-07 15:24:04.992741:  
2023-08-07 15:24:04.992848: Epoch 274 
2023-08-07 15:24:04.992934: Current learning rate: 0.00088 
2023-08-07 15:25:08.401141: train_loss -0.3229 
2023-08-07 15:25:08.401299: val_loss -0.4039 
2023-08-07 15:25:08.401352: Pseudo dice [0.7516] 
2023-08-07 15:25:08.401403: Epoch time: 63.41 s 
2023-08-07 15:25:09.369319:  
2023-08-07 15:25:09.369415: Epoch 275 
2023-08-07 15:25:09.369503: Current learning rate: 0.00088 
2023-08-07 15:26:12.832124: train_loss -0.2901 
2023-08-07 15:26:12.832274: val_loss -0.3562 
2023-08-07 15:26:12.832327: Pseudo dice [0.6896] 
2023-08-07 15:26:12.832377: Epoch time: 63.46 s 
2023-08-07 15:26:13.832359:  
2023-08-07 15:26:13.832657: Epoch 276 
2023-08-07 15:26:13.832844: Current learning rate: 0.00087 
2023-08-07 15:27:17.293386: train_loss -0.369 
2023-08-07 15:27:17.293535: val_loss -0.3814 
2023-08-07 15:27:17.293586: Pseudo dice [0.7772] 
2023-08-07 15:27:17.293653: Epoch time: 63.46 s 
2023-08-07 15:27:18.273244:  
2023-08-07 15:27:18.273355: Epoch 277 
2023-08-07 15:27:18.273427: Current learning rate: 0.00087 
2023-08-07 15:28:21.735509: train_loss -0.3609 
2023-08-07 15:28:21.735670: val_loss -0.2826 
2023-08-07 15:28:21.735723: Pseudo dice [0.782] 
2023-08-07 15:28:21.735774: Epoch time: 63.46 s 
2023-08-07 15:28:22.869468:  
2023-08-07 15:28:22.869573: Epoch 278 
2023-08-07 15:28:22.869664: Current learning rate: 0.00087 
2023-08-07 15:29:26.251763: train_loss -0.3267 
2023-08-07 15:29:26.251920: val_loss -0.3662 
2023-08-07 15:29:26.251971: Pseudo dice [0.7501] 
2023-08-07 15:29:26.252021: Epoch time: 63.38 s 
2023-08-07 15:29:27.223725:  
2023-08-07 15:29:27.223941: Epoch 279 
2023-08-07 15:29:27.224019: Current learning rate: 0.00087 
2023-08-07 15:30:30.750099: train_loss -0.2989 
2023-08-07 15:30:30.750247: val_loss -0.3244 
2023-08-07 15:30:30.750295: Pseudo dice [0.572] 
2023-08-07 15:30:30.750347: Epoch time: 63.53 s 
2023-08-07 15:30:31.724052:  
2023-08-07 15:30:31.724152: Epoch 280 
2023-08-07 15:30:31.724224: Current learning rate: 0.00087 
2023-08-07 15:31:35.040627: train_loss -0.3133 
2023-08-07 15:31:35.040778: val_loss -0.3487 
2023-08-07 15:31:35.040828: Pseudo dice [0.7105] 
2023-08-07 15:31:35.040895: Epoch time: 63.32 s 
2023-08-07 15:31:36.048208:  
2023-08-07 15:31:36.048300: Epoch 281 
2023-08-07 15:31:36.048374: Current learning rate: 0.00087 
2023-08-07 15:32:39.413994: train_loss -0.3449 
2023-08-07 15:32:39.414160: val_loss -0.3291 
2023-08-07 15:32:39.414213: Pseudo dice [0.6998] 
2023-08-07 15:32:39.414265: Epoch time: 63.37 s 
2023-08-07 15:32:40.411909:  
2023-08-07 15:32:40.412123: Epoch 282 
2023-08-07 15:32:40.412200: Current learning rate: 0.00087 
2023-08-07 15:33:43.598505: train_loss -0.316 
2023-08-07 15:33:43.598645: val_loss -0.243 
2023-08-07 15:33:43.598693: Pseudo dice [0.5295] 
2023-08-07 15:33:43.598760: Epoch time: 63.19 s 
2023-08-07 15:33:44.709745:  
2023-08-07 15:33:44.709858: Epoch 283 
2023-08-07 15:33:44.709948: Current learning rate: 0.00087 
2023-08-07 15:34:48.284831: train_loss -0.2969 
2023-08-07 15:34:48.284980: val_loss -0.3529 
2023-08-07 15:34:48.285050: Pseudo dice [0.7397] 
2023-08-07 15:34:48.285100: Epoch time: 63.58 s 
2023-08-07 15:34:49.276024:  
2023-08-07 15:34:49.276122: Epoch 284 
2023-08-07 15:34:49.276194: Current learning rate: 0.00087 
2023-08-07 15:35:52.637259: train_loss -0.2987 
2023-08-07 15:35:52.637406: val_loss -0.2993 
2023-08-07 15:35:52.637457: Pseudo dice [0.7797] 
2023-08-07 15:35:52.637508: Epoch time: 63.36 s 
2023-08-07 15:35:53.617861:  
2023-08-07 15:35:53.618089: Epoch 285 
2023-08-07 15:35:53.618167: Current learning rate: 0.00087 
2023-08-07 15:36:57.041158: train_loss -0.3129 
2023-08-07 15:36:57.041316: val_loss -0.3549 
2023-08-07 15:36:57.041367: Pseudo dice [0.875] 
2023-08-07 15:36:57.041418: Epoch time: 63.42 s 
2023-08-07 15:36:58.022378:  
2023-08-07 15:36:58.022472: Epoch 286 
2023-08-07 15:36:58.022545: Current learning rate: 0.00087 
2023-08-07 15:38:01.552595: train_loss -0.2959 
2023-08-07 15:38:01.552747: val_loss -0.3248 
2023-08-07 15:38:01.552799: Pseudo dice [0.6569] 
2023-08-07 15:38:01.552849: Epoch time: 63.53 s 
2023-08-07 15:38:02.558865:  
2023-08-07 15:38:02.558959: Epoch 287 
2023-08-07 15:38:02.559031: Current learning rate: 0.00087 
2023-08-07 15:39:05.940572: train_loss -0.3374 
2023-08-07 15:39:05.940725: val_loss -0.2971 
2023-08-07 15:39:05.940780: Pseudo dice [0.7422] 
2023-08-07 15:39:05.940830: Epoch time: 63.38 s 
2023-08-07 15:39:06.946408:  
2023-08-07 15:39:06.946500: Epoch 288 
2023-08-07 15:39:06.946570: Current learning rate: 0.00087 
2023-08-07 15:40:10.409488: train_loss -0.3241 
2023-08-07 15:40:10.409628: val_loss -0.3022 
2023-08-07 15:40:10.409694: Pseudo dice [0.6707] 
2023-08-07 15:40:10.409745: Epoch time: 63.46 s 
2023-08-07 15:40:11.582221:  
2023-08-07 15:40:11.582460: Epoch 289 
2023-08-07 15:40:11.582537: Current learning rate: 0.00087 
2023-08-07 15:41:15.151676: train_loss -0.321 
2023-08-07 15:41:15.151833: val_loss -0.3068 
2023-08-07 15:41:15.151888: Pseudo dice [0.7344] 
2023-08-07 15:41:15.151939: Epoch time: 63.57 s 
2023-08-07 15:41:16.157377:  
2023-08-07 15:41:16.157501: Epoch 290 
2023-08-07 15:41:16.157660: Current learning rate: 0.00087 
2023-08-07 15:42:19.718307: train_loss -0.2858 
2023-08-07 15:42:19.718449: val_loss -0.4141 
2023-08-07 15:42:19.718498: Pseudo dice [0.7596] 
2023-08-07 15:42:19.718563: Epoch time: 63.56 s 
2023-08-07 15:42:20.711690:  
2023-08-07 15:42:20.711792: Epoch 291 
2023-08-07 15:42:20.711866: Current learning rate: 0.00087 
2023-08-07 15:43:24.188452: train_loss -0.3308 
2023-08-07 15:43:24.188616: val_loss -0.2898 
2023-08-07 15:43:24.188678: Pseudo dice [0.7785] 
2023-08-07 15:43:24.188738: Epoch time: 63.48 s 
2023-08-07 15:43:25.189564:  
2023-08-07 15:43:25.189660: Epoch 292 
2023-08-07 15:43:25.189746: Current learning rate: 0.00087 
2023-08-07 15:44:28.684604: train_loss -0.3325 
2023-08-07 15:44:28.684765: val_loss -0.2616 
2023-08-07 15:44:28.684819: Pseudo dice [0.7027] 
2023-08-07 15:44:28.684870: Epoch time: 63.5 s 
2023-08-07 15:44:29.705601:  
2023-08-07 15:44:29.705695: Epoch 293 
2023-08-07 15:44:29.705784: Current learning rate: 0.00087 
2023-08-07 15:45:32.976970: train_loss -0.3078 
2023-08-07 15:45:32.977114: val_loss -0.3386 
2023-08-07 15:45:32.977165: Pseudo dice [0.8023] 
2023-08-07 15:45:32.977213: Epoch time: 63.27 s 
2023-08-07 15:45:33.969472:  
2023-08-07 15:45:33.969570: Epoch 294 
2023-08-07 15:45:33.969644: Current learning rate: 0.00087 
2023-08-07 15:46:37.250585: train_loss -0.3314 
2023-08-07 15:46:37.250756: val_loss -0.3681 
2023-08-07 15:46:37.250809: Pseudo dice [0.8019] 
2023-08-07 15:46:37.250859: Epoch time: 63.28 s 
2023-08-07 15:46:38.406447:  
2023-08-07 15:46:38.406564: Epoch 295 
2023-08-07 15:46:38.406655: Current learning rate: 0.00087 
2023-08-07 15:47:41.837984: train_loss -0.3375 
2023-08-07 15:47:41.838138: val_loss -0.3092 
2023-08-07 15:47:41.838191: Pseudo dice [0.7294] 
2023-08-07 15:47:41.838241: Epoch time: 63.43 s 
2023-08-07 15:47:42.839488:  
2023-08-07 15:47:42.839610: Epoch 296 
2023-08-07 15:47:42.839685: Current learning rate: 0.00087 
2023-08-07 15:48:46.321411: train_loss -0.3175 
2023-08-07 15:48:46.321567: val_loss -0.411 
2023-08-07 15:48:46.321618: Pseudo dice [0.8322] 
2023-08-07 15:48:46.321683: Epoch time: 63.48 s 
2023-08-07 15:48:46.321724: Yayy! New best EMA pseudo Dice: 0.7496 
2023-08-07 15:48:47.679482:  
2023-08-07 15:48:47.679856: Epoch 297 
2023-08-07 15:48:47.679935: Current learning rate: 0.00087 
2023-08-07 15:49:50.879198: train_loss -0.3276 
2023-08-07 15:49:50.879345: val_loss -0.3479 
2023-08-07 15:49:50.879395: Pseudo dice [0.7036] 
2023-08-07 15:49:50.879461: Epoch time: 63.2 s 
2023-08-07 15:49:51.894804:  
2023-08-07 15:49:51.895108: Epoch 298 
2023-08-07 15:49:51.895201: Current learning rate: 0.00086 
2023-08-07 15:50:55.362755: train_loss -0.3395 
2023-08-07 15:50:55.362904: val_loss -0.3129 
2023-08-07 15:50:55.362956: Pseudo dice [0.7468] 
2023-08-07 15:50:55.363006: Epoch time: 63.47 s 
2023-08-07 15:50:56.363223:  
2023-08-07 15:50:56.363420: Epoch 299 
2023-08-07 15:50:56.363497: Current learning rate: 0.00086 
2023-08-07 15:51:59.718203: train_loss -0.2962 
2023-08-07 15:51:59.718371: val_loss -0.2813 
2023-08-07 15:51:59.718422: Pseudo dice [0.653] 
2023-08-07 15:51:59.718473: Epoch time: 63.36 s 
2023-08-07 15:52:01.228669:  
2023-08-07 15:52:01.228774: Epoch 300 
2023-08-07 15:52:01.228913: Current learning rate: 0.00086 
2023-08-07 15:53:04.579032: train_loss -0.3206 
2023-08-07 15:53:04.579176: val_loss -0.2849 
2023-08-07 15:53:04.579225: Pseudo dice [0.8113] 
2023-08-07 15:53:04.579275: Epoch time: 63.35 s 
2023-08-07 15:53:05.678610:  
2023-08-07 15:53:05.678706: Epoch 301 
2023-08-07 15:53:05.678794: Current learning rate: 0.00086 
2023-08-07 15:54:09.200800: train_loss -0.3751 
2023-08-07 15:54:09.200953: val_loss -0.3142 
2023-08-07 15:54:09.201007: Pseudo dice [0.6981] 
2023-08-07 15:54:09.201056: Epoch time: 63.52 s 
2023-08-07 15:54:10.192898:  
2023-08-07 15:54:10.193101: Epoch 302 
2023-08-07 15:54:10.193178: Current learning rate: 0.00086 
2023-08-07 15:55:13.626167: train_loss -0.3113 
2023-08-07 15:55:13.626320: val_loss -0.316 
2023-08-07 15:55:13.626369: Pseudo dice [0.6006] 
2023-08-07 15:55:13.626418: Epoch time: 63.43 s 
2023-08-07 15:55:14.642812:  
2023-08-07 15:55:14.643157: Epoch 303 
2023-08-07 15:55:14.643237: Current learning rate: 0.00086 
2023-08-07 15:56:18.059226: train_loss -0.3607 
2023-08-07 15:56:18.059388: val_loss -0.309 
2023-08-07 15:56:18.067730: Pseudo dice [0.6864] 
2023-08-07 15:56:18.067809: Epoch time: 63.42 s 
2023-08-07 15:56:19.104528:  
2023-08-07 15:56:19.104627: Epoch 304 
2023-08-07 15:56:19.104727: Current learning rate: 0.00086 
2023-08-07 15:57:22.361356: train_loss -0.3057 
2023-08-07 15:57:22.361514: val_loss -0.4326 
2023-08-07 15:57:22.361567: Pseudo dice [0.7408] 
2023-08-07 15:57:22.361633: Epoch time: 63.26 s 
2023-08-07 15:57:23.368416:  
2023-08-07 15:57:23.368510: Epoch 305 
2023-08-07 15:57:23.368600: Current learning rate: 0.00086 
2023-08-07 15:58:26.685782: train_loss -0.3199 
2023-08-07 15:58:26.685924: val_loss -0.3112 
2023-08-07 15:58:26.685973: Pseudo dice [0.5832] 
2023-08-07 15:58:26.686024: Epoch time: 63.32 s 
2023-08-07 15:58:27.892302:  
2023-08-07 15:58:27.892484: Epoch 306 
2023-08-07 15:58:27.892577: Current learning rate: 0.00086 
2023-08-07 15:59:31.591117: train_loss -0.3492 
2023-08-07 15:59:31.591259: val_loss -0.3424 
2023-08-07 15:59:31.591313: Pseudo dice [0.6618] 
2023-08-07 15:59:31.591381: Epoch time: 63.7 s 
2023-08-07 15:59:32.586833:  
2023-08-07 15:59:32.587039: Epoch 307 
2023-08-07 15:59:32.587132: Current learning rate: 0.00086 
2023-08-07 16:00:36.068463: train_loss -0.3318 
2023-08-07 16:00:36.068615: val_loss -0.2957 
2023-08-07 16:00:36.068667: Pseudo dice [0.7458] 
2023-08-07 16:00:36.068717: Epoch time: 63.48 s 
2023-08-07 16:00:37.085347:  
2023-08-07 16:00:37.085438: Epoch 308 
2023-08-07 16:00:37.085512: Current learning rate: 0.00086 
2023-08-07 16:01:40.512258: train_loss -0.3643 
2023-08-07 16:01:40.512402: val_loss -0.3434 
2023-08-07 16:01:40.512455: Pseudo dice [0.7837] 
2023-08-07 16:01:40.512506: Epoch time: 63.43 s 
2023-08-07 16:01:41.510617:  
2023-08-07 16:01:41.510714: Epoch 309 
2023-08-07 16:01:41.510802: Current learning rate: 0.00086 
2023-08-07 16:02:44.975515: train_loss -0.3282 
2023-08-07 16:02:44.975685: val_loss -0.3382 
2023-08-07 16:02:44.975737: Pseudo dice [0.8353] 
2023-08-07 16:02:44.975786: Epoch time: 63.47 s 
2023-08-07 16:02:46.005837:  
2023-08-07 16:02:46.006011: Epoch 310 
2023-08-07 16:02:46.006098: Current learning rate: 0.00086 
2023-08-07 16:03:49.388299: train_loss -0.3251 
2023-08-07 16:03:49.388448: val_loss -0.2676 
2023-08-07 16:03:49.388503: Pseudo dice [0.6434] 
2023-08-07 16:03:49.388554: Epoch time: 63.38 s 
2023-08-07 16:03:50.538143:  
2023-08-07 16:03:50.538378: Epoch 311 
2023-08-07 16:03:50.538461: Current learning rate: 0.00086 
2023-08-07 16:04:53.964635: train_loss -0.3426 
2023-08-07 16:04:53.964782: val_loss -0.3328 
2023-08-07 16:04:53.964832: Pseudo dice [0.7539] 
2023-08-07 16:04:53.964882: Epoch time: 63.43 s 
2023-08-07 16:04:55.008596:  
2023-08-07 16:04:55.008693: Epoch 312 
2023-08-07 16:04:55.008808: Current learning rate: 0.00086 
2023-08-07 16:05:58.338836: train_loss -0.3418 
2023-08-07 16:05:58.338984: val_loss -0.2368 
2023-08-07 16:05:58.339034: Pseudo dice [0.7246] 
2023-08-07 16:05:58.339100: Epoch time: 63.33 s 
2023-08-07 16:05:59.336548:  
2023-08-07 16:05:59.336646: Epoch 313 
2023-08-07 16:05:59.336736: Current learning rate: 0.00086 
2023-08-07 16:07:02.604831: train_loss -0.358 
2023-08-07 16:07:02.604992: val_loss -0.3016 
2023-08-07 16:07:02.605047: Pseudo dice [0.8111] 
2023-08-07 16:07:02.605097: Epoch time: 63.27 s 
2023-08-07 16:07:03.634936:  
2023-08-07 16:07:03.635113: Epoch 314 
2023-08-07 16:07:03.635190: Current learning rate: 0.00086 
2023-08-07 16:08:07.020810: train_loss -0.3253 
2023-08-07 16:08:07.020957: val_loss -0.2517 
2023-08-07 16:08:07.021006: Pseudo dice [0.5647] 
2023-08-07 16:08:07.021056: Epoch time: 63.39 s 
2023-08-07 16:08:08.057730:  
2023-08-07 16:08:08.057826: Epoch 315 
2023-08-07 16:08:08.057918: Current learning rate: 0.00086 
2023-08-07 16:09:11.562825: train_loss -0.3488 
2023-08-07 16:09:11.562978: val_loss -0.3428 
2023-08-07 16:09:11.563030: Pseudo dice [0.793] 
2023-08-07 16:09:11.563095: Epoch time: 63.51 s 
2023-08-07 16:09:12.704643:  
2023-08-07 16:09:12.704747: Epoch 316 
2023-08-07 16:09:12.704825: Current learning rate: 0.00086 
2023-08-07 16:10:16.157230: train_loss -0.3101 
2023-08-07 16:10:16.157392: val_loss -0.3714 
2023-08-07 16:10:16.157447: Pseudo dice [0.7919] 
2023-08-07 16:10:16.157499: Epoch time: 63.45 s 
2023-08-07 16:10:17.154820:  
2023-08-07 16:10:17.154913: Epoch 317 
2023-08-07 16:10:17.155001: Current learning rate: 0.00086 
2023-08-07 16:11:20.490210: train_loss -0.3182 
2023-08-07 16:11:20.490381: val_loss -0.3492 
2023-08-07 16:11:20.490433: Pseudo dice [0.8334] 
2023-08-07 16:11:20.490485: Epoch time: 63.34 s 
2023-08-07 16:11:21.502509:  
2023-08-07 16:11:21.502839: Epoch 318 
2023-08-07 16:11:21.502949: Current learning rate: 0.00086 
2023-08-07 16:12:24.891370: train_loss -0.3185 
2023-08-07 16:12:24.891524: val_loss -0.2548 
2023-08-07 16:12:24.891604: Pseudo dice [0.7248] 
2023-08-07 16:12:24.891659: Epoch time: 63.39 s 
2023-08-07 16:12:25.891916:  
2023-08-07 16:12:25.892014: Epoch 319 
2023-08-07 16:12:25.892086: Current learning rate: 0.00086 
2023-08-07 16:13:29.239082: train_loss -0.2885 
2023-08-07 16:13:29.239233: val_loss -0.3146 
2023-08-07 16:13:29.239285: Pseudo dice [0.7668] 
2023-08-07 16:13:29.239352: Epoch time: 63.35 s 
2023-08-07 16:13:30.232796:  
2023-08-07 16:13:30.232970: Epoch 320 
2023-08-07 16:13:30.233046: Current learning rate: 0.00085 
2023-08-07 16:14:33.674998: train_loss -0.3046 
2023-08-07 16:14:33.675154: val_loss -0.3198 
2023-08-07 16:14:33.675213: Pseudo dice [0.8405] 
2023-08-07 16:14:33.675270: Epoch time: 63.44 s 
2023-08-07 16:14:33.675316: Yayy! New best EMA pseudo Dice: 0.7514 
2023-08-07 16:14:35.089525:  
2023-08-07 16:14:35.089620: Epoch 321 
2023-08-07 16:14:35.089695: Current learning rate: 0.00085 
2023-08-07 16:15:38.611163: train_loss -0.3178 
2023-08-07 16:15:38.611320: val_loss -0.3455 
2023-08-07 16:15:38.611387: Pseudo dice [0.7562] 
2023-08-07 16:15:38.611439: Epoch time: 63.52 s 
2023-08-07 16:15:38.611480: Yayy! New best EMA pseudo Dice: 0.7519 
2023-08-07 16:15:40.118696:  
2023-08-07 16:15:40.118794: Epoch 322 
2023-08-07 16:15:40.118884: Current learning rate: 0.00085 
2023-08-07 16:16:43.487512: train_loss -0.3068 
2023-08-07 16:16:43.487977: val_loss -0.3125 
2023-08-07 16:16:43.496248: Pseudo dice [0.7234] 
2023-08-07 16:16:43.496473: Epoch time: 63.37 s 
2023-08-07 16:16:44.536190:  
2023-08-07 16:16:44.536395: Epoch 323 
2023-08-07 16:16:44.536472: Current learning rate: 0.00085 
2023-08-07 16:17:47.888610: train_loss -0.3183 
2023-08-07 16:17:47.888756: val_loss -0.2553 
2023-08-07 16:17:47.888808: Pseudo dice [0.8344] 
2023-08-07 16:17:47.888856: Epoch time: 63.35 s 
2023-08-07 16:17:47.888896: Yayy! New best EMA pseudo Dice: 0.7576 
2023-08-07 16:17:49.250425:  
2023-08-07 16:17:49.250603: Epoch 324 
2023-08-07 16:17:49.250699: Current learning rate: 0.00085 
2023-08-07 16:18:52.537619: train_loss -0.3087 
2023-08-07 16:18:52.537775: val_loss -0.3628 
2023-08-07 16:18:52.537950: Pseudo dice [0.7867] 
2023-08-07 16:18:52.538003: Epoch time: 63.29 s 
2023-08-07 16:18:52.538044: Yayy! New best EMA pseudo Dice: 0.7605 
2023-08-07 16:18:53.988874:  
2023-08-07 16:18:53.988970: Epoch 325 
2023-08-07 16:18:53.989058: Current learning rate: 0.00085 
2023-08-07 16:19:57.356896: train_loss -0.3158 
2023-08-07 16:19:57.357041: val_loss -0.376 
2023-08-07 16:19:57.357092: Pseudo dice [0.8053] 
2023-08-07 16:19:57.357142: Epoch time: 63.37 s 
2023-08-07 16:19:57.357184: Yayy! New best EMA pseudo Dice: 0.765 
2023-08-07 16:19:58.739697:  
2023-08-07 16:19:58.739905: Epoch 326 
2023-08-07 16:19:58.740000: Current learning rate: 0.00085 
2023-08-07 16:21:02.080343: train_loss -0.3174 
2023-08-07 16:21:02.080496: val_loss -0.3372 
2023-08-07 16:21:02.080548: Pseudo dice [0.7903] 
2023-08-07 16:21:02.080599: Epoch time: 63.34 s 
2023-08-07 16:21:02.080639: Yayy! New best EMA pseudo Dice: 0.7675 
2023-08-07 16:21:03.587014:  
2023-08-07 16:21:03.587116: Epoch 327 
2023-08-07 16:21:03.587192: Current learning rate: 0.00085 
2023-08-07 16:22:06.885334: train_loss -0.3165 
2023-08-07 16:22:06.885483: val_loss -0.3855 
2023-08-07 16:22:06.885535: Pseudo dice [0.7099] 
2023-08-07 16:22:06.885605: Epoch time: 63.3 s 
2023-08-07 16:22:07.982951:  
2023-08-07 16:22:07.983049: Epoch 328 
2023-08-07 16:22:07.983126: Current learning rate: 0.00085 
2023-08-07 16:23:11.401765: train_loss -0.3248 
2023-08-07 16:23:11.401928: val_loss -0.3585 
2023-08-07 16:23:11.401981: Pseudo dice [0.7546] 
2023-08-07 16:23:11.402050: Epoch time: 63.42 s 
2023-08-07 16:23:12.401204:  
2023-08-07 16:23:12.401403: Epoch 329 
2023-08-07 16:23:12.401493: Current learning rate: 0.00085 
2023-08-07 16:24:15.923453: train_loss -0.3446 
2023-08-07 16:24:15.923610: val_loss -0.2727 
2023-08-07 16:24:15.923665: Pseudo dice [0.7984] 
2023-08-07 16:24:15.923715: Epoch time: 63.52 s 
2023-08-07 16:24:16.942198:  
2023-08-07 16:24:16.942375: Epoch 330 
2023-08-07 16:24:16.942466: Current learning rate: 0.00085 
2023-08-07 16:25:20.414782: train_loss -0.3177 
2023-08-07 16:25:20.414928: val_loss -0.3094 
2023-08-07 16:25:20.414978: Pseudo dice [0.7451] 
2023-08-07 16:25:20.415027: Epoch time: 63.47 s 
2023-08-07 16:25:21.440402:  
2023-08-07 16:25:21.440605: Epoch 331 
2023-08-07 16:25:21.440695: Current learning rate: 0.00085 
2023-08-07 16:26:24.767713: train_loss -0.3068 
2023-08-07 16:26:24.767865: val_loss -0.3838 
2023-08-07 16:26:24.767918: Pseudo dice [0.7723] 
2023-08-07 16:26:24.767969: Epoch time: 63.33 s 
2023-08-07 16:26:25.932026:  
2023-08-07 16:26:25.932125: Epoch 332 
2023-08-07 16:26:25.932200: Current learning rate: 0.00085 
2023-08-07 16:27:29.498855: train_loss -0.3339 
2023-08-07 16:27:29.499009: val_loss -0.3126 
2023-08-07 16:27:29.499060: Pseudo dice [0.6896] 
2023-08-07 16:27:29.499110: Epoch time: 63.57 s 
2023-08-07 16:27:30.515753:  
2023-08-07 16:27:30.515962: Epoch 333 
2023-08-07 16:27:30.516056: Current learning rate: 0.00085 
2023-08-07 16:28:34.014010: train_loss -0.3157 
2023-08-07 16:28:34.014172: val_loss -0.298 
2023-08-07 16:28:34.014242: Pseudo dice [0.7014] 
2023-08-07 16:28:34.014293: Epoch time: 63.5 s 
2023-08-07 16:28:35.052154:  
2023-08-07 16:28:35.052248: Epoch 334 
2023-08-07 16:28:35.052320: Current learning rate: 0.00085 
2023-08-07 16:29:38.430429: train_loss -0.2947 
2023-08-07 16:29:38.430576: val_loss -0.357 
2023-08-07 16:29:38.430644: Pseudo dice [0.8476] 
2023-08-07 16:29:38.430696: Epoch time: 63.38 s 
2023-08-07 16:29:39.469953:  
2023-08-07 16:29:39.470303: Epoch 335 
2023-08-07 16:29:39.470399: Current learning rate: 0.00085 
2023-08-07 16:30:42.847032: train_loss -0.3261 
2023-08-07 16:30:42.847176: val_loss -0.3316 
2023-08-07 16:30:42.847227: Pseudo dice [0.7431] 
2023-08-07 16:30:42.847294: Epoch time: 63.38 s 
2023-08-07 16:30:43.894974:  
2023-08-07 16:30:43.895068: Epoch 336 
2023-08-07 16:30:43.895138: Current learning rate: 0.00085 
2023-08-07 16:31:47.191347: train_loss -0.346 
2023-08-07 16:31:47.191493: val_loss -0.3016 
2023-08-07 16:31:47.191547: Pseudo dice [0.7753] 
2023-08-07 16:31:47.191607: Epoch time: 63.3 s 
2023-08-07 16:31:48.392053:  
2023-08-07 16:31:48.392246: Epoch 337 
2023-08-07 16:31:48.392339: Current learning rate: 0.00085 
2023-08-07 16:32:51.801792: train_loss -0.3282 
2023-08-07 16:32:51.801947: val_loss -0.3118 
2023-08-07 16:32:51.802000: Pseudo dice [0.7596] 
2023-08-07 16:32:51.802066: Epoch time: 63.41 s 
2023-08-07 16:32:52.829559:  
2023-08-07 16:32:52.829662: Epoch 338 
2023-08-07 16:32:52.829733: Current learning rate: 0.00085 
2023-08-07 16:33:56.294118: train_loss -0.3271 
2023-08-07 16:33:56.294345: val_loss -0.3863 
2023-08-07 16:33:56.294403: Pseudo dice [0.7874] 
2023-08-07 16:33:56.294454: Epoch time: 63.47 s 
2023-08-07 16:33:57.331246:  
2023-08-07 16:33:57.331338: Epoch 339 
2023-08-07 16:33:57.331411: Current learning rate: 0.00085 
2023-08-07 16:35:00.681816: train_loss -0.3216 
2023-08-07 16:35:00.681967: val_loss -0.3468 
2023-08-07 16:35:00.682021: Pseudo dice [0.7257] 
2023-08-07 16:35:00.682092: Epoch time: 63.35 s 
2023-08-07 16:35:01.758994:  
2023-08-07 16:35:01.759090: Epoch 340 
2023-08-07 16:35:01.759162: Current learning rate: 0.00085 
2023-08-07 16:36:05.183500: train_loss -0.3157 
2023-08-07 16:36:05.183673: val_loss -0.2712 
2023-08-07 16:36:05.183734: Pseudo dice [0.6542] 
2023-08-07 16:36:05.183795: Epoch time: 63.43 s 
2023-08-07 16:36:06.193383:  
2023-08-07 16:36:06.193476: Epoch 341 
2023-08-07 16:36:06.193546: Current learning rate: 0.00085 
2023-08-07 16:37:09.587693: train_loss -0.3452 
2023-08-07 16:37:09.587843: val_loss -0.376 
2023-08-07 16:37:09.587897: Pseudo dice [0.7477] 
2023-08-07 16:37:09.587948: Epoch time: 63.4 s 
2023-08-07 16:37:10.605052:  
2023-08-07 16:37:10.605251: Epoch 342 
2023-08-07 16:37:10.605328: Current learning rate: 0.00084 
2023-08-07 16:38:13.889064: train_loss -0.3169 
2023-08-07 16:38:13.889218: val_loss -0.3646 
2023-08-07 16:38:13.889267: Pseudo dice [0.6729] 
2023-08-07 16:38:13.889317: Epoch time: 63.28 s 
2023-08-07 16:38:15.077695:  
2023-08-07 16:38:15.077916: Epoch 343 
2023-08-07 16:38:15.078008: Current learning rate: 0.00084 
2023-08-07 16:39:18.324203: train_loss -0.3497 
2023-08-07 16:39:18.324370: val_loss -0.2529 
2023-08-07 16:39:18.324425: Pseudo dice [0.781] 
2023-08-07 16:39:18.324477: Epoch time: 63.25 s 
2023-08-07 16:39:19.377070:  
2023-08-07 16:39:19.377167: Epoch 344 
2023-08-07 16:39:19.377270: Current learning rate: 0.00084 
2023-08-07 16:40:22.644753: train_loss -0.3584 
2023-08-07 16:40:22.644910: val_loss -0.3562 
2023-08-07 16:40:22.644962: Pseudo dice [0.6641] 
2023-08-07 16:40:22.645032: Epoch time: 63.27 s 
2023-08-07 16:40:23.666087:  
2023-08-07 16:40:23.666186: Epoch 345 
2023-08-07 16:40:23.666258: Current learning rate: 0.00084 
2023-08-07 16:41:26.954679: train_loss -0.3174 
2023-08-07 16:41:26.954843: val_loss -0.2905 
2023-08-07 16:41:26.954898: Pseudo dice [0.7531] 
2023-08-07 16:41:26.954949: Epoch time: 63.29 s 
2023-08-07 16:41:28.011517:  
2023-08-07 16:41:28.011622: Epoch 346 
2023-08-07 16:41:28.011700: Current learning rate: 0.00084 
2023-08-07 16:42:31.439330: train_loss -0.3481 
2023-08-07 16:42:31.439490: val_loss -0.3402 
2023-08-07 16:42:31.439540: Pseudo dice [0.6999] 
2023-08-07 16:42:31.439599: Epoch time: 63.43 s 
2023-08-07 16:42:32.495438:  
2023-08-07 16:42:32.495542: Epoch 347 
2023-08-07 16:42:32.495653: Current learning rate: 0.00084 
2023-08-07 16:43:35.849881: train_loss -0.3506 
2023-08-07 16:43:35.850029: val_loss -0.4038 
2023-08-07 16:43:35.850097: Pseudo dice [0.8786] 
2023-08-07 16:43:35.850147: Epoch time: 63.36 s 
2023-08-07 16:43:37.049141:  
2023-08-07 16:43:37.049241: Epoch 348 
2023-08-07 16:43:37.049329: Current learning rate: 0.00084 
2023-08-07 16:44:40.423590: train_loss -0.3224 
2023-08-07 16:44:40.423751: val_loss -0.2799 
2023-08-07 16:44:40.423801: Pseudo dice [0.8403] 
2023-08-07 16:44:40.423851: Epoch time: 63.38 s 
2023-08-07 16:44:41.442585:  
2023-08-07 16:44:41.442681: Epoch 349 
2023-08-07 16:44:41.442752: Current learning rate: 0.00084 
2023-08-07 16:45:44.966474: train_loss -0.3036 
2023-08-07 16:45:44.966620: val_loss -0.3968 
2023-08-07 16:45:44.966670: Pseudo dice [0.8411] 
2023-08-07 16:45:44.966720: Epoch time: 63.52 s 
2023-08-07 16:45:46.411347:  
2023-08-07 16:45:46.411442: Epoch 350 
2023-08-07 16:45:46.411532: Current learning rate: 0.00084 
2023-08-07 16:46:49.781775: train_loss -0.3412 
2023-08-07 16:46:49.781934: val_loss -0.2875 
2023-08-07 16:46:49.781986: Pseudo dice [0.6863] 
2023-08-07 16:46:49.782037: Epoch time: 63.37 s 
2023-08-07 16:46:50.803058:  
2023-08-07 16:46:50.803159: Epoch 351 
2023-08-07 16:46:50.803228: Current learning rate: 0.00084 
2023-08-07 16:47:54.265520: train_loss -0.3151 
2023-08-07 16:47:54.265665: val_loss -0.3288 
2023-08-07 16:47:54.265716: Pseudo dice [0.6823] 
2023-08-07 16:47:54.265767: Epoch time: 63.46 s 
2023-08-07 16:47:55.288502:  
2023-08-07 16:47:55.288823: Epoch 352 
2023-08-07 16:47:55.288903: Current learning rate: 0.00084 
2023-08-07 16:48:58.700227: train_loss -0.3182 
2023-08-07 16:48:58.700365: val_loss -0.2965 
2023-08-07 16:48:58.700414: Pseudo dice [0.7127] 
2023-08-07 16:48:58.700465: Epoch time: 63.41 s 
2023-08-07 16:48:59.890045:  
2023-08-07 16:48:59.890150: Epoch 353 
2023-08-07 16:48:59.890242: Current learning rate: 0.00084 
2023-08-07 16:50:03.502738: train_loss -0.2993 
2023-08-07 16:50:03.502899: val_loss -0.3181 
2023-08-07 16:50:03.502950: Pseudo dice [0.5306] 
2023-08-07 16:50:03.503019: Epoch time: 63.61 s 
2023-08-07 16:50:04.522918:  
2023-08-07 16:50:04.523015: Epoch 354 
2023-08-07 16:50:04.523119: Current learning rate: 0.00084 
2023-08-07 16:51:08.133252: train_loss -0.2966 
2023-08-07 16:51:08.133402: val_loss -0.2551 
2023-08-07 16:51:08.133469: Pseudo dice [0.7086] 
2023-08-07 16:51:08.133519: Epoch time: 63.61 s 
2023-08-07 16:51:09.149858:  
2023-08-07 16:51:09.149951: Epoch 355 
2023-08-07 16:51:09.150021: Current learning rate: 0.00084 
2023-08-07 16:52:12.489349: train_loss -0.3248 
2023-08-07 16:52:12.489506: val_loss -0.3639 
2023-08-07 16:52:12.489576: Pseudo dice [0.8087] 
2023-08-07 16:52:12.489629: Epoch time: 63.34 s 
2023-08-07 16:52:13.549065:  
2023-08-07 16:52:13.549160: Epoch 356 
2023-08-07 16:52:13.549232: Current learning rate: 0.00084 
2023-08-07 16:53:16.983896: train_loss -0.3209 
2023-08-07 16:53:16.984040: val_loss -0.3349 
2023-08-07 16:53:16.984090: Pseudo dice [0.7824] 
2023-08-07 16:53:16.984142: Epoch time: 63.44 s 
2023-08-07 16:53:18.059487:  
2023-08-07 16:53:18.059587: Epoch 357 
2023-08-07 16:53:18.059681: Current learning rate: 0.00084 
2023-08-07 16:54:21.546412: train_loss -0.3549 
2023-08-07 16:54:21.546565: val_loss -0.3248 
2023-08-07 16:54:21.546633: Pseudo dice [0.8261] 
2023-08-07 16:54:21.546688: Epoch time: 63.49 s 
2023-08-07 16:54:22.572610:  
2023-08-07 16:54:22.572714: Epoch 358 
2023-08-07 16:54:22.572787: Current learning rate: 0.00084 
2023-08-07 16:55:26.357378: train_loss -0.3242 
2023-08-07 16:55:26.357539: val_loss -0.3544 
2023-08-07 16:55:26.357590: Pseudo dice [0.8136] 
2023-08-07 16:55:26.357640: Epoch time: 63.79 s 
2023-08-07 16:55:27.412585:  
2023-08-07 16:55:27.412704: Epoch 359 
2023-08-07 16:55:27.412778: Current learning rate: 0.00084 
2023-08-07 16:56:30.917470: train_loss -0.3248 
2023-08-07 16:56:30.917629: val_loss -0.3653 
2023-08-07 16:56:30.917684: Pseudo dice [0.9093] 
2023-08-07 16:56:30.917737: Epoch time: 63.51 s 
2023-08-07 16:56:30.917778: Yayy! New best EMA pseudo Dice: 0.7685 
2023-08-07 16:56:32.297496:  
2023-08-07 16:56:32.297687: Epoch 360 
2023-08-07 16:56:32.297872: Current learning rate: 0.00084 
2023-08-07 16:57:35.593258: train_loss -0.3555 
2023-08-07 16:57:35.593408: val_loss -0.3 
2023-08-07 16:57:35.593460: Pseudo dice [0.8365] 
2023-08-07 16:57:35.593510: Epoch time: 63.3 s 
2023-08-07 16:57:35.593551: Yayy! New best EMA pseudo Dice: 0.7753 
2023-08-07 16:57:36.967906:  
2023-08-07 16:57:36.968003: Epoch 361 
2023-08-07 16:57:36.968076: Current learning rate: 0.00084 
2023-08-07 16:58:40.451518: train_loss -0.3377 
2023-08-07 16:58:40.451689: val_loss -0.2553 
2023-08-07 16:58:40.451741: Pseudo dice [0.7893] 
2023-08-07 16:58:40.451791: Epoch time: 63.48 s 
2023-08-07 16:58:40.451832: Yayy! New best EMA pseudo Dice: 0.7767 
2023-08-07 16:58:41.817701:  
2023-08-07 16:58:41.817893: Epoch 362 
2023-08-07 16:58:41.817973: Current learning rate: 0.00084 
2023-08-07 16:59:45.276167: train_loss -0.3372 
2023-08-07 16:59:45.276316: val_loss -0.2771 
2023-08-07 16:59:45.276368: Pseudo dice [0.7716] 
2023-08-07 16:59:45.276418: Epoch time: 63.46 s 
2023-08-07 16:59:46.435092:  
2023-08-07 16:59:46.435197: Epoch 363 
2023-08-07 16:59:46.435270: Current learning rate: 0.00084 
2023-08-07 17:00:49.891257: train_loss -0.3187 
2023-08-07 17:00:49.891498: val_loss -0.3059 
2023-08-07 17:00:49.891550: Pseudo dice [0.6966] 
2023-08-07 17:00:49.891611: Epoch time: 63.46 s 
2023-08-07 17:00:50.916214:  
2023-08-07 17:00:50.916313: Epoch 364 
2023-08-07 17:00:50.916388: Current learning rate: 0.00083 
2023-08-07 17:01:54.367115: train_loss -0.347 
2023-08-07 17:01:54.367260: val_loss -0.3719 
2023-08-07 17:01:54.367327: Pseudo dice [0.7939] 
2023-08-07 17:01:54.367377: Epoch time: 63.45 s 
2023-08-07 17:01:55.404722:  
2023-08-07 17:01:55.404831: Epoch 365 
2023-08-07 17:01:55.404907: Current learning rate: 0.00083 
2023-08-07 17:02:58.911392: train_loss -0.3279 
2023-08-07 17:02:58.911586: val_loss -0.3473 
2023-08-07 17:02:58.911648: Pseudo dice [0.693] 
2023-08-07 17:02:58.911700: Epoch time: 63.51 s 
2023-08-07 17:02:59.921497:  
2023-08-07 17:02:59.921594: Epoch 366 
2023-08-07 17:02:59.921665: Current learning rate: 0.00083 
2023-08-07 17:04:03.231023: train_loss -0.3517 
2023-08-07 17:04:03.231191: val_loss -0.381 
2023-08-07 17:04:03.231245: Pseudo dice [0.7523] 
2023-08-07 17:04:03.231296: Epoch time: 63.31 s 
2023-08-07 17:04:04.259039:  
2023-08-07 17:04:04.259271: Epoch 367 
2023-08-07 17:04:04.259367: Current learning rate: 0.00083 
2023-08-07 17:05:07.681345: train_loss -0.3148 
2023-08-07 17:05:07.681493: val_loss -0.3041 
2023-08-07 17:05:07.681560: Pseudo dice [0.7222] 
2023-08-07 17:05:07.681611: Epoch time: 63.42 s 
2023-08-07 17:05:08.704710:  
2023-08-07 17:05:08.704822: Epoch 368 
2023-08-07 17:05:08.704897: Current learning rate: 0.00083 
2023-08-07 17:06:12.068126: train_loss -0.3454 
2023-08-07 17:06:12.068400: val_loss -0.3047 
2023-08-07 17:06:12.068455: Pseudo dice [0.8567] 
2023-08-07 17:06:12.068505: Epoch time: 63.36 s 
2023-08-07 17:06:13.288000:  
2023-08-07 17:06:13.288178: Epoch 369 
2023-08-07 17:06:13.288252: Current learning rate: 0.00083 
2023-08-07 17:07:16.480329: train_loss -0.3558 
2023-08-07 17:07:16.480480: val_loss -0.3637 
2023-08-07 17:07:16.480532: Pseudo dice [0.7448] 
2023-08-07 17:07:16.480583: Epoch time: 63.19 s 
2023-08-07 17:07:17.524886:  
2023-08-07 17:07:17.524982: Epoch 370 
2023-08-07 17:07:17.525054: Current learning rate: 0.00083 
2023-08-07 17:08:20.670845: train_loss -0.3011 
2023-08-07 17:08:20.670995: val_loss -0.3521 
2023-08-07 17:08:20.671045: Pseudo dice [0.8383] 
2023-08-07 17:08:20.671096: Epoch time: 63.15 s 
2023-08-07 17:08:21.709000:  
2023-08-07 17:08:21.709110: Epoch 371 
2023-08-07 17:08:21.709202: Current learning rate: 0.00083 
2023-08-07 17:09:25.180608: train_loss -0.3618 
2023-08-07 17:09:25.180761: val_loss -0.3397 
2023-08-07 17:09:25.180816: Pseudo dice [0.7076] 
2023-08-07 17:09:25.180867: Epoch time: 63.47 s 
2023-08-07 17:09:26.232955:  
2023-08-07 17:09:26.233051: Epoch 372 
2023-08-07 17:09:26.233139: Current learning rate: 0.00083 
2023-08-07 17:10:29.824414: train_loss -0.3512 
2023-08-07 17:10:29.824569: val_loss -0.3401 
2023-08-07 17:10:29.824621: Pseudo dice [0.6265] 
2023-08-07 17:10:29.824673: Epoch time: 63.59 s 
2023-08-07 17:10:30.876844:  
2023-08-07 17:10:30.876951: Epoch 373 
2023-08-07 17:10:30.877041: Current learning rate: 0.00083 
2023-08-07 17:11:34.369557: train_loss -0.3304 
2023-08-07 17:11:34.369968: val_loss -0.3154 
2023-08-07 17:11:34.370046: Pseudo dice [0.7468] 
2023-08-07 17:11:34.370099: Epoch time: 63.49 s 
2023-08-07 17:11:35.562085:  
2023-08-07 17:11:35.562180: Epoch 374 
2023-08-07 17:11:35.562270: Current learning rate: 0.00083 
2023-08-07 17:12:38.904638: train_loss -0.3589 
2023-08-07 17:12:38.904815: val_loss -0.36 
2023-08-07 17:12:38.904870: Pseudo dice [0.8182] 
2023-08-07 17:12:38.904920: Epoch time: 63.34 s 
2023-08-07 17:12:39.982425:  
2023-08-07 17:12:39.982519: Epoch 375 
2023-08-07 17:12:39.982607: Current learning rate: 0.00083 
2023-08-07 17:13:43.431194: train_loss -0.3566 
2023-08-07 17:13:43.431340: val_loss -0.342 
2023-08-07 17:13:43.431410: Pseudo dice [0.7778] 
2023-08-07 17:13:43.431461: Epoch time: 63.45 s 
2023-08-07 17:13:44.449303:  
2023-08-07 17:13:44.449405: Epoch 376 
2023-08-07 17:13:44.449478: Current learning rate: 0.00083 
2023-08-07 17:14:48.127689: train_loss -0.3088 
2023-08-07 17:14:48.127834: val_loss -0.3439 
2023-08-07 17:14:48.127885: Pseudo dice [0.8263] 
2023-08-07 17:14:48.127935: Epoch time: 63.68 s 
2023-08-07 17:14:49.167601:  
2023-08-07 17:14:49.167697: Epoch 377 
2023-08-07 17:14:49.167768: Current learning rate: 0.00083 
2023-08-07 17:15:52.560465: train_loss -0.3186 
2023-08-07 17:15:52.560622: val_loss -0.3009 
2023-08-07 17:15:52.560676: Pseudo dice [0.7895] 
2023-08-07 17:15:52.560726: Epoch time: 63.39 s 
2023-08-07 17:15:53.616854:  
2023-08-07 17:15:53.616951: Epoch 378 
2023-08-07 17:15:53.617026: Current learning rate: 0.00083 
2023-08-07 17:16:57.087837: train_loss -0.3498 
2023-08-07 17:16:57.087988: val_loss -0.3998 
2023-08-07 17:16:57.088040: Pseudo dice [0.8705] 
2023-08-07 17:16:57.088092: Epoch time: 63.47 s 
2023-08-07 17:16:57.088133: Yayy! New best EMA pseudo Dice: 0.7793 
2023-08-07 17:16:58.671008:  
2023-08-07 17:16:58.671116: Epoch 379 
2023-08-07 17:16:58.671201: Current learning rate: 0.00083 
2023-08-07 17:18:02.218089: train_loss -0.3438 
2023-08-07 17:18:02.218241: val_loss -0.3019 
2023-08-07 17:18:02.218292: Pseudo dice [0.7276] 
2023-08-07 17:18:02.218341: Epoch time: 63.55 s 
2023-08-07 17:18:03.245021:  
2023-08-07 17:18:03.245115: Epoch 380 
2023-08-07 17:18:03.245200: Current learning rate: 0.00083 
2023-08-07 17:19:06.801023: train_loss -0.3487 
2023-08-07 17:19:06.801169: val_loss -0.3436 
2023-08-07 17:19:06.801218: Pseudo dice [0.6647] 
2023-08-07 17:19:06.801283: Epoch time: 63.56 s 
2023-08-07 17:19:07.896889:  
2023-08-07 17:19:07.897203: Epoch 381 
2023-08-07 17:19:07.897299: Current learning rate: 0.00083 
2023-08-07 17:20:11.232411: train_loss -0.3452 
2023-08-07 17:20:11.232560: val_loss -0.3183 
2023-08-07 17:20:11.232613: Pseudo dice [0.7498] 
2023-08-07 17:20:11.232664: Epoch time: 63.34 s 
2023-08-07 17:20:12.297500:  
2023-08-07 17:20:12.297761: Epoch 382 
2023-08-07 17:20:12.297928: Current learning rate: 0.00083 
2023-08-07 17:21:15.741382: train_loss -0.3471 
2023-08-07 17:21:15.741531: val_loss -0.3357 
2023-08-07 17:21:15.741584: Pseudo dice [0.7089] 
2023-08-07 17:21:15.741636: Epoch time: 63.44 s 
2023-08-07 17:21:16.771678:  
2023-08-07 17:21:16.771777: Epoch 383 
2023-08-07 17:21:16.771848: Current learning rate: 0.00083 
2023-08-07 17:22:20.359648: train_loss -0.3566 
2023-08-07 17:22:20.359798: val_loss -0.307 
2023-08-07 17:22:20.359852: Pseudo dice [0.7898] 
2023-08-07 17:22:20.359901: Epoch time: 63.59 s 
2023-08-07 17:22:21.411487:  
2023-08-07 17:22:21.411588: Epoch 384 
2023-08-07 17:22:21.411677: Current learning rate: 0.00083 
2023-08-07 17:23:24.954756: train_loss -0.3512 
2023-08-07 17:23:24.954911: val_loss -0.3508 
2023-08-07 17:23:24.954962: Pseudo dice [0.7621] 
2023-08-07 17:23:24.955032: Epoch time: 63.54 s 
2023-08-07 17:23:26.242030:  
2023-08-07 17:23:26.242137: Epoch 385 
2023-08-07 17:23:26.242208: Current learning rate: 0.00082 
2023-08-07 17:24:29.659764: train_loss -0.309 
2023-08-07 17:24:29.659912: val_loss -0.4393 
2023-08-07 17:24:29.659966: Pseudo dice [0.8687] 
2023-08-07 17:24:29.660016: Epoch time: 63.42 s 
2023-08-07 17:24:30.693544:  
2023-08-07 17:24:30.693870: Epoch 386 
2023-08-07 17:24:30.694021: Current learning rate: 0.00082 
2023-08-07 17:25:34.330959: train_loss -0.3288 
2023-08-07 17:25:34.331109: val_loss -0.2891 
2023-08-07 17:25:34.331159: Pseudo dice [0.8148] 
2023-08-07 17:25:34.331224: Epoch time: 63.64 s 
2023-08-07 17:25:35.371981:  
2023-08-07 17:25:35.372189: Epoch 387 
2023-08-07 17:25:35.372266: Current learning rate: 0.00082 
2023-08-07 17:26:38.757557: train_loss -0.2876 
2023-08-07 17:26:38.757719: val_loss -0.3404 
2023-08-07 17:26:38.757780: Pseudo dice [0.8288] 
2023-08-07 17:26:38.757839: Epoch time: 63.39 s 
2023-08-07 17:26:38.757888: Yayy! New best EMA pseudo Dice: 0.7807 
2023-08-07 17:26:40.175945:  
2023-08-07 17:26:40.176053: Epoch 388 
2023-08-07 17:26:40.176128: Current learning rate: 0.00082 
2023-08-07 17:27:43.495172: train_loss -0.3427 
2023-08-07 17:27:43.495317: val_loss -0.3975 
2023-08-07 17:27:43.495370: Pseudo dice [0.8489] 
2023-08-07 17:27:43.495419: Epoch time: 63.32 s 
2023-08-07 17:27:43.495459: Yayy! New best EMA pseudo Dice: 0.7875 
2023-08-07 17:27:45.065762:  
2023-08-07 17:27:45.065956: Epoch 389 
2023-08-07 17:27:45.066042: Current learning rate: 0.00082 
2023-08-07 17:28:48.403152: train_loss -0.3409 
2023-08-07 17:28:48.403296: val_loss -0.3492 
2023-08-07 17:28:48.403363: Pseudo dice [0.7016] 
2023-08-07 17:28:48.403413: Epoch time: 63.34 s 
2023-08-07 17:28:49.438625:  
2023-08-07 17:28:49.438720: Epoch 390 
2023-08-07 17:28:49.438792: Current learning rate: 0.00082 
2023-08-07 17:29:52.992230: train_loss -0.3179 
2023-08-07 17:29:52.992379: val_loss -0.3265 
2023-08-07 17:29:52.992432: Pseudo dice [0.8534] 
2023-08-07 17:29:52.992482: Epoch time: 63.55 s 
2023-08-07 17:29:54.037910:  
2023-08-07 17:29:54.038013: Epoch 391 
2023-08-07 17:29:54.038086: Current learning rate: 0.00082 
2023-08-07 17:30:57.470013: train_loss -0.3584 
2023-08-07 17:30:57.470159: val_loss -0.3922 
2023-08-07 17:30:57.470207: Pseudo dice [0.7897] 
2023-08-07 17:30:57.470274: Epoch time: 63.43 s 
2023-08-07 17:30:58.531092:  
2023-08-07 17:30:58.531195: Epoch 392 
2023-08-07 17:30:58.531268: Current learning rate: 0.00082 
2023-08-07 17:32:01.965274: train_loss -0.2825 
2023-08-07 17:32:01.965433: val_loss -0.339 
2023-08-07 17:32:01.965483: Pseudo dice [0.7481] 
2023-08-07 17:32:01.965538: Epoch time: 63.43 s 
2023-08-07 17:32:03.012017:  
2023-08-07 17:32:03.012116: Epoch 393 
2023-08-07 17:32:03.012207: Current learning rate: 0.00082 
2023-08-07 17:33:06.528886: train_loss -0.3188 
2023-08-07 17:33:06.529034: val_loss -0.3513 
2023-08-07 17:33:06.529086: Pseudo dice [0.7624] 
2023-08-07 17:33:06.529136: Epoch time: 63.52 s 
2023-08-07 17:33:07.563029:  
2023-08-07 17:33:07.563208: Epoch 394 
2023-08-07 17:33:07.563299: Current learning rate: 0.00082 
2023-08-07 17:34:11.026718: train_loss -0.2992 
2023-08-07 17:34:11.026860: val_loss -0.3306 
2023-08-07 17:34:11.026911: Pseudo dice [0.846] 
2023-08-07 17:34:11.026961: Epoch time: 63.46 s 
2023-08-07 17:34:12.222112:  
2023-08-07 17:34:12.222211: Epoch 395 
2023-08-07 17:34:12.222299: Current learning rate: 0.00082 
2023-08-07 17:35:15.591141: train_loss -0.329 
2023-08-07 17:35:15.591292: val_loss -0.3338 
2023-08-07 17:35:15.591348: Pseudo dice [0.8496] 
2023-08-07 17:35:15.591400: Epoch time: 63.37 s 
2023-08-07 17:35:15.591441: Yayy! New best EMA pseudo Dice: 0.7935 
2023-08-07 17:35:16.998223:  
2023-08-07 17:35:16.998323: Epoch 396 
2023-08-07 17:35:16.998395: Current learning rate: 0.00082 
2023-08-07 17:36:20.411491: train_loss -0.3486 
2023-08-07 17:36:20.411936: val_loss -0.3482 
2023-08-07 17:36:20.412111: Pseudo dice [0.7838] 
2023-08-07 17:36:20.412254: Epoch time: 63.41 s 
2023-08-07 17:36:21.504825:  
2023-08-07 17:36:21.505003: Epoch 397 
2023-08-07 17:36:21.505109: Current learning rate: 0.00082 
2023-08-07 17:37:24.918055: train_loss -0.3203 
2023-08-07 17:37:24.918217: val_loss -0.3391 
2023-08-07 17:37:24.918286: Pseudo dice [0.6139] 
2023-08-07 17:37:24.918336: Epoch time: 63.41 s 
2023-08-07 17:37:25.975058:  
2023-08-07 17:37:25.975154: Epoch 398 
2023-08-07 17:37:25.975226: Current learning rate: 0.00082 
2023-08-07 17:38:29.516402: train_loss -0.3438 
2023-08-07 17:38:29.516553: val_loss -0.2971 
2023-08-07 17:38:29.516604: Pseudo dice [0.7331] 
2023-08-07 17:38:29.516656: Epoch time: 63.54 s 
2023-08-07 17:38:30.549851:  
2023-08-07 17:38:30.549943: Epoch 399 
2023-08-07 17:38:30.550030: Current learning rate: 0.00082 
2023-08-07 17:39:34.027400: train_loss -0.3518 
2023-08-07 17:39:34.027550: val_loss -0.3437 
2023-08-07 17:39:34.027758: Pseudo dice [0.8164] 
2023-08-07 17:39:34.027810: Epoch time: 63.48 s 
2023-08-07 17:39:35.583201:  
2023-08-07 17:39:35.583527: Epoch 400 
2023-08-07 17:39:35.583613: Current learning rate: 0.00082 
2023-08-07 17:40:39.097291: train_loss -0.349 
2023-08-07 17:40:39.097433: val_loss -0.3296 
2023-08-07 17:40:39.097485: Pseudo dice [0.8121] 
2023-08-07 17:40:39.097552: Epoch time: 63.51 s 
2023-08-07 17:40:40.133743:  
2023-08-07 17:40:40.134027: Epoch 401 
2023-08-07 17:40:40.134200: Current learning rate: 0.00082 
2023-08-07 17:41:43.585694: train_loss -0.346 
2023-08-07 17:41:43.585840: val_loss -0.3409 
2023-08-07 17:41:43.585890: Pseudo dice [0.718] 
2023-08-07 17:41:43.585956: Epoch time: 63.45 s 
2023-08-07 17:41:44.656852:  
2023-08-07 17:41:44.656946: Epoch 402 
2023-08-07 17:41:44.657016: Current learning rate: 0.00082 
2023-08-07 17:42:47.856440: train_loss -0.3164 
2023-08-07 17:42:47.856591: val_loss -0.361 
2023-08-07 17:42:47.856643: Pseudo dice [0.8104] 
2023-08-07 17:42:47.856694: Epoch time: 63.2 s 
2023-08-07 17:42:48.936522:  
2023-08-07 17:42:48.936619: Epoch 403 
2023-08-07 17:42:48.936707: Current learning rate: 0.00082 
2023-08-07 17:43:52.290067: train_loss -0.3526 
2023-08-07 17:43:52.290222: val_loss -0.3492 
2023-08-07 17:43:52.290290: Pseudo dice [0.7273] 
2023-08-07 17:43:52.290342: Epoch time: 63.35 s 
2023-08-07 17:43:53.433946:  
2023-08-07 17:43:53.434041: Epoch 404 
2023-08-07 17:43:53.434114: Current learning rate: 0.00082 
2023-08-07 17:44:56.980078: train_loss -0.334 
2023-08-07 17:44:56.980222: val_loss -0.3395 
2023-08-07 17:44:56.980272: Pseudo dice [0.8382] 
2023-08-07 17:44:56.980322: Epoch time: 63.55 s 
2023-08-07 17:44:58.019902:  
2023-08-07 17:44:58.019997: Epoch 405 
2023-08-07 17:44:58.020072: Current learning rate: 0.00082 
2023-08-07 17:46:01.716000: train_loss -0.3253 
2023-08-07 17:46:01.716149: val_loss -0.3513 
2023-08-07 17:46:01.716200: Pseudo dice [0.8182] 
2023-08-07 17:46:01.716249: Epoch time: 63.7 s 
2023-08-07 17:46:02.782644:  
2023-08-07 17:46:02.782746: Epoch 406 
2023-08-07 17:46:02.782820: Current learning rate: 0.00082 
2023-08-07 17:47:06.190707: train_loss -0.3407 
2023-08-07 17:47:06.190887: val_loss -0.3539 
2023-08-07 17:47:06.190955: Pseudo dice [0.7983] 
2023-08-07 17:47:06.191007: Epoch time: 63.41 s 
2023-08-07 17:47:07.271032:  
2023-08-07 17:47:07.271124: Epoch 407 
2023-08-07 17:47:07.271194: Current learning rate: 0.00081 
2023-08-07 17:48:10.556524: train_loss -0.3055 
2023-08-07 17:48:10.556670: val_loss -0.3361 
2023-08-07 17:48:10.556721: Pseudo dice [0.7097] 
2023-08-07 17:48:10.556772: Epoch time: 63.29 s 
2023-08-07 17:48:11.598298:  
2023-08-07 17:48:11.598400: Epoch 408 
2023-08-07 17:48:11.598473: Current learning rate: 0.00081 
2023-08-07 17:49:14.918953: train_loss -0.3324 
2023-08-07 17:49:14.919225: val_loss -0.3023 
2023-08-07 17:49:14.919279: Pseudo dice [0.7694] 
2023-08-07 17:49:14.919330: Epoch time: 63.32 s 
2023-08-07 17:49:15.964688:  
2023-08-07 17:49:15.964963: Epoch 409 
2023-08-07 17:49:15.965077: Current learning rate: 0.00081 
2023-08-07 17:50:19.439973: train_loss -0.3542 
2023-08-07 17:50:19.440131: val_loss -0.3922 
2023-08-07 17:50:19.440182: Pseudo dice [0.7102] 
2023-08-07 17:50:19.440235: Epoch time: 63.48 s 
2023-08-07 17:50:20.620530:  
2023-08-07 17:50:20.620697: Epoch 410 
2023-08-07 17:50:20.620776: Current learning rate: 0.00081 
2023-08-07 17:51:24.314709: train_loss -0.3315 
2023-08-07 17:51:24.314883: val_loss -0.3976 
2023-08-07 17:51:24.314937: Pseudo dice [0.7851] 
2023-08-07 17:51:24.314989: Epoch time: 63.69 s 
2023-08-07 17:51:25.311309:  
2023-08-07 17:51:25.311406: Epoch 411 
2023-08-07 17:51:25.311495: Current learning rate: 0.00081 
2023-08-07 17:52:28.724092: train_loss -0.3439 
2023-08-07 17:52:28.724245: val_loss -0.3461 
2023-08-07 17:52:28.724298: Pseudo dice [0.7721] 
2023-08-07 17:52:28.724347: Epoch time: 63.41 s 
2023-08-07 17:52:29.785296:  
2023-08-07 17:52:29.785394: Epoch 412 
2023-08-07 17:52:29.785482: Current learning rate: 0.00081 
2023-08-07 17:53:33.193884: train_loss -0.3243 
2023-08-07 17:53:33.194039: val_loss -0.3561 
2023-08-07 17:53:33.194093: Pseudo dice [0.7258] 
2023-08-07 17:53:33.194144: Epoch time: 63.41 s 
2023-08-07 17:53:34.192565:  
2023-08-07 17:53:34.192662: Epoch 413 
2023-08-07 17:53:34.192736: Current learning rate: 0.00081 
2023-08-07 17:54:37.716936: train_loss -0.2971 
2023-08-07 17:54:37.717082: val_loss -0.3621 
2023-08-07 17:54:37.717149: Pseudo dice [0.8245] 
2023-08-07 17:54:37.717202: Epoch time: 63.53 s 
2023-08-07 17:54:38.741159:  
2023-08-07 17:54:38.741261: Epoch 414 
2023-08-07 17:54:38.741334: Current learning rate: 0.00081 
2023-08-07 17:55:42.253217: train_loss -0.3544 
2023-08-07 17:55:42.253387: val_loss -0.3913 
2023-08-07 17:55:42.253557: Pseudo dice [0.7943] 
2023-08-07 17:55:42.253612: Epoch time: 63.51 s 
2023-08-07 17:55:43.251483:  
2023-08-07 17:55:43.251818: Epoch 415 
2023-08-07 17:55:43.252032: Current learning rate: 0.00081 
2023-08-07 17:56:46.639793: train_loss -0.3313 
2023-08-07 17:56:46.639946: val_loss -0.3363 
2023-08-07 17:56:46.640008: Pseudo dice [0.7654] 
2023-08-07 17:56:46.640059: Epoch time: 63.39 s 
2023-08-07 17:56:47.801714:  
2023-08-07 17:56:47.801820: Epoch 416 
2023-08-07 17:56:47.801906: Current learning rate: 0.00081 
2023-08-07 17:57:51.165905: train_loss -0.3285 
2023-08-07 17:57:51.166047: val_loss -0.3496 
2023-08-07 17:57:51.166097: Pseudo dice [0.7439] 
2023-08-07 17:57:51.166163: Epoch time: 63.36 s 
2023-08-07 17:57:52.170061:  
2023-08-07 17:57:52.170156: Epoch 417 
2023-08-07 17:57:52.170243: Current learning rate: 0.00081 
2023-08-07 17:58:55.731452: train_loss -0.3159 
2023-08-07 17:58:55.731621: val_loss -0.3831 
2023-08-07 17:58:55.731692: Pseudo dice [0.8077] 
2023-08-07 17:58:55.731744: Epoch time: 63.56 s 
2023-08-07 17:58:56.719809:  
2023-08-07 17:58:56.719907: Epoch 418 
2023-08-07 17:58:56.719998: Current learning rate: 0.00081 
2023-08-07 18:00:00.092924: train_loss -0.3207 
2023-08-07 18:00:00.093258: val_loss -0.3718 
2023-08-07 18:00:00.093352: Pseudo dice [0.8405] 
2023-08-07 18:00:00.093444: Epoch time: 63.37 s 
2023-08-07 18:00:01.081277:  
2023-08-07 18:00:01.081373: Epoch 419 
2023-08-07 18:00:01.081444: Current learning rate: 0.00081 
2023-08-07 18:01:04.492746: train_loss -0.3674 
2023-08-07 18:01:04.492891: val_loss -0.3122 
2023-08-07 18:01:04.492945: Pseudo dice [0.7826] 
2023-08-07 18:01:04.492996: Epoch time: 63.41 s 
2023-08-07 18:01:05.469465:  
2023-08-07 18:01:05.469565: Epoch 420 
2023-08-07 18:01:05.469638: Current learning rate: 0.00081 
2023-08-07 18:02:09.002841: train_loss -0.3616 
2023-08-07 18:02:09.002989: val_loss -0.3151 
2023-08-07 18:02:09.003041: Pseudo dice [0.802] 
2023-08-07 18:02:09.003092: Epoch time: 63.53 s 
2023-08-07 18:02:09.994807:  
2023-08-07 18:02:09.994904: Epoch 421 
2023-08-07 18:02:09.994994: Current learning rate: 0.00081 
2023-08-07 18:03:13.307075: train_loss -0.3517 
2023-08-07 18:03:13.307305: val_loss -0.3522 
2023-08-07 18:03:13.307360: Pseudo dice [0.8025] 
2023-08-07 18:03:13.307411: Epoch time: 63.31 s 
2023-08-07 18:03:14.442799:  
2023-08-07 18:03:14.442908: Epoch 422 
2023-08-07 18:03:14.442983: Current learning rate: 0.00081 
2023-08-07 18:04:17.849525: train_loss -0.3172 
2023-08-07 18:04:17.849674: val_loss -0.4046 
2023-08-07 18:04:17.849727: Pseudo dice [0.8372] 
2023-08-07 18:04:17.849793: Epoch time: 63.41 s 
2023-08-07 18:04:18.848520:  
2023-08-07 18:04:18.848622: Epoch 423 
2023-08-07 18:04:18.848697: Current learning rate: 0.00081 
2023-08-07 18:05:22.322708: train_loss -0.3374 
2023-08-07 18:05:22.322858: val_loss -0.3489 
2023-08-07 18:05:22.323050: Pseudo dice [0.7636] 
2023-08-07 18:05:22.323104: Epoch time: 63.47 s 
2023-08-07 18:05:23.319222:  
2023-08-07 18:05:23.319318: Epoch 424 
2023-08-07 18:05:23.319389: Current learning rate: 0.00081 
2023-08-07 18:06:26.815565: train_loss -0.328 
2023-08-07 18:06:26.815734: val_loss -0.345 
2023-08-07 18:06:26.815787: Pseudo dice [0.7033] 
2023-08-07 18:06:26.815839: Epoch time: 63.5 s 
2023-08-07 18:06:27.793428:  
2023-08-07 18:06:27.793535: Epoch 425 
2023-08-07 18:06:27.793622: Current learning rate: 0.00081 
2023-08-07 18:07:31.188329: train_loss -0.323 
2023-08-07 18:07:31.188492: val_loss -0.2745 
2023-08-07 18:07:31.188545: Pseudo dice [0.6505] 
2023-08-07 18:07:31.188596: Epoch time: 63.4 s 
2023-08-07 18:07:32.230779:  
2023-08-07 18:07:32.230877: Epoch 426 
2023-08-07 18:07:32.230949: Current learning rate: 0.00081 
2023-08-07 18:08:35.439532: train_loss -0.3457 
2023-08-07 18:08:35.439708: val_loss -0.3744 
2023-08-07 18:08:35.439762: Pseudo dice [0.8055] 
2023-08-07 18:08:35.439814: Epoch time: 63.21 s 
2023-08-07 18:08:36.413881:  
2023-08-07 18:08:36.414052: Epoch 427 
2023-08-07 18:08:36.414126: Current learning rate: 0.00081 
2023-08-07 18:09:39.754068: train_loss -0.3169 
2023-08-07 18:09:39.754217: val_loss -0.352 
2023-08-07 18:09:39.754267: Pseudo dice [0.7866] 
2023-08-07 18:09:39.754317: Epoch time: 63.34 s 
2023-08-07 18:09:40.906878:  
2023-08-07 18:09:40.907057: Epoch 428 
2023-08-07 18:09:40.907136: Current learning rate: 0.00081 
2023-08-07 18:10:44.454329: train_loss -0.3513 
2023-08-07 18:10:44.454480: val_loss -0.2687 
2023-08-07 18:10:44.454533: Pseudo dice [0.8539] 
2023-08-07 18:10:44.454601: Epoch time: 63.55 s 
2023-08-07 18:10:45.432732:  
2023-08-07 18:10:45.432846: Epoch 429 
2023-08-07 18:10:45.432915: Current learning rate: 0.0008 
2023-08-07 18:11:48.748149: train_loss -0.3404 
2023-08-07 18:11:48.748303: val_loss -0.3175 
2023-08-07 18:11:48.748352: Pseudo dice [0.8511] 
2023-08-07 18:11:48.748403: Epoch time: 63.32 s 
2023-08-07 18:11:49.716232:  
2023-08-07 18:11:49.716338: Epoch 430 
2023-08-07 18:11:49.716411: Current learning rate: 0.0008 
2023-08-07 18:12:53.155471: train_loss -0.315 
2023-08-07 18:12:53.155635: val_loss -0.3007 
2023-08-07 18:12:53.155686: Pseudo dice [0.7201] 
2023-08-07 18:12:53.155737: Epoch time: 63.44 s 
2023-08-07 18:12:54.149291:  
2023-08-07 18:12:54.149390: Epoch 431 
2023-08-07 18:12:54.149477: Current learning rate: 0.0008 
2023-08-07 18:13:57.565480: train_loss -0.322 
2023-08-07 18:13:57.565629: val_loss -0.3183 
2023-08-07 18:13:57.565697: Pseudo dice [0.707] 
2023-08-07 18:13:57.565747: Epoch time: 63.42 s 
2023-08-07 18:13:58.571240:  
2023-08-07 18:13:58.571337: Epoch 432 
2023-08-07 18:13:58.571409: Current learning rate: 0.0008 
2023-08-07 18:15:01.966965: train_loss -0.3546 
2023-08-07 18:15:01.967128: val_loss -0.3052 
2023-08-07 18:15:01.967180: Pseudo dice [0.8481] 
2023-08-07 18:15:01.967230: Epoch time: 63.4 s 
2023-08-07 18:15:02.961162:  
2023-08-07 18:15:02.961262: Epoch 433 
2023-08-07 18:15:02.961351: Current learning rate: 0.0008 
2023-08-07 18:16:06.332314: train_loss -0.3229 
2023-08-07 18:16:06.332467: val_loss -0.3245 
2023-08-07 18:16:06.332523: Pseudo dice [0.8405] 
2023-08-07 18:16:06.332574: Epoch time: 63.37 s 
2023-08-07 18:16:07.470056:  
2023-08-07 18:16:07.470166: Epoch 434 
2023-08-07 18:16:07.470255: Current learning rate: 0.0008 
2023-08-07 18:17:10.902389: train_loss -0.3396 
2023-08-07 18:17:10.902542: val_loss -0.3047 
2023-08-07 18:17:10.902592: Pseudo dice [0.847] 
2023-08-07 18:17:10.902642: Epoch time: 63.43 s 
2023-08-07 18:17:11.917817:  
2023-08-07 18:17:11.917912: Epoch 435 
2023-08-07 18:17:11.918000: Current learning rate: 0.0008 
2023-08-07 18:18:15.389552: train_loss -0.3072 
2023-08-07 18:18:15.389704: val_loss -0.3853 
2023-08-07 18:18:15.389757: Pseudo dice [0.7561] 
2023-08-07 18:18:15.389807: Epoch time: 63.47 s 
2023-08-07 18:18:16.386619:  
2023-08-07 18:18:16.386717: Epoch 436 
2023-08-07 18:18:16.386788: Current learning rate: 0.0008 
2023-08-07 18:19:19.696151: train_loss -0.3704 
2023-08-07 18:19:19.696300: val_loss -0.3049 
2023-08-07 18:19:19.696351: Pseudo dice [0.8592] 
2023-08-07 18:19:19.696402: Epoch time: 63.31 s 
2023-08-07 18:19:19.696442: Yayy! New best EMA pseudo Dice: 0.796 
2023-08-07 18:19:21.077405:  
2023-08-07 18:19:21.077503: Epoch 437 
2023-08-07 18:19:21.077575: Current learning rate: 0.0008 
2023-08-07 18:20:24.370358: train_loss -0.3773 
2023-08-07 18:20:24.370510: val_loss -0.2654 
2023-08-07 18:20:24.370577: Pseudo dice [0.6925] 
2023-08-07 18:20:24.370629: Epoch time: 63.29 s 
2023-08-07 18:20:25.353979:  
2023-08-07 18:20:25.354077: Epoch 438 
2023-08-07 18:20:25.354148: Current learning rate: 0.0008 
2023-08-07 18:21:28.806624: train_loss -0.3843 
2023-08-07 18:21:28.806778: val_loss -0.2745 
2023-08-07 18:21:28.806829: Pseudo dice [0.8147] 
2023-08-07 18:21:28.806898: Epoch time: 63.45 s 
2023-08-07 18:21:29.799124:  
2023-08-07 18:21:29.799220: Epoch 439 
2023-08-07 18:21:29.799292: Current learning rate: 0.0008 
2023-08-07 18:22:33.112509: train_loss -0.3462 
2023-08-07 18:22:33.112667: val_loss -0.2815 
2023-08-07 18:22:33.112721: Pseudo dice [0.8727] 
2023-08-07 18:22:33.112772: Epoch time: 63.31 s 
2023-08-07 18:22:33.112813: Yayy! New best EMA pseudo Dice: 0.797 
2023-08-07 18:22:34.617480:  
2023-08-07 18:22:34.617722: Epoch 440 
2023-08-07 18:22:34.617803: Current learning rate: 0.0008 
2023-08-07 18:23:38.073343: train_loss -0.3305 
2023-08-07 18:23:38.073497: val_loss -0.3285 
2023-08-07 18:23:38.073566: Pseudo dice [0.8128] 
2023-08-07 18:23:38.073626: Epoch time: 63.46 s 
2023-08-07 18:23:38.073668: Yayy! New best EMA pseudo Dice: 0.7986 
2023-08-07 18:23:39.408995:  
2023-08-07 18:23:39.409096: Epoch 441 
2023-08-07 18:23:39.409173: Current learning rate: 0.0008 
2023-08-07 18:24:42.971867: train_loss -0.3372 
2023-08-07 18:24:42.972011: val_loss -0.3505 
2023-08-07 18:24:42.972065: Pseudo dice [0.8043] 
2023-08-07 18:24:42.972115: Epoch time: 63.56 s 
2023-08-07 18:24:42.972154: Yayy! New best EMA pseudo Dice: 0.7991 
2023-08-07 18:24:44.353976:  
2023-08-07 18:24:44.354075: Epoch 442 
2023-08-07 18:24:44.354147: Current learning rate: 0.0008 
2023-08-07 18:25:47.622190: train_loss -0.2897 
2023-08-07 18:25:47.622362: val_loss -0.3223 
2023-08-07 18:25:47.622416: Pseudo dice [0.6995] 
2023-08-07 18:25:47.622468: Epoch time: 63.27 s 
2023-08-07 18:25:48.608447:  
2023-08-07 18:25:48.608613: Epoch 443 
2023-08-07 18:25:48.608773: Current learning rate: 0.0008 
2023-08-07 18:26:52.021410: train_loss -0.3049 
2023-08-07 18:26:52.021560: val_loss -0.3333 
2023-08-07 18:26:52.021609: Pseudo dice [0.6785] 
2023-08-07 18:26:52.021676: Epoch time: 63.41 s 
2023-08-07 18:26:52.995848:  
2023-08-07 18:26:52.995955: Epoch 444 
2023-08-07 18:26:52.996045: Current learning rate: 0.0008 
2023-08-07 18:27:56.407846: train_loss -0.31 
2023-08-07 18:27:56.407996: val_loss -0.3068 
2023-08-07 18:27:56.408050: Pseudo dice [0.814] 
2023-08-07 18:27:56.408099: Epoch time: 63.41 s 
2023-08-07 18:27:57.534452:  
2023-08-07 18:27:57.534559: Epoch 445 
2023-08-07 18:27:57.534633: Current learning rate: 0.0008 
2023-08-07 18:29:00.927504: train_loss -0.3278 
2023-08-07 18:29:00.927674: val_loss -0.3374 
2023-08-07 18:29:00.927730: Pseudo dice [0.8118] 
2023-08-07 18:29:00.927781: Epoch time: 63.39 s 
2023-08-07 18:29:01.930979:  
2023-08-07 18:29:01.931076: Epoch 446 
2023-08-07 18:29:01.931151: Current learning rate: 0.0008 
2023-08-07 18:30:05.391381: train_loss -0.3587 
2023-08-07 18:30:05.391529: val_loss -0.3735 
2023-08-07 18:30:05.391605: Pseudo dice [0.795] 
2023-08-07 18:30:05.391658: Epoch time: 63.46 s 
2023-08-07 18:30:06.370770:  
2023-08-07 18:30:06.370867: Epoch 447 
2023-08-07 18:30:06.370941: Current learning rate: 0.0008 
2023-08-07 18:31:09.804154: train_loss -0.3477 
2023-08-07 18:31:09.804310: val_loss -0.2919 
2023-08-07 18:31:09.804363: Pseudo dice [0.7557] 
2023-08-07 18:31:09.804414: Epoch time: 63.43 s 
2023-08-07 18:31:10.798890:  
2023-08-07 18:31:10.798986: Epoch 448 
2023-08-07 18:31:10.799060: Current learning rate: 0.0008 
2023-08-07 18:32:14.238352: train_loss -0.3273 
2023-08-07 18:32:14.238507: val_loss -0.3268 
2023-08-07 18:32:14.238556: Pseudo dice [0.7043] 
2023-08-07 18:32:14.238608: Epoch time: 63.44 s 
2023-08-07 18:32:15.247706:  
2023-08-07 18:32:15.247806: Epoch 449 
2023-08-07 18:32:15.247896: Current learning rate: 0.0008 
2023-08-07 18:33:18.617982: train_loss -0.362 
2023-08-07 18:33:18.618124: val_loss -0.2778 
2023-08-07 18:33:18.618173: Pseudo dice [0.7301] 
2023-08-07 18:33:18.618222: Epoch time: 63.37 s 
2023-08-07 18:33:19.960382:  
2023-08-07 18:33:19.960475: Epoch 450 
2023-08-07 18:33:19.960549: Current learning rate: 0.0008 
2023-08-07 18:34:23.402604: train_loss -0.3407 
2023-08-07 18:34:23.402750: val_loss -0.3197 
2023-08-07 18:34:23.402818: Pseudo dice [0.7618] 
2023-08-07 18:34:23.402869: Epoch time: 63.44 s 
2023-08-07 18:34:24.537803:  
2023-08-07 18:34:24.537908: Epoch 451 
2023-08-07 18:34:24.537981: Current learning rate: 0.00079 
2023-08-07 18:35:27.886486: train_loss -0.3341 
2023-08-07 18:35:27.886634: val_loss -0.34 
2023-08-07 18:35:27.886699: Pseudo dice [0.7495] 
2023-08-07 18:35:27.886750: Epoch time: 63.35 s 
2023-08-07 18:35:28.877885:  
2023-08-07 18:35:28.877982: Epoch 452 
2023-08-07 18:35:28.878054: Current learning rate: 0.00079 
2023-08-07 18:36:32.142872: train_loss -0.3603 
2023-08-07 18:36:32.143020: val_loss -0.337 
2023-08-07 18:36:32.143068: Pseudo dice [0.7403] 
2023-08-07 18:36:32.143118: Epoch time: 63.27 s 
2023-08-07 18:36:33.103072:  
2023-08-07 18:36:33.103175: Epoch 453 
2023-08-07 18:36:33.103265: Current learning rate: 0.00079 
2023-08-07 18:37:36.458706: train_loss -0.3527 
2023-08-07 18:37:36.458857: val_loss -0.3332 
2023-08-07 18:37:36.458910: Pseudo dice [0.7293] 
2023-08-07 18:37:36.458978: Epoch time: 63.36 s 
2023-08-07 18:37:37.420502:  
2023-08-07 18:37:37.420597: Epoch 454 
2023-08-07 18:37:37.420686: Current learning rate: 0.00079 
2023-08-07 18:38:40.762204: train_loss -0.3657 
2023-08-07 18:38:40.762485: val_loss -0.3095 
2023-08-07 18:38:40.762570: Pseudo dice [0.8052] 
2023-08-07 18:38:40.762650: Epoch time: 63.34 s 
2023-08-07 18:38:41.729987:  
2023-08-07 18:38:41.730083: Epoch 455 
2023-08-07 18:38:41.730172: Current learning rate: 0.00079 
2023-08-07 18:39:45.235267: train_loss -0.3803 
2023-08-07 18:39:45.235430: val_loss -0.3215 
2023-08-07 18:39:45.235493: Pseudo dice [0.8141] 
2023-08-07 18:39:45.235543: Epoch time: 63.51 s 
2023-08-07 18:39:46.344149:  
2023-08-07 18:39:46.344242: Epoch 456 
2023-08-07 18:39:46.344329: Current learning rate: 0.00079 
2023-08-07 18:40:49.775127: train_loss -0.3375 
2023-08-07 18:40:49.775274: val_loss -0.3399 
2023-08-07 18:40:49.775326: Pseudo dice [0.7685] 
2023-08-07 18:40:49.775375: Epoch time: 63.43 s 
2023-08-07 18:40:50.741059:  
2023-08-07 18:40:50.741158: Epoch 457 
2023-08-07 18:40:50.741247: Current learning rate: 0.00079 
2023-08-07 18:41:54.145515: train_loss -0.358 
2023-08-07 18:41:54.145682: val_loss -0.3569 
2023-08-07 18:41:54.145737: Pseudo dice [0.7669] 
2023-08-07 18:41:54.145789: Epoch time: 63.41 s 
2023-08-07 18:41:55.129284:  
2023-08-07 18:41:55.129381: Epoch 458 
2023-08-07 18:41:55.129451: Current learning rate: 0.00079 
2023-08-07 18:42:58.462632: train_loss -0.3048 
2023-08-07 18:42:58.462781: val_loss -0.3772 
2023-08-07 18:42:58.462835: Pseudo dice [0.8439] 
2023-08-07 18:42:58.462901: Epoch time: 63.33 s 
2023-08-07 18:42:59.460791:  
2023-08-07 18:42:59.460898: Epoch 459 
2023-08-07 18:42:59.460987: Current learning rate: 0.00079 
2023-08-07 18:44:02.862430: train_loss -0.3569 
2023-08-07 18:44:02.862577: val_loss -0.3232 
2023-08-07 18:44:02.862629: Pseudo dice [0.7335] 
2023-08-07 18:44:02.862679: Epoch time: 63.4 s 
2023-08-07 18:44:03.873993:  
2023-08-07 18:44:03.874170: Epoch 460 
2023-08-07 18:44:03.874262: Current learning rate: 0.00079 
2023-08-07 18:45:07.366337: train_loss -0.3298 
2023-08-07 18:45:07.366512: val_loss -0.3254 
2023-08-07 18:45:07.366564: Pseudo dice [0.822] 
2023-08-07 18:45:07.366614: Epoch time: 63.49 s 
2023-08-07 18:45:08.334383:  
2023-08-07 18:45:08.334476: Epoch 461 
2023-08-07 18:45:08.334564: Current learning rate: 0.00079 
2023-08-07 18:46:11.621464: train_loss -0.355 
2023-08-07 18:46:11.621625: val_loss -0.3321 
2023-08-07 18:46:11.621677: Pseudo dice [0.7947] 
2023-08-07 18:46:11.621729: Epoch time: 63.29 s 
2023-08-07 18:46:12.749612:  
2023-08-07 18:46:12.749710: Epoch 462 
2023-08-07 18:46:12.749783: Current learning rate: 0.00079 
2023-08-07 18:47:15.964412: train_loss -0.348 
2023-08-07 18:47:15.964561: val_loss -0.2762 
2023-08-07 18:47:15.964614: Pseudo dice [0.701] 
2023-08-07 18:47:15.964663: Epoch time: 63.22 s 
2023-08-07 18:47:16.929902:  
2023-08-07 18:47:16.929996: Epoch 463 
2023-08-07 18:47:16.930067: Current learning rate: 0.00079 
2023-08-07 18:48:20.380195: train_loss -0.332 
2023-08-07 18:48:20.380341: val_loss -0.2714 
2023-08-07 18:48:20.380392: Pseudo dice [0.6271] 
2023-08-07 18:48:20.380442: Epoch time: 63.45 s 
2023-08-07 18:48:21.383356:  
2023-08-07 18:48:21.383542: Epoch 464 
2023-08-07 18:48:21.383622: Current learning rate: 0.00079 
2023-08-07 18:49:24.763263: train_loss -0.3237 
2023-08-07 18:49:24.763419: val_loss -0.4469 
2023-08-07 18:49:24.763608: Pseudo dice [0.8368] 
2023-08-07 18:49:24.763662: Epoch time: 63.38 s 
2023-08-07 18:49:25.750710:  
2023-08-07 18:49:25.750807: Epoch 465 
2023-08-07 18:49:25.750892: Current learning rate: 0.00079 
2023-08-07 18:50:29.123934: train_loss -0.3461 
2023-08-07 18:50:29.124080: val_loss -0.2817 
2023-08-07 18:50:29.124147: Pseudo dice [0.7448] 
2023-08-07 18:50:29.124207: Epoch time: 63.37 s 
2023-08-07 18:50:30.114841:  
2023-08-07 18:50:30.115113: Epoch 466 
2023-08-07 18:50:30.115323: Current learning rate: 0.00079 
2023-08-07 18:51:33.646431: train_loss -0.3258 
2023-08-07 18:51:33.646581: val_loss -0.2857 
2023-08-07 18:51:33.646634: Pseudo dice [0.7064] 
2023-08-07 18:51:33.646703: Epoch time: 63.53 s 
2023-08-07 18:51:34.612896:  
2023-08-07 18:51:34.612992: Epoch 467 
2023-08-07 18:51:34.613081: Current learning rate: 0.00079 
2023-08-07 18:52:38.046846: train_loss -0.3382 
2023-08-07 18:52:38.047046: val_loss -0.3511 
2023-08-07 18:52:38.047099: Pseudo dice [0.7456] 
2023-08-07 18:52:38.047151: Epoch time: 63.43 s 
2023-08-07 18:52:39.014766:  
2023-08-07 18:52:39.014866: Epoch 468 
2023-08-07 18:52:39.014937: Current learning rate: 0.00079 
2023-08-07 18:53:42.372054: train_loss -0.3542 
2023-08-07 18:53:42.372200: val_loss -0.3641 
2023-08-07 18:53:42.372252: Pseudo dice [0.7922] 
2023-08-07 18:53:42.372302: Epoch time: 63.36 s 
2023-08-07 18:53:43.351911:  
2023-08-07 18:53:43.352009: Epoch 469 
2023-08-07 18:53:43.352086: Current learning rate: 0.00079 
2023-08-07 18:54:46.843408: train_loss -0.3328 
2023-08-07 18:54:46.843607: val_loss -0.2696 
2023-08-07 18:54:46.843661: Pseudo dice [0.7828] 
2023-08-07 18:54:46.843712: Epoch time: 63.49 s 
2023-08-07 18:54:47.808509:  
2023-08-07 18:54:47.808610: Epoch 470 
2023-08-07 18:54:47.808682: Current learning rate: 0.00079 
2023-08-07 18:55:51.263578: train_loss -0.3108 
2023-08-07 18:55:51.263743: val_loss -0.2477 
2023-08-07 18:55:51.263802: Pseudo dice [0.7556] 
2023-08-07 18:55:51.263852: Epoch time: 63.46 s 
2023-08-07 18:55:52.236330:  
2023-08-07 18:55:52.236432: Epoch 471 
2023-08-07 18:55:52.236505: Current learning rate: 0.00079 
2023-08-07 18:56:55.820809: train_loss -0.335 
2023-08-07 18:56:55.820962: val_loss -0.4851 
2023-08-07 18:56:55.821013: Pseudo dice [0.8506] 
2023-08-07 18:56:55.821079: Epoch time: 63.59 s 
2023-08-07 18:56:56.793428:  
2023-08-07 18:56:56.793525: Epoch 472 
2023-08-07 18:56:56.793596: Current learning rate: 0.00078 
2023-08-07 18:58:00.087935: train_loss -0.3468 
2023-08-07 18:58:00.088086: val_loss -0.2909 
2023-08-07 18:58:00.088135: Pseudo dice [0.7198] 
2023-08-07 18:58:00.088184: Epoch time: 63.3 s 
2023-08-07 18:58:01.222808:  
2023-08-07 18:58:01.222910: Epoch 473 
2023-08-07 18:58:01.223031: Current learning rate: 0.00078 
2023-08-07 18:59:04.638967: train_loss -0.312 
2023-08-07 18:59:04.639112: val_loss -0.4159 
2023-08-07 18:59:04.639160: Pseudo dice [0.8504] 
2023-08-07 18:59:04.639225: Epoch time: 63.42 s 
2023-08-07 18:59:05.638897:  
2023-08-07 18:59:05.638992: Epoch 474 
2023-08-07 18:59:05.639080: Current learning rate: 0.00078 
2023-08-07 19:00:09.055136: train_loss -0.3201 
2023-08-07 19:00:09.055293: val_loss -0.427 
2023-08-07 19:00:09.055345: Pseudo dice [0.8411] 
2023-08-07 19:00:09.055395: Epoch time: 63.42 s 
2023-08-07 19:00:10.026000:  
2023-08-07 19:00:10.026098: Epoch 475 
2023-08-07 19:00:10.026186: Current learning rate: 0.00078 
2023-08-07 19:01:13.406124: train_loss -0.3427 
2023-08-07 19:01:13.406293: val_loss -0.3515 
2023-08-07 19:01:13.406347: Pseudo dice [0.7296] 
2023-08-07 19:01:13.406396: Epoch time: 63.38 s 
2023-08-07 19:01:14.376654:  
2023-08-07 19:01:14.376834: Epoch 476 
2023-08-07 19:01:14.376909: Current learning rate: 0.00078 
2023-08-07 19:02:17.697974: train_loss -0.3445 
2023-08-07 19:02:17.698119: val_loss -0.3178 
2023-08-07 19:02:17.698170: Pseudo dice [0.8171] 
2023-08-07 19:02:17.698222: Epoch time: 63.32 s 
2023-08-07 19:02:18.658338:  
2023-08-07 19:02:18.658436: Epoch 477 
2023-08-07 19:02:18.658508: Current learning rate: 0.00078 
2023-08-07 19:03:21.929476: train_loss -0.3232 
2023-08-07 19:03:21.929633: val_loss -0.2767 
2023-08-07 19:03:21.929704: Pseudo dice [0.76] 
2023-08-07 19:03:21.929755: Epoch time: 63.27 s 
2023-08-07 19:03:22.928800:  
2023-08-07 19:03:22.928903: Epoch 478 
2023-08-07 19:03:22.928994: Current learning rate: 0.00078 
2023-08-07 19:04:26.303168: train_loss -0.3282 
2023-08-07 19:04:26.303318: val_loss -0.3766 
2023-08-07 19:04:26.303378: Pseudo dice [0.8569] 
2023-08-07 19:04:26.303430: Epoch time: 63.38 s 
2023-08-07 19:04:27.447222:  
2023-08-07 19:04:27.447333: Epoch 479 
2023-08-07 19:04:27.447421: Current learning rate: 0.00078 
2023-08-07 19:05:30.808180: train_loss -0.3342 
2023-08-07 19:05:30.808329: val_loss -0.3457 
2023-08-07 19:05:30.808380: Pseudo dice [0.7561] 
2023-08-07 19:05:30.808431: Epoch time: 63.36 s 
2023-08-07 19:05:31.800699:  
2023-08-07 19:05:31.800908: Epoch 480 
2023-08-07 19:05:31.800983: Current learning rate: 0.00078 
2023-08-07 19:06:35.140403: train_loss -0.3406 
2023-08-07 19:06:35.140548: val_loss -0.2959 
2023-08-07 19:06:35.140600: Pseudo dice [0.8037] 
2023-08-07 19:06:35.140650: Epoch time: 63.34 s 
2023-08-07 19:06:36.127117:  
2023-08-07 19:06:36.127209: Epoch 481 
2023-08-07 19:06:36.127299: Current learning rate: 0.00078 
2023-08-07 19:07:39.442633: train_loss -0.3162 
2023-08-07 19:07:39.442780: val_loss -0.4644 
2023-08-07 19:07:39.442831: Pseudo dice [0.8306] 
2023-08-07 19:07:39.442882: Epoch time: 63.32 s 
2023-08-07 19:07:40.431818:  
2023-08-07 19:07:40.431995: Epoch 482 
2023-08-07 19:07:40.432085: Current learning rate: 0.00078 
2023-08-07 19:08:43.810292: train_loss -0.3144 
2023-08-07 19:08:43.810438: val_loss -0.3444 
2023-08-07 19:08:43.810488: Pseudo dice [0.7991] 
2023-08-07 19:08:43.810555: Epoch time: 63.38 s 
2023-08-07 19:08:44.797203:  
2023-08-07 19:08:44.797299: Epoch 483 
2023-08-07 19:08:44.797372: Current learning rate: 0.00078 
2023-08-07 19:09:48.117604: train_loss -0.3419 
2023-08-07 19:09:48.117747: val_loss -0.4275 
2023-08-07 19:09:48.117815: Pseudo dice [0.7446] 
2023-08-07 19:09:48.117866: Epoch time: 63.32 s 
2023-08-07 19:09:49.137203:  
2023-08-07 19:09:49.137298: Epoch 484 
2023-08-07 19:09:49.137370: Current learning rate: 0.00078 
2023-08-07 19:10:52.421650: train_loss -0.3408 
2023-08-07 19:10:52.421803: val_loss -0.3104 
2023-08-07 19:10:52.421860: Pseudo dice [0.756] 
2023-08-07 19:10:52.421915: Epoch time: 63.29 s 
2023-08-07 19:10:53.578452:  
2023-08-07 19:10:53.578555: Epoch 485 
2023-08-07 19:10:53.578650: Current learning rate: 0.00078 
2023-08-07 19:11:57.014625: train_loss -0.3847 
2023-08-07 19:11:57.014771: val_loss -0.3951 
2023-08-07 19:11:57.014827: Pseudo dice [0.7536] 
2023-08-07 19:11:57.014878: Epoch time: 63.44 s 
2023-08-07 19:11:58.005139:  
2023-08-07 19:11:58.005376: Epoch 486 
2023-08-07 19:11:58.005459: Current learning rate: 0.00078 
2023-08-07 19:13:01.278687: train_loss -0.3438 
2023-08-07 19:13:01.278841: val_loss -0.3416 
2023-08-07 19:13:01.278892: Pseudo dice [0.7836] 
2023-08-07 19:13:01.278960: Epoch time: 63.27 s 
2023-08-07 19:13:02.287111:  
2023-08-07 19:13:02.287387: Epoch 487 
2023-08-07 19:13:02.287564: Current learning rate: 0.00078 
2023-08-07 19:14:05.787489: train_loss -0.3159 
2023-08-07 19:14:05.787666: val_loss -0.3193 
2023-08-07 19:14:05.787717: Pseudo dice [0.7471] 
2023-08-07 19:14:05.787768: Epoch time: 63.5 s 
2023-08-07 19:14:06.801424:  
2023-08-07 19:14:06.801516: Epoch 488 
2023-08-07 19:14:06.801586: Current learning rate: 0.00078 
2023-08-07 19:15:10.333542: train_loss -0.355 
2023-08-07 19:15:10.333689: val_loss -0.337 
2023-08-07 19:15:10.333739: Pseudo dice [0.8092] 
2023-08-07 19:15:10.333804: Epoch time: 63.53 s 
2023-08-07 19:15:11.350026:  
2023-08-07 19:15:11.350122: Epoch 489 
2023-08-07 19:15:11.350195: Current learning rate: 0.00078 
2023-08-07 19:16:14.555051: train_loss -0.3398 
2023-08-07 19:16:14.555205: val_loss -0.3551 
2023-08-07 19:16:14.555271: Pseudo dice [0.7504] 
2023-08-07 19:16:14.555321: Epoch time: 63.21 s 
2023-08-07 19:16:15.542341:  
2023-08-07 19:16:15.542437: Epoch 490 
2023-08-07 19:16:15.542525: Current learning rate: 0.00078 
2023-08-07 19:17:18.900970: train_loss -0.3346 
2023-08-07 19:17:18.901116: val_loss -0.4242 
2023-08-07 19:17:18.901166: Pseudo dice [0.8152] 
2023-08-07 19:17:18.901216: Epoch time: 63.36 s 
2023-08-07 19:17:20.045294:  
2023-08-07 19:17:20.045395: Epoch 491 
2023-08-07 19:17:20.045467: Current learning rate: 0.00078 
2023-08-07 19:18:23.458823: train_loss -0.3259 
2023-08-07 19:18:23.458969: val_loss -0.2704 
2023-08-07 19:18:23.459017: Pseudo dice [0.7995] 
2023-08-07 19:18:23.459083: Epoch time: 63.41 s 
2023-08-07 19:18:24.470491:  
2023-08-07 19:18:24.470591: Epoch 492 
2023-08-07 19:18:24.470680: Current learning rate: 0.00078 
2023-08-07 19:19:27.983231: train_loss -0.3261 
2023-08-07 19:19:27.983389: val_loss -0.3298 
2023-08-07 19:19:27.983443: Pseudo dice [0.7292] 
2023-08-07 19:19:27.983494: Epoch time: 63.51 s 
2023-08-07 19:19:28.996739:  
2023-08-07 19:19:28.996848: Epoch 493 
2023-08-07 19:19:28.996919: Current learning rate: 0.00078 
2023-08-07 19:20:32.477205: train_loss -0.3209 
2023-08-07 19:20:32.477354: val_loss -0.3769 
2023-08-07 19:20:32.477432: Pseudo dice [0.8391] 
2023-08-07 19:20:32.477498: Epoch time: 63.48 s 
2023-08-07 19:20:33.500412:  
2023-08-07 19:20:33.500518: Epoch 494 
2023-08-07 19:20:33.500594: Current learning rate: 0.00077 
2023-08-07 19:21:37.088512: train_loss -0.3336 
2023-08-07 19:21:37.088667: val_loss -0.3093 
2023-08-07 19:21:37.088720: Pseudo dice [0.7145] 
2023-08-07 19:21:37.088771: Epoch time: 63.59 s 
2023-08-07 19:21:38.085239:  
2023-08-07 19:21:38.085389: Epoch 495 
2023-08-07 19:21:38.085567: Current learning rate: 0.00077 
2023-08-07 19:22:41.463853: train_loss -0.3134 
2023-08-07 19:22:41.464011: val_loss -0.3696 
2023-08-07 19:22:41.464062: Pseudo dice [0.7986] 
2023-08-07 19:22:41.464112: Epoch time: 63.38 s 
2023-08-07 19:22:42.599442:  
2023-08-07 19:22:42.599550: Epoch 496 
2023-08-07 19:22:42.599663: Current learning rate: 0.00077 
2023-08-07 19:23:45.946157: train_loss -0.3311 
2023-08-07 19:23:45.946316: val_loss -0.3039 
2023-08-07 19:23:45.946385: Pseudo dice [0.7954] 
2023-08-07 19:23:45.946437: Epoch time: 63.35 s 
2023-08-07 19:23:46.933466:  
2023-08-07 19:23:46.933561: Epoch 497 
2023-08-07 19:23:46.933648: Current learning rate: 0.00077 
2023-08-07 19:24:50.488833: train_loss -0.3211 
2023-08-07 19:24:50.488990: val_loss -0.3438 
2023-08-07 19:24:50.489041: Pseudo dice [0.8803] 
2023-08-07 19:24:50.489092: Epoch time: 63.56 s 
2023-08-07 19:24:51.487971:  
2023-08-07 19:24:51.488070: Epoch 498 
2023-08-07 19:24:51.488144: Current learning rate: 0.00077 
2023-08-07 19:25:54.985944: train_loss -0.3226 
2023-08-07 19:25:54.986090: val_loss -0.3516 
2023-08-07 19:25:54.986144: Pseudo dice [0.791] 
2023-08-07 19:25:54.986195: Epoch time: 63.5 s 
2023-08-07 19:25:55.976847:  
2023-08-07 19:25:55.976942: Epoch 499 
2023-08-07 19:25:55.977030: Current learning rate: 0.00077 
2023-08-07 19:26:59.352546: train_loss -0.3146 
2023-08-07 19:26:59.352697: val_loss -0.3273 
2023-08-07 19:26:59.352747: Pseudo dice [0.696] 
2023-08-07 19:26:59.352796: Epoch time: 63.38 s 
2023-08-07 19:27:00.736613:  
2023-08-07 19:27:00.736713: Epoch 500 
2023-08-07 19:27:00.736788: Current learning rate: 0.00077 
2023-08-07 19:28:04.117836: train_loss -0.3371 
2023-08-07 19:28:04.117993: val_loss -0.3895 
2023-08-07 19:28:04.118062: Pseudo dice [0.9005] 
2023-08-07 19:28:04.118113: Epoch time: 63.38 s 
2023-08-07 19:28:05.145730:  
2023-08-07 19:28:05.145823: Epoch 501 
2023-08-07 19:28:05.145896: Current learning rate: 0.00077 
2023-08-07 19:29:08.677126: train_loss -0.3267 
2023-08-07 19:29:08.677281: val_loss -0.3554 
2023-08-07 19:29:08.677334: Pseudo dice [0.6513] 
2023-08-07 19:29:08.677386: Epoch time: 63.53 s 
2023-08-07 19:29:09.827279:  
2023-08-07 19:29:09.827532: Epoch 502 
2023-08-07 19:29:09.827622: Current learning rate: 0.00077 
2023-08-07 19:30:13.325252: train_loss -0.3579 
2023-08-07 19:30:13.325398: val_loss -0.2867 
2023-08-07 19:30:13.325467: Pseudo dice [0.604] 
2023-08-07 19:30:13.325516: Epoch time: 63.5 s 
2023-08-07 19:30:14.337039:  
2023-08-07 19:30:14.337132: Epoch 503 
2023-08-07 19:30:14.337223: Current learning rate: 0.00077 
2023-08-07 19:31:17.906438: train_loss -0.3349 
2023-08-07 19:31:17.906589: val_loss -0.3009 
2023-08-07 19:31:17.906642: Pseudo dice [0.798] 
2023-08-07 19:31:17.906693: Epoch time: 63.57 s 
2023-08-07 19:31:18.913907:  
2023-08-07 19:31:18.914075: Epoch 504 
2023-08-07 19:31:18.914242: Current learning rate: 0.00077 
2023-08-07 19:32:22.317832: train_loss -0.3487 
2023-08-07 19:32:22.317978: val_loss -0.3432 
2023-08-07 19:32:22.318027: Pseudo dice [0.7934] 
2023-08-07 19:32:22.318094: Epoch time: 63.4 s 
2023-08-07 19:32:23.309162:  
2023-08-07 19:32:23.309365: Epoch 505 
2023-08-07 19:32:23.309446: Current learning rate: 0.00077 
2023-08-07 19:33:26.769010: train_loss -0.3543 
2023-08-07 19:33:26.769162: val_loss -0.2205 
2023-08-07 19:33:26.769231: Pseudo dice [0.5689] 
2023-08-07 19:33:26.769283: Epoch time: 63.46 s 
2023-08-07 19:33:27.778419:  
2023-08-07 19:33:27.778516: Epoch 506 
2023-08-07 19:33:27.778604: Current learning rate: 0.00077 
2023-08-07 19:34:31.338902: train_loss -0.3611 
2023-08-07 19:34:31.339049: val_loss -0.3575 
2023-08-07 19:34:31.339100: Pseudo dice [0.7038] 
2023-08-07 19:34:31.339152: Epoch time: 63.56 s 
2023-08-07 19:34:32.483860:  
2023-08-07 19:34:32.483971: Epoch 507 
2023-08-07 19:34:32.484133: Current learning rate: 0.00077 
2023-08-07 19:35:35.919089: train_loss -0.3461 
2023-08-07 19:35:35.919238: val_loss -0.3904 
2023-08-07 19:35:35.919291: Pseudo dice [0.8804] 
2023-08-07 19:35:35.919341: Epoch time: 63.44 s 
2023-08-07 19:35:36.910263:  
2023-08-07 19:35:36.910356: Epoch 508 
2023-08-07 19:35:36.910445: Current learning rate: 0.00077 
2023-08-07 19:36:40.468889: train_loss -0.35 
2023-08-07 19:36:40.469038: val_loss -0.3655 
2023-08-07 19:36:40.469089: Pseudo dice [0.7857] 
2023-08-07 19:36:40.469140: Epoch time: 63.56 s 
2023-08-07 19:36:41.477866:  
2023-08-07 19:36:41.477965: Epoch 509 
2023-08-07 19:36:41.478037: Current learning rate: 0.00077 
2023-08-07 19:37:44.866509: train_loss -0.3255 
2023-08-07 19:37:44.866789: val_loss -0.2838 
2023-08-07 19:37:44.866843: Pseudo dice [0.6467] 
2023-08-07 19:37:44.866894: Epoch time: 63.39 s 
2023-08-07 19:37:45.860688:  
2023-08-07 19:37:45.860790: Epoch 510 
2023-08-07 19:37:45.860971: Current learning rate: 0.00077 
2023-08-07 19:38:49.344506: train_loss -0.3289 
2023-08-07 19:38:49.344653: val_loss -0.3402 
2023-08-07 19:38:49.344703: Pseudo dice [0.8519] 
2023-08-07 19:38:49.344753: Epoch time: 63.48 s 
2023-08-07 19:38:50.332011:  
2023-08-07 19:38:50.332113: Epoch 511 
2023-08-07 19:38:50.332199: Current learning rate: 0.00077 
2023-08-07 19:39:53.904120: train_loss -0.343 
2023-08-07 19:39:53.904283: val_loss -0.3667 
2023-08-07 19:39:53.904340: Pseudo dice [0.747] 
2023-08-07 19:39:53.904396: Epoch time: 63.57 s 
2023-08-07 19:39:54.906722:  
2023-08-07 19:39:54.906922: Epoch 512 
2023-08-07 19:39:54.907013: Current learning rate: 0.00077 
2023-08-07 19:40:58.467690: train_loss -0.337 
2023-08-07 19:40:58.467849: val_loss -0.3907 
2023-08-07 19:40:58.467898: Pseudo dice [0.8203] 
2023-08-07 19:40:58.467947: Epoch time: 63.56 s 
2023-08-07 19:40:59.647480:  
2023-08-07 19:40:59.647932: Epoch 513 
2023-08-07 19:40:59.648204: Current learning rate: 0.00077 
2023-08-07 19:42:03.105110: train_loss -0.3358 
2023-08-07 19:42:03.105272: val_loss -0.3491 
2023-08-07 19:42:03.105323: Pseudo dice [0.817] 
2023-08-07 19:42:03.105373: Epoch time: 63.46 s 
2023-08-07 19:42:04.120093:  
2023-08-07 19:42:04.120193: Epoch 514 
2023-08-07 19:42:04.120267: Current learning rate: 0.00077 
2023-08-07 19:43:07.556861: train_loss -0.3724 
2023-08-07 19:43:07.557031: val_loss -0.307 
2023-08-07 19:43:07.557083: Pseudo dice [0.751] 
2023-08-07 19:43:07.557132: Epoch time: 63.44 s 
2023-08-07 19:43:08.592362:  
2023-08-07 19:43:08.592460: Epoch 515 
2023-08-07 19:43:08.592537: Current learning rate: 0.00076 
2023-08-07 19:44:11.924025: train_loss -0.3217 
2023-08-07 19:44:11.924248: val_loss -0.2716 
2023-08-07 19:44:11.924300: Pseudo dice [0.7533] 
2023-08-07 19:44:11.924351: Epoch time: 63.33 s 
2023-08-07 19:44:12.915336:  
2023-08-07 19:44:12.915431: Epoch 516 
2023-08-07 19:44:12.915519: Current learning rate: 0.00076 
2023-08-07 19:45:16.384963: train_loss -0.3444 
2023-08-07 19:45:16.385116: val_loss -0.3034 
2023-08-07 19:45:16.385166: Pseudo dice [0.7633] 
2023-08-07 19:45:16.385226: Epoch time: 63.47 s 
2023-08-07 19:45:17.374454:  
2023-08-07 19:45:17.374815: Epoch 517 
2023-08-07 19:45:17.374912: Current learning rate: 0.00076 
2023-08-07 19:46:20.687189: train_loss -0.3353 
2023-08-07 19:46:20.687337: val_loss -0.3611 
2023-08-07 19:46:20.687387: Pseudo dice [0.8588] 
2023-08-07 19:46:20.687437: Epoch time: 63.31 s 
2023-08-07 19:46:21.680203:  
2023-08-07 19:46:21.680301: Epoch 518 
2023-08-07 19:46:21.680374: Current learning rate: 0.00076 
2023-08-07 19:47:24.979701: train_loss -0.3277 
2023-08-07 19:47:24.979853: val_loss -0.3425 
2023-08-07 19:47:24.979906: Pseudo dice [0.7618] 
2023-08-07 19:47:24.979958: Epoch time: 63.3 s 
2023-08-07 19:47:26.155581:  
2023-08-07 19:47:26.155704: Epoch 519 
2023-08-07 19:47:26.155777: Current learning rate: 0.00076 
2023-08-07 19:48:29.770108: train_loss -0.3137 
2023-08-07 19:48:29.770261: val_loss -0.3536 
2023-08-07 19:48:29.770315: Pseudo dice [0.826] 
2023-08-07 19:48:29.770365: Epoch time: 63.62 s 
2023-08-07 19:48:30.795456:  
2023-08-07 19:48:30.795565: Epoch 520 
2023-08-07 19:48:30.795654: Current learning rate: 0.00076 
2023-08-07 19:49:34.250483: train_loss -0.3493 
2023-08-07 19:49:34.250622: val_loss -0.3307 
2023-08-07 19:49:34.250673: Pseudo dice [0.7549] 
2023-08-07 19:49:34.250722: Epoch time: 63.46 s 
2023-08-07 19:49:35.239656:  
2023-08-07 19:49:35.239756: Epoch 521 
2023-08-07 19:49:35.239833: Current learning rate: 0.00076 
2023-08-07 19:50:38.887547: train_loss -0.3739 
2023-08-07 19:50:38.887701: val_loss -0.2916 
2023-08-07 19:50:38.887753: Pseudo dice [0.7289] 
2023-08-07 19:50:38.887803: Epoch time: 63.65 s 
2023-08-07 19:50:39.875208:  
2023-08-07 19:50:39.875406: Epoch 522 
2023-08-07 19:50:39.875498: Current learning rate: 0.00076 
2023-08-07 19:51:43.263081: train_loss -0.3241 
2023-08-07 19:51:43.263295: val_loss -0.3095 
2023-08-07 19:51:43.263390: Pseudo dice [0.8006] 
2023-08-07 19:51:43.263484: Epoch time: 63.39 s 
2023-08-07 19:51:44.281678:  
2023-08-07 19:51:44.281884: Epoch 523 
2023-08-07 19:51:44.281974: Current learning rate: 0.00076 
2023-08-07 19:52:47.703366: train_loss -0.341 
2023-08-07 19:52:47.703510: val_loss -0.3217 
2023-08-07 19:52:47.703586: Pseudo dice [0.826] 
2023-08-07 19:52:47.703637: Epoch time: 63.42 s 
2023-08-07 19:52:48.724035:  
2023-08-07 19:52:48.724209: Epoch 524 
2023-08-07 19:52:48.724285: Current learning rate: 0.00076 
2023-08-07 19:53:52.124479: train_loss -0.35 
2023-08-07 19:53:52.124629: val_loss -0.3669 
2023-08-07 19:53:52.124683: Pseudo dice [0.8408] 
2023-08-07 19:53:52.124736: Epoch time: 63.4 s 
2023-08-07 19:53:53.308055:  
2023-08-07 19:53:53.308264: Epoch 525 
2023-08-07 19:53:53.308341: Current learning rate: 0.00076 
2023-08-07 19:54:56.730962: train_loss -0.3514 
2023-08-07 19:54:56.731111: val_loss -0.2808 
2023-08-07 19:54:56.731164: Pseudo dice [0.7011] 
2023-08-07 19:54:56.731214: Epoch time: 63.42 s 
2023-08-07 19:54:57.720326:  
2023-08-07 19:54:57.720427: Epoch 526 
2023-08-07 19:54:57.720500: Current learning rate: 0.00076 
2023-08-07 19:56:01.263528: train_loss -0.319 
2023-08-07 19:56:01.263700: val_loss -0.4119 
2023-08-07 19:56:01.263752: Pseudo dice [0.7932] 
2023-08-07 19:56:01.263803: Epoch time: 63.54 s 
2023-08-07 19:56:02.255024:  
2023-08-07 19:56:02.255120: Epoch 527 
2023-08-07 19:56:02.255193: Current learning rate: 0.00076 
2023-08-07 19:57:05.655182: train_loss -0.33 
2023-08-07 19:57:05.655329: val_loss -0.3185 
2023-08-07 19:57:05.655380: Pseudo dice [0.6869] 
2023-08-07 19:57:05.655450: Epoch time: 63.4 s 
2023-08-07 19:57:06.696687:  
2023-08-07 19:57:06.696869: Epoch 528 
2023-08-07 19:57:06.696962: Current learning rate: 0.00076 
2023-08-07 19:58:10.038264: train_loss -0.2992 
2023-08-07 19:58:10.038410: val_loss -0.3428 
2023-08-07 19:58:10.038459: Pseudo dice [0.763] 
2023-08-07 19:58:10.038525: Epoch time: 63.34 s 
2023-08-07 19:58:11.033551:  
2023-08-07 19:58:11.033640: Epoch 529 
2023-08-07 19:58:11.033728: Current learning rate: 0.00076 
2023-08-07 19:59:14.437464: train_loss -0.3173 
2023-08-07 19:59:14.437623: val_loss -0.3387 
2023-08-07 19:59:14.437695: Pseudo dice [0.7795] 
2023-08-07 19:59:14.437747: Epoch time: 63.4 s 
2023-08-07 19:59:15.462403:  
2023-08-07 19:59:15.462498: Epoch 530 
2023-08-07 19:59:15.462584: Current learning rate: 0.00076 
2023-08-07 20:00:19.150177: train_loss -0.4079 
2023-08-07 20:00:19.150486: val_loss -0.2841 
2023-08-07 20:00:19.150545: Pseudo dice [0.7545] 
2023-08-07 20:00:19.150595: Epoch time: 63.69 s 
2023-08-07 20:00:20.163273:  
2023-08-07 20:00:20.163373: Epoch 531 
2023-08-07 20:00:20.163464: Current learning rate: 0.00076 
2023-08-07 20:01:23.580392: train_loss -0.3439 
2023-08-07 20:01:23.580537: val_loss -0.3709 
2023-08-07 20:01:23.580590: Pseudo dice [0.8401] 
2023-08-07 20:01:23.580641: Epoch time: 63.42 s 
2023-08-07 20:01:24.614073:  
2023-08-07 20:01:24.614172: Epoch 532 
2023-08-07 20:01:24.614247: Current learning rate: 0.00076 
2023-08-07 20:02:28.206128: train_loss -0.3467 
2023-08-07 20:02:28.206288: val_loss -0.3804 
2023-08-07 20:02:28.206356: Pseudo dice [0.7756] 
2023-08-07 20:02:28.206408: Epoch time: 63.59 s 
2023-08-07 20:02:29.205230:  
2023-08-07 20:02:29.205473: Epoch 533 
2023-08-07 20:02:29.205642: Current learning rate: 0.00076 
2023-08-07 20:03:32.597076: train_loss -0.3824 
2023-08-07 20:03:32.597224: val_loss -0.4016 
2023-08-07 20:03:32.597291: Pseudo dice [0.7601] 
2023-08-07 20:03:32.597341: Epoch time: 63.39 s 
2023-08-07 20:03:33.625566:  
2023-08-07 20:03:33.625925: Epoch 534 
2023-08-07 20:03:33.626021: Current learning rate: 0.00076 
2023-08-07 20:04:36.985817: train_loss -0.3694 
2023-08-07 20:04:36.985983: val_loss -0.424 
2023-08-07 20:04:36.986032: Pseudo dice [0.8545] 
2023-08-07 20:04:36.986083: Epoch time: 63.36 s 
2023-08-07 20:04:38.009008:  
2023-08-07 20:04:38.009102: Epoch 535 
2023-08-07 20:04:38.009175: Current learning rate: 0.00076 
2023-08-07 20:05:41.453504: train_loss -0.3362 
2023-08-07 20:05:41.453671: val_loss -0.3618 
2023-08-07 20:05:41.453723: Pseudo dice [0.7589] 
2023-08-07 20:05:41.453773: Epoch time: 63.45 s 
2023-08-07 20:05:42.600449:  
2023-08-07 20:05:42.600556: Epoch 536 
2023-08-07 20:05:42.600633: Current learning rate: 0.00076 
2023-08-07 20:06:46.189409: train_loss -0.3272 
2023-08-07 20:06:46.189561: val_loss -0.3088 
2023-08-07 20:06:46.189614: Pseudo dice [0.7365] 
2023-08-07 20:06:46.189680: Epoch time: 63.59 s 
2023-08-07 20:06:47.239233:  
2023-08-07 20:06:47.239437: Epoch 537 
2023-08-07 20:06:47.239529: Current learning rate: 0.00075 
2023-08-07 20:07:50.720091: train_loss -0.3357 
2023-08-07 20:07:50.720248: val_loss -0.3173 
2023-08-07 20:07:50.720303: Pseudo dice [0.7704] 
2023-08-07 20:07:50.720354: Epoch time: 63.48 s 
2023-08-07 20:07:51.716438:  
2023-08-07 20:07:51.716660: Epoch 538 
2023-08-07 20:07:51.716739: Current learning rate: 0.00075 
2023-08-07 20:08:55.041827: train_loss -0.3161 
2023-08-07 20:08:55.041999: val_loss -0.3447 
2023-08-07 20:08:55.050429: Pseudo dice [0.7648] 
2023-08-07 20:08:55.050660: Epoch time: 63.33 s 
2023-08-07 20:08:56.060478:  
2023-08-07 20:08:56.060571: Epoch 539 
2023-08-07 20:08:56.060659: Current learning rate: 0.00075 
2023-08-07 20:09:59.540329: train_loss -0.3711 
2023-08-07 20:09:59.540585: val_loss -0.4054 
2023-08-07 20:09:59.540707: Pseudo dice [0.8452] 
2023-08-07 20:09:59.540907: Epoch time: 63.48 s 
2023-08-07 20:10:00.544378:  
2023-08-07 20:10:00.544722: Epoch 540 
2023-08-07 20:10:00.544803: Current learning rate: 0.00075 
2023-08-07 20:11:04.037754: train_loss -0.3426 
2023-08-07 20:11:04.037912: val_loss -0.352 
2023-08-07 20:11:04.046263: Pseudo dice [0.7523] 
2023-08-07 20:11:04.046339: Epoch time: 63.49 s 
2023-08-07 20:11:05.187235:  
2023-08-07 20:11:05.187541: Epoch 541 
2023-08-07 20:11:05.187736: Current learning rate: 0.00075 
2023-08-07 20:12:08.849447: train_loss -0.3438 
2023-08-07 20:12:08.849617: val_loss -0.3592 
2023-08-07 20:12:08.849684: Pseudo dice [0.7829] 
2023-08-07 20:12:08.849748: Epoch time: 63.66 s 
2023-08-07 20:12:09.845458:  
2023-08-07 20:12:09.845608: Epoch 542 
2023-08-07 20:12:09.845781: Current learning rate: 0.00075 
2023-08-07 20:13:13.234968: train_loss -0.331 
2023-08-07 20:13:13.235122: val_loss -0.4141 
2023-08-07 20:13:13.235174: Pseudo dice [0.8379] 
2023-08-07 20:13:13.235244: Epoch time: 63.39 s 
2023-08-07 20:13:14.236242:  
2023-08-07 20:13:14.236338: Epoch 543 
2023-08-07 20:13:14.236410: Current learning rate: 0.00075 
2023-08-07 20:14:17.576416: train_loss -0.349 
2023-08-07 20:14:17.576567: val_loss -0.3282 
2023-08-07 20:14:17.576618: Pseudo dice [0.8295] 
2023-08-07 20:14:17.576670: Epoch time: 63.34 s 
2023-08-07 20:14:18.573257:  
2023-08-07 20:14:18.573608: Epoch 544 
2023-08-07 20:14:18.573788: Current learning rate: 0.00075 
2023-08-07 20:15:22.005498: train_loss -0.3371 
2023-08-07 20:15:22.005666: val_loss -0.3424 
2023-08-07 20:15:22.005716: Pseudo dice [0.7214] 
2023-08-07 20:15:22.005766: Epoch time: 63.43 s 
2023-08-07 20:15:23.002732:  
2023-08-07 20:15:23.002825: Epoch 545 
2023-08-07 20:15:23.002895: Current learning rate: 0.00075 
2023-08-07 20:16:26.412883: train_loss -0.3264 
2023-08-07 20:16:26.413065: val_loss -0.3927 
2023-08-07 20:16:26.413120: Pseudo dice [0.746] 
2023-08-07 20:16:26.413170: Epoch time: 63.41 s 
2023-08-07 20:16:27.410267:  
2023-08-07 20:16:27.410470: Epoch 546 
2023-08-07 20:16:27.410563: Current learning rate: 0.00075 
2023-08-07 20:17:30.799467: train_loss -0.3593 
2023-08-07 20:17:30.799640: val_loss -0.3807 
2023-08-07 20:17:30.799692: Pseudo dice [0.7997] 
2023-08-07 20:17:30.799743: Epoch time: 63.39 s 
2023-08-07 20:17:31.969374:  
2023-08-07 20:17:31.969491: Epoch 547 
2023-08-07 20:17:31.969568: Current learning rate: 0.00075 
2023-08-07 20:18:35.505813: train_loss -0.3329 
2023-08-07 20:18:35.505970: val_loss -0.2889 
2023-08-07 20:18:35.506039: Pseudo dice [0.8423] 
2023-08-07 20:18:35.506140: Epoch time: 63.54 s 
2023-08-07 20:18:36.499595:  
2023-08-07 20:18:36.499692: Epoch 548 
2023-08-07 20:18:36.499765: Current learning rate: 0.00075 
2023-08-07 20:19:40.050642: train_loss -0.3456 
2023-08-07 20:19:40.050790: val_loss -0.3778 
2023-08-07 20:19:40.050841: Pseudo dice [0.7654] 
2023-08-07 20:19:40.050907: Epoch time: 63.55 s 
2023-08-07 20:19:41.047072:  
2023-08-07 20:19:41.047164: Epoch 549 
2023-08-07 20:19:41.047252: Current learning rate: 0.00075 
2023-08-07 20:20:44.604589: train_loss -0.3522 
2023-08-07 20:20:44.604745: val_loss -0.3227 
2023-08-07 20:20:44.604800: Pseudo dice [0.7608] 
2023-08-07 20:20:44.604850: Epoch time: 63.56 s 
2023-08-07 20:20:45.957593:  
2023-08-07 20:20:45.957685: Epoch 550 
2023-08-07 20:20:45.957775: Current learning rate: 0.00075 
2023-08-07 20:21:49.468116: train_loss -0.3434 
2023-08-07 20:21:49.468263: val_loss -0.388 
2023-08-07 20:21:49.468316: Pseudo dice [0.8716] 
2023-08-07 20:21:49.468368: Epoch time: 63.51 s 
2023-08-07 20:21:50.461884:  
2023-08-07 20:21:50.461989: Epoch 551 
2023-08-07 20:21:50.462064: Current learning rate: 0.00075 
2023-08-07 20:22:53.999693: train_loss -0.3388 
2023-08-07 20:22:53.999847: val_loss -0.3672 
2023-08-07 20:22:53.999899: Pseudo dice [0.8091] 
2023-08-07 20:22:53.999951: Epoch time: 63.54 s 
2023-08-07 20:22:55.019994:  
2023-08-07 20:22:55.020197: Epoch 552 
2023-08-07 20:22:55.020274: Current learning rate: 0.00075 
2023-08-07 20:23:58.541017: train_loss -0.3354 
2023-08-07 20:23:58.541164: val_loss -0.3323 
2023-08-07 20:23:58.541217: Pseudo dice [0.827] 
2023-08-07 20:23:58.541266: Epoch time: 63.52 s 
2023-08-07 20:23:59.739005:  
2023-08-07 20:23:59.739180: Epoch 553 
2023-08-07 20:23:59.739256: Current learning rate: 0.00075 
2023-08-07 20:25:03.212564: train_loss -0.3562 
2023-08-07 20:25:03.212714: val_loss -0.3461 
2023-08-07 20:25:03.212765: Pseudo dice [0.7938] 
2023-08-07 20:25:03.212816: Epoch time: 63.47 s 
2023-08-07 20:25:04.319632:  
2023-08-07 20:25:04.319729: Epoch 554 
2023-08-07 20:25:04.319803: Current learning rate: 0.00075 
2023-08-07 20:26:07.830664: train_loss -0.335 
2023-08-07 20:26:07.830812: val_loss -0.3531 
2023-08-07 20:26:07.830864: Pseudo dice [0.8121] 
2023-08-07 20:26:07.830914: Epoch time: 63.51 s 
2023-08-07 20:26:08.871995:  
2023-08-07 20:26:08.872087: Epoch 555 
2023-08-07 20:26:08.872177: Current learning rate: 0.00075 
2023-08-07 20:27:12.398659: train_loss -0.3348 
2023-08-07 20:27:12.398807: val_loss -0.3209 
2023-08-07 20:27:12.398858: Pseudo dice [0.804] 
2023-08-07 20:27:12.398928: Epoch time: 63.53 s 
2023-08-07 20:27:13.385461:  
2023-08-07 20:27:13.385558: Epoch 556 
2023-08-07 20:27:13.385628: Current learning rate: 0.00075 
2023-08-07 20:28:17.035125: train_loss -0.3201 
2023-08-07 20:28:17.035272: val_loss -0.2872 
2023-08-07 20:28:17.035341: Pseudo dice [0.6636] 
2023-08-07 20:28:17.035391: Epoch time: 63.65 s 
2023-08-07 20:28:18.040497:  
2023-08-07 20:28:18.040593: Epoch 557 
2023-08-07 20:28:18.040669: Current learning rate: 0.00075 
2023-08-07 20:29:21.428865: train_loss -0.3437 
2023-08-07 20:29:21.429010: val_loss -0.3745 
2023-08-07 20:29:21.429064: Pseudo dice [0.8275] 
2023-08-07 20:29:21.429114: Epoch time: 63.39 s 
2023-08-07 20:29:22.561087:  
2023-08-07 20:29:22.561191: Epoch 558 
2023-08-07 20:29:22.561284: Current learning rate: 0.00074 
2023-08-07 20:30:26.003038: train_loss -0.34 
2023-08-07 20:30:26.003191: val_loss -0.3122 
2023-08-07 20:30:26.003242: Pseudo dice [0.6838] 
2023-08-07 20:30:26.003299: Epoch time: 63.44 s 
2023-08-07 20:30:27.017720:  
2023-08-07 20:30:27.017831: Epoch 559 
2023-08-07 20:30:27.017920: Current learning rate: 0.00074 
2023-08-07 20:31:30.586241: train_loss -0.3486 
2023-08-07 20:31:30.586396: val_loss -0.3634 
2023-08-07 20:31:30.586449: Pseudo dice [0.7625] 
2023-08-07 20:31:30.586498: Epoch time: 63.57 s 
2023-08-07 20:31:31.576988:  
2023-08-07 20:31:31.577159: Epoch 560 
2023-08-07 20:31:31.577253: Current learning rate: 0.00074 
2023-08-07 20:32:34.996586: train_loss -0.3451 
2023-08-07 20:32:34.996746: val_loss -0.352 
2023-08-07 20:32:34.996798: Pseudo dice [0.8139] 
2023-08-07 20:32:34.996855: Epoch time: 63.42 s 
2023-08-07 20:32:36.002372:  
2023-08-07 20:32:36.002586: Epoch 561 
2023-08-07 20:32:36.002679: Current learning rate: 0.00074 
2023-08-07 20:33:39.658713: train_loss -0.3312 
2023-08-07 20:33:39.658861: val_loss -0.3971 
2023-08-07 20:33:39.658909: Pseudo dice [0.8212] 
2023-08-07 20:33:39.658975: Epoch time: 63.66 s 
2023-08-07 20:33:40.659526:  
2023-08-07 20:33:40.659643: Epoch 562 
2023-08-07 20:33:40.659714: Current learning rate: 0.00074 
2023-08-07 20:34:43.910781: train_loss -0.3639 
2023-08-07 20:34:43.910929: val_loss -0.3382 
2023-08-07 20:34:43.910980: Pseudo dice [0.8382] 
2023-08-07 20:34:43.911046: Epoch time: 63.25 s 
2023-08-07 20:34:44.900822:  
2023-08-07 20:34:44.900914: Epoch 563 
2023-08-07 20:34:44.900986: Current learning rate: 0.00074 
2023-08-07 20:35:48.254448: train_loss -0.3576 
2023-08-07 20:35:48.254613: val_loss -0.3411 
2023-08-07 20:35:48.254665: Pseudo dice [0.7909] 
2023-08-07 20:35:48.254713: Epoch time: 63.35 s 
2023-08-07 20:35:49.441298:  
2023-08-07 20:35:49.441403: Epoch 564 
2023-08-07 20:35:49.441497: Current learning rate: 0.00074 
2023-08-07 20:36:52.978828: train_loss -0.3349 
2023-08-07 20:36:52.978971: val_loss -0.4121 
2023-08-07 20:36:52.979024: Pseudo dice [0.8413] 
2023-08-07 20:36:52.979092: Epoch time: 63.54 s 
2023-08-07 20:36:54.005788:  
2023-08-07 20:36:54.005883: Epoch 565 
2023-08-07 20:36:54.005971: Current learning rate: 0.00074 
2023-08-07 20:37:57.423996: train_loss -0.3123 
2023-08-07 20:37:57.424149: val_loss -0.3015 
2023-08-07 20:37:57.424198: Pseudo dice [0.7422] 
2023-08-07 20:37:57.424248: Epoch time: 63.42 s 
2023-08-07 20:37:58.449336:  
2023-08-07 20:37:58.449426: Epoch 566 
2023-08-07 20:37:58.449515: Current learning rate: 0.00074 
2023-08-07 20:39:01.970559: train_loss -0.3285 
2023-08-07 20:39:01.970960: val_loss -0.3384 
2023-08-07 20:39:01.971015: Pseudo dice [0.7779] 
2023-08-07 20:39:01.971067: Epoch time: 63.52 s 
2023-08-07 20:39:03.025658:  
2023-08-07 20:39:03.025991: Epoch 567 
2023-08-07 20:39:03.026083: Current learning rate: 0.00074 
2023-08-07 20:40:06.496052: train_loss -0.3388 
2023-08-07 20:40:06.496195: val_loss -0.3129 
2023-08-07 20:40:06.496245: Pseudo dice [0.8039] 
2023-08-07 20:40:06.496303: Epoch time: 63.47 s 
2023-08-07 20:40:07.493046:  
2023-08-07 20:40:07.493145: Epoch 568 
2023-08-07 20:40:07.493215: Current learning rate: 0.00074 
2023-08-07 20:41:10.920838: train_loss -0.3436 
2023-08-07 20:41:10.920994: val_loss -0.3571 
2023-08-07 20:41:10.921043: Pseudo dice [0.8169] 
2023-08-07 20:41:10.921108: Epoch time: 63.43 s 
2023-08-07 20:41:11.940560:  
2023-08-07 20:41:11.940894: Epoch 569 
2023-08-07 20:41:11.940992: Current learning rate: 0.00074 
2023-08-07 20:42:15.316990: train_loss -0.3234 
2023-08-07 20:42:15.317248: val_loss -0.3669 
2023-08-07 20:42:15.317304: Pseudo dice [0.7735] 
2023-08-07 20:42:15.317354: Epoch time: 63.38 s 
2023-08-07 20:42:16.475307:  
2023-08-07 20:42:16.475530: Epoch 570 
2023-08-07 20:42:16.475617: Current learning rate: 0.00074 
2023-08-07 20:43:19.940972: train_loss -0.3571 
2023-08-07 20:43:19.941121: val_loss -0.3277 
2023-08-07 20:43:19.941174: Pseudo dice [0.8439] 
2023-08-07 20:43:19.941241: Epoch time: 63.47 s 
2023-08-07 20:43:20.938948:  
2023-08-07 20:43:20.939040: Epoch 571 
2023-08-07 20:43:20.939111: Current learning rate: 0.00074 
2023-08-07 20:44:24.447884: train_loss -0.3547 
2023-08-07 20:44:24.448034: val_loss -0.3397 
2023-08-07 20:44:24.448087: Pseudo dice [0.8075] 
2023-08-07 20:44:24.448138: Epoch time: 63.51 s 
2023-08-07 20:44:25.479804:  
2023-08-07 20:44:25.479899: Epoch 572 
2023-08-07 20:44:25.479971: Current learning rate: 0.00074 
2023-08-07 20:45:28.858196: train_loss -0.3319 
2023-08-07 20:45:28.858353: val_loss -0.2954 
2023-08-07 20:45:28.858408: Pseudo dice [0.8194] 
2023-08-07 20:45:28.858461: Epoch time: 63.38 s 
2023-08-07 20:45:28.858502: Yayy! New best EMA pseudo Dice: 0.7996 
2023-08-07 20:45:30.270853:  
2023-08-07 20:45:30.270954: Epoch 573 
2023-08-07 20:45:30.271042: Current learning rate: 0.00074 
2023-08-07 20:46:33.747900: train_loss -0.3327 
2023-08-07 20:46:33.748052: val_loss -0.354 
2023-08-07 20:46:33.748208: Pseudo dice [0.7407] 
2023-08-07 20:46:33.748261: Epoch time: 63.48 s 
2023-08-07 20:46:34.762169:  
2023-08-07 20:46:34.762268: Epoch 574 
2023-08-07 20:46:34.762342: Current learning rate: 0.00074 
2023-08-07 20:47:38.064572: train_loss -0.3407 
2023-08-07 20:47:38.064723: val_loss -0.3844 
2023-08-07 20:47:38.064775: Pseudo dice [0.7936] 
2023-08-07 20:47:38.064826: Epoch time: 63.3 s 
2023-08-07 20:47:39.267298:  
2023-08-07 20:47:39.267701: Epoch 575 
2023-08-07 20:47:39.267965: Current learning rate: 0.00074 
2023-08-07 20:48:42.802391: train_loss -0.372 
2023-08-07 20:48:42.802533: val_loss -0.3565 
2023-08-07 20:48:42.802584: Pseudo dice [0.8109] 
2023-08-07 20:48:42.802634: Epoch time: 63.54 s 
2023-08-07 20:48:43.811927:  
2023-08-07 20:48:43.812138: Epoch 576 
2023-08-07 20:48:43.812215: Current learning rate: 0.00074 
2023-08-07 20:49:47.179032: train_loss -0.3669 
2023-08-07 20:49:47.179184: val_loss -0.3732 
2023-08-07 20:49:47.179237: Pseudo dice [0.8738] 
2023-08-07 20:49:47.179288: Epoch time: 63.37 s 
2023-08-07 20:49:47.179328: Yayy! New best EMA pseudo Dice: 0.8033 
2023-08-07 20:49:48.541149:  
2023-08-07 20:49:48.541253: Epoch 577 
2023-08-07 20:49:48.541328: Current learning rate: 0.00074 
2023-08-07 20:50:51.897134: train_loss -0.3585 
2023-08-07 20:50:51.897294: val_loss -0.3332 
2023-08-07 20:50:51.897362: Pseudo dice [0.8148] 
2023-08-07 20:50:51.897414: Epoch time: 63.36 s 
2023-08-07 20:50:51.897453: Yayy! New best EMA pseudo Dice: 0.8044 
2023-08-07 20:50:53.289605:  
2023-08-07 20:50:53.289807: Epoch 578 
2023-08-07 20:50:53.289887: Current learning rate: 0.00074 
2023-08-07 20:51:56.775635: train_loss -0.3295 
2023-08-07 20:51:56.775782: val_loss -0.2974 
2023-08-07 20:51:56.775834: Pseudo dice [0.7326] 
2023-08-07 20:51:56.775886: Epoch time: 63.49 s 
2023-08-07 20:51:57.795243:  
2023-08-07 20:51:57.795417: Epoch 579 
2023-08-07 20:51:57.795495: Current learning rate: 0.00074 
2023-08-07 20:53:01.190528: train_loss -0.3507 
2023-08-07 20:53:01.190697: val_loss -0.4059 
2023-08-07 20:53:01.190750: Pseudo dice [0.8525] 
2023-08-07 20:53:01.190809: Epoch time: 63.4 s 
2023-08-07 20:53:02.199435:  
2023-08-07 20:53:02.199526: Epoch 580 
2023-08-07 20:53:02.199637: Current learning rate: 0.00073 
2023-08-07 20:54:05.525467: train_loss -0.3226 
2023-08-07 20:54:05.525624: val_loss -0.3125 
2023-08-07 20:54:05.525674: Pseudo dice [0.7989] 
2023-08-07 20:54:05.525741: Epoch time: 63.33 s 
2023-08-07 20:54:06.694463:  
2023-08-07 20:54:06.694669: Epoch 581 
2023-08-07 20:54:06.694765: Current learning rate: 0.00073 
2023-08-07 20:55:10.211617: train_loss -0.3663 
2023-08-07 20:55:10.211763: val_loss -0.3361 
2023-08-07 20:55:10.211815: Pseudo dice [0.7465] 
2023-08-07 20:55:10.211865: Epoch time: 63.52 s 
2023-08-07 20:55:11.244374:  
2023-08-07 20:55:11.244472: Epoch 582 
2023-08-07 20:55:11.244547: Current learning rate: 0.00073 
2023-08-07 20:56:14.743535: train_loss -0.3346 
2023-08-07 20:56:14.743716: val_loss -0.365 
2023-08-07 20:56:14.743769: Pseudo dice [0.8132] 
2023-08-07 20:56:14.743820: Epoch time: 63.5 s 
2023-08-07 20:56:15.753252:  
2023-08-07 20:56:15.753349: Epoch 583 
2023-08-07 20:56:15.753437: Current learning rate: 0.00073 
2023-08-07 20:57:19.076189: train_loss -0.3585 
2023-08-07 20:57:19.076346: val_loss -0.3548 
2023-08-07 20:57:19.076398: Pseudo dice [0.8807] 
2023-08-07 20:57:19.076449: Epoch time: 63.32 s 
2023-08-07 20:57:19.076489: Yayy! New best EMA pseudo Dice: 0.8067 
2023-08-07 20:57:20.432406:  
2023-08-07 20:57:20.432504: Epoch 584 
2023-08-07 20:57:20.432592: Current learning rate: 0.00073 
2023-08-07 20:58:23.914832: train_loss -0.3109 
2023-08-07 20:58:23.915012: val_loss -0.3157 
2023-08-07 20:58:23.915064: Pseudo dice [0.7951] 
2023-08-07 20:58:23.915113: Epoch time: 63.48 s 
2023-08-07 20:58:24.931800:  
2023-08-07 20:58:24.931899: Epoch 585 
2023-08-07 20:58:24.931988: Current learning rate: 0.00073 
2023-08-07 20:59:28.445221: train_loss -0.3641 
2023-08-07 20:59:28.445398: val_loss -0.3356 
2023-08-07 20:59:28.445454: Pseudo dice [0.7471] 
2023-08-07 20:59:28.445506: Epoch time: 63.51 s 
2023-08-07 20:59:29.615801:  
2023-08-07 20:59:29.615910: Epoch 586 
2023-08-07 20:59:29.615984: Current learning rate: 0.00073 
2023-08-07 21:00:32.993783: train_loss -0.3345 
2023-08-07 21:00:32.993927: val_loss -0.2901 
2023-08-07 21:00:32.993991: Pseudo dice [0.8268] 
2023-08-07 21:00:32.994040: Epoch time: 63.38 s 
2023-08-07 21:00:34.022627:  
2023-08-07 21:00:34.022721: Epoch 587 
2023-08-07 21:00:34.022812: Current learning rate: 0.00073 
2023-08-07 21:01:37.423793: train_loss -0.3355 
2023-08-07 21:01:37.423943: val_loss -0.4195 
2023-08-07 21:01:37.423994: Pseudo dice [0.8377] 
2023-08-07 21:01:37.424045: Epoch time: 63.4 s 
2023-08-07 21:01:38.466901:  
2023-08-07 21:01:38.467144: Epoch 588 
2023-08-07 21:01:38.467237: Current learning rate: 0.00073 
2023-08-07 21:02:42.026664: train_loss -0.3294 
2023-08-07 21:02:42.026821: val_loss -0.3816 
2023-08-07 21:02:42.026872: Pseudo dice [0.7678] 
2023-08-07 21:02:42.026940: Epoch time: 63.56 s 
2023-08-07 21:02:43.061227:  
2023-08-07 21:02:43.061427: Epoch 589 
2023-08-07 21:02:43.061509: Current learning rate: 0.00073 
2023-08-07 21:03:46.527397: train_loss -0.3104 
2023-08-07 21:03:46.527546: val_loss -0.3382 
2023-08-07 21:03:46.527607: Pseudo dice [0.7645] 
2023-08-07 21:03:46.527658: Epoch time: 63.47 s 
2023-08-07 21:03:47.530422:  
2023-08-07 21:03:47.530516: Epoch 590 
2023-08-07 21:03:47.530585: Current learning rate: 0.00073 
2023-08-07 21:04:50.831311: train_loss -0.3481 
2023-08-07 21:04:50.831565: val_loss -0.3796 
2023-08-07 21:04:50.831689: Pseudo dice [0.8437] 
2023-08-07 21:04:50.831798: Epoch time: 63.3 s 
2023-08-07 21:04:51.890594:  
2023-08-07 21:04:51.890686: Epoch 591 
2023-08-07 21:04:51.890757: Current learning rate: 0.00073 
2023-08-07 21:05:55.118330: train_loss -0.3641 
2023-08-07 21:05:55.118482: val_loss -0.3567 
2023-08-07 21:05:55.118551: Pseudo dice [0.8033] 
2023-08-07 21:05:55.118603: Epoch time: 63.23 s 
2023-08-07 21:05:56.299214:  
2023-08-07 21:05:56.299309: Epoch 592 
2023-08-07 21:05:56.299402: Current learning rate: 0.00073 
2023-08-07 21:06:59.868526: train_loss -0.3526 
2023-08-07 21:06:59.868674: val_loss -0.4202 
2023-08-07 21:06:59.868725: Pseudo dice [0.7924] 
2023-08-07 21:06:59.868775: Epoch time: 63.57 s 
2023-08-07 21:07:00.883657:  
2023-08-07 21:07:00.883836: Epoch 593 
2023-08-07 21:07:00.883914: Current learning rate: 0.00073 
2023-08-07 21:08:04.373353: train_loss -0.3735 
2023-08-07 21:08:04.373502: val_loss -0.4111 
2023-08-07 21:08:04.373555: Pseudo dice [0.8476] 
2023-08-07 21:08:04.373605: Epoch time: 63.49 s 
2023-08-07 21:08:05.384946:  
2023-08-07 21:08:05.385042: Epoch 594 
2023-08-07 21:08:05.385114: Current learning rate: 0.00073 
2023-08-07 21:09:08.898816: train_loss -0.3263 
2023-08-07 21:09:08.898966: val_loss -0.4008 
2023-08-07 21:09:08.899016: Pseudo dice [0.7941] 
2023-08-07 21:09:08.899082: Epoch time: 63.51 s 
2023-08-07 21:09:09.912430:  
2023-08-07 21:09:09.912639: Epoch 595 
2023-08-07 21:09:09.912721: Current learning rate: 0.00073 
2023-08-07 21:10:13.427450: train_loss -0.3667 
2023-08-07 21:10:13.427621: val_loss -0.3111 
2023-08-07 21:10:13.427676: Pseudo dice [0.8117] 
2023-08-07 21:10:13.427726: Epoch time: 63.52 s 
2023-08-07 21:10:14.475541:  
2023-08-07 21:10:14.475750: Epoch 596 
2023-08-07 21:10:14.475828: Current learning rate: 0.00073 
2023-08-07 21:11:17.910014: train_loss -0.3648 
2023-08-07 21:11:17.910280: val_loss -0.4266 
2023-08-07 21:11:17.910335: Pseudo dice [0.8706] 
2023-08-07 21:11:17.910388: Epoch time: 63.44 s 
2023-08-07 21:11:17.910429: Yayy! New best EMA pseudo Dice: 0.8123 
2023-08-07 21:11:19.535119:  
2023-08-07 21:11:19.535230: Epoch 597 
2023-08-07 21:11:19.535303: Current learning rate: 0.00073 
2023-08-07 21:12:23.077989: train_loss -0.3447 
2023-08-07 21:12:23.078152: val_loss -0.3481 
2023-08-07 21:12:23.078207: Pseudo dice [0.7973] 
2023-08-07 21:12:23.078257: Epoch time: 63.54 s 
2023-08-07 21:12:24.122313:  
2023-08-07 21:12:24.122627: Epoch 598 
2023-08-07 21:12:24.122706: Current learning rate: 0.00073 
2023-08-07 21:13:27.530940: train_loss -0.3547 
2023-08-07 21:13:27.531089: val_loss -0.2991 
2023-08-07 21:13:27.531141: Pseudo dice [0.7502] 
2023-08-07 21:13:27.531191: Epoch time: 63.41 s 
2023-08-07 21:13:28.574951:  
2023-08-07 21:13:28.575049: Epoch 599 
2023-08-07 21:13:28.575139: Current learning rate: 0.00073 
2023-08-07 21:14:31.960557: train_loss -0.3241 
2023-08-07 21:14:31.960703: val_loss -0.4075 
2023-08-07 21:14:31.960755: Pseudo dice [0.8836] 
2023-08-07 21:14:31.960806: Epoch time: 63.39 s 
2023-08-07 21:14:32.324390: Yayy! New best EMA pseudo Dice: 0.8127 
2023-08-07 21:14:33.708644:  
2023-08-07 21:14:33.708748: Epoch 600 
2023-08-07 21:14:33.708824: Current learning rate: 0.00073 
2023-08-07 21:15:37.149663: train_loss -0.3595 
2023-08-07 21:15:37.149825: val_loss -0.317 
2023-08-07 21:15:37.149877: Pseudo dice [0.8571] 
2023-08-07 21:15:37.149926: Epoch time: 63.44 s 
2023-08-07 21:15:37.149966: Yayy! New best EMA pseudo Dice: 0.8171 
2023-08-07 21:15:38.560094:  
2023-08-07 21:15:38.560194: Epoch 601 
2023-08-07 21:15:38.560270: Current learning rate: 0.00072 
2023-08-07 21:16:42.093916: train_loss -0.3394 
2023-08-07 21:16:42.094066: val_loss -0.3614 
2023-08-07 21:16:42.094119: Pseudo dice [0.8025] 
2023-08-07 21:16:42.094170: Epoch time: 63.53 s 
2023-08-07 21:16:43.302584:  
2023-08-07 21:16:43.302682: Epoch 602 
2023-08-07 21:16:43.302760: Current learning rate: 0.00072 
2023-08-07 21:17:46.811544: train_loss -0.3176 
2023-08-07 21:17:46.811696: val_loss -0.2951 
2023-08-07 21:17:46.811748: Pseudo dice [0.7826] 
2023-08-07 21:17:46.811799: Epoch time: 63.51 s 
2023-08-07 21:17:47.895869:  
2023-08-07 21:17:47.896046: Epoch 603 
2023-08-07 21:17:47.896123: Current learning rate: 0.00072 
2023-08-07 21:18:51.207984: train_loss -0.3338 
2023-08-07 21:18:51.208261: val_loss -0.3237 
2023-08-07 21:18:51.208318: Pseudo dice [0.788] 
2023-08-07 21:18:51.208369: Epoch time: 63.31 s 
2023-08-07 21:18:52.219285:  
2023-08-07 21:18:52.219380: Epoch 604 
2023-08-07 21:18:52.219468: Current learning rate: 0.00072 
2023-08-07 21:19:55.833173: train_loss -0.3138 
2023-08-07 21:19:55.833326: val_loss -0.2961 
2023-08-07 21:19:55.833379: Pseudo dice [0.7259] 
2023-08-07 21:19:55.833445: Epoch time: 63.61 s 
2023-08-07 21:19:56.855340:  
2023-08-07 21:19:56.855433: Epoch 605 
2023-08-07 21:19:56.855505: Current learning rate: 0.00072 
2023-08-07 21:21:00.158936: train_loss -0.3373 
2023-08-07 21:21:00.159082: val_loss -0.3177 
2023-08-07 21:21:00.159149: Pseudo dice [0.8186] 
2023-08-07 21:21:00.159198: Epoch time: 63.3 s 
2023-08-07 21:21:01.209191:  
2023-08-07 21:21:01.209378: Epoch 606 
2023-08-07 21:21:01.209473: Current learning rate: 0.00072 
2023-08-07 21:22:04.616449: train_loss -0.3354 
2023-08-07 21:22:04.616597: val_loss -0.367 
2023-08-07 21:22:04.616646: Pseudo dice [0.7964] 
2023-08-07 21:22:04.616697: Epoch time: 63.41 s 
2023-08-07 21:22:05.639770:  
2023-08-07 21:22:05.639868: Epoch 607 
2023-08-07 21:22:05.639945: Current learning rate: 0.00072 
2023-08-07 21:23:08.878428: train_loss -0.3593 
2023-08-07 21:23:08.878573: val_loss -0.351 
2023-08-07 21:23:08.878622: Pseudo dice [0.853] 
2023-08-07 21:23:08.878687: Epoch time: 63.24 s 
2023-08-07 21:23:10.055037:  
2023-08-07 21:23:10.055134: Epoch 608 
2023-08-07 21:23:10.055209: Current learning rate: 0.00072 
2023-08-07 21:24:13.480428: train_loss -0.3603 
2023-08-07 21:24:13.480583: val_loss -0.3673 
2023-08-07 21:24:13.480639: Pseudo dice [0.9026] 
2023-08-07 21:24:13.480689: Epoch time: 63.43 s 
2023-08-07 21:24:14.526269:  
2023-08-07 21:24:14.526541: Epoch 609 
2023-08-07 21:24:14.526699: Current learning rate: 0.00072 
2023-08-07 21:25:18.146158: train_loss -0.3338 
2023-08-07 21:25:18.146304: val_loss -0.2712 
2023-08-07 21:25:18.146358: Pseudo dice [0.7329] 
2023-08-07 21:25:18.146407: Epoch time: 63.62 s 
2023-08-07 21:25:19.162718:  
2023-08-07 21:25:19.162813: Epoch 610 
2023-08-07 21:25:19.162885: Current learning rate: 0.00072 
2023-08-07 21:26:22.724444: train_loss -0.3438 
2023-08-07 21:26:22.724704: val_loss -0.4046 
2023-08-07 21:26:22.724761: Pseudo dice [0.7835] 
2023-08-07 21:26:22.724813: Epoch time: 63.56 s 
2023-08-07 21:26:23.743849:  
2023-08-07 21:26:23.744178: Epoch 611 
2023-08-07 21:26:23.744306: Current learning rate: 0.00072 
2023-08-07 21:27:27.143265: train_loss -0.3567 
2023-08-07 21:27:27.143416: val_loss -0.3007 
2023-08-07 21:27:27.143484: Pseudo dice [0.7123] 
2023-08-07 21:27:27.147908: Epoch time: 63.4 s 
2023-08-07 21:27:28.220845:  
2023-08-07 21:27:28.221020: Epoch 612 
2023-08-07 21:27:28.221095: Current learning rate: 0.00072 
2023-08-07 21:28:31.733871: train_loss -0.3425 
2023-08-07 21:28:31.734019: val_loss -0.2591 
2023-08-07 21:28:31.734068: Pseudo dice [0.7322] 
2023-08-07 21:28:31.734132: Epoch time: 63.51 s 
2023-08-07 21:28:32.932677:  
2023-08-07 21:28:32.932798: Epoch 613 
2023-08-07 21:28:32.932967: Current learning rate: 0.00072 
2023-08-07 21:29:36.457748: train_loss -0.3667 
2023-08-07 21:29:36.457889: val_loss -0.4717 
2023-08-07 21:29:36.457957: Pseudo dice [0.8567] 
2023-08-07 21:29:36.458007: Epoch time: 63.53 s 
2023-08-07 21:29:37.475427:  
2023-08-07 21:29:37.475523: Epoch 614 
2023-08-07 21:29:37.475633: Current learning rate: 0.00072 
2023-08-07 21:30:40.952855: train_loss -0.3338 
2023-08-07 21:30:40.953010: val_loss -0.3855 
2023-08-07 21:30:40.953061: Pseudo dice [0.773] 
2023-08-07 21:30:40.953129: Epoch time: 63.48 s 
2023-08-07 21:30:42.009794:  
2023-08-07 21:30:42.009973: Epoch 615 
2023-08-07 21:30:42.010066: Current learning rate: 0.00072 
2023-08-07 21:31:45.407583: train_loss -0.3424 
2023-08-07 21:31:45.407829: val_loss -0.354 
2023-08-07 21:31:45.407880: Pseudo dice [0.8174] 
2023-08-07 21:31:45.407932: Epoch time: 63.4 s 
2023-08-07 21:31:46.444561:  
2023-08-07 21:31:46.444770: Epoch 616 
2023-08-07 21:31:46.444847: Current learning rate: 0.00072 
2023-08-07 21:32:49.727546: train_loss -0.3449 
2023-08-07 21:32:49.727709: val_loss -0.3204 
2023-08-07 21:32:49.727902: Pseudo dice [0.8344] 
2023-08-07 21:32:49.727956: Epoch time: 63.28 s 
2023-08-07 21:32:50.736982:  
2023-08-07 21:32:50.737179: Epoch 617 
2023-08-07 21:32:50.737282: Current learning rate: 0.00072 
2023-08-07 21:33:54.096066: train_loss -0.3708 
2023-08-07 21:33:54.096207: val_loss -0.388 
2023-08-07 21:33:54.096257: Pseudo dice [0.8457] 
2023-08-07 21:33:54.096306: Epoch time: 63.36 s 
2023-08-07 21:33:55.107416:  
2023-08-07 21:33:55.107505: Epoch 618 
2023-08-07 21:33:55.107597: Current learning rate: 0.00072 
2023-08-07 21:34:58.473325: train_loss -0.3141 
2023-08-07 21:34:58.473478: val_loss -0.3544 
2023-08-07 21:34:58.473547: Pseudo dice [0.9083] 
2023-08-07 21:34:58.473596: Epoch time: 63.37 s 
2023-08-07 21:34:59.699392:  
2023-08-07 21:34:59.699507: Epoch 619 
2023-08-07 21:34:59.699592: Current learning rate: 0.00072 
2023-08-07 21:36:03.038106: train_loss -0.3409 
2023-08-07 21:36:03.038380: val_loss -0.3551 
2023-08-07 21:36:03.038438: Pseudo dice [0.8639] 
2023-08-07 21:36:03.038490: Epoch time: 63.34 s 
2023-08-07 21:36:03.038531: Yayy! New best EMA pseudo Dice: 0.8203 
2023-08-07 21:36:04.454152:  
2023-08-07 21:36:04.454253: Epoch 620 
2023-08-07 21:36:04.454325: Current learning rate: 0.00072 
2023-08-07 21:37:07.786568: train_loss -0.3463 
2023-08-07 21:37:07.786720: val_loss -0.3469 
2023-08-07 21:37:07.786772: Pseudo dice [0.8405] 
2023-08-07 21:37:07.786823: Epoch time: 63.33 s 
2023-08-07 21:37:07.786862: Yayy! New best EMA pseudo Dice: 0.8223 
2023-08-07 21:37:09.222290:  
2023-08-07 21:37:09.222385: Epoch 621 
2023-08-07 21:37:09.222499: Current learning rate: 0.00072 
2023-08-07 21:38:12.672566: train_loss -0.3002 
2023-08-07 21:38:12.672714: val_loss -0.348 
2023-08-07 21:38:12.672765: Pseudo dice [0.7881] 
2023-08-07 21:38:12.672815: Epoch time: 63.45 s 
2023-08-07 21:38:13.710202:  
2023-08-07 21:38:13.710529: Epoch 622 
2023-08-07 21:38:13.710624: Current learning rate: 0.00072 
2023-08-07 21:39:17.011123: train_loss -0.3424 
2023-08-07 21:39:17.011269: val_loss -0.3237 
2023-08-07 21:39:17.011319: Pseudo dice [0.6869] 
2023-08-07 21:39:17.011385: Epoch time: 63.3 s 
2023-08-07 21:39:18.067390:  
2023-08-07 21:39:18.067704: Epoch 623 
2023-08-07 21:39:18.067866: Current learning rate: 0.00071 
2023-08-07 21:40:21.262041: train_loss -0.3256 
2023-08-07 21:40:21.262190: val_loss -0.3608 
2023-08-07 21:40:21.262243: Pseudo dice [0.8047] 
2023-08-07 21:40:21.262293: Epoch time: 63.2 s 
2023-08-07 21:40:22.433862:  
2023-08-07 21:40:22.434073: Epoch 624 
2023-08-07 21:40:22.434148: Current learning rate: 0.00071 
2023-08-07 21:41:25.724984: train_loss -0.3714 
2023-08-07 21:41:25.725137: val_loss -0.4279 
2023-08-07 21:41:25.725186: Pseudo dice [0.7842] 
2023-08-07 21:41:25.725253: Epoch time: 63.29 s 
2023-08-07 21:41:26.772753:  
2023-08-07 21:41:26.772863: Epoch 625 
2023-08-07 21:41:26.773033: Current learning rate: 0.00071 
2023-08-07 21:42:30.391167: train_loss -0.333 
2023-08-07 21:42:30.391319: val_loss -0.3366 
2023-08-07 21:42:30.391371: Pseudo dice [0.8134] 
2023-08-07 21:42:30.391420: Epoch time: 63.62 s 
2023-08-07 21:42:31.411035:  
2023-08-07 21:42:31.411134: Epoch 626 
2023-08-07 21:42:31.411205: Current learning rate: 0.00071 
2023-08-07 21:43:34.769567: train_loss -0.3957 
2023-08-07 21:43:34.769709: val_loss -0.3488 
2023-08-07 21:43:34.769775: Pseudo dice [0.8548] 
2023-08-07 21:43:34.769825: Epoch time: 63.36 s 
2023-08-07 21:43:35.814865:  
2023-08-07 21:43:35.814966: Epoch 627 
2023-08-07 21:43:35.815056: Current learning rate: 0.00071 
2023-08-07 21:44:39.391127: train_loss -0.36 
2023-08-07 21:44:39.391278: val_loss -0.332 
2023-08-07 21:44:39.391328: Pseudo dice [0.7958] 
2023-08-07 21:44:39.391378: Epoch time: 63.58 s 
2023-08-07 21:44:40.428289:  
2023-08-07 21:44:40.428464: Epoch 628 
2023-08-07 21:44:40.428540: Current learning rate: 0.00071 
2023-08-07 21:45:43.871220: train_loss -0.3279 
2023-08-07 21:45:43.871371: val_loss -0.3679 
2023-08-07 21:45:43.871422: Pseudo dice [0.8215] 
2023-08-07 21:45:43.871487: Epoch time: 63.44 s 
2023-08-07 21:45:44.888777:  
2023-08-07 21:45:44.888880: Epoch 629 
2023-08-07 21:45:44.888961: Current learning rate: 0.00071 
2023-08-07 21:46:48.333682: train_loss -0.3468 
2023-08-07 21:46:48.333851: val_loss -0.3408 
2023-08-07 21:46:48.333922: Pseudo dice [0.8873] 
2023-08-07 21:46:48.333973: Epoch time: 63.45 s 
2023-08-07 21:46:49.518864:  
2023-08-07 21:46:49.519171: Epoch 630 
2023-08-07 21:46:49.519264: Current learning rate: 0.00071 
2023-08-07 21:47:53.182710: train_loss -0.3736 
2023-08-07 21:47:53.182859: val_loss -0.3957 
2023-08-07 21:47:53.182908: Pseudo dice [0.7215] 
2023-08-07 21:47:53.182973: Epoch time: 63.66 s 
2023-08-07 21:47:54.227688:  
2023-08-07 21:47:54.227994: Epoch 631 
2023-08-07 21:47:54.228127: Current learning rate: 0.00071 
2023-08-07 21:48:57.741666: train_loss -0.3302 
2023-08-07 21:48:57.741899: val_loss -0.3294 
2023-08-07 21:48:57.741953: Pseudo dice [0.8136] 
2023-08-07 21:48:57.742003: Epoch time: 63.51 s 
2023-08-07 21:48:58.776478:  
2023-08-07 21:48:58.776576: Epoch 632 
2023-08-07 21:48:58.776649: Current learning rate: 0.00071 
2023-08-07 21:50:02.339218: train_loss -0.3025 
2023-08-07 21:50:02.339370: val_loss -0.3505 
2023-08-07 21:50:02.339424: Pseudo dice [0.8452] 
2023-08-07 21:50:02.339474: Epoch time: 63.56 s 
2023-08-07 21:50:03.358628:  
2023-08-07 21:50:03.358852: Epoch 633 
2023-08-07 21:50:03.358930: Current learning rate: 0.00071 
2023-08-07 21:51:06.873681: train_loss -0.358 
2023-08-07 21:51:06.873836: val_loss -0.3854 
2023-08-07 21:51:06.873889: Pseudo dice [0.907] 
2023-08-07 21:51:06.873939: Epoch time: 63.52 s 
2023-08-07 21:51:07.899695:  
2023-08-07 21:51:07.900005: Epoch 634 
2023-08-07 21:51:07.900084: Current learning rate: 0.00071 
2023-08-07 21:52:11.327888: train_loss -0.3389 
2023-08-07 21:52:11.328041: val_loss -0.3338 
2023-08-07 21:52:11.328093: Pseudo dice [0.8319] 
2023-08-07 21:52:11.328142: Epoch time: 63.43 s 
2023-08-07 21:52:11.328182: Yayy! New best EMA pseudo Dice: 0.8225 
2023-08-07 21:52:12.895658:  
2023-08-07 21:52:12.895866: Epoch 635 
2023-08-07 21:52:12.895959: Current learning rate: 0.00071 
2023-08-07 21:53:16.328621: train_loss -0.3536 
2023-08-07 21:53:16.328767: val_loss -0.3351 
2023-08-07 21:53:16.328817: Pseudo dice [0.7928] 
2023-08-07 21:53:16.328868: Epoch time: 63.43 s 
2023-08-07 21:53:17.367209:  
2023-08-07 21:53:17.367509: Epoch 636 
2023-08-07 21:53:17.367822: Current learning rate: 0.00071 
2023-08-07 21:54:20.961024: train_loss -0.3399 
2023-08-07 21:54:20.961174: val_loss -0.4087 
2023-08-07 21:54:20.961248: Pseudo dice [0.8387] 
2023-08-07 21:54:20.961299: Epoch time: 63.59 s 
2023-08-07 21:54:21.990485:  
2023-08-07 21:54:21.990582: Epoch 637 
2023-08-07 21:54:21.990657: Current learning rate: 0.00071 
2023-08-07 21:55:25.396477: train_loss -0.3046 
2023-08-07 21:55:25.396617: val_loss -0.327 
2023-08-07 21:55:25.396666: Pseudo dice [0.7802] 
2023-08-07 21:55:25.396715: Epoch time: 63.41 s 
2023-08-07 21:55:26.415809:  
2023-08-07 21:55:26.415904: Epoch 638 
2023-08-07 21:55:26.415979: Current learning rate: 0.00071 
2023-08-07 21:56:29.783448: train_loss -0.3783 
2023-08-07 21:56:29.783608: val_loss -0.3121 
2023-08-07 21:56:29.783679: Pseudo dice [0.7898] 
2023-08-07 21:56:29.783731: Epoch time: 63.37 s 
2023-08-07 21:56:30.842353:  
2023-08-07 21:56:30.842561: Epoch 639 
2023-08-07 21:56:30.842638: Current learning rate: 0.00071 
2023-08-07 21:57:34.210804: train_loss -0.3297 
2023-08-07 21:57:34.210966: val_loss -0.3619 
2023-08-07 21:57:34.211016: Pseudo dice [0.8552] 
2023-08-07 21:57:34.211068: Epoch time: 63.37 s 
2023-08-07 21:57:35.251015:  
2023-08-07 21:57:35.251106: Epoch 640 
2023-08-07 21:57:35.251196: Current learning rate: 0.00071 
2023-08-07 21:58:38.549110: train_loss -0.3254 
2023-08-07 21:58:38.549290: val_loss -0.338 
2023-08-07 21:58:38.549342: Pseudo dice [0.8202] 
2023-08-07 21:58:38.549393: Epoch time: 63.3 s 
2023-08-07 21:58:39.779188:  
2023-08-07 21:58:39.779383: Epoch 641 
2023-08-07 21:58:39.779471: Current learning rate: 0.00071 
2023-08-07 21:59:43.238204: train_loss -0.3654 
2023-08-07 21:59:43.238355: val_loss -0.4218 
2023-08-07 21:59:43.238410: Pseudo dice [0.8217] 
2023-08-07 21:59:43.238460: Epoch time: 63.46 s 
2023-08-07 21:59:44.253829:  
2023-08-07 21:59:44.253932: Epoch 642 
2023-08-07 21:59:44.254005: Current learning rate: 0.00071 
2023-08-07 22:00:47.847672: train_loss -0.3258 
2023-08-07 22:00:47.847827: val_loss -0.3966 
2023-08-07 22:00:47.847879: Pseudo dice [0.8744] 
2023-08-07 22:00:47.847929: Epoch time: 63.59 s 
2023-08-07 22:00:47.847969: Yayy! New best EMA pseudo Dice: 0.8246 
2023-08-07 22:00:49.259802:  
2023-08-07 22:00:49.260007: Epoch 643 
2023-08-07 22:00:49.260085: Current learning rate: 0.00071 
2023-08-07 22:01:52.724740: train_loss -0.363 
2023-08-07 22:01:52.724887: val_loss -0.4101 
2023-08-07 22:01:52.724938: Pseudo dice [0.8294] 
2023-08-07 22:01:52.724988: Epoch time: 63.47 s 
2023-08-07 22:01:52.725028: Yayy! New best EMA pseudo Dice: 0.8251 
2023-08-07 22:01:54.128594:  
2023-08-07 22:01:54.128695: Epoch 644 
2023-08-07 22:01:54.128786: Current learning rate: 0.0007 
2023-08-07 22:02:57.467057: train_loss -0.3375 
2023-08-07 22:02:57.467204: val_loss -0.3481 
2023-08-07 22:02:57.467254: Pseudo dice [0.8496] 
2023-08-07 22:02:57.467307: Epoch time: 63.34 s 
2023-08-07 22:02:57.467346: Yayy! New best EMA pseudo Dice: 0.8275 
2023-08-07 22:02:58.867306:  
2023-08-07 22:02:58.867404: Epoch 645 
2023-08-07 22:02:58.867479: Current learning rate: 0.0007 
2023-08-07 22:04:02.356658: train_loss -0.3498 
2023-08-07 22:04:02.356813: val_loss -0.3613 
2023-08-07 22:04:02.356865: Pseudo dice [0.8426] 
2023-08-07 22:04:02.356916: Epoch time: 63.49 s 
2023-08-07 22:04:02.356958: Yayy! New best EMA pseudo Dice: 0.829 
2023-08-07 22:04:03.889707:  
2023-08-07 22:04:03.889887: Epoch 646 
2023-08-07 22:04:03.889971: Current learning rate: 0.0007 
2023-08-07 22:05:07.341134: train_loss -0.3079 
2023-08-07 22:05:07.341326: val_loss -0.3344 
2023-08-07 22:05:07.341377: Pseudo dice [0.6834] 
2023-08-07 22:05:07.341429: Epoch time: 63.45 s 
2023-08-07 22:05:08.370797:  
2023-08-07 22:05:08.371169: Epoch 647 
2023-08-07 22:05:08.371263: Current learning rate: 0.0007 
2023-08-07 22:06:11.878756: train_loss -0.3378 
2023-08-07 22:06:11.878900: val_loss -0.3929 
2023-08-07 22:06:11.878953: Pseudo dice [0.792] 
2023-08-07 22:06:11.879002: Epoch time: 63.51 s 
2023-08-07 22:06:12.917707:  
2023-08-07 22:06:12.917802: Epoch 648 
2023-08-07 22:06:12.917889: Current learning rate: 0.0007 
2023-08-07 22:07:16.421545: train_loss -0.3331 
2023-08-07 22:07:16.421693: val_loss -0.3112 
2023-08-07 22:07:16.421744: Pseudo dice [0.8244] 
2023-08-07 22:07:16.421794: Epoch time: 63.5 s 
2023-08-07 22:07:17.442996:  
2023-08-07 22:07:17.443112: Epoch 649 
2023-08-07 22:07:17.443185: Current learning rate: 0.0007 
2023-08-07 22:08:20.712999: train_loss -0.3515 
2023-08-07 22:08:20.713145: val_loss -0.3812 
2023-08-07 22:08:20.713196: Pseudo dice [0.8301] 
2023-08-07 22:08:20.713244: Epoch time: 63.27 s 
2023-08-07 22:08:22.117101:  
2023-08-07 22:08:22.117197: Epoch 650 
2023-08-07 22:08:22.117286: Current learning rate: 0.0007 
2023-08-07 22:09:25.472868: train_loss -0.346 
2023-08-07 22:09:25.473013: val_loss -0.3085 
2023-08-07 22:09:25.473065: Pseudo dice [0.8291] 
2023-08-07 22:09:25.473116: Epoch time: 63.36 s 
2023-08-07 22:09:26.648402:  
2023-08-07 22:09:26.648714: Epoch 651 
2023-08-07 22:09:26.648792: Current learning rate: 0.0007 
2023-08-07 22:10:29.963528: train_loss -0.3054 
2023-08-07 22:10:29.963689: val_loss -0.4003 
2023-08-07 22:10:29.963743: Pseudo dice [0.8089] 
2023-08-07 22:10:29.963793: Epoch time: 63.32 s 
2023-08-07 22:10:31.033089:  
2023-08-07 22:10:31.033284: Epoch 652 
2023-08-07 22:10:31.033363: Current learning rate: 0.0007 
2023-08-07 22:11:34.420949: train_loss -0.3206 
2023-08-07 22:11:34.421097: val_loss -0.4332 
2023-08-07 22:11:34.421167: Pseudo dice [0.8655] 
2023-08-07 22:11:34.421216: Epoch time: 63.39 s 
2023-08-07 22:11:35.468318:  
2023-08-07 22:11:35.468522: Epoch 653 
2023-08-07 22:11:35.468595: Current learning rate: 0.0007 
2023-08-07 22:12:38.953846: train_loss -0.2972 
2023-08-07 22:12:38.953999: val_loss -0.3849 
2023-08-07 22:12:38.954050: Pseudo dice [0.7701] 
2023-08-07 22:12:38.954118: Epoch time: 63.49 s 
2023-08-07 22:12:39.973290:  
2023-08-07 22:12:39.973466: Epoch 654 
2023-08-07 22:12:39.973556: Current learning rate: 0.0007 
2023-08-07 22:13:43.327500: train_loss -0.3022 
2023-08-07 22:13:43.327662: val_loss -0.3423 
2023-08-07 22:13:43.327715: Pseudo dice [0.7945] 
2023-08-07 22:13:43.327767: Epoch time: 63.35 s 
2023-08-07 22:13:44.367114:  
2023-08-07 22:13:44.367434: Epoch 655 
2023-08-07 22:13:44.367597: Current learning rate: 0.0007 
2023-08-07 22:14:47.808213: train_loss -0.3651 
2023-08-07 22:14:47.808372: val_loss -0.3481 
2023-08-07 22:14:47.808424: Pseudo dice [0.7567] 
2023-08-07 22:14:47.808475: Epoch time: 63.44 s 
2023-08-07 22:14:49.005767:  
2023-08-07 22:14:49.005867: Epoch 656 
2023-08-07 22:14:49.005941: Current learning rate: 0.0007 
2023-08-07 22:15:52.565086: train_loss -0.3691 
2023-08-07 22:15:52.565233: val_loss -0.3147 
2023-08-07 22:15:52.565284: Pseudo dice [0.9094] 
2023-08-07 22:15:52.565349: Epoch time: 63.56 s 
2023-08-07 22:15:53.588459:  
2023-08-07 22:15:53.588564: Epoch 657 
2023-08-07 22:15:53.588640: Current learning rate: 0.0007 
2023-08-07 22:16:56.994070: train_loss -0.3254 
2023-08-07 22:16:56.994330: val_loss -0.4175 
2023-08-07 22:16:56.994388: Pseudo dice [0.8539] 
2023-08-07 22:16:56.994440: Epoch time: 63.41 s 
2023-08-07 22:16:58.049304:  
2023-08-07 22:16:58.049400: Epoch 658 
2023-08-07 22:16:58.049472: Current learning rate: 0.0007 
2023-08-07 22:18:01.625332: train_loss -0.3721 
2023-08-07 22:18:01.625485: val_loss -0.3098 
2023-08-07 22:18:01.633958: Pseudo dice [0.8567] 
2023-08-07 22:18:01.634186: Epoch time: 63.58 s 
2023-08-07 22:18:02.668737:  
2023-08-07 22:18:02.668845: Epoch 659 
2023-08-07 22:18:02.668916: Current learning rate: 0.0007 
2023-08-07 22:19:06.139645: train_loss -0.3282 
2023-08-07 22:19:06.139795: val_loss -0.4538 
2023-08-07 22:19:06.139844: Pseudo dice [0.8463] 
2023-08-07 22:19:06.139894: Epoch time: 63.47 s 
2023-08-07 22:19:07.170583:  
2023-08-07 22:19:07.170880: Epoch 660 
2023-08-07 22:19:07.170971: Current learning rate: 0.0007 
2023-08-07 22:20:10.742490: train_loss -0.364 
2023-08-07 22:20:10.742646: val_loss -0.3895 
2023-08-07 22:20:10.742698: Pseudo dice [0.7877] 
2023-08-07 22:20:10.742749: Epoch time: 63.57 s 
2023-08-07 22:20:11.912676:  
2023-08-07 22:20:11.912799: Epoch 661 
2023-08-07 22:20:11.912871: Current learning rate: 0.0007 
2023-08-07 22:21:15.420659: train_loss -0.3361 
2023-08-07 22:21:15.420822: val_loss -0.3633 
2023-08-07 22:21:15.420873: Pseudo dice [0.7896] 
2023-08-07 22:21:15.420924: Epoch time: 63.51 s 
2023-08-07 22:21:16.443336:  
2023-08-07 22:21:16.443438: Epoch 662 
2023-08-07 22:21:16.443510: Current learning rate: 0.0007 
2023-08-07 22:22:19.854458: train_loss -0.3469 
2023-08-07 22:22:19.854612: val_loss -0.4274 
2023-08-07 22:22:19.854684: Pseudo dice [0.8104] 
2023-08-07 22:22:19.854735: Epoch time: 63.41 s 
2023-08-07 22:22:20.908697:  
2023-08-07 22:22:20.908803: Epoch 663 
2023-08-07 22:22:20.908882: Current learning rate: 0.0007 
2023-08-07 22:23:24.314771: train_loss -0.3338 
2023-08-07 22:23:24.314917: val_loss -0.3313 
2023-08-07 22:23:24.314969: Pseudo dice [0.7937] 
2023-08-07 22:23:24.315018: Epoch time: 63.41 s 
2023-08-07 22:23:25.340648:  
2023-08-07 22:23:25.340745: Epoch 664 
2023-08-07 22:23:25.340816: Current learning rate: 0.0007 
2023-08-07 22:24:28.968626: train_loss -0.3534 
2023-08-07 22:24:28.968774: val_loss -0.3775 
2023-08-07 22:24:28.968827: Pseudo dice [0.7469] 
2023-08-07 22:24:28.968878: Epoch time: 63.63 s 
2023-08-07 22:24:29.991065:  
2023-08-07 22:24:29.991242: Epoch 665 
2023-08-07 22:24:29.991335: Current learning rate: 0.0007 
2023-08-07 22:25:33.405407: train_loss -0.337 
2023-08-07 22:25:33.405574: val_loss -0.337 
2023-08-07 22:25:33.405626: Pseudo dice [0.8048] 
2023-08-07 22:25:33.405677: Epoch time: 63.42 s 
2023-08-07 22:25:34.454834:  
2023-08-07 22:25:34.454928: Epoch 666 
2023-08-07 22:25:34.455000: Current learning rate: 0.00069 
2023-08-07 22:26:37.697101: train_loss -0.3468 
2023-08-07 22:26:37.697252: val_loss -0.3445 
2023-08-07 22:26:37.697304: Pseudo dice [0.7192] 
2023-08-07 22:26:37.697365: Epoch time: 63.24 s 
2023-08-07 22:26:38.932458:  
2023-08-07 22:26:38.932639: Epoch 667 
2023-08-07 22:26:38.932716: Current learning rate: 0.00069 
2023-08-07 22:27:42.414237: train_loss -0.3367 
2023-08-07 22:27:42.414381: val_loss -0.2999 
2023-08-07 22:27:42.414449: Pseudo dice [0.8049] 
2023-08-07 22:27:42.414499: Epoch time: 63.48 s 
2023-08-07 22:27:43.452074:  
2023-08-07 22:27:43.452173: Epoch 668 
2023-08-07 22:27:43.452244: Current learning rate: 0.00069 
2023-08-07 22:28:46.938474: train_loss -0.3784 
2023-08-07 22:28:46.938733: val_loss -0.3494 
2023-08-07 22:28:46.938787: Pseudo dice [0.8328] 
2023-08-07 22:28:46.938837: Epoch time: 63.49 s 
2023-08-07 22:28:47.976477:  
2023-08-07 22:28:47.976573: Epoch 669 
2023-08-07 22:28:47.976661: Current learning rate: 0.00069 
2023-08-07 22:29:51.529475: train_loss -0.3402 
2023-08-07 22:29:51.529629: val_loss -0.3491 
2023-08-07 22:29:51.529697: Pseudo dice [0.7877] 
2023-08-07 22:29:51.529747: Epoch time: 63.55 s 
2023-08-07 22:29:52.584977:  
2023-08-07 22:29:52.585088: Epoch 670 
2023-08-07 22:29:52.585160: Current learning rate: 0.00069 
2023-08-07 22:30:56.062659: train_loss -0.3952 
2023-08-07 22:30:56.062810: val_loss -0.4219 
2023-08-07 22:30:56.062863: Pseudo dice [0.8583] 
2023-08-07 22:30:56.062914: Epoch time: 63.48 s 
2023-08-07 22:30:57.101265:  
2023-08-07 22:30:57.101359: Epoch 671 
2023-08-07 22:30:57.101448: Current learning rate: 0.00069 
2023-08-07 22:32:00.651621: train_loss -0.3339 
2023-08-07 22:32:00.651793: val_loss -0.3714 
2023-08-07 22:32:00.651851: Pseudo dice [0.7667] 
2023-08-07 22:32:00.651906: Epoch time: 63.55 s 
2023-08-07 22:32:01.844879:  
2023-08-07 22:32:01.844988: Epoch 672 
2023-08-07 22:32:01.845061: Current learning rate: 0.00069 
2023-08-07 22:33:05.333200: train_loss -0.3213 
2023-08-07 22:33:05.333338: val_loss -0.3494 
2023-08-07 22:33:05.333388: Pseudo dice [0.8545] 
2023-08-07 22:33:05.333454: Epoch time: 63.49 s 
2023-08-07 22:33:06.440722:  
2023-08-07 22:33:06.440895: Epoch 673 
2023-08-07 22:33:06.440987: Current learning rate: 0.00069 
2023-08-07 22:34:10.108649: train_loss -0.3534 
2023-08-07 22:34:10.108802: val_loss -0.4173 
2023-08-07 22:34:10.108852: Pseudo dice [0.8983] 
2023-08-07 22:34:10.108903: Epoch time: 63.67 s 
2023-08-07 22:34:11.143415:  
2023-08-07 22:34:11.143510: Epoch 674 
2023-08-07 22:34:11.143620: Current learning rate: 0.00069 
2023-08-07 22:35:14.648038: train_loss -0.3416 
2023-08-07 22:35:14.648417: val_loss -0.3874 
2023-08-07 22:35:14.648573: Pseudo dice [0.7882] 
2023-08-07 22:35:14.648708: Epoch time: 63.51 s 
2023-08-07 22:35:15.755020:  
2023-08-07 22:35:15.755219: Epoch 675 
2023-08-07 22:35:15.755293: Current learning rate: 0.00069 
2023-08-07 22:36:19.175660: train_loss -0.3571 
2023-08-07 22:36:19.175812: val_loss -0.3983 
2023-08-07 22:36:19.175864: Pseudo dice [0.8837] 
2023-08-07 22:36:19.175916: Epoch time: 63.42 s 
2023-08-07 22:36:20.234658:  
2023-08-07 22:36:20.234883: Epoch 676 
2023-08-07 22:36:20.234959: Current learning rate: 0.00069 
2023-08-07 22:37:23.666061: train_loss -0.3214 
2023-08-07 22:37:23.666211: val_loss -0.3062 
2023-08-07 22:37:23.666263: Pseudo dice [0.7351] 
2023-08-07 22:37:23.666315: Epoch time: 63.43 s 
2023-08-07 22:37:24.727577:  
2023-08-07 22:37:24.727683: Epoch 677 
2023-08-07 22:37:24.727758: Current learning rate: 0.00069 
2023-08-07 22:38:28.089215: train_loss -0.3459 
2023-08-07 22:38:28.089372: val_loss -0.2965 
2023-08-07 22:38:28.089421: Pseudo dice [0.7872] 
2023-08-07 22:38:28.089486: Epoch time: 63.36 s 
2023-08-07 22:38:29.303353:  
2023-08-07 22:38:29.303457: Epoch 678 
2023-08-07 22:38:29.303548: Current learning rate: 0.00069 
2023-08-07 22:39:32.717768: train_loss -0.3403 
2023-08-07 22:39:32.717921: val_loss -0.3224 
2023-08-07 22:39:32.717969: Pseudo dice [0.8124] 
2023-08-07 22:39:32.718035: Epoch time: 63.42 s 
2023-08-07 22:39:33.756629:  
2023-08-07 22:39:33.756810: Epoch 679 
2023-08-07 22:39:33.756886: Current learning rate: 0.00069 
2023-08-07 22:40:37.212415: train_loss -0.3304 
2023-08-07 22:40:37.212577: val_loss -0.332 
2023-08-07 22:40:37.212630: Pseudo dice [0.8561] 
2023-08-07 22:40:37.212682: Epoch time: 63.46 s 
2023-08-07 22:40:38.253166:  
2023-08-07 22:40:38.253274: Epoch 680 
2023-08-07 22:40:38.253347: Current learning rate: 0.00069 
2023-08-07 22:41:41.423950: train_loss -0.3508 
2023-08-07 22:41:41.424130: val_loss -0.2584 
2023-08-07 22:41:41.424183: Pseudo dice [0.705] 
2023-08-07 22:41:41.424232: Epoch time: 63.17 s 
2023-08-07 22:41:42.455967:  
2023-08-07 22:41:42.456068: Epoch 681 
2023-08-07 22:41:42.456160: Current learning rate: 0.00069 
2023-08-07 22:42:45.884791: train_loss -0.3055 
2023-08-07 22:42:45.884946: val_loss -0.2964 
2023-08-07 22:42:45.885012: Pseudo dice [0.841] 
2023-08-07 22:42:45.885062: Epoch time: 63.43 s 
2023-08-07 22:42:46.919326:  
2023-08-07 22:42:46.919422: Epoch 682 
2023-08-07 22:42:46.919514: Current learning rate: 0.00069 
2023-08-07 22:43:50.259163: train_loss -0.33 
2023-08-07 22:43:50.259313: val_loss -0.3208 
2023-08-07 22:43:50.259382: Pseudo dice [0.7254] 
2023-08-07 22:43:50.259433: Epoch time: 63.34 s 
2023-08-07 22:43:51.452007:  
2023-08-07 22:43:51.452333: Epoch 683 
2023-08-07 22:43:51.452468: Current learning rate: 0.00069 
2023-08-07 22:44:55.057739: train_loss -0.3769 
2023-08-07 22:44:55.057890: val_loss -0.3813 
2023-08-07 22:44:55.057945: Pseudo dice [0.7903] 
2023-08-07 22:44:55.057996: Epoch time: 63.61 s 
2023-08-07 22:44:56.111795:  
2023-08-07 22:44:56.111954: Epoch 684 
2023-08-07 22:44:56.112084: Current learning rate: 0.00069 
2023-08-07 22:45:59.449628: train_loss -0.3249 
2023-08-07 22:45:59.449788: val_loss -0.3559 
2023-08-07 22:45:59.449841: Pseudo dice [0.8283] 
2023-08-07 22:45:59.449892: Epoch time: 63.34 s 
2023-08-07 22:46:00.491728:  
2023-08-07 22:46:00.491823: Epoch 685 
2023-08-07 22:46:00.491913: Current learning rate: 0.00069 
2023-08-07 22:47:03.884799: train_loss -0.3631 
2023-08-07 22:47:03.884959: val_loss -0.4192 
2023-08-07 22:47:03.885012: Pseudo dice [0.7865] 
2023-08-07 22:47:03.885063: Epoch time: 63.39 s 
2023-08-07 22:47:04.920995:  
2023-08-07 22:47:04.921091: Epoch 686 
2023-08-07 22:47:04.921166: Current learning rate: 0.00069 
2023-08-07 22:48:08.479786: train_loss -0.3514 
2023-08-07 22:48:08.479937: val_loss -0.3329 
2023-08-07 22:48:08.479989: Pseudo dice [0.7924] 
2023-08-07 22:48:08.480038: Epoch time: 63.56 s 
2023-08-07 22:48:09.520739:  
2023-08-07 22:48:09.521002: Epoch 687 
2023-08-07 22:48:09.521143: Current learning rate: 0.00068 
2023-08-07 22:49:12.980418: train_loss -0.3217 
2023-08-07 22:49:12.980562: val_loss -0.2669 
2023-08-07 22:49:12.980614: Pseudo dice [0.7894] 
2023-08-07 22:49:12.980664: Epoch time: 63.46 s 
2023-08-07 22:49:14.020051:  
2023-08-07 22:49:14.020351: Epoch 688 
2023-08-07 22:49:14.020429: Current learning rate: 0.00068 
2023-08-07 22:50:17.253604: train_loss -0.3571 
2023-08-07 22:50:17.253754: val_loss -0.4095 
2023-08-07 22:50:17.253806: Pseudo dice [0.8725] 
2023-08-07 22:50:17.253856: Epoch time: 63.23 s 
2023-08-07 22:50:18.458251:  
2023-08-07 22:50:18.458352: Epoch 689 
2023-08-07 22:50:18.458426: Current learning rate: 0.00068 
2023-08-07 22:51:21.819354: train_loss -0.3322 
2023-08-07 22:51:21.819506: val_loss -0.3667 
2023-08-07 22:51:21.819574: Pseudo dice [0.797] 
2023-08-07 22:51:21.819643: Epoch time: 63.36 s 
2023-08-07 22:51:22.889655:  
2023-08-07 22:51:22.889748: Epoch 690 
2023-08-07 22:51:22.889839: Current learning rate: 0.00068 
2023-08-07 22:52:26.160259: train_loss -0.3258 
2023-08-07 22:52:26.160414: val_loss -0.4045 
2023-08-07 22:52:26.160464: Pseudo dice [0.8175] 
2023-08-07 22:52:26.160515: Epoch time: 63.27 s 
2023-08-07 22:52:27.261670:  
2023-08-07 22:52:27.261916: Epoch 691 
2023-08-07 22:52:27.262078: Current learning rate: 0.00068 
2023-08-07 22:53:30.488342: train_loss -0.3383 
2023-08-07 22:53:30.488492: val_loss -0.381 
2023-08-07 22:53:30.488543: Pseudo dice [0.771] 
2023-08-07 22:53:30.488593: Epoch time: 63.23 s 
2023-08-07 22:53:31.527503:  
2023-08-07 22:53:31.527782: Epoch 692 
2023-08-07 22:53:31.527951: Current learning rate: 0.00068 
2023-08-07 22:54:34.936104: train_loss -0.3356 
2023-08-07 22:54:34.936257: val_loss -0.3184 
2023-08-07 22:54:34.936308: Pseudo dice [0.7616] 
2023-08-07 22:54:34.936359: Epoch time: 63.41 s 
2023-08-07 22:54:36.022328:  
2023-08-07 22:54:36.022424: Epoch 693 
2023-08-07 22:54:36.022495: Current learning rate: 0.00068 
2023-08-07 22:55:39.427403: train_loss -0.3642 
2023-08-07 22:55:39.427560: val_loss -0.3149 
2023-08-07 22:55:39.427631: Pseudo dice [0.7839] 
2023-08-07 22:55:39.427680: Epoch time: 63.41 s 
2023-08-07 22:55:40.611745:  
2023-08-07 22:55:40.612082: Epoch 694 
2023-08-07 22:55:40.612160: Current learning rate: 0.00068 
2023-08-07 22:56:44.082985: train_loss -0.362 
2023-08-07 22:56:44.083145: val_loss -0.3177 
2023-08-07 22:56:44.083205: Pseudo dice [0.7631] 
2023-08-07 22:56:44.083255: Epoch time: 63.47 s 
2023-08-07 22:56:45.119279:  
2023-08-07 22:56:45.119487: Epoch 695 
2023-08-07 22:56:45.119586: Current learning rate: 0.00068 
2023-08-07 22:57:48.838873: train_loss -0.3277 
2023-08-07 22:57:48.839023: val_loss -0.3423 
2023-08-07 22:57:48.839073: Pseudo dice [0.764] 
2023-08-07 22:57:48.839122: Epoch time: 63.72 s 
2023-08-07 22:57:49.882642:  
2023-08-07 22:57:49.882754: Epoch 696 
2023-08-07 22:57:49.882829: Current learning rate: 0.00068 
2023-08-07 22:58:53.246039: train_loss -0.3334 
2023-08-07 22:58:53.246192: val_loss -0.2751 
2023-08-07 22:58:53.246243: Pseudo dice [0.7999] 
2023-08-07 22:58:53.246293: Epoch time: 63.36 s 
2023-08-07 22:58:54.289195:  
2023-08-07 22:58:54.289403: Epoch 697 
2023-08-07 22:58:54.289498: Current learning rate: 0.00068 
2023-08-07 22:59:57.821459: train_loss -0.3218 
2023-08-07 22:59:57.821609: val_loss -0.2707 
2023-08-07 22:59:57.821676: Pseudo dice [0.7418] 
2023-08-07 22:59:57.821727: Epoch time: 63.53 s 
2023-08-07 22:59:58.868551:  
2023-08-07 22:59:58.868873: Epoch 698 
2023-08-07 22:59:58.868969: Current learning rate: 0.00068 
2023-08-07 23:01:02.207393: train_loss -0.3668 
2023-08-07 23:01:02.207550: val_loss -0.4402 
2023-08-07 23:01:02.207631: Pseudo dice [0.8768] 
2023-08-07 23:01:02.207683: Epoch time: 63.34 s 
2023-08-07 23:01:03.244038:  
2023-08-07 23:01:03.244132: Epoch 699 
2023-08-07 23:01:03.244205: Current learning rate: 0.00068 
2023-08-07 23:02:06.764781: train_loss -0.3559 
2023-08-07 23:02:06.764926: val_loss -0.4266 
2023-08-07 23:02:06.764975: Pseudo dice [0.8946] 
2023-08-07 23:02:06.765040: Epoch time: 63.52 s 
2023-08-07 23:02:08.382709:  
2023-08-07 23:02:08.382807: Epoch 700 
2023-08-07 23:02:08.382880: Current learning rate: 0.00068 
2023-08-07 23:03:11.834915: train_loss -0.3348 
2023-08-07 23:03:11.835067: val_loss -0.4826 
2023-08-07 23:03:11.835116: Pseudo dice [0.8994] 
2023-08-07 23:03:11.835182: Epoch time: 63.45 s 
2023-08-07 23:03:12.879249:  
2023-08-07 23:03:12.879477: Epoch 701 
2023-08-07 23:03:12.879600: Current learning rate: 0.00068 
2023-08-07 23:04:16.313584: train_loss -0.3837 
2023-08-07 23:04:16.313736: val_loss -0.3974 
2023-08-07 23:04:16.313789: Pseudo dice [0.8971] 
2023-08-07 23:04:16.313855: Epoch time: 63.44 s 
2023-08-07 23:04:17.358414:  
2023-08-07 23:04:17.358538: Epoch 702 
2023-08-07 23:04:17.358674: Current learning rate: 0.00068 
2023-08-07 23:05:20.788049: train_loss -0.299 
2023-08-07 23:05:20.788194: val_loss -0.3518 
2023-08-07 23:05:20.788243: Pseudo dice [0.8223] 
2023-08-07 23:05:20.788293: Epoch time: 63.43 s 
2023-08-07 23:05:21.829748:  
2023-08-07 23:05:21.829926: Epoch 703 
2023-08-07 23:05:21.830043: Current learning rate: 0.00068 
2023-08-07 23:06:25.294151: train_loss -0.3288 
2023-08-07 23:06:25.294304: val_loss -0.3182 
2023-08-07 23:06:25.294357: Pseudo dice [0.8075] 
2023-08-07 23:06:25.294407: Epoch time: 63.47 s 
2023-08-07 23:06:26.354281:  
2023-08-07 23:06:26.354379: Epoch 704 
2023-08-07 23:06:26.354452: Current learning rate: 0.00068 
2023-08-07 23:07:29.755299: train_loss -0.3198 
2023-08-07 23:07:29.755444: val_loss -0.4246 
2023-08-07 23:07:29.755497: Pseudo dice [0.8878] 
2023-08-07 23:07:29.755548: Epoch time: 63.4 s 
2023-08-07 23:07:30.951932:  
2023-08-07 23:07:30.952210: Epoch 705 
2023-08-07 23:07:30.952390: Current learning rate: 0.00068 
2023-08-07 23:08:34.518378: train_loss -0.3743 
2023-08-07 23:08:34.518530: val_loss -0.3759 
2023-08-07 23:08:34.518579: Pseudo dice [0.8134] 
2023-08-07 23:08:34.518629: Epoch time: 63.57 s 
2023-08-07 23:08:35.557763:  
2023-08-07 23:08:35.557862: Epoch 706 
2023-08-07 23:08:35.557934: Current learning rate: 0.00068 
2023-08-07 23:09:39.057322: train_loss -0.3578 
2023-08-07 23:09:39.057487: val_loss -0.391 
2023-08-07 23:09:39.057536: Pseudo dice [0.8729] 
2023-08-07 23:09:39.057587: Epoch time: 63.5 s 
2023-08-07 23:09:39.057626: Yayy! New best EMA pseudo Dice: 0.8313 
2023-08-07 23:09:40.453396:  
2023-08-07 23:09:40.453651: Epoch 707 
2023-08-07 23:09:40.453727: Current learning rate: 0.00068 
2023-08-07 23:10:44.004723: train_loss -0.3646 
2023-08-07 23:10:44.004903: val_loss -0.3296 
2023-08-07 23:10:44.004956: Pseudo dice [0.8562] 
2023-08-07 23:10:44.005007: Epoch time: 63.55 s 
2023-08-07 23:10:44.005047: Yayy! New best EMA pseudo Dice: 0.8338 
2023-08-07 23:10:45.455985:  
2023-08-07 23:10:45.456091: Epoch 708 
2023-08-07 23:10:45.456165: Current learning rate: 0.00067 
2023-08-07 23:11:48.686934: train_loss -0.3732 
2023-08-07 23:11:48.687080: val_loss -0.3686 
2023-08-07 23:11:48.687129: Pseudo dice [0.8394] 
2023-08-07 23:11:48.687195: Epoch time: 63.23 s 
2023-08-07 23:11:48.687236: Yayy! New best EMA pseudo Dice: 0.8343 
2023-08-07 23:11:50.118147:  
2023-08-07 23:11:50.118246: Epoch 709 
2023-08-07 23:11:50.118316: Current learning rate: 0.00067 
2023-08-07 23:12:53.620911: train_loss -0.3438 
2023-08-07 23:12:53.621158: val_loss -0.2924 
2023-08-07 23:12:53.621209: Pseudo dice [0.7693] 
2023-08-07 23:12:53.621260: Epoch time: 63.5 s 
2023-08-07 23:12:54.815549:  
2023-08-07 23:12:54.815771: Epoch 710 
2023-08-07 23:12:54.815850: Current learning rate: 0.00067 
2023-08-07 23:13:58.435963: train_loss -0.3751 
2023-08-07 23:13:58.436118: val_loss -0.3269 
2023-08-07 23:13:58.436170: Pseudo dice [0.7566] 
2023-08-07 23:13:58.436220: Epoch time: 63.62 s 
2023-08-07 23:13:59.490031:  
2023-08-07 23:13:59.490158: Epoch 711 
2023-08-07 23:13:59.490235: Current learning rate: 0.00067 
2023-08-07 23:15:03.096545: train_loss -0.309 
2023-08-07 23:15:03.096695: val_loss -0.3489 
2023-08-07 23:15:03.096745: Pseudo dice [0.8144] 
2023-08-07 23:15:03.096797: Epoch time: 63.61 s 
2023-08-07 23:15:04.135946:  
2023-08-07 23:15:04.136040: Epoch 712 
2023-08-07 23:15:04.136113: Current learning rate: 0.00067 
2023-08-07 23:16:07.456514: train_loss -0.3347 
2023-08-07 23:16:07.456668: val_loss -0.3474 
2023-08-07 23:16:07.456720: Pseudo dice [0.777] 
2023-08-07 23:16:07.456769: Epoch time: 63.32 s 
2023-08-07 23:16:08.553196:  
2023-08-07 23:16:08.553292: Epoch 713 
2023-08-07 23:16:08.553365: Current learning rate: 0.00067 
2023-08-07 23:17:12.075444: train_loss -0.3634 
2023-08-07 23:17:12.075656: val_loss -0.3698 
2023-08-07 23:17:12.075714: Pseudo dice [0.8001] 
2023-08-07 23:17:12.075766: Epoch time: 63.52 s 
2023-08-07 23:17:13.121226:  
2023-08-07 23:17:13.121321: Epoch 714 
2023-08-07 23:17:13.121394: Current learning rate: 0.00067 
2023-08-07 23:18:16.529262: train_loss -0.3715 
2023-08-07 23:18:16.529411: val_loss -0.3088 
2023-08-07 23:18:16.529462: Pseudo dice [0.8332] 
2023-08-07 23:18:16.529511: Epoch time: 63.41 s 
2023-08-07 23:18:17.759304:  
2023-08-07 23:18:17.759405: Epoch 715 
2023-08-07 23:18:17.759582: Current learning rate: 0.00067 
2023-08-07 23:19:21.102819: train_loss -0.359 
2023-08-07 23:19:21.102981: val_loss -0.3441 
2023-08-07 23:19:21.103032: Pseudo dice [0.7968] 
2023-08-07 23:19:21.103084: Epoch time: 63.34 s 
2023-08-07 23:19:22.185668:  
2023-08-07 23:19:22.185761: Epoch 716 
2023-08-07 23:19:22.185833: Current learning rate: 0.00067 
2023-08-07 23:20:25.771123: train_loss -0.3687 
2023-08-07 23:20:25.771281: val_loss -0.3504 
2023-08-07 23:20:25.771334: Pseudo dice [0.836] 
2023-08-07 23:20:25.771386: Epoch time: 63.59 s 
2023-08-07 23:20:26.814489:  
2023-08-07 23:20:26.814595: Epoch 717 
2023-08-07 23:20:26.814688: Current learning rate: 0.00067 
2023-08-07 23:21:30.213419: train_loss -0.3367 
2023-08-07 23:21:30.213571: val_loss -0.3676 
2023-08-07 23:21:30.213623: Pseudo dice [0.7438] 
2023-08-07 23:21:30.213673: Epoch time: 63.4 s 
2023-08-07 23:21:31.257477:  
2023-08-07 23:21:31.257573: Epoch 718 
2023-08-07 23:21:31.257645: Current learning rate: 0.00067 
2023-08-07 23:22:34.741732: train_loss -0.341 
2023-08-07 23:22:34.741883: val_loss -0.3361 
2023-08-07 23:22:34.741933: Pseudo dice [0.89] 
2023-08-07 23:22:34.741999: Epoch time: 63.48 s 
2023-08-07 23:22:35.874667:  
2023-08-07 23:22:35.874762: Epoch 719 
2023-08-07 23:22:35.874874: Current learning rate: 0.00067 
2023-08-07 23:23:39.367072: train_loss -0.3699 
2023-08-07 23:23:39.367227: val_loss -0.3524 
2023-08-07 23:23:39.367279: Pseudo dice [0.8254] 
2023-08-07 23:23:39.367348: Epoch time: 63.49 s 
2023-08-07 23:23:40.576502:  
2023-08-07 23:23:40.576677: Epoch 720 
2023-08-07 23:23:40.576767: Current learning rate: 0.00067 
2023-08-07 23:24:44.009324: train_loss -0.3275 
2023-08-07 23:24:44.009468: val_loss -0.4222 
2023-08-07 23:24:44.009537: Pseudo dice [0.7835] 
2023-08-07 23:24:44.009586: Epoch time: 63.43 s 
2023-08-07 23:24:45.054469:  
2023-08-07 23:24:45.054646: Epoch 721 
2023-08-07 23:24:45.054736: Current learning rate: 0.00067 
2023-08-07 23:25:48.680368: train_loss -0.3281 
2023-08-07 23:25:48.680519: val_loss -0.3174 
2023-08-07 23:25:48.680574: Pseudo dice [0.7564] 
2023-08-07 23:25:48.680624: Epoch time: 63.63 s 
2023-08-07 23:25:49.728706:  
2023-08-07 23:25:49.728806: Epoch 722 
2023-08-07 23:25:49.728923: Current learning rate: 0.00067 
2023-08-07 23:26:53.231240: train_loss -0.3407 
2023-08-07 23:26:53.231391: val_loss -0.3449 
2023-08-07 23:26:53.231444: Pseudo dice [0.8473] 
2023-08-07 23:26:53.231510: Epoch time: 63.5 s 
2023-08-07 23:26:54.273630:  
2023-08-07 23:26:54.273726: Epoch 723 
2023-08-07 23:26:54.273797: Current learning rate: 0.00067 
2023-08-07 23:27:57.743582: train_loss -0.3795 
2023-08-07 23:27:57.743740: val_loss -0.4571 
2023-08-07 23:27:57.743791: Pseudo dice [0.8994] 
2023-08-07 23:27:57.743841: Epoch time: 63.47 s 
2023-08-07 23:27:58.784187:  
2023-08-07 23:27:58.784286: Epoch 724 
2023-08-07 23:27:58.784359: Current learning rate: 0.00067 
2023-08-07 23:29:02.044916: train_loss -0.345 
2023-08-07 23:29:02.045063: val_loss -0.395 
2023-08-07 23:29:02.045111: Pseudo dice [0.8106] 
2023-08-07 23:29:02.045178: Epoch time: 63.26 s 
2023-08-07 23:29:03.230803:  
2023-08-07 23:29:03.231006: Epoch 725 
2023-08-07 23:29:03.231117: Current learning rate: 0.00067 
2023-08-07 23:30:06.877710: train_loss -0.3178 
2023-08-07 23:30:06.877869: val_loss -0.3398 
2023-08-07 23:30:06.877932: Pseudo dice [0.8034] 
2023-08-07 23:30:06.877984: Epoch time: 63.65 s 
2023-08-07 23:30:07.917306:  
2023-08-07 23:30:07.917478: Epoch 726 
2023-08-07 23:30:07.917552: Current learning rate: 0.00067 
2023-08-07 23:31:11.404899: train_loss -0.3873 
2023-08-07 23:31:11.405180: val_loss -0.3616 
2023-08-07 23:31:11.405319: Pseudo dice [0.7758] 
2023-08-07 23:31:11.405469: Epoch time: 63.49 s 
2023-08-07 23:31:12.470592:  
2023-08-07 23:31:12.470820: Epoch 727 
2023-08-07 23:31:12.470899: Current learning rate: 0.00067 
2023-08-07 23:32:15.881639: train_loss -0.3752 
2023-08-07 23:32:15.881807: val_loss -0.3592 
2023-08-07 23:32:15.881885: Pseudo dice [0.8501] 
2023-08-07 23:32:15.881935: Epoch time: 63.41 s 
2023-08-07 23:32:16.959483:  
2023-08-07 23:32:16.959585: Epoch 728 
2023-08-07 23:32:16.959675: Current learning rate: 0.00067 
2023-08-07 23:33:20.490636: train_loss -0.3849 
2023-08-07 23:33:20.490781: val_loss -0.2363 
2023-08-07 23:33:20.490837: Pseudo dice [0.7057] 
2023-08-07 23:33:20.490889: Epoch time: 63.53 s 
2023-08-07 23:33:21.564396:  
2023-08-07 23:33:21.564493: Epoch 729 
2023-08-07 23:33:21.564584: Current learning rate: 0.00066 
2023-08-07 23:34:24.931918: train_loss -0.3416 
2023-08-07 23:34:24.932068: val_loss -0.3506 
2023-08-07 23:34:24.932119: Pseudo dice [0.8164] 
2023-08-07 23:34:24.932178: Epoch time: 63.37 s 
2023-08-07 23:34:26.156278:  
2023-08-07 23:34:26.156469: Epoch 730 
2023-08-07 23:34:26.156564: Current learning rate: 0.00066 
2023-08-07 23:35:29.643268: train_loss -0.3472 
2023-08-07 23:35:29.643414: val_loss -0.4168 
2023-08-07 23:35:29.643480: Pseudo dice [0.8725] 
2023-08-07 23:35:29.643531: Epoch time: 63.49 s 
2023-08-07 23:35:30.697223:  
2023-08-07 23:35:30.697392: Epoch 731 
2023-08-07 23:35:30.697471: Current learning rate: 0.00066 
2023-08-07 23:36:34.120693: train_loss -0.3291 
2023-08-07 23:36:34.120851: val_loss -0.3997 
2023-08-07 23:36:34.120903: Pseudo dice [0.8438] 
2023-08-07 23:36:34.120953: Epoch time: 63.42 s 
2023-08-07 23:36:35.169446:  
2023-08-07 23:36:35.169545: Epoch 732 
2023-08-07 23:36:35.169615: Current learning rate: 0.00066 
2023-08-07 23:37:38.504351: train_loss -0.3288 
2023-08-07 23:37:38.504504: val_loss -0.3214 
2023-08-07 23:37:38.504557: Pseudo dice [0.7552] 
2023-08-07 23:37:38.504608: Epoch time: 63.34 s 
2023-08-07 23:37:39.554181:  
2023-08-07 23:37:39.554275: Epoch 733 
2023-08-07 23:37:39.554365: Current learning rate: 0.00066 
2023-08-07 23:38:43.067309: train_loss -0.3552 
2023-08-07 23:38:43.067460: val_loss -0.4626 
2023-08-07 23:38:43.067527: Pseudo dice [0.8649] 
2023-08-07 23:38:43.067588: Epoch time: 63.51 s 
2023-08-07 23:38:44.117967:  
2023-08-07 23:38:44.118063: Epoch 734 
2023-08-07 23:38:44.118152: Current learning rate: 0.00066 
2023-08-07 23:39:47.433289: train_loss -0.3639 
2023-08-07 23:39:47.433434: val_loss -0.3498 
2023-08-07 23:39:47.433484: Pseudo dice [0.8695] 
2023-08-07 23:39:47.433550: Epoch time: 63.32 s 
2023-08-07 23:39:48.492411:  
2023-08-07 23:39:48.492503: Epoch 735 
2023-08-07 23:39:48.492576: Current learning rate: 0.00066 
2023-08-07 23:40:52.003242: train_loss -0.3612 
2023-08-07 23:40:52.003413: val_loss -0.3687 
2023-08-07 23:40:52.003465: Pseudo dice [0.7704] 
2023-08-07 23:40:52.003515: Epoch time: 63.51 s 
2023-08-07 23:40:53.275035:  
2023-08-07 23:40:53.275150: Epoch 736 
2023-08-07 23:40:53.275240: Current learning rate: 0.00066 
2023-08-07 23:41:56.597941: train_loss -0.3248 
2023-08-07 23:41:56.598089: val_loss -0.4245 
2023-08-07 23:41:56.598141: Pseudo dice [0.8569] 
2023-08-07 23:41:56.598211: Epoch time: 63.32 s 
2023-08-07 23:41:57.647022:  
2023-08-07 23:41:57.647121: Epoch 737 
2023-08-07 23:41:57.647210: Current learning rate: 0.00066 
2023-08-07 23:43:01.111757: train_loss -0.3167 
2023-08-07 23:43:01.111907: val_loss -0.4204 
2023-08-07 23:43:01.111959: Pseudo dice [0.8137] 
2023-08-07 23:43:01.112009: Epoch time: 63.47 s 
2023-08-07 23:43:02.160499:  
2023-08-07 23:43:02.160823: Epoch 738 
2023-08-07 23:43:02.160901: Current learning rate: 0.00066 
2023-08-07 23:44:05.633248: train_loss -0.3473 
2023-08-07 23:44:05.633394: val_loss -0.4003 
2023-08-07 23:44:05.633447: Pseudo dice [0.8655] 
2023-08-07 23:44:05.633518: Epoch time: 63.47 s 
2023-08-07 23:44:06.674623:  
2023-08-07 23:44:06.674770: Epoch 739 
2023-08-07 23:44:06.674927: Current learning rate: 0.00066 
2023-08-07 23:45:10.093831: train_loss -0.3796 
2023-08-07 23:45:10.093977: val_loss -0.3426 
2023-08-07 23:45:10.094026: Pseudo dice [0.7917] 
2023-08-07 23:45:10.094093: Epoch time: 63.42 s 
2023-08-07 23:45:11.174427:  
2023-08-07 23:45:11.174520: Epoch 740 
2023-08-07 23:45:11.174609: Current learning rate: 0.00066 
2023-08-07 23:46:14.681229: train_loss -0.3848 
2023-08-07 23:46:14.681387: val_loss -0.3962 
2023-08-07 23:46:14.681441: Pseudo dice [0.8536] 
2023-08-07 23:46:14.681493: Epoch time: 63.51 s 
2023-08-07 23:46:15.881442:  
2023-08-07 23:46:15.881541: Epoch 741 
2023-08-07 23:46:15.881630: Current learning rate: 0.00066 
2023-08-07 23:47:19.359398: train_loss -0.3405 
2023-08-07 23:47:19.359543: val_loss -0.3601 
2023-08-07 23:47:19.359624: Pseudo dice [0.8291] 
2023-08-07 23:47:19.359675: Epoch time: 63.48 s 
2023-08-07 23:47:20.429563:  
2023-08-07 23:47:20.429762: Epoch 742 
2023-08-07 23:47:20.429852: Current learning rate: 0.00066 
2023-08-07 23:48:23.793134: train_loss -0.3746 
2023-08-07 23:48:23.793304: val_loss -0.4275 
2023-08-07 23:48:23.801773: Pseudo dice [0.8108] 
2023-08-07 23:48:23.801883: Epoch time: 63.36 s 
2023-08-07 23:48:24.858696:  
2023-08-07 23:48:24.858794: Epoch 743 
2023-08-07 23:48:24.858865: Current learning rate: 0.00066 
2023-08-07 23:49:28.362173: train_loss -0.3445 
2023-08-07 23:49:28.362427: val_loss -0.3288 
2023-08-07 23:49:28.362484: Pseudo dice [0.7917] 
2023-08-07 23:49:28.362537: Epoch time: 63.5 s 
2023-08-07 23:49:29.418174:  
2023-08-07 23:49:29.418272: Epoch 744 
2023-08-07 23:49:29.418346: Current learning rate: 0.00066 
2023-08-07 23:50:32.893883: train_loss -0.3551 
2023-08-07 23:50:32.894033: val_loss -0.4093 
2023-08-07 23:50:32.894083: Pseudo dice [0.772] 
2023-08-07 23:50:32.894148: Epoch time: 63.48 s 
2023-08-07 23:50:33.935974:  
2023-08-07 23:50:33.936071: Epoch 745 
2023-08-07 23:50:33.936145: Current learning rate: 0.00066 
2023-08-07 23:51:37.438362: train_loss -0.3204 
2023-08-07 23:51:37.438515: val_loss -0.3395 
2023-08-07 23:51:37.438577: Pseudo dice [0.7935] 
2023-08-07 23:51:37.438643: Epoch time: 63.5 s 
2023-08-07 23:51:38.678117:  
2023-08-07 23:51:38.678222: Epoch 746 
2023-08-07 23:51:38.678294: Current learning rate: 0.00066 
2023-08-07 23:52:42.156031: train_loss -0.3181 
2023-08-07 23:52:42.156185: val_loss -0.4233 
2023-08-07 23:52:42.156240: Pseudo dice [0.8081] 
2023-08-07 23:52:42.156290: Epoch time: 63.48 s 
2023-08-07 23:52:43.201949:  
2023-08-07 23:52:43.202046: Epoch 747 
2023-08-07 23:52:43.202121: Current learning rate: 0.00066 
2023-08-07 23:53:46.638154: train_loss -0.341 
2023-08-07 23:53:46.638304: val_loss -0.3883 
2023-08-07 23:53:46.638357: Pseudo dice [0.7929] 
2023-08-07 23:53:46.638408: Epoch time: 63.44 s 
2023-08-07 23:53:47.686077:  
2023-08-07 23:53:47.686172: Epoch 748 
2023-08-07 23:53:47.686261: Current learning rate: 0.00066 
2023-08-07 23:54:51.078232: train_loss -0.3564 
2023-08-07 23:54:51.078396: val_loss -0.3971 
2023-08-07 23:54:51.078464: Pseudo dice [0.7458] 
2023-08-07 23:54:51.078515: Epoch time: 63.39 s 
2023-08-07 23:54:52.119854:  
2023-08-07 23:54:52.120069: Epoch 749 
2023-08-07 23:54:52.120162: Current learning rate: 0.00066 
2023-08-07 23:55:55.445768: train_loss -0.3563 
2023-08-07 23:55:55.445923: val_loss -0.3443 
2023-08-07 23:55:55.445992: Pseudo dice [0.8551] 
2023-08-07 23:55:55.446040: Epoch time: 63.33 s 
2023-08-07 23:55:56.874139:  
2023-08-07 23:55:56.874319: Epoch 750 
2023-08-07 23:55:56.874429: Current learning rate: 0.00066 
2023-08-07 23:57:00.468644: train_loss -0.3568 
2023-08-07 23:57:00.468799: val_loss -0.4282 
2023-08-07 23:57:00.468850: Pseudo dice [0.8628] 
2023-08-07 23:57:00.468901: Epoch time: 63.6 s 
2023-08-07 23:57:01.569567:  
2023-08-07 23:57:01.569662: Epoch 751 
2023-08-07 23:57:01.569732: Current learning rate: 0.00065 
2023-08-07 23:58:05.252099: train_loss -0.343 
2023-08-07 23:58:05.252251: val_loss -0.372 
2023-08-07 23:58:05.252307: Pseudo dice [0.8121] 
2023-08-07 23:58:05.252357: Epoch time: 63.68 s 
2023-08-07 23:58:06.295928:  
2023-08-07 23:58:06.296137: Epoch 752 
2023-08-07 23:58:06.296232: Current learning rate: 0.00065 
2023-08-07 23:59:09.797632: train_loss -0.3249 
2023-08-07 23:59:09.797788: val_loss -0.4232 
2023-08-07 23:59:09.797842: Pseudo dice [0.7278] 
2023-08-07 23:59:09.797892: Epoch time: 63.5 s 
2023-08-07 23:59:10.849131:  
2023-08-07 23:59:10.849360: Epoch 753 
2023-08-07 23:59:10.849437: Current learning rate: 0.00065 
2023-08-08 00:00:14.381881: train_loss -0.3102 
2023-08-08 00:00:14.382034: val_loss -0.4264 
2023-08-08 00:00:14.382086: Pseudo dice [0.8783] 
2023-08-08 00:00:14.382137: Epoch time: 63.53 s 
2023-08-08 00:00:15.440861:  
2023-08-08 00:00:15.440963: Epoch 754 
2023-08-08 00:00:15.441035: Current learning rate: 0.00065 
2023-08-08 00:01:18.748882: train_loss -0.3597 
2023-08-08 00:01:18.749055: val_loss -0.3005 
2023-08-08 00:01:18.749107: Pseudo dice [0.8316] 
2023-08-08 00:01:18.749158: Epoch time: 63.31 s 
2023-08-08 00:01:19.796847:  
2023-08-08 00:01:19.796954: Epoch 755 
2023-08-08 00:01:19.797043: Current learning rate: 0.00065 
2023-08-08 00:02:23.095814: train_loss -0.3384 
2023-08-08 00:02:23.095979: val_loss -0.3059 
2023-08-08 00:02:23.096033: Pseudo dice [0.8006] 
2023-08-08 00:02:23.096086: Epoch time: 63.3 s 
2023-08-08 00:02:24.181509:  
2023-08-08 00:02:24.181707: Epoch 756 
2023-08-08 00:02:24.181800: Current learning rate: 0.00065 
2023-08-08 00:03:27.593224: train_loss -0.3495 
2023-08-08 00:03:27.593387: val_loss -0.3373 
2023-08-08 00:03:27.593440: Pseudo dice [0.7661] 
2023-08-08 00:03:27.593492: Epoch time: 63.41 s 
2023-08-08 00:03:28.808303:  
2023-08-08 00:03:28.808403: Epoch 757 
2023-08-08 00:03:28.808480: Current learning rate: 0.00065 
2023-08-08 00:04:32.229598: train_loss -0.3831 
2023-08-08 00:04:32.229748: val_loss -0.2332 
2023-08-08 00:04:32.229814: Pseudo dice [0.7622] 
2023-08-08 00:04:32.229864: Epoch time: 63.42 s 
2023-08-08 00:04:33.293262:  
2023-08-08 00:04:33.293365: Epoch 758 
2023-08-08 00:04:33.293454: Current learning rate: 0.00065 
2023-08-08 00:05:36.738223: train_loss -0.3919 
2023-08-08 00:05:36.738366: val_loss -0.4355 
2023-08-08 00:05:36.738417: Pseudo dice [0.9122] 
2023-08-08 00:05:36.738467: Epoch time: 63.45 s 
2023-08-08 00:05:37.778577:  
2023-08-08 00:05:37.778676: Epoch 759 
2023-08-08 00:05:37.778853: Current learning rate: 0.00065 
2023-08-08 00:06:41.352845: train_loss -0.3681 
2023-08-08 00:06:41.352994: val_loss -0.3259 
2023-08-08 00:06:41.353043: Pseudo dice [0.8069] 
2023-08-08 00:06:41.353109: Epoch time: 63.58 s 
2023-08-08 00:06:42.421269:  
2023-08-08 00:06:42.421361: Epoch 760 
2023-08-08 00:06:42.421435: Current learning rate: 0.00065 
2023-08-08 00:07:45.997055: train_loss -0.3522 
2023-08-08 00:07:45.997201: val_loss -0.3413 
2023-08-08 00:07:45.997251: Pseudo dice [0.8246] 
2023-08-08 00:07:45.997302: Epoch time: 63.58 s 
2023-08-08 00:07:47.038421:  
2023-08-08 00:07:47.038570: Epoch 761 
2023-08-08 00:07:47.038741: Current learning rate: 0.00065 
2023-08-08 00:08:50.463618: train_loss -0.3226 
2023-08-08 00:08:50.463777: val_loss -0.4002 
2023-08-08 00:08:50.463829: Pseudo dice [0.8803] 
2023-08-08 00:08:50.463881: Epoch time: 63.43 s 
2023-08-08 00:08:51.697267:  
2023-08-08 00:08:51.697366: Epoch 762 
2023-08-08 00:08:51.697441: Current learning rate: 0.00065 
2023-08-08 00:09:55.195252: train_loss -0.3459 
2023-08-08 00:09:55.195412: val_loss -0.292 
2023-08-08 00:09:55.195464: Pseudo dice [0.7798] 
2023-08-08 00:09:55.195514: Epoch time: 63.5 s 
2023-08-08 00:09:56.280559:  
2023-08-08 00:09:56.280656: Epoch 763 
2023-08-08 00:09:56.280728: Current learning rate: 0.00065 
2023-08-08 00:10:59.813109: train_loss -0.355 
2023-08-08 00:10:59.813276: val_loss -0.4175 
2023-08-08 00:10:59.813329: Pseudo dice [0.8899] 
2023-08-08 00:10:59.813380: Epoch time: 63.53 s 
2023-08-08 00:11:00.903113:  
2023-08-08 00:11:00.903319: Epoch 764 
2023-08-08 00:11:00.903413: Current learning rate: 0.00065 
2023-08-08 00:12:04.348912: train_loss -0.3486 
2023-08-08 00:12:04.349073: val_loss -0.3837 
2023-08-08 00:12:04.349123: Pseudo dice [0.8838] 
2023-08-08 00:12:04.349189: Epoch time: 63.45 s 
2023-08-08 00:12:05.405937:  
2023-08-08 00:12:05.406037: Epoch 765 
2023-08-08 00:12:05.406111: Current learning rate: 0.00065 
2023-08-08 00:13:08.812519: train_loss -0.3512 
2023-08-08 00:13:08.812669: val_loss -0.379 
2023-08-08 00:13:08.812720: Pseudo dice [0.8573] 
2023-08-08 00:13:08.812770: Epoch time: 63.41 s 
2023-08-08 00:13:09.909898:  
2023-08-08 00:13:09.909987: Epoch 766 
2023-08-08 00:13:09.910075: Current learning rate: 0.00065 
2023-08-08 00:14:13.301149: train_loss -0.351 
2023-08-08 00:14:13.301305: val_loss -0.4131 
2023-08-08 00:14:13.301355: Pseudo dice [0.8102] 
2023-08-08 00:14:13.301424: Epoch time: 63.39 s 
2023-08-08 00:14:14.525118:  
2023-08-08 00:14:14.525220: Epoch 767 
2023-08-08 00:14:14.525293: Current learning rate: 0.00065 
2023-08-08 00:15:17.867864: train_loss -0.341 
2023-08-08 00:15:17.868003: val_loss -0.4513 
2023-08-08 00:15:17.868054: Pseudo dice [0.8611] 
2023-08-08 00:15:17.868103: Epoch time: 63.34 s 
2023-08-08 00:15:18.929920:  
2023-08-08 00:15:18.930019: Epoch 768 
2023-08-08 00:15:18.930093: Current learning rate: 0.00065 
2023-08-08 00:16:22.317568: train_loss -0.3345 
2023-08-08 00:16:22.317728: val_loss -0.2763 
2023-08-08 00:16:22.317779: Pseudo dice [0.8477] 
2023-08-08 00:16:22.317831: Epoch time: 63.39 s 
2023-08-08 00:16:22.317872: Yayy! New best EMA pseudo Dice: 0.8354 
2023-08-08 00:16:23.826821:  
2023-08-08 00:16:23.826920: Epoch 769 
2023-08-08 00:16:23.827010: Current learning rate: 0.00065 
2023-08-08 00:17:27.370901: train_loss -0.3781 
2023-08-08 00:17:27.371067: val_loss -0.3751 
2023-08-08 00:17:27.371120: Pseudo dice [0.8271] 
2023-08-08 00:17:27.371171: Epoch time: 63.54 s 
2023-08-08 00:17:28.428786:  
2023-08-08 00:17:28.428891: Epoch 770 
2023-08-08 00:17:28.428979: Current learning rate: 0.00065 
2023-08-08 00:18:31.875286: train_loss -0.3274 
2023-08-08 00:18:31.875430: val_loss -0.33 
2023-08-08 00:18:31.875497: Pseudo dice [0.8495] 
2023-08-08 00:18:31.875547: Epoch time: 63.45 s 
2023-08-08 00:18:31.875596: Yayy! New best EMA pseudo Dice: 0.836 
2023-08-08 00:18:33.454591:  
2023-08-08 00:18:33.454700: Epoch 771 
2023-08-08 00:18:33.454790: Current learning rate: 0.00065 
2023-08-08 00:19:36.724145: train_loss -0.3693 
2023-08-08 00:19:36.724297: val_loss -0.4191 
2023-08-08 00:19:36.724349: Pseudo dice [0.8165] 
2023-08-08 00:19:36.724400: Epoch time: 63.27 s 
2023-08-08 00:19:37.783221:  
2023-08-08 00:19:37.783322: Epoch 772 
2023-08-08 00:19:37.783411: Current learning rate: 0.00064 
2023-08-08 00:20:41.204101: train_loss -0.328 
2023-08-08 00:20:41.204253: val_loss -0.3311 
2023-08-08 00:20:41.204305: Pseudo dice [0.8347] 
2023-08-08 00:20:41.204356: Epoch time: 63.42 s 
2023-08-08 00:20:42.268809:  
2023-08-08 00:20:42.269105: Epoch 773 
2023-08-08 00:20:42.269282: Current learning rate: 0.00064 
2023-08-08 00:21:45.761358: train_loss -0.3401 
2023-08-08 00:21:45.761503: val_loss -0.3442 
2023-08-08 00:21:45.761554: Pseudo dice [0.7666] 
2023-08-08 00:21:45.761605: Epoch time: 63.49 s 
2023-08-08 00:21:46.828795:  
2023-08-08 00:21:46.828906: Epoch 774 
2023-08-08 00:21:46.828981: Current learning rate: 0.00064 
2023-08-08 00:22:50.342291: train_loss -0.3441 
2023-08-08 00:22:50.342441: val_loss -0.329 
2023-08-08 00:22:50.342491: Pseudo dice [0.8376] 
2023-08-08 00:22:50.342541: Epoch time: 63.51 s 
2023-08-08 00:22:51.441491:  
2023-08-08 00:22:51.441588: Epoch 775 
2023-08-08 00:22:51.441676: Current learning rate: 0.00064 
2023-08-08 00:23:54.942668: train_loss -0.3612 
2023-08-08 00:23:54.942829: val_loss -0.3344 
2023-08-08 00:23:54.942884: Pseudo dice [0.7873] 
2023-08-08 00:23:54.942952: Epoch time: 63.5 s 
2023-08-08 00:23:56.055417:  
2023-08-08 00:23:56.055510: Epoch 776 
2023-08-08 00:23:56.055620: Current learning rate: 0.00064 
2023-08-08 00:24:59.482856: train_loss -0.3348 
2023-08-08 00:24:59.482999: val_loss -0.3435 
2023-08-08 00:24:59.483051: Pseudo dice [0.8257] 
2023-08-08 00:24:59.483100: Epoch time: 63.43 s 
2023-08-08 00:25:00.779717:  
2023-08-08 00:25:00.780042: Epoch 777 
2023-08-08 00:25:00.780275: Current learning rate: 0.00064 
2023-08-08 00:26:04.048896: train_loss -0.3595 
2023-08-08 00:26:04.049041: val_loss -0.3341 
2023-08-08 00:26:04.049092: Pseudo dice [0.8746] 
2023-08-08 00:26:04.049141: Epoch time: 63.27 s 
2023-08-08 00:26:05.109973:  
2023-08-08 00:26:05.110150: Epoch 778 
2023-08-08 00:26:05.110224: Current learning rate: 0.00064 
2023-08-08 00:27:08.483964: train_loss -0.3604 
2023-08-08 00:27:08.484211: val_loss -0.3876 
2023-08-08 00:27:08.484264: Pseudo dice [0.8812] 
2023-08-08 00:27:08.484334: Epoch time: 63.37 s 
2023-08-08 00:27:09.546530:  
2023-08-08 00:27:09.546624: Epoch 779 
2023-08-08 00:27:09.546696: Current learning rate: 0.00064 
2023-08-08 00:28:12.829863: train_loss -0.3761 
2023-08-08 00:28:12.830015: val_loss -0.3254 
2023-08-08 00:28:12.830068: Pseudo dice [0.879] 
2023-08-08 00:28:12.830138: Epoch time: 63.28 s 
2023-08-08 00:28:12.830178: Yayy! New best EMA pseudo Dice: 0.8391 
2023-08-08 00:28:14.285723:  
2023-08-08 00:28:14.285929: Epoch 780 
2023-08-08 00:28:14.286033: Current learning rate: 0.00064 
2023-08-08 00:29:17.414249: train_loss -0.3348 
2023-08-08 00:29:17.414403: val_loss -0.4084 
2023-08-08 00:29:17.414453: Pseudo dice [0.8057] 
2023-08-08 00:29:17.414502: Epoch time: 63.13 s 
2023-08-08 00:29:18.477225:  
2023-08-08 00:29:18.477396: Epoch 781 
2023-08-08 00:29:18.477486: Current learning rate: 0.00064 
2023-08-08 00:30:21.933779: train_loss -0.3234 
2023-08-08 00:30:21.933940: val_loss -0.3179 
2023-08-08 00:30:21.933992: Pseudo dice [0.7815] 
2023-08-08 00:30:21.934042: Epoch time: 63.46 s 
2023-08-08 00:30:23.157430:  
2023-08-08 00:30:23.157763: Epoch 782 
2023-08-08 00:30:23.157867: Current learning rate: 0.00064 
2023-08-08 00:31:26.535783: train_loss -0.3185 
2023-08-08 00:31:26.535941: val_loss -0.2386 
2023-08-08 00:31:26.535993: Pseudo dice [0.7668] 
2023-08-08 00:31:26.536043: Epoch time: 63.38 s 
2023-08-08 00:31:27.628990:  
2023-08-08 00:31:27.629086: Epoch 783 
2023-08-08 00:31:27.629158: Current learning rate: 0.00064 
2023-08-08 00:32:31.109758: train_loss -0.3085 
2023-08-08 00:32:31.109902: val_loss -0.3515 
2023-08-08 00:32:31.109953: Pseudo dice [0.8027] 
2023-08-08 00:32:31.110005: Epoch time: 63.48 s 
2023-08-08 00:32:32.178725:  
2023-08-08 00:32:32.178962: Epoch 784 
2023-08-08 00:32:32.179060: Current learning rate: 0.00064 
2023-08-08 00:33:35.577974: train_loss -0.3323 
2023-08-08 00:33:35.578120: val_loss -0.3819 
2023-08-08 00:33:35.578169: Pseudo dice [0.8279] 
2023-08-08 00:33:35.578235: Epoch time: 63.4 s 
2023-08-08 00:33:36.666266:  
2023-08-08 00:33:36.666365: Epoch 785 
2023-08-08 00:33:36.666437: Current learning rate: 0.00064 
2023-08-08 00:34:39.967911: train_loss -0.3239 
2023-08-08 00:34:39.968158: val_loss -0.3527 
2023-08-08 00:34:39.968213: Pseudo dice [0.8188] 
2023-08-08 00:34:39.968263: Epoch time: 63.3 s 
2023-08-08 00:34:41.033149:  
2023-08-08 00:34:41.033242: Epoch 786 
2023-08-08 00:34:41.033329: Current learning rate: 0.00064 
2023-08-08 00:35:44.654904: train_loss -0.33 
2023-08-08 00:35:44.655055: val_loss -0.3113 
2023-08-08 00:35:44.655107: Pseudo dice [0.8494] 
2023-08-08 00:35:44.655178: Epoch time: 63.62 s 
2023-08-08 00:35:45.872996:  
2023-08-08 00:35:45.873098: Epoch 787 
2023-08-08 00:35:45.873170: Current learning rate: 0.00064 
2023-08-08 00:36:49.472414: train_loss -0.3396 
2023-08-08 00:36:49.472579: val_loss -0.3971 
2023-08-08 00:36:49.472631: Pseudo dice [0.7627] 
2023-08-08 00:36:49.472683: Epoch time: 63.6 s 
2023-08-08 00:36:50.534820:  
2023-08-08 00:36:50.534919: Epoch 788 
2023-08-08 00:36:50.535008: Current learning rate: 0.00064 
2023-08-08 00:37:53.925208: train_loss -0.3959 
2023-08-08 00:37:53.925353: val_loss -0.3318 
2023-08-08 00:37:53.925402: Pseudo dice [0.8698] 
2023-08-08 00:37:53.925469: Epoch time: 63.39 s 
2023-08-08 00:37:54.992003:  
2023-08-08 00:37:54.992176: Epoch 789 
2023-08-08 00:37:54.992254: Current learning rate: 0.00064 
2023-08-08 00:38:58.427146: train_loss -0.336 
2023-08-08 00:38:58.427306: val_loss -0.4099 
2023-08-08 00:38:58.427355: Pseudo dice [0.8249] 
2023-08-08 00:38:58.427420: Epoch time: 63.44 s 
2023-08-08 00:38:59.487405:  
2023-08-08 00:38:59.487500: Epoch 790 
2023-08-08 00:38:59.487594: Current learning rate: 0.00064 
2023-08-08 00:40:02.877234: train_loss -0.3574 
2023-08-08 00:40:02.877376: val_loss -0.3628 
2023-08-08 00:40:02.877443: Pseudo dice [0.8895] 
2023-08-08 00:40:02.877493: Epoch time: 63.39 s 
2023-08-08 00:40:03.942255:  
2023-08-08 00:40:03.942351: Epoch 791 
2023-08-08 00:40:03.942424: Current learning rate: 0.00064 
2023-08-08 00:41:07.436690: train_loss -0.374 
2023-08-08 00:41:07.436840: val_loss -0.3232 
2023-08-08 00:41:07.436895: Pseudo dice [0.854] 
2023-08-08 00:41:07.436946: Epoch time: 63.5 s 
2023-08-08 00:41:08.657521:  
2023-08-08 00:41:08.657619: Epoch 792 
2023-08-08 00:41:08.657696: Current learning rate: 0.00064 
2023-08-08 00:42:12.181309: train_loss -0.3533 
2023-08-08 00:42:12.181461: val_loss -0.3389 
2023-08-08 00:42:12.181529: Pseudo dice [0.8483] 
2023-08-08 00:42:12.181588: Epoch time: 63.52 s 
2023-08-08 00:42:13.279898:  
2023-08-08 00:42:13.279999: Epoch 793 
2023-08-08 00:42:13.280073: Current learning rate: 0.00063 
2023-08-08 00:43:16.799231: train_loss -0.3458 
2023-08-08 00:43:16.799391: val_loss -0.3837 
2023-08-08 00:43:16.799444: Pseudo dice [0.7268] 
2023-08-08 00:43:16.799495: Epoch time: 63.52 s 
2023-08-08 00:43:17.859117:  
2023-08-08 00:43:17.859214: Epoch 794 
2023-08-08 00:43:17.859304: Current learning rate: 0.00063 
2023-08-08 00:44:21.371789: train_loss -0.3553 
2023-08-08 00:44:21.371945: val_loss -0.3562 
2023-08-08 00:44:21.371999: Pseudo dice [0.8546] 
2023-08-08 00:44:21.372050: Epoch time: 63.51 s 
2023-08-08 00:44:22.434582:  
2023-08-08 00:44:22.434772: Epoch 795 
2023-08-08 00:44:22.434844: Current learning rate: 0.00063 
2023-08-08 00:45:26.071641: train_loss -0.341 
2023-08-08 00:45:26.071788: val_loss -0.3301 
2023-08-08 00:45:26.071837: Pseudo dice [0.7888] 
2023-08-08 00:45:26.071887: Epoch time: 63.64 s 
2023-08-08 00:45:27.133898:  
2023-08-08 00:45:27.133992: Epoch 796 
2023-08-08 00:45:27.134061: Current learning rate: 0.00063 
2023-08-08 00:46:30.813357: train_loss -0.3379 
2023-08-08 00:46:30.813505: val_loss -0.3736 
2023-08-08 00:46:30.813557: Pseudo dice [0.8425] 
2023-08-08 00:46:30.813606: Epoch time: 63.68 s 
2023-08-08 00:46:31.882306:  
2023-08-08 00:46:31.882406: Epoch 797 
2023-08-08 00:46:31.882507: Current learning rate: 0.00063 
2023-08-08 00:47:35.161771: train_loss -0.3331 
2023-08-08 00:47:35.161923: val_loss -0.3334 
2023-08-08 00:47:35.161991: Pseudo dice [0.8011] 
2023-08-08 00:47:35.162040: Epoch time: 63.28 s 
2023-08-08 00:47:36.224797:  
2023-08-08 00:47:36.224907: Epoch 798 
2023-08-08 00:47:36.225020: Current learning rate: 0.00063 
2023-08-08 00:48:39.550237: train_loss -0.3294 
2023-08-08 00:48:39.550395: val_loss -0.3953 
2023-08-08 00:48:39.550464: Pseudo dice [0.841] 
2023-08-08 00:48:39.550515: Epoch time: 63.33 s 
2023-08-08 00:48:40.611540:  
2023-08-08 00:48:40.611946: Epoch 799 
2023-08-08 00:48:40.612023: Current learning rate: 0.00063 
2023-08-08 00:49:43.948791: train_loss -0.358 
2023-08-08 00:49:43.949177: val_loss -0.3417 
2023-08-08 00:49:43.949233: Pseudo dice [0.7377] 
2023-08-08 00:49:43.949285: Epoch time: 63.34 s 
2023-08-08 00:49:45.409667:  
2023-08-08 00:49:45.409765: Epoch 800 
2023-08-08 00:49:45.409857: Current learning rate: 0.00063 
2023-08-08 00:50:49.001787: train_loss -0.3113 
2023-08-08 00:50:49.001940: val_loss -0.4369 
2023-08-08 00:50:49.001993: Pseudo dice [0.7876] 
2023-08-08 00:50:49.002045: Epoch time: 63.59 s 
2023-08-08 00:50:50.242198:  
2023-08-08 00:50:50.242376: Epoch 801 
2023-08-08 00:50:50.242469: Current learning rate: 0.00063 
2023-08-08 00:51:53.670336: train_loss -0.3921 
2023-08-08 00:51:53.670480: val_loss -0.3552 
2023-08-08 00:51:53.670534: Pseudo dice [0.8093] 
2023-08-08 00:51:53.670603: Epoch time: 63.43 s 
2023-08-08 00:51:54.733604:  
2023-08-08 00:51:54.733870: Epoch 802 
2023-08-08 00:51:54.734067: Current learning rate: 0.00063 
2023-08-08 00:52:58.282784: train_loss -0.3319 
2023-08-08 00:52:58.282932: val_loss -0.4369 
2023-08-08 00:52:58.282984: Pseudo dice [0.8091] 
2023-08-08 00:52:58.283050: Epoch time: 63.55 s 
2023-08-08 00:52:59.344040:  
2023-08-08 00:52:59.344140: Epoch 803 
2023-08-08 00:52:59.344215: Current learning rate: 0.00063 
2023-08-08 00:54:02.718099: train_loss -0.3721 
2023-08-08 00:54:02.718248: val_loss -0.4197 
2023-08-08 00:54:02.718300: Pseudo dice [0.8978] 
2023-08-08 00:54:02.718366: Epoch time: 63.37 s 
2023-08-08 00:54:03.784587:  
2023-08-08 00:54:03.784734: Epoch 804 
2023-08-08 00:54:03.784872: Current learning rate: 0.00063 
2023-08-08 00:55:07.311988: train_loss -0.3621 
2023-08-08 00:55:07.312136: val_loss -0.3727 
2023-08-08 00:55:07.312188: Pseudo dice [0.8247] 
2023-08-08 00:55:07.312238: Epoch time: 63.53 s 
2023-08-08 00:55:08.455559:  
2023-08-08 00:55:08.455650: Epoch 805 
2023-08-08 00:55:08.455736: Current learning rate: 0.00063 
2023-08-08 00:56:11.939674: train_loss -0.3533 
2023-08-08 00:56:11.939827: val_loss -0.2489 
2023-08-08 00:56:11.939889: Pseudo dice [0.7037] 
2023-08-08 00:56:11.939939: Epoch time: 63.48 s 
2023-08-08 00:56:13.003864:  
2023-08-08 00:56:13.004034: Epoch 806 
2023-08-08 00:56:13.004112: Current learning rate: 0.00063 
2023-08-08 00:57:16.524179: train_loss -0.3654 
2023-08-08 00:57:16.524328: val_loss -0.4134 
2023-08-08 00:57:16.524378: Pseudo dice [0.8882] 
2023-08-08 00:57:16.524427: Epoch time: 63.52 s 
2023-08-08 00:57:17.755980:  
2023-08-08 00:57:17.756243: Epoch 807 
2023-08-08 00:57:17.756421: Current learning rate: 0.00063 
2023-08-08 00:58:21.149922: train_loss -0.3539 
2023-08-08 00:58:21.150077: val_loss -0.3316 
2023-08-08 00:58:21.150130: Pseudo dice [0.8834] 
2023-08-08 00:58:21.150180: Epoch time: 63.39 s 
2023-08-08 00:58:22.209219:  
2023-08-08 00:58:22.209314: Epoch 808 
2023-08-08 00:58:22.209401: Current learning rate: 0.00063 
2023-08-08 00:59:25.712560: train_loss -0.3478 
2023-08-08 00:59:25.712713: val_loss -0.4254 
2023-08-08 00:59:25.712763: Pseudo dice [0.8247] 
2023-08-08 00:59:25.712815: Epoch time: 63.5 s 
2023-08-08 00:59:26.798962:  
2023-08-08 00:59:26.799061: Epoch 809 
2023-08-08 00:59:26.799150: Current learning rate: 0.00063 
2023-08-08 01:00:30.368626: train_loss -0.3553 
2023-08-08 01:00:30.368775: val_loss -0.3694 
2023-08-08 01:00:30.368826: Pseudo dice [0.8237] 
2023-08-08 01:00:30.368876: Epoch time: 63.57 s 
2023-08-08 01:00:31.478610:  
2023-08-08 01:00:31.478704: Epoch 810 
2023-08-08 01:00:31.478792: Current learning rate: 0.00063 
2023-08-08 01:01:34.846000: train_loss -0.3746 
2023-08-08 01:01:34.846161: val_loss -0.3283 
2023-08-08 01:01:34.846215: Pseudo dice [0.8827] 
2023-08-08 01:01:34.846265: Epoch time: 63.37 s 
2023-08-08 01:01:35.929964:  
2023-08-08 01:01:35.930078: Epoch 811 
2023-08-08 01:01:35.930176: Current learning rate: 0.00063 
2023-08-08 01:02:39.439528: train_loss -0.3858 
2023-08-08 01:02:39.439699: val_loss -0.3883 
2023-08-08 01:02:39.439751: Pseudo dice [0.8311] 
2023-08-08 01:02:39.439802: Epoch time: 63.51 s 
2023-08-08 01:02:40.659599:  
2023-08-08 01:02:40.659705: Epoch 812 
2023-08-08 01:02:40.659781: Current learning rate: 0.00063 
2023-08-08 01:03:44.198541: train_loss -0.356 
2023-08-08 01:03:44.198695: val_loss -0.4053 
2023-08-08 01:03:44.198749: Pseudo dice [0.8565] 
2023-08-08 01:03:44.198798: Epoch time: 63.54 s 
2023-08-08 01:03:45.263740:  
2023-08-08 01:03:45.264024: Epoch 813 
2023-08-08 01:03:45.264200: Current learning rate: 0.00063 
2023-08-08 01:04:48.712630: train_loss -0.3536 
2023-08-08 01:04:48.712789: val_loss -0.3428 
2023-08-08 01:04:48.712857: Pseudo dice [0.8485] 
2023-08-08 01:04:48.712906: Epoch time: 63.45 s 
2023-08-08 01:04:49.816736:  
2023-08-08 01:04:49.816835: Epoch 814 
2023-08-08 01:04:49.816933: Current learning rate: 0.00062 
2023-08-08 01:05:53.401614: train_loss -0.3507 
2023-08-08 01:05:53.401863: val_loss -0.3632 
2023-08-08 01:05:53.401927: Pseudo dice [0.8721] 
2023-08-08 01:05:53.401982: Epoch time: 63.59 s 
2023-08-08 01:05:54.474853:  
2023-08-08 01:05:54.474970: Epoch 815 
2023-08-08 01:05:54.475045: Current learning rate: 0.00062 
2023-08-08 01:06:57.974909: train_loss -0.3474 
2023-08-08 01:06:57.975074: val_loss -0.3292 
2023-08-08 01:06:57.975126: Pseudo dice [0.8661] 
2023-08-08 01:06:57.975177: Epoch time: 63.5 s 
2023-08-08 01:06:57.975268: Yayy! New best EMA pseudo Dice: 0.8408 
2023-08-08 01:06:59.397630:  
2023-08-08 01:06:59.397805: Epoch 816 
2023-08-08 01:06:59.397908: Current learning rate: 0.00062 
2023-08-08 01:08:02.862023: train_loss -0.4012 
2023-08-08 01:08:02.862175: val_loss -0.3448 
2023-08-08 01:08:02.862227: Pseudo dice [0.8525] 
2023-08-08 01:08:02.862278: Epoch time: 63.47 s 
2023-08-08 01:08:02.862317: Yayy! New best EMA pseudo Dice: 0.842 
2023-08-08 01:08:04.298239:  
2023-08-08 01:08:04.298339: Epoch 817 
2023-08-08 01:08:04.298413: Current learning rate: 0.00062 
2023-08-08 01:09:07.624713: train_loss -0.3502 
2023-08-08 01:09:07.624863: val_loss -0.3719 
2023-08-08 01:09:07.624915: Pseudo dice [0.8395] 
2023-08-08 01:09:07.624965: Epoch time: 63.33 s 
2023-08-08 01:09:08.703152:  
2023-08-08 01:09:08.703351: Epoch 818 
2023-08-08 01:09:08.703430: Current learning rate: 0.00062 
2023-08-08 01:10:12.250428: train_loss -0.3341 
2023-08-08 01:10:12.250575: val_loss -0.3336 
2023-08-08 01:10:12.250640: Pseudo dice [0.8152] 
2023-08-08 01:10:12.250690: Epoch time: 63.55 s 
2023-08-08 01:10:13.343532:  
2023-08-08 01:10:13.344015: Epoch 819 
2023-08-08 01:10:13.344277: Current learning rate: 0.00062 
2023-08-08 01:11:16.800422: train_loss -0.3435 
2023-08-08 01:11:16.800577: val_loss -0.4073 
2023-08-08 01:11:16.800627: Pseudo dice [0.8749] 
2023-08-08 01:11:16.800677: Epoch time: 63.46 s 
2023-08-08 01:11:16.800717: Yayy! New best EMA pseudo Dice: 0.8426 
2023-08-08 01:11:18.177684:  
2023-08-08 01:11:18.177863: Epoch 820 
2023-08-08 01:11:18.177938: Current learning rate: 0.00062 
2023-08-08 01:12:21.585983: train_loss -0.3333 
2023-08-08 01:12:21.586138: val_loss -0.3696 
2023-08-08 01:12:21.586188: Pseudo dice [0.7907] 
2023-08-08 01:12:21.586255: Epoch time: 63.41 s 
2023-08-08 01:12:22.584012:  
2023-08-08 01:12:22.584335: Epoch 821 
2023-08-08 01:12:22.584413: Current learning rate: 0.00062 
2023-08-08 01:13:26.179423: train_loss -0.3535 
2023-08-08 01:13:26.179595: val_loss -0.3419 
2023-08-08 01:13:26.179671: Pseudo dice [0.7348] 
2023-08-08 01:13:26.179723: Epoch time: 63.6 s 
2023-08-08 01:13:27.224437:  
2023-08-08 01:13:27.224640: Epoch 822 
2023-08-08 01:13:27.224797: Current learning rate: 0.00062 
2023-08-08 01:14:30.540812: train_loss -0.3486 
2023-08-08 01:14:30.541064: val_loss -0.3501 
2023-08-08 01:14:30.541120: Pseudo dice [0.7778] 
2023-08-08 01:14:30.541172: Epoch time: 63.32 s 
2023-08-08 01:14:31.540883:  
2023-08-08 01:14:31.541219: Epoch 823 
2023-08-08 01:14:31.541296: Current learning rate: 0.00062 
2023-08-08 01:15:34.973490: train_loss -0.3534 
2023-08-08 01:15:34.973644: val_loss -0.3985 
2023-08-08 01:15:34.973715: Pseudo dice [0.7782] 
2023-08-08 01:15:34.973765: Epoch time: 63.43 s 
2023-08-08 01:15:35.973404:  
2023-08-08 01:15:35.973499: Epoch 824 
2023-08-08 01:15:35.973588: Current learning rate: 0.00062 
2023-08-08 01:16:39.488960: train_loss -0.3634 
2023-08-08 01:16:39.489095: val_loss -0.3031 
2023-08-08 01:16:39.489144: Pseudo dice [0.8544] 
2023-08-08 01:16:39.489211: Epoch time: 63.52 s 
2023-08-08 01:16:40.481195:  
2023-08-08 01:16:40.481587: Epoch 825 
2023-08-08 01:16:40.481680: Current learning rate: 0.00062 
2023-08-08 01:17:43.868880: train_loss -0.344 
2023-08-08 01:17:43.869025: val_loss -0.4235 
2023-08-08 01:17:43.869077: Pseudo dice [0.8601] 
2023-08-08 01:17:43.869128: Epoch time: 63.39 s 
2023-08-08 01:17:44.864625:  
2023-08-08 01:17:44.864719: Epoch 826 
2023-08-08 01:17:44.864794: Current learning rate: 0.00062 
2023-08-08 01:18:48.065570: train_loss -0.3852 
2023-08-08 01:18:48.065727: val_loss -0.3384 
2023-08-08 01:18:48.065779: Pseudo dice [0.8287] 
2023-08-08 01:18:48.065828: Epoch time: 63.2 s 
2023-08-08 01:18:49.254830:  
2023-08-08 01:18:49.254933: Epoch 827 
2023-08-08 01:18:49.255006: Current learning rate: 0.00062 
2023-08-08 01:19:52.707944: train_loss -0.3528 
2023-08-08 01:19:52.708092: val_loss -0.4198 
2023-08-08 01:19:52.708144: Pseudo dice [0.8416] 
2023-08-08 01:19:52.708193: Epoch time: 63.45 s 
2023-08-08 01:19:53.709134:  
2023-08-08 01:19:53.709339: Epoch 828 
2023-08-08 01:19:53.709420: Current learning rate: 0.00062 
2023-08-08 01:20:57.305693: train_loss -0.366 
2023-08-08 01:20:57.305865: val_loss -0.3528 
2023-08-08 01:20:57.305918: Pseudo dice [0.7143] 
2023-08-08 01:20:57.305970: Epoch time: 63.6 s 
2023-08-08 01:20:58.323943:  
2023-08-08 01:20:58.324196: Epoch 829 
2023-08-08 01:20:58.324354: Current learning rate: 0.00062 
2023-08-08 01:22:01.792768: train_loss -0.3565 
2023-08-08 01:22:01.792917: val_loss -0.2893 
2023-08-08 01:22:01.792966: Pseudo dice [0.7557] 
2023-08-08 01:22:01.793015: Epoch time: 63.47 s 
2023-08-08 01:22:02.795559:  
2023-08-08 01:22:02.795684: Epoch 830 
2023-08-08 01:22:02.795756: Current learning rate: 0.00062 
2023-08-08 01:23:06.098639: train_loss -0.3453 
2023-08-08 01:23:06.098799: val_loss -0.3784 
2023-08-08 01:23:06.098869: Pseudo dice [0.8052] 
2023-08-08 01:23:06.098920: Epoch time: 63.3 s 
2023-08-08 01:23:07.168121:  
2023-08-08 01:23:07.168232: Epoch 831 
2023-08-08 01:23:07.168305: Current learning rate: 0.00062 
2023-08-08 01:24:10.359842: train_loss -0.3192 
2023-08-08 01:24:10.359989: val_loss -0.3565 
2023-08-08 01:24:10.360042: Pseudo dice [0.8296] 
2023-08-08 01:24:10.360091: Epoch time: 63.19 s 
2023-08-08 01:24:11.561852:  
2023-08-08 01:24:11.562020: Epoch 832 
2023-08-08 01:24:11.562098: Current learning rate: 0.00062 
2023-08-08 01:25:15.037169: train_loss -0.3123 
2023-08-08 01:25:15.037329: val_loss -0.3444 
2023-08-08 01:25:15.037382: Pseudo dice [0.8439] 
2023-08-08 01:25:15.037432: Epoch time: 63.48 s 
2023-08-08 01:25:16.044230:  
2023-08-08 01:25:16.044406: Epoch 833 
2023-08-08 01:25:16.044482: Current learning rate: 0.00062 
2023-08-08 01:26:19.422547: train_loss -0.3297 
2023-08-08 01:26:19.422939: val_loss -0.3101 
2023-08-08 01:26:19.422994: Pseudo dice [0.7786] 
2023-08-08 01:26:19.423045: Epoch time: 63.38 s 
2023-08-08 01:26:20.422986:  
2023-08-08 01:26:20.423234: Epoch 834 
2023-08-08 01:26:20.423441: Current learning rate: 0.00062 
2023-08-08 01:27:23.684272: train_loss -0.351 
2023-08-08 01:27:23.684425: val_loss -0.2825 
2023-08-08 01:27:23.684477: Pseudo dice [0.8433] 
2023-08-08 01:27:23.684527: Epoch time: 63.26 s 
2023-08-08 01:27:24.684103:  
2023-08-08 01:27:24.684201: Epoch 835 
2023-08-08 01:27:24.684276: Current learning rate: 0.00061 
2023-08-08 01:28:27.953034: train_loss -0.3395 
2023-08-08 01:28:27.953180: val_loss -0.3608 
2023-08-08 01:28:27.953231: Pseudo dice [0.8781] 
2023-08-08 01:28:27.953279: Epoch time: 63.27 s 
2023-08-08 01:28:29.013831:  
2023-08-08 01:28:29.014072: Epoch 836 
2023-08-08 01:28:29.014297: Current learning rate: 0.00061 
2023-08-08 01:29:32.284808: train_loss -0.3551 
2023-08-08 01:29:32.285093: val_loss -0.3461 
2023-08-08 01:29:32.285146: Pseudo dice [0.8634] 
2023-08-08 01:29:32.285196: Epoch time: 63.27 s 
2023-08-08 01:29:33.312356:  
2023-08-08 01:29:33.312449: Epoch 837 
2023-08-08 01:29:33.312539: Current learning rate: 0.00061 
2023-08-08 01:30:36.779619: train_loss -0.3319 
2023-08-08 01:30:36.779778: val_loss -0.339 
2023-08-08 01:30:36.779828: Pseudo dice [0.7981] 
2023-08-08 01:30:36.779878: Epoch time: 63.47 s 
2023-08-08 01:30:37.944674:  
2023-08-08 01:30:37.944783: Epoch 838 
2023-08-08 01:30:37.944870: Current learning rate: 0.00061 
2023-08-08 01:31:41.556050: train_loss -0.316 
2023-08-08 01:31:41.556200: val_loss -0.3671 
2023-08-08 01:31:41.556252: Pseudo dice [0.837] 
2023-08-08 01:31:41.556302: Epoch time: 63.61 s 
2023-08-08 01:31:42.578532:  
2023-08-08 01:31:42.578797: Epoch 839 
2023-08-08 01:31:42.578968: Current learning rate: 0.00061 
2023-08-08 01:32:46.116103: train_loss -0.3376 
2023-08-08 01:32:46.116256: val_loss -0.3006 
2023-08-08 01:32:46.116311: Pseudo dice [0.768] 
2023-08-08 01:32:46.116361: Epoch time: 63.54 s 
2023-08-08 01:32:47.214676:  
2023-08-08 01:32:47.214782: Epoch 840 
2023-08-08 01:32:47.214871: Current learning rate: 0.00061 
2023-08-08 01:33:50.711599: train_loss -0.3702 
2023-08-08 01:33:50.711746: val_loss -0.3633 
2023-08-08 01:33:50.711800: Pseudo dice [0.8133] 
2023-08-08 01:33:50.711868: Epoch time: 63.5 s 
2023-08-08 01:33:51.730206:  
2023-08-08 01:33:51.730646: Epoch 841 
2023-08-08 01:33:51.730836: Current learning rate: 0.00061 
2023-08-08 01:34:55.263777: train_loss -0.36 
2023-08-08 01:34:55.264046: val_loss -0.3725 
2023-08-08 01:34:55.264101: Pseudo dice [0.7679] 
2023-08-08 01:34:55.264151: Epoch time: 63.54 s 
2023-08-08 01:34:56.292966:  
2023-08-08 01:34:56.293063: Epoch 842 
2023-08-08 01:34:56.293152: Current learning rate: 0.00061 
2023-08-08 01:35:59.571141: train_loss -0.3305 
2023-08-08 01:35:59.571286: val_loss -0.3522 
2023-08-08 01:35:59.571335: Pseudo dice [0.8444] 
2023-08-08 01:35:59.571400: Epoch time: 63.28 s 
2023-08-08 01:36:00.590834:  
2023-08-08 01:36:00.590930: Epoch 843 
2023-08-08 01:36:00.591007: Current learning rate: 0.00061 
2023-08-08 01:37:04.107266: train_loss -0.3613 
2023-08-08 01:37:04.107413: val_loss -0.4153 
2023-08-08 01:37:04.107482: Pseudo dice [0.8727] 
2023-08-08 01:37:04.107533: Epoch time: 63.52 s 
2023-08-08 01:37:05.329205:  
2023-08-08 01:37:05.329308: Epoch 844 
2023-08-08 01:37:05.329396: Current learning rate: 0.00061 
2023-08-08 01:38:08.555532: train_loss -0.3596 
2023-08-08 01:38:08.555719: val_loss -0.2861 
2023-08-08 01:38:08.555773: Pseudo dice [0.783] 
2023-08-08 01:38:08.555824: Epoch time: 63.23 s 
2023-08-08 01:38:09.571256:  
2023-08-08 01:38:09.571370: Epoch 845 
2023-08-08 01:38:09.571452: Current learning rate: 0.00061 
2023-08-08 01:39:13.112420: train_loss -0.355 
2023-08-08 01:39:13.112572: val_loss -0.3256 
2023-08-08 01:39:13.112627: Pseudo dice [0.857] 
2023-08-08 01:39:13.112676: Epoch time: 63.54 s 
2023-08-08 01:39:14.124222:  
2023-08-08 01:39:14.124318: Epoch 846 
2023-08-08 01:39:14.124391: Current learning rate: 0.00061 
2023-08-08 01:40:17.720510: train_loss -0.3773 
2023-08-08 01:40:17.720660: val_loss -0.323 
2023-08-08 01:40:17.720712: Pseudo dice [0.819] 
2023-08-08 01:40:17.720762: Epoch time: 63.6 s 
2023-08-08 01:40:18.762982:  
2023-08-08 01:40:18.763080: Epoch 847 
2023-08-08 01:40:18.763156: Current learning rate: 0.00061 
2023-08-08 01:41:22.028949: train_loss -0.3442 
2023-08-08 01:41:22.029096: val_loss -0.4062 
2023-08-08 01:41:22.029148: Pseudo dice [0.8885] 
2023-08-08 01:41:22.029198: Epoch time: 63.27 s 
2023-08-08 01:41:23.032643:  
2023-08-08 01:41:23.032737: Epoch 848 
2023-08-08 01:41:23.032807: Current learning rate: 0.00061 
2023-08-08 01:42:26.322795: train_loss -0.3512 
2023-08-08 01:42:26.322943: val_loss -0.3293 
2023-08-08 01:42:26.323000: Pseudo dice [0.8633] 
2023-08-08 01:42:26.323050: Epoch time: 63.29 s 
2023-08-08 01:42:27.329334:  
2023-08-08 01:42:27.329523: Epoch 849 
2023-08-08 01:42:27.329597: Current learning rate: 0.00061 
2023-08-08 01:43:30.897245: train_loss -0.363 
2023-08-08 01:43:30.897384: val_loss -0.3372 
2023-08-08 01:43:30.897438: Pseudo dice [0.7824] 
2023-08-08 01:43:30.897487: Epoch time: 63.57 s 
2023-08-08 01:43:32.274208:  
2023-08-08 01:43:32.274510: Epoch 850 
2023-08-08 01:43:32.274681: Current learning rate: 0.00061 
2023-08-08 01:44:35.731268: train_loss -0.3295 
2023-08-08 01:44:35.731495: val_loss -0.3332 
2023-08-08 01:44:35.731549: Pseudo dice [0.7062] 
2023-08-08 01:44:35.731609: Epoch time: 63.46 s 
2023-08-08 01:44:36.736255:  
2023-08-08 01:44:36.736351: Epoch 851 
2023-08-08 01:44:36.736427: Current learning rate: 0.00061 
2023-08-08 01:45:40.127850: train_loss -0.3428 
2023-08-08 01:45:40.128000: val_loss -0.376 
2023-08-08 01:45:40.128051: Pseudo dice [0.8242] 
2023-08-08 01:45:40.128100: Epoch time: 63.39 s 
2023-08-08 01:45:41.134543:  
2023-08-08 01:45:41.134650: Epoch 852 
2023-08-08 01:45:41.134737: Current learning rate: 0.00061 
2023-08-08 01:46:44.493828: train_loss -0.3404 
2023-08-08 01:46:44.493983: val_loss -0.3901 
2023-08-08 01:46:44.494035: Pseudo dice [0.8252] 
2023-08-08 01:46:44.494101: Epoch time: 63.36 s 
2023-08-08 01:46:45.528999:  
2023-08-08 01:46:45.529284: Epoch 853 
2023-08-08 01:46:45.529469: Current learning rate: 0.00061 
2023-08-08 01:47:49.017588: train_loss -0.3626 
2023-08-08 01:47:49.017734: val_loss -0.3805 
2023-08-08 01:47:49.017802: Pseudo dice [0.8789] 
2023-08-08 01:47:49.017852: Epoch time: 63.49 s 
2023-08-08 01:47:50.017054:  
2023-08-08 01:47:50.017245: Epoch 854 
2023-08-08 01:47:50.017506: Current learning rate: 0.00061 
2023-08-08 01:48:53.414654: train_loss -0.375 
2023-08-08 01:48:53.414822: val_loss -0.3745 
2023-08-08 01:48:53.414877: Pseudo dice [0.8333] 
2023-08-08 01:48:53.414929: Epoch time: 63.4 s 
2023-08-08 01:48:54.577559:  
2023-08-08 01:48:54.577664: Epoch 855 
2023-08-08 01:48:54.577739: Current learning rate: 0.00061 
2023-08-08 01:49:58.225596: train_loss -0.3747 
2023-08-08 01:49:58.225864: val_loss -0.284 
2023-08-08 01:49:58.225920: Pseudo dice [0.7371] 
2023-08-08 01:49:58.225971: Epoch time: 63.65 s 
2023-08-08 01:49:59.239472:  
2023-08-08 01:49:59.239576: Epoch 856 
2023-08-08 01:49:59.239667: Current learning rate: 0.0006 
2023-08-08 01:51:02.787092: train_loss -0.3523 
2023-08-08 01:51:02.787268: val_loss -0.3638 
2023-08-08 01:51:02.787323: Pseudo dice [0.862] 
2023-08-08 01:51:02.787375: Epoch time: 63.55 s 
2023-08-08 01:51:03.812231:  
2023-08-08 01:51:03.812335: Epoch 857 
2023-08-08 01:51:03.812411: Current learning rate: 0.0006 
2023-08-08 01:52:07.302557: train_loss -0.3165 
2023-08-08 01:52:07.302714: val_loss -0.4132 
2023-08-08 01:52:07.302764: Pseudo dice [0.8401] 
2023-08-08 01:52:07.302830: Epoch time: 63.49 s 
2023-08-08 01:52:08.329066:  
2023-08-08 01:52:08.329279: Epoch 858 
2023-08-08 01:52:08.329358: Current learning rate: 0.0006 
2023-08-08 01:53:11.771888: train_loss -0.388 
2023-08-08 01:53:11.772038: val_loss -0.3978 
2023-08-08 01:53:11.772089: Pseudo dice [0.8529] 
2023-08-08 01:53:11.772138: Epoch time: 63.44 s 
2023-08-08 01:53:12.812054:  
2023-08-08 01:53:12.812154: Epoch 859 
2023-08-08 01:53:12.812244: Current learning rate: 0.0006 
2023-08-08 01:54:16.266578: train_loss -0.3419 
2023-08-08 01:54:16.266727: val_loss -0.3555 
2023-08-08 01:54:16.266777: Pseudo dice [0.8961] 
2023-08-08 01:54:16.266828: Epoch time: 63.46 s 
2023-08-08 01:54:17.475745:  
2023-08-08 01:54:17.475842: Epoch 860 
2023-08-08 01:54:17.475958: Current learning rate: 0.0006 
2023-08-08 01:55:21.200959: train_loss -0.3714 
2023-08-08 01:55:21.201095: val_loss -0.307 
2023-08-08 01:55:21.201142: Pseudo dice [0.8069] 
2023-08-08 01:55:21.201207: Epoch time: 63.73 s 
2023-08-08 01:55:22.201684:  
2023-08-08 01:55:22.201783: Epoch 861 
2023-08-08 01:55:22.201853: Current learning rate: 0.0006 
2023-08-08 01:56:25.682486: train_loss -0.3315 
2023-08-08 01:56:25.682646: val_loss -0.3971 
2023-08-08 01:56:25.682707: Pseudo dice [0.872] 
2023-08-08 01:56:25.682764: Epoch time: 63.48 s 
2023-08-08 01:56:26.726061:  
2023-08-08 01:56:26.726325: Epoch 862 
2023-08-08 01:56:26.726520: Current learning rate: 0.0006 
2023-08-08 01:57:30.035925: train_loss -0.3452 
2023-08-08 01:57:30.036086: val_loss -0.3717 
2023-08-08 01:57:30.036139: Pseudo dice [0.7827] 
2023-08-08 01:57:30.036190: Epoch time: 63.31 s 
2023-08-08 01:57:31.040133:  
2023-08-08 01:57:31.040491: Epoch 863 
2023-08-08 01:57:31.040590: Current learning rate: 0.0006 
2023-08-08 01:58:34.296849: train_loss -0.3462 
2023-08-08 01:58:34.297125: val_loss -0.3976 
2023-08-08 01:58:34.297219: Pseudo dice [0.8971] 
2023-08-08 01:58:34.297311: Epoch time: 63.26 s 
2023-08-08 01:58:35.385092:  
2023-08-08 01:58:35.385186: Epoch 864 
2023-08-08 01:58:35.385257: Current learning rate: 0.0006 
2023-08-08 01:59:38.794744: train_loss -0.3615 
2023-08-08 01:59:38.794897: val_loss -0.3613 
2023-08-08 01:59:38.794950: Pseudo dice [0.8429] 
2023-08-08 01:59:38.795017: Epoch time: 63.41 s 
2023-08-08 01:59:39.805114:  
2023-08-08 01:59:39.805211: Epoch 865 
2023-08-08 01:59:39.805300: Current learning rate: 0.0006 
2023-08-08 02:00:43.219025: train_loss -0.3656 
2023-08-08 02:00:43.219178: val_loss -0.3692 
2023-08-08 02:00:43.219229: Pseudo dice [0.8886] 
2023-08-08 02:00:43.219278: Epoch time: 63.41 s 
2023-08-08 02:00:44.418654:  
2023-08-08 02:00:44.418758: Epoch 866 
2023-08-08 02:00:44.418848: Current learning rate: 0.0006 
2023-08-08 02:01:47.742044: train_loss -0.35 
2023-08-08 02:01:47.742198: val_loss -0.3619 
2023-08-08 02:01:47.742255: Pseudo dice [0.8015] 
2023-08-08 02:01:47.742305: Epoch time: 63.32 s 
2023-08-08 02:01:48.769195:  
2023-08-08 02:01:48.769298: Epoch 867 
2023-08-08 02:01:48.769386: Current learning rate: 0.0006 
2023-08-08 02:02:52.164799: train_loss -0.3184 
2023-08-08 02:02:52.164978: val_loss -0.477 
2023-08-08 02:02:52.165031: Pseudo dice [0.8176] 
2023-08-08 02:02:52.165082: Epoch time: 63.4 s 
2023-08-08 02:02:53.171370:  
2023-08-08 02:02:53.171464: Epoch 868 
2023-08-08 02:02:53.171559: Current learning rate: 0.0006 
2023-08-08 02:03:56.556734: train_loss -0.3508 
2023-08-08 02:03:56.556894: val_loss -0.3229 
2023-08-08 02:03:56.556944: Pseudo dice [0.783] 
2023-08-08 02:03:56.557018: Epoch time: 63.39 s 
2023-08-08 02:03:57.558459:  
2023-08-08 02:03:57.558740: Epoch 869 
2023-08-08 02:03:57.558902: Current learning rate: 0.0006 
2023-08-08 02:05:01.144875: train_loss -0.3303 
2023-08-08 02:05:01.145034: val_loss -0.3819 
2023-08-08 02:05:01.145097: Pseudo dice [0.8542] 
2023-08-08 02:05:01.145164: Epoch time: 63.59 s 
2023-08-08 02:05:02.152854:  
2023-08-08 02:05:02.152947: Epoch 870 
2023-08-08 02:05:02.153044: Current learning rate: 0.0006 
2023-08-08 02:06:05.749864: train_loss -0.3446 
2023-08-08 02:06:05.750009: val_loss -0.3704 
2023-08-08 02:06:05.750062: Pseudo dice [0.8285] 
2023-08-08 02:06:05.750112: Epoch time: 63.6 s 
2023-08-08 02:06:06.963435:  
2023-08-08 02:06:06.963533: Epoch 871 
2023-08-08 02:06:06.963628: Current learning rate: 0.0006 
2023-08-08 02:07:10.538438: train_loss -0.3349 
2023-08-08 02:07:10.538585: val_loss -0.3283 
2023-08-08 02:07:10.538635: Pseudo dice [0.829] 
2023-08-08 02:07:10.538684: Epoch time: 63.58 s 
2023-08-08 02:07:11.544391:  
2023-08-08 02:07:11.544597: Epoch 872 
2023-08-08 02:07:11.544674: Current learning rate: 0.0006 
2023-08-08 02:08:14.902084: train_loss -0.3445 
2023-08-08 02:08:14.902249: val_loss -0.4293 
2023-08-08 02:08:14.902307: Pseudo dice [0.855] 
2023-08-08 02:08:14.902357: Epoch time: 63.36 s 
2023-08-08 02:08:15.908452:  
2023-08-08 02:08:15.908553: Epoch 873 
2023-08-08 02:08:15.908626: Current learning rate: 0.0006 
2023-08-08 02:09:19.310574: train_loss -0.3618 
2023-08-08 02:09:19.310724: val_loss -0.4285 
2023-08-08 02:09:19.310775: Pseudo dice [0.8917] 
2023-08-08 02:09:19.310827: Epoch time: 63.4 s 
2023-08-08 02:09:20.315763:  
2023-08-08 02:09:20.315963: Epoch 874 
2023-08-08 02:09:20.316041: Current learning rate: 0.0006 
2023-08-08 02:10:23.853266: train_loss -0.3571 
2023-08-08 02:10:23.853420: val_loss -0.3226 
2023-08-08 02:10:23.853475: Pseudo dice [0.7354] 
2023-08-08 02:10:23.853525: Epoch time: 63.54 s 
2023-08-08 02:10:24.890719:  
2023-08-08 02:10:24.890813: Epoch 875 
2023-08-08 02:10:24.890885: Current learning rate: 0.0006 
2023-08-08 02:11:28.319319: train_loss -0.3498 
2023-08-08 02:11:28.319833: val_loss -0.412 
2023-08-08 02:11:28.320040: Pseudo dice [0.8145] 
2023-08-08 02:11:28.320189: Epoch time: 63.43 s 
2023-08-08 02:11:29.390665:  
2023-08-08 02:11:29.390770: Epoch 876 
2023-08-08 02:11:29.390841: Current learning rate: 0.0006 
2023-08-08 02:12:32.745896: train_loss -0.323 
2023-08-08 02:12:32.746041: val_loss -0.4329 
2023-08-08 02:12:32.746091: Pseudo dice [0.8514] 
2023-08-08 02:12:32.746141: Epoch time: 63.36 s 
2023-08-08 02:12:33.926942:  
2023-08-08 02:12:33.927041: Epoch 877 
2023-08-08 02:12:33.927115: Current learning rate: 0.00059 
2023-08-08 02:13:37.481515: train_loss -0.3411 
2023-08-08 02:13:37.481668: val_loss -0.2603 
2023-08-08 02:13:37.481721: Pseudo dice [0.8094] 
2023-08-08 02:13:37.481771: Epoch time: 63.56 s 
2023-08-08 02:13:38.524103:  
2023-08-08 02:13:38.524199: Epoch 878 
2023-08-08 02:13:38.524274: Current learning rate: 0.00059 
2023-08-08 02:14:42.048775: train_loss -0.3838 
2023-08-08 02:14:42.048922: val_loss -0.3492 
2023-08-08 02:14:42.048975: Pseudo dice [0.799] 
2023-08-08 02:14:42.049025: Epoch time: 63.53 s 
2023-08-08 02:14:43.086287:  
2023-08-08 02:14:43.086383: Epoch 879 
2023-08-08 02:14:43.086473: Current learning rate: 0.00059 
2023-08-08 02:15:46.491349: train_loss -0.3281 
2023-08-08 02:15:46.491502: val_loss -0.3215 
2023-08-08 02:15:46.491563: Pseudo dice [0.7913] 
2023-08-08 02:15:46.491616: Epoch time: 63.41 s 
2023-08-08 02:15:47.522586:  
2023-08-08 02:15:47.522886: Epoch 880 
2023-08-08 02:15:47.522961: Current learning rate: 0.00059 
2023-08-08 02:16:51.120950: train_loss -0.339 
2023-08-08 02:16:51.121124: val_loss -0.3696 
2023-08-08 02:16:51.121177: Pseudo dice [0.8849] 
2023-08-08 02:16:51.121227: Epoch time: 63.6 s 
2023-08-08 02:16:52.127048:  
2023-08-08 02:16:52.127146: Epoch 881 
2023-08-08 02:16:52.127220: Current learning rate: 0.00059 
2023-08-08 02:17:55.531156: train_loss -0.3341 
2023-08-08 02:17:55.531315: val_loss -0.3772 
2023-08-08 02:17:55.531368: Pseudo dice [0.8339] 
2023-08-08 02:17:55.531438: Epoch time: 63.4 s 
2023-08-08 02:17:56.532252:  
2023-08-08 02:17:56.532461: Epoch 882 
2023-08-08 02:17:56.532554: Current learning rate: 0.00059 
2023-08-08 02:18:59.896588: train_loss -0.3407 
2023-08-08 02:18:59.896741: val_loss -0.3481 
2023-08-08 02:18:59.896793: Pseudo dice [0.8587] 
2023-08-08 02:18:59.896842: Epoch time: 63.37 s 
2023-08-08 02:19:01.065754:  
2023-08-08 02:19:01.065871: Epoch 883 
2023-08-08 02:19:01.065944: Current learning rate: 0.00059 
2023-08-08 02:20:04.538271: train_loss -0.35 
2023-08-08 02:20:04.538425: val_loss -0.2973 
2023-08-08 02:20:04.538563: Pseudo dice [0.8367] 
2023-08-08 02:20:04.538619: Epoch time: 63.47 s 
2023-08-08 02:20:05.579366:  
2023-08-08 02:20:05.579458: Epoch 884 
2023-08-08 02:20:05.579546: Current learning rate: 0.00059 
2023-08-08 02:21:08.919859: train_loss -0.3612 
2023-08-08 02:21:08.920145: val_loss -0.3305 
2023-08-08 02:21:08.920201: Pseudo dice [0.8321] 
2023-08-08 02:21:08.920253: Epoch time: 63.34 s 
2023-08-08 02:21:09.937595:  
2023-08-08 02:21:09.937695: Epoch 885 
2023-08-08 02:21:09.937768: Current learning rate: 0.00059 
2023-08-08 02:22:13.438524: train_loss -0.3607 
2023-08-08 02:22:13.438671: val_loss -0.3393 
2023-08-08 02:22:13.438723: Pseudo dice [0.8219] 
2023-08-08 02:22:13.438774: Epoch time: 63.5 s 
2023-08-08 02:22:14.448956:  
2023-08-08 02:22:14.449054: Epoch 886 
2023-08-08 02:22:14.449127: Current learning rate: 0.00059 
2023-08-08 02:23:18.002367: train_loss -0.3498 
2023-08-08 02:23:18.002512: val_loss -0.3867 
2023-08-08 02:23:18.002560: Pseudo dice [0.8461] 
2023-08-08 02:23:18.002627: Epoch time: 63.55 s 
2023-08-08 02:23:19.051097:  
2023-08-08 02:23:19.051192: Epoch 887 
2023-08-08 02:23:19.051262: Current learning rate: 0.00059 
2023-08-08 02:24:22.470282: train_loss -0.3552 
2023-08-08 02:24:22.470434: val_loss -0.39 
2023-08-08 02:24:22.470643: Pseudo dice [0.8279] 
2023-08-08 02:24:22.470697: Epoch time: 63.42 s 
2023-08-08 02:24:23.479783:  
2023-08-08 02:24:23.479876: Epoch 888 
2023-08-08 02:24:23.479964: Current learning rate: 0.00059 
2023-08-08 02:25:26.915220: train_loss -0.3549 
2023-08-08 02:25:26.915371: val_loss -0.3852 
2023-08-08 02:25:26.915423: Pseudo dice [0.8201] 
2023-08-08 02:25:26.915474: Epoch time: 63.44 s 
2023-08-08 02:25:28.072061:  
2023-08-08 02:25:28.072333: Epoch 889 
2023-08-08 02:25:28.072500: Current learning rate: 0.00059 
2023-08-08 02:26:31.510992: train_loss -0.3634 
2023-08-08 02:26:31.511146: val_loss -0.3116 
2023-08-08 02:26:31.511194: Pseudo dice [0.8347] 
2023-08-08 02:26:31.511259: Epoch time: 63.44 s 
2023-08-08 02:26:32.503557:  
2023-08-08 02:26:32.503879: Epoch 890 
2023-08-08 02:26:32.503958: Current learning rate: 0.00059 
2023-08-08 02:27:36.065243: train_loss -0.34 
2023-08-08 02:27:36.065396: val_loss -0.3839 
2023-08-08 02:27:36.065447: Pseudo dice [0.7845] 
2023-08-08 02:27:36.065515: Epoch time: 63.56 s 
2023-08-08 02:27:37.092770:  
2023-08-08 02:27:37.092987: Epoch 891 
2023-08-08 02:27:37.093116: Current learning rate: 0.00059 
2023-08-08 02:28:40.521703: train_loss -0.3625 
2023-08-08 02:28:40.521849: val_loss -0.3641 
2023-08-08 02:28:40.521898: Pseudo dice [0.8354] 
2023-08-08 02:28:40.521948: Epoch time: 63.43 s 
2023-08-08 02:28:41.516503:  
2023-08-08 02:28:41.516602: Epoch 892 
2023-08-08 02:28:41.516673: Current learning rate: 0.00059 
2023-08-08 02:29:44.792851: train_loss -0.3668 
2023-08-08 02:29:44.793004: val_loss -0.381 
2023-08-08 02:29:44.793056: Pseudo dice [0.9098] 
2023-08-08 02:29:44.793125: Epoch time: 63.28 s 
2023-08-08 02:29:45.804224:  
2023-08-08 02:29:45.804396: Epoch 893 
2023-08-08 02:29:45.804473: Current learning rate: 0.00059 
2023-08-08 02:30:49.193615: train_loss -0.326 
2023-08-08 02:30:49.193765: val_loss -0.3273 
2023-08-08 02:30:49.193819: Pseudo dice [0.8481] 
2023-08-08 02:30:49.193888: Epoch time: 63.39 s 
2023-08-08 02:30:50.186500:  
2023-08-08 02:30:50.186802: Epoch 894 
2023-08-08 02:30:50.186880: Current learning rate: 0.00059 
2023-08-08 02:31:53.541947: train_loss -0.3404 
2023-08-08 02:31:53.542103: val_loss -0.3126 
2023-08-08 02:31:53.542170: Pseudo dice [0.828] 
2023-08-08 02:31:53.542220: Epoch time: 63.36 s 
2023-08-08 02:31:54.692074:  
2023-08-08 02:31:54.692466: Epoch 895 
2023-08-08 02:31:54.692564: Current learning rate: 0.00059 
2023-08-08 02:32:58.241862: train_loss -0.3342 
2023-08-08 02:32:58.242015: val_loss -0.3605 
2023-08-08 02:32:58.242065: Pseudo dice [0.7538] 
2023-08-08 02:32:58.242115: Epoch time: 63.55 s 
2023-08-08 02:32:59.266868:  
2023-08-08 02:32:59.267094: Epoch 896 
2023-08-08 02:32:59.267174: Current learning rate: 0.00059 
2023-08-08 02:34:02.715216: train_loss -0.3423 
2023-08-08 02:34:02.715377: val_loss -0.325 
2023-08-08 02:34:02.715429: Pseudo dice [0.7939] 
2023-08-08 02:34:02.715479: Epoch time: 63.45 s 
2023-08-08 02:34:03.758383:  
2023-08-08 02:34:03.758564: Epoch 897 
2023-08-08 02:34:03.758655: Current learning rate: 0.00059 
2023-08-08 02:35:07.215475: train_loss -0.3433 
2023-08-08 02:35:07.215635: val_loss -0.2936 
2023-08-08 02:35:07.215689: Pseudo dice [0.7709] 
2023-08-08 02:35:07.215740: Epoch time: 63.46 s 
2023-08-08 02:35:08.250966:  
2023-08-08 02:35:08.251109: Epoch 898 
2023-08-08 02:35:08.251237: Current learning rate: 0.00058 
2023-08-08 02:36:11.765575: train_loss -0.3471 
2023-08-08 02:36:11.765716: val_loss -0.3709 
2023-08-08 02:36:11.765784: Pseudo dice [0.7886] 
2023-08-08 02:36:11.765835: Epoch time: 63.52 s 
2023-08-08 02:36:12.787096:  
2023-08-08 02:36:12.787192: Epoch 899 
2023-08-08 02:36:12.787263: Current learning rate: 0.00058 
2023-08-08 02:37:16.234859: train_loss -0.3646 
2023-08-08 02:37:16.235008: val_loss -0.3859 
2023-08-08 02:37:16.235076: Pseudo dice [0.8986] 
2023-08-08 02:37:16.235125: Epoch time: 63.45 s 
2023-08-08 02:37:17.618377:  
2023-08-08 02:37:17.618468: Epoch 900 
2023-08-08 02:37:17.618556: Current learning rate: 0.00058 
2023-08-08 02:38:21.124460: train_loss -0.381 
2023-08-08 02:38:21.124603: val_loss -0.3359 
2023-08-08 02:38:21.124653: Pseudo dice [0.8836] 
2023-08-08 02:38:21.124702: Epoch time: 63.51 s 
2023-08-08 02:38:22.280400:  
2023-08-08 02:38:22.280504: Epoch 901 
2023-08-08 02:38:22.280608: Current learning rate: 0.00058 
2023-08-08 02:39:25.775273: train_loss -0.3153 
2023-08-08 02:39:25.775423: val_loss -0.3735 
2023-08-08 02:39:25.775475: Pseudo dice [0.8863] 
2023-08-08 02:39:25.775541: Epoch time: 63.5 s 
2023-08-08 02:39:26.784876:  
2023-08-08 02:39:26.785041: Epoch 902 
2023-08-08 02:39:26.785183: Current learning rate: 0.00058 
2023-08-08 02:40:30.280712: train_loss -0.3715 
2023-08-08 02:40:30.280858: val_loss -0.3736 
2023-08-08 02:40:30.280910: Pseudo dice [0.796] 
2023-08-08 02:40:30.280960: Epoch time: 63.5 s 
2023-08-08 02:40:31.313466:  
2023-08-08 02:40:31.313624: Epoch 903 
2023-08-08 02:40:31.313796: Current learning rate: 0.00058 
2023-08-08 02:41:34.659539: train_loss -0.3531 
2023-08-08 02:41:34.659712: val_loss -0.3303 
2023-08-08 02:41:34.659766: Pseudo dice [0.8734] 
2023-08-08 02:41:34.659815: Epoch time: 63.35 s 
2023-08-08 02:41:35.707013:  
2023-08-08 02:41:35.707110: Epoch 904 
2023-08-08 02:41:35.707200: Current learning rate: 0.00058 
2023-08-08 02:42:39.212576: train_loss -0.3434 
2023-08-08 02:42:39.212730: val_loss -0.4417 
2023-08-08 02:42:39.212782: Pseudo dice [0.8569] 
2023-08-08 02:42:39.212833: Epoch time: 63.51 s 
2023-08-08 02:42:40.208483:  
2023-08-08 02:42:40.208579: Epoch 905 
2023-08-08 02:42:40.208677: Current learning rate: 0.00058 
2023-08-08 02:43:43.496934: train_loss -0.3702 
2023-08-08 02:43:43.497079: val_loss -0.3454 
2023-08-08 02:43:43.497129: Pseudo dice [0.8315] 
2023-08-08 02:43:43.497179: Epoch time: 63.29 s 
2023-08-08 02:43:44.684927:  
2023-08-08 02:43:44.685038: Epoch 906 
2023-08-08 02:43:44.685128: Current learning rate: 0.00058 
2023-08-08 02:44:48.226093: train_loss -0.3523 
2023-08-08 02:44:48.226236: val_loss -0.4221 
2023-08-08 02:44:48.226290: Pseudo dice [0.8552] 
2023-08-08 02:44:48.226356: Epoch time: 63.54 s 
2023-08-08 02:44:49.258909:  
2023-08-08 02:44:49.259003: Epoch 907 
2023-08-08 02:44:49.259076: Current learning rate: 0.00058 
2023-08-08 02:45:52.614600: train_loss -0.3329 
2023-08-08 02:45:52.614774: val_loss -0.3954 
2023-08-08 02:45:52.614827: Pseudo dice [0.7828] 
2023-08-08 02:45:52.614878: Epoch time: 63.36 s 
2023-08-08 02:45:53.634601:  
2023-08-08 02:45:53.634706: Epoch 908 
2023-08-08 02:45:53.634796: Current learning rate: 0.00058 
2023-08-08 02:46:57.036144: train_loss -0.3903 
2023-08-08 02:46:57.036296: val_loss -0.3009 
2023-08-08 02:46:57.036350: Pseudo dice [0.7591] 
2023-08-08 02:46:57.036401: Epoch time: 63.4 s 
2023-08-08 02:46:58.040155:  
2023-08-08 02:46:58.040259: Epoch 909 
2023-08-08 02:46:58.040333: Current learning rate: 0.00058 
2023-08-08 02:48:01.275034: train_loss -0.3682 
2023-08-08 02:48:01.275188: val_loss -0.3662 
2023-08-08 02:48:01.275241: Pseudo dice [0.7675] 
2023-08-08 02:48:01.275307: Epoch time: 63.24 s 
2023-08-08 02:48:02.325464:  
2023-08-08 02:48:02.325711: Epoch 910 
2023-08-08 02:48:02.325912: Current learning rate: 0.00058 
2023-08-08 02:49:05.581456: train_loss -0.3415 
2023-08-08 02:49:05.581622: val_loss -0.3375 
2023-08-08 02:49:05.581672: Pseudo dice [0.8173] 
2023-08-08 02:49:05.581723: Epoch time: 63.26 s 
2023-08-08 02:49:06.614534:  
2023-08-08 02:49:06.614629: Epoch 911 
2023-08-08 02:49:06.614717: Current learning rate: 0.00058 
2023-08-08 02:50:09.975259: train_loss -0.3287 
2023-08-08 02:50:09.975411: val_loss -0.3141 
2023-08-08 02:50:09.975478: Pseudo dice [0.7829] 
2023-08-08 02:50:09.975529: Epoch time: 63.36 s 
2023-08-08 02:50:11.138599:  
2023-08-08 02:50:11.138885: Epoch 912 
2023-08-08 02:50:11.139045: Current learning rate: 0.00058 
2023-08-08 02:51:14.633875: train_loss -0.3585 
2023-08-08 02:51:14.634020: val_loss -0.4161 
2023-08-08 02:51:14.634068: Pseudo dice [0.7352] 
2023-08-08 02:51:14.634133: Epoch time: 63.5 s 
2023-08-08 02:51:15.628088:  
2023-08-08 02:51:15.628188: Epoch 913 
2023-08-08 02:51:15.628262: Current learning rate: 0.00058 
2023-08-08 02:52:19.009263: train_loss -0.3586 
2023-08-08 02:52:19.009421: val_loss -0.4047 
2023-08-08 02:52:19.011381: Pseudo dice [0.8922] 
2023-08-08 02:52:19.011474: Epoch time: 63.38 s 
2023-08-08 02:52:20.005033:  
2023-08-08 02:52:20.005265: Epoch 914 
2023-08-08 02:52:20.005477: Current learning rate: 0.00058 
2023-08-08 02:53:23.320433: train_loss -0.3412 
2023-08-08 02:53:23.320588: val_loss -0.3428 
2023-08-08 02:53:23.320638: Pseudo dice [0.7684] 
2023-08-08 02:53:23.320690: Epoch time: 63.32 s 
2023-08-08 02:53:24.319927:  
2023-08-08 02:53:24.320031: Epoch 915 
2023-08-08 02:53:24.320107: Current learning rate: 0.00058 
2023-08-08 02:54:27.859797: train_loss -0.3644 
2023-08-08 02:54:27.859943: val_loss -0.4113 
2023-08-08 02:54:27.859995: Pseudo dice [0.8562] 
2023-08-08 02:54:27.860045: Epoch time: 63.54 s 
2023-08-08 02:54:28.852787:  
2023-08-08 02:54:28.853085: Epoch 916 
2023-08-08 02:54:28.853256: Current learning rate: 0.00058 
2023-08-08 02:55:32.282403: train_loss -0.347 
2023-08-08 02:55:32.282556: val_loss -0.3483 
2023-08-08 02:55:32.282608: Pseudo dice [0.7777] 
2023-08-08 02:55:32.282659: Epoch time: 63.43 s 
2023-08-08 02:55:33.283336:  
2023-08-08 02:55:33.283432: Epoch 917 
2023-08-08 02:55:33.283523: Current learning rate: 0.00058 
2023-08-08 02:56:36.781616: train_loss -0.3662 
2023-08-08 02:56:36.781758: val_loss -0.3482 
2023-08-08 02:56:36.781809: Pseudo dice [0.7753] 
2023-08-08 02:56:36.781859: Epoch time: 63.5 s 
2023-08-08 02:56:38.003569:  
2023-08-08 02:56:38.003669: Epoch 918 
2023-08-08 02:56:38.003757: Current learning rate: 0.00058 
2023-08-08 02:57:41.542157: train_loss -0.3473 
2023-08-08 02:57:41.542315: val_loss -0.3836 
2023-08-08 02:57:41.542382: Pseudo dice [0.773] 
2023-08-08 02:57:41.542433: Epoch time: 63.54 s 
2023-08-08 02:57:42.537417:  
2023-08-08 02:57:42.537673: Epoch 919 
2023-08-08 02:57:42.537862: Current learning rate: 0.00057 
2023-08-08 02:58:46.191026: train_loss -0.3602 
2023-08-08 02:58:46.191175: val_loss -0.3568 
2023-08-08 02:58:46.191229: Pseudo dice [0.8208] 
2023-08-08 02:58:46.191287: Epoch time: 63.65 s 
2023-08-08 02:58:47.188621:  
2023-08-08 02:58:47.188720: Epoch 920 
2023-08-08 02:58:47.188819: Current learning rate: 0.00057 
2023-08-08 02:59:50.605690: train_loss -0.3547 
2023-08-08 02:59:50.605848: val_loss -0.3097 
2023-08-08 02:59:50.605905: Pseudo dice [0.7766] 
2023-08-08 02:59:50.605955: Epoch time: 63.42 s 
2023-08-08 02:59:51.629031:  
2023-08-08 02:59:51.629131: Epoch 921 
2023-08-08 02:59:51.629221: Current learning rate: 0.00057 
2023-08-08 03:00:55.168384: train_loss -0.3252 
2023-08-08 03:00:55.168542: val_loss -0.4252 
2023-08-08 03:00:55.168596: Pseudo dice [0.7253] 
2023-08-08 03:00:55.168647: Epoch time: 63.54 s 
2023-08-08 03:00:56.166833:  
2023-08-08 03:00:56.166926: Epoch 922 
2023-08-08 03:00:56.167013: Current learning rate: 0.00057 
2023-08-08 03:01:59.493661: train_loss -0.3561 
2023-08-08 03:01:59.493817: val_loss -0.3939 
2023-08-08 03:01:59.493886: Pseudo dice [0.8314] 
2023-08-08 03:01:59.493936: Epoch time: 63.33 s 
2023-08-08 03:02:00.502830:  
2023-08-08 03:02:00.503092: Epoch 923 
2023-08-08 03:02:00.503264: Current learning rate: 0.00057 
2023-08-08 03:03:04.000257: train_loss -0.3666 
2023-08-08 03:03:04.000405: val_loss -0.3236 
2023-08-08 03:03:04.000455: Pseudo dice [0.7629] 
2023-08-08 03:03:04.000504: Epoch time: 63.5 s 
2023-08-08 03:03:05.167010:  
2023-08-08 03:03:05.167113: Epoch 924 
2023-08-08 03:03:05.167183: Current learning rate: 0.00057 
2023-08-08 03:04:08.651049: train_loss -0.323 
2023-08-08 03:04:08.651213: val_loss -0.3394 
2023-08-08 03:04:08.651270: Pseudo dice [0.7964] 
2023-08-08 03:04:08.651321: Epoch time: 63.48 s 
2023-08-08 03:04:09.646406:  
2023-08-08 03:04:09.646617: Epoch 925 
2023-08-08 03:04:09.646711: Current learning rate: 0.00057 
2023-08-08 03:05:13.061575: train_loss -0.3377 
2023-08-08 03:05:13.061736: val_loss -0.2902 
2023-08-08 03:05:13.061790: Pseudo dice [0.7211] 
2023-08-08 03:05:13.061841: Epoch time: 63.42 s 
2023-08-08 03:05:14.085745:  
2023-08-08 03:05:14.085856: Epoch 926 
2023-08-08 03:05:14.085931: Current learning rate: 0.00057 
2023-08-08 03:06:17.565478: train_loss -0.3549 
2023-08-08 03:06:17.565626: val_loss -0.351 
2023-08-08 03:06:17.565676: Pseudo dice [0.8166] 
2023-08-08 03:06:17.565727: Epoch time: 63.48 s 
2023-08-08 03:06:18.582458:  
2023-08-08 03:06:18.582572: Epoch 927 
2023-08-08 03:06:18.582650: Current learning rate: 0.00057 
2023-08-08 03:07:22.054248: train_loss -0.3728 
2023-08-08 03:07:22.054403: val_loss -0.2899 
2023-08-08 03:07:22.054470: Pseudo dice [0.7894] 
2023-08-08 03:07:22.054519: Epoch time: 63.47 s 
2023-08-08 03:07:23.069805:  
2023-08-08 03:07:23.069902: Epoch 928 
2023-08-08 03:07:23.069975: Current learning rate: 0.00057 
2023-08-08 03:08:26.648724: train_loss -0.3238 
2023-08-08 03:08:26.648870: val_loss -0.3813 
2023-08-08 03:08:26.648923: Pseudo dice [0.8803] 
2023-08-08 03:08:26.648972: Epoch time: 63.58 s 
2023-08-08 03:08:27.647625:  
2023-08-08 03:08:27.647838: Epoch 929 
2023-08-08 03:08:27.647929: Current learning rate: 0.00057 
2023-08-08 03:09:31.131852: train_loss -0.3598 
2023-08-08 03:09:31.132011: val_loss -0.3851 
2023-08-08 03:09:31.132064: Pseudo dice [0.9021] 
2023-08-08 03:09:31.132114: Epoch time: 63.48 s 
2023-08-08 03:09:32.332314:  
2023-08-08 03:09:32.332490: Epoch 930 
2023-08-08 03:09:32.332586: Current learning rate: 0.00057 
2023-08-08 03:10:35.946264: train_loss -0.3678 
2023-08-08 03:10:35.946411: val_loss -0.401 
2023-08-08 03:10:35.946459: Pseudo dice [0.7991] 
2023-08-08 03:10:35.946526: Epoch time: 63.61 s 
2023-08-08 03:10:36.979175:  
2023-08-08 03:10:36.979277: Epoch 931 
2023-08-08 03:10:36.979352: Current learning rate: 0.00057 
2023-08-08 03:11:40.560474: train_loss -0.3522 
2023-08-08 03:11:40.560632: val_loss -0.4026 
2023-08-08 03:11:40.560689: Pseudo dice [0.8364] 
2023-08-08 03:11:40.560739: Epoch time: 63.58 s 
2023-08-08 03:11:41.639795:  
2023-08-08 03:11:41.639897: Epoch 932 
2023-08-08 03:11:41.639988: Current learning rate: 0.00057 
2023-08-08 03:12:45.109171: train_loss -0.3662 
2023-08-08 03:12:45.109336: val_loss -0.4053 
2023-08-08 03:12:45.109407: Pseudo dice [0.8556] 
2023-08-08 03:12:45.109456: Epoch time: 63.47 s 
2023-08-08 03:12:46.123169:  
2023-08-08 03:12:46.123265: Epoch 933 
2023-08-08 03:12:46.123366: Current learning rate: 0.00057 
2023-08-08 03:13:49.773760: train_loss -0.3408 
2023-08-08 03:13:49.773916: val_loss -0.3933 
2023-08-08 03:13:49.773969: Pseudo dice [0.8817] 
2023-08-08 03:13:49.774020: Epoch time: 63.65 s 
2023-08-08 03:13:50.769266:  
2023-08-08 03:13:50.769490: Epoch 934 
2023-08-08 03:13:50.769647: Current learning rate: 0.00057 
2023-08-08 03:14:54.126230: train_loss -0.3339 
2023-08-08 03:14:54.126505: val_loss -0.3959 
2023-08-08 03:14:54.126623: Pseudo dice [0.8385] 
2023-08-08 03:14:54.126676: Epoch time: 63.36 s 
2023-08-08 03:14:55.127270:  
2023-08-08 03:14:55.127376: Epoch 935 
2023-08-08 03:14:55.127462: Current learning rate: 0.00057 
2023-08-08 03:15:58.554447: train_loss -0.368 
2023-08-08 03:15:58.554598: val_loss -0.3432 
2023-08-08 03:15:58.554647: Pseudo dice [0.7767] 
2023-08-08 03:15:58.554715: Epoch time: 63.43 s 
2023-08-08 03:15:59.754503:  
2023-08-08 03:15:59.754616: Epoch 936 
2023-08-08 03:15:59.754698: Current learning rate: 0.00057 
2023-08-08 03:17:03.312721: train_loss -0.3607 
2023-08-08 03:17:03.312895: val_loss -0.3504 
2023-08-08 03:17:03.312948: Pseudo dice [0.7738] 
2023-08-08 03:17:03.312999: Epoch time: 63.56 s 
2023-08-08 03:17:04.303903:  
2023-08-08 03:17:04.304248: Epoch 937 
2023-08-08 03:17:04.304328: Current learning rate: 0.00057 
2023-08-08 03:18:07.769258: train_loss -0.3303 
2023-08-08 03:18:07.769409: val_loss -0.3162 
2023-08-08 03:18:07.769478: Pseudo dice [0.8582] 
2023-08-08 03:18:07.769528: Epoch time: 63.47 s 
2023-08-08 03:18:08.778505:  
2023-08-08 03:18:08.778605: Epoch 938 
2023-08-08 03:18:08.778695: Current learning rate: 0.00057 
2023-08-08 03:19:12.235747: train_loss -0.3734 
2023-08-08 03:19:12.235899: val_loss -0.3308 
2023-08-08 03:19:12.235952: Pseudo dice [0.8426] 
2023-08-08 03:19:12.236003: Epoch time: 63.46 s 
2023-08-08 03:19:13.228278:  
2023-08-08 03:19:13.228553: Epoch 939 
2023-08-08 03:19:13.228716: Current learning rate: 0.00057 
2023-08-08 03:20:16.810243: train_loss -0.3557 
2023-08-08 03:20:16.810486: val_loss -0.3653 
2023-08-08 03:20:16.810539: Pseudo dice [0.8523] 
2023-08-08 03:20:16.810589: Epoch time: 63.58 s 
2023-08-08 03:20:17.806067:  
2023-08-08 03:20:17.806164: Epoch 940 
2023-08-08 03:20:17.806237: Current learning rate: 0.00056 
2023-08-08 03:21:21.333818: train_loss -0.3604 
2023-08-08 03:21:21.333969: val_loss -0.4124 
2023-08-08 03:21:21.334022: Pseudo dice [0.8274] 
2023-08-08 03:21:21.334073: Epoch time: 63.53 s 
2023-08-08 03:21:22.367220:  
2023-08-08 03:21:22.367315: Epoch 941 
2023-08-08 03:21:22.367385: Current learning rate: 0.00056 
2023-08-08 03:22:25.855754: train_loss -0.3581 
2023-08-08 03:22:25.855899: val_loss -0.3553 
2023-08-08 03:22:25.855948: Pseudo dice [0.8672] 
2023-08-08 03:22:25.855998: Epoch time: 63.49 s 
2023-08-08 03:22:27.021075:  
2023-08-08 03:22:27.021164: Epoch 942 
2023-08-08 03:22:27.021258: Current learning rate: 0.00056 
2023-08-08 03:23:30.501606: train_loss -0.3506 
2023-08-08 03:23:30.501751: val_loss -0.3909 
2023-08-08 03:23:30.501801: Pseudo dice [0.8083] 
2023-08-08 03:23:30.501852: Epoch time: 63.48 s 
2023-08-08 03:23:31.536774:  
2023-08-08 03:23:31.536878: Epoch 943 
2023-08-08 03:23:31.536952: Current learning rate: 0.00056 
2023-08-08 03:24:35.019885: train_loss -0.3845 
2023-08-08 03:24:35.020038: val_loss -0.399 
2023-08-08 03:24:35.020088: Pseudo dice [0.843] 
2023-08-08 03:24:35.020139: Epoch time: 63.48 s 
2023-08-08 03:24:36.051803:  
2023-08-08 03:24:36.052011: Epoch 944 
2023-08-08 03:24:36.052086: Current learning rate: 0.00056 
2023-08-08 03:25:39.507382: train_loss -0.348 
2023-08-08 03:25:39.507529: val_loss -0.4067 
2023-08-08 03:25:39.507607: Pseudo dice [0.8417] 
2023-08-08 03:25:39.507658: Epoch time: 63.46 s 
2023-08-08 03:25:40.509552:  
2023-08-08 03:25:40.509651: Epoch 945 
2023-08-08 03:25:40.509728: Current learning rate: 0.00056 
2023-08-08 03:26:43.952163: train_loss -0.3712 
2023-08-08 03:26:43.952326: val_loss -0.3411 
2023-08-08 03:26:43.952379: Pseudo dice [0.8907] 
2023-08-08 03:26:43.952430: Epoch time: 63.44 s 
2023-08-08 03:26:44.947808:  
2023-08-08 03:26:44.948015: Epoch 946 
2023-08-08 03:26:44.948091: Current learning rate: 0.00056 
2023-08-08 03:27:48.312997: train_loss -0.3472 
2023-08-08 03:27:48.313147: val_loss -0.3264 
2023-08-08 03:27:48.313197: Pseudo dice [0.8791] 
2023-08-08 03:27:48.313246: Epoch time: 63.37 s 
2023-08-08 03:27:49.348097:  
2023-08-08 03:27:49.348195: Epoch 947 
2023-08-08 03:27:49.348267: Current learning rate: 0.00056 
2023-08-08 03:28:52.827033: train_loss -0.352 
2023-08-08 03:28:52.827178: val_loss -0.3779 
2023-08-08 03:28:52.827245: Pseudo dice [0.841] 
2023-08-08 03:28:52.827295: Epoch time: 63.48 s 
2023-08-08 03:28:54.002793:  
2023-08-08 03:28:54.002890: Epoch 948 
2023-08-08 03:28:54.002963: Current learning rate: 0.00056 
2023-08-08 03:29:57.592584: train_loss -0.3529 
2023-08-08 03:29:57.592730: val_loss -0.364 
2023-08-08 03:29:57.592783: Pseudo dice [0.8516] 
2023-08-08 03:29:57.592834: Epoch time: 63.59 s 
2023-08-08 03:29:58.644785:  
2023-08-08 03:29:58.644895: Epoch 949 
2023-08-08 03:29:58.644984: Current learning rate: 0.00056 
2023-08-08 03:31:02.062141: train_loss -0.3508 
2023-08-08 03:31:02.062290: val_loss -0.3831 
2023-08-08 03:31:02.062340: Pseudo dice [0.8582] 
2023-08-08 03:31:02.062390: Epoch time: 63.42 s 
2023-08-08 03:31:02.503714: Yayy! New best EMA pseudo Dice: 0.8432 
2023-08-08 03:31:03.873104:  
2023-08-08 03:31:03.873471: Epoch 950 
2023-08-08 03:31:03.873550: Current learning rate: 0.00056 
2023-08-08 03:32:07.319348: train_loss -0.3573 
2023-08-08 03:32:07.319500: val_loss -0.3563 
2023-08-08 03:32:07.319575: Pseudo dice [0.8891] 
2023-08-08 03:32:07.319627: Epoch time: 63.45 s 
2023-08-08 03:32:07.319668: Yayy! New best EMA pseudo Dice: 0.8478 
2023-08-08 03:32:08.702426:  
2023-08-08 03:32:08.702527: Epoch 951 
2023-08-08 03:32:08.702615: Current learning rate: 0.00056 
2023-08-08 03:33:11.918558: train_loss -0.3605 
2023-08-08 03:33:11.918718: val_loss -0.4018 
2023-08-08 03:33:11.918769: Pseudo dice [0.8347] 
2023-08-08 03:33:11.918820: Epoch time: 63.22 s 
2023-08-08 03:33:12.915267:  
2023-08-08 03:33:12.915362: Epoch 952 
2023-08-08 03:33:12.915449: Current learning rate: 0.00056 
2023-08-08 03:34:16.469519: train_loss -0.3499 
2023-08-08 03:34:16.469675: val_loss -0.3982 
2023-08-08 03:34:16.469729: Pseudo dice [0.9036] 
2023-08-08 03:34:16.469779: Epoch time: 63.55 s 
2023-08-08 03:34:16.469819: Yayy! New best EMA pseudo Dice: 0.8522 
2023-08-08 03:34:17.913151:  
2023-08-08 03:34:17.913258: Epoch 953 
2023-08-08 03:34:17.913348: Current learning rate: 0.00056 
2023-08-08 03:35:21.559318: train_loss -0.3569 
2023-08-08 03:35:21.559482: val_loss -0.3102 
2023-08-08 03:35:21.559534: Pseudo dice [0.8536] 
2023-08-08 03:35:21.559595: Epoch time: 63.65 s 
2023-08-08 03:35:21.559636: Yayy! New best EMA pseudo Dice: 0.8523 
2023-08-08 03:35:22.944249:  
2023-08-08 03:35:22.944525: Epoch 954 
2023-08-08 03:35:22.944709: Current learning rate: 0.00056 
2023-08-08 03:36:26.379239: train_loss -0.3388 
2023-08-08 03:36:26.379401: val_loss -0.3055 
2023-08-08 03:36:26.379456: Pseudo dice [0.8285] 
2023-08-08 03:36:26.379508: Epoch time: 63.44 s 
2023-08-08 03:36:27.415398:  
2023-08-08 03:36:27.415494: Epoch 955 
2023-08-08 03:36:27.415570: Current learning rate: 0.00056 
2023-08-08 03:37:30.922180: train_loss -0.3355 
2023-08-08 03:37:30.922333: val_loss -0.3877 
2023-08-08 03:37:30.922401: Pseudo dice [0.8775] 
2023-08-08 03:37:30.922451: Epoch time: 63.51 s 
2023-08-08 03:37:30.922492: Yayy! New best EMA pseudo Dice: 0.8527 
2023-08-08 03:37:32.294858:  
2023-08-08 03:37:32.295065: Epoch 956 
2023-08-08 03:37:32.295158: Current learning rate: 0.00056 
2023-08-08 03:38:35.395929: train_loss -0.3566 
2023-08-08 03:38:35.396100: val_loss -0.3677 
2023-08-08 03:38:35.396156: Pseudo dice [0.7326] 
2023-08-08 03:38:35.396220: Epoch time: 63.1 s 
2023-08-08 03:38:36.410582:  
2023-08-08 03:38:36.410677: Epoch 957 
2023-08-08 03:38:36.410766: Current learning rate: 0.00056 
2023-08-08 03:39:39.913856: train_loss -0.358 
2023-08-08 03:39:39.914006: val_loss -0.4464 
2023-08-08 03:39:39.914054: Pseudo dice [0.8734] 
2023-08-08 03:39:39.914120: Epoch time: 63.5 s 
2023-08-08 03:39:40.959822:  
2023-08-08 03:39:40.959921: Epoch 958 
2023-08-08 03:39:40.960011: Current learning rate: 0.00056 
2023-08-08 03:40:44.441729: train_loss -0.3391 
2023-08-08 03:40:44.441878: val_loss -0.3051 
2023-08-08 03:40:44.441932: Pseudo dice [0.8292] 
2023-08-08 03:40:44.442003: Epoch time: 63.48 s 
2023-08-08 03:40:45.608747:  
2023-08-08 03:40:45.609157: Epoch 959 
2023-08-08 03:40:45.609237: Current learning rate: 0.00056 
2023-08-08 03:41:49.235934: train_loss -0.3637 
2023-08-08 03:41:49.236085: val_loss -0.4164 
2023-08-08 03:41:49.236138: Pseudo dice [0.8548] 
2023-08-08 03:41:49.236188: Epoch time: 63.63 s 
2023-08-08 03:41:50.294915:  
2023-08-08 03:41:50.295014: Epoch 960 
2023-08-08 03:41:50.295103: Current learning rate: 0.00056 
2023-08-08 03:42:53.804718: train_loss -0.3723 
2023-08-08 03:42:53.804911: val_loss -0.3607 
2023-08-08 03:42:53.804995: Pseudo dice [0.7244] 
2023-08-08 03:42:53.805077: Epoch time: 63.51 s 
2023-08-08 03:42:54.843018:  
2023-08-08 03:42:54.843115: Epoch 961 
2023-08-08 03:42:54.843203: Current learning rate: 0.00055 
2023-08-08 03:43:58.073018: train_loss -0.3668 
2023-08-08 03:43:58.073180: val_loss -0.327 
2023-08-08 03:43:58.073230: Pseudo dice [0.7656] 
2023-08-08 03:43:58.073283: Epoch time: 63.23 s 
2023-08-08 03:43:59.115999:  
2023-08-08 03:43:59.116106: Epoch 962 
2023-08-08 03:43:59.116194: Current learning rate: 0.00055 
2023-08-08 03:45:02.562971: train_loss -0.381 
2023-08-08 03:45:02.563122: val_loss -0.3224 
2023-08-08 03:45:02.563173: Pseudo dice [0.8621] 
2023-08-08 03:45:02.563224: Epoch time: 63.45 s 
2023-08-08 03:45:03.636242:  
2023-08-08 03:45:03.636345: Epoch 963 
2023-08-08 03:45:03.636419: Current learning rate: 0.00055 
2023-08-08 03:46:07.111333: train_loss -0.3362 
2023-08-08 03:46:07.111482: val_loss -0.429 
2023-08-08 03:46:07.111535: Pseudo dice [0.8348] 
2023-08-08 03:46:07.111613: Epoch time: 63.48 s 
2023-08-08 03:46:08.283860:  
2023-08-08 03:46:08.283973: Epoch 964 
2023-08-08 03:46:08.284046: Current learning rate: 0.00055 
2023-08-08 03:47:11.822713: train_loss -0.3804 
2023-08-08 03:47:11.822862: val_loss -0.3015 
2023-08-08 03:47:11.822912: Pseudo dice [0.7753] 
2023-08-08 03:47:11.822961: Epoch time: 63.54 s 
2023-08-08 03:47:12.833398:  
2023-08-08 03:47:12.833724: Epoch 965 
2023-08-08 03:47:12.833920: Current learning rate: 0.00055 
2023-08-08 03:48:16.235876: train_loss -0.349 
2023-08-08 03:48:16.236026: val_loss -0.3476 
2023-08-08 03:48:16.236077: Pseudo dice [0.8483] 
2023-08-08 03:48:16.236128: Epoch time: 63.4 s 
2023-08-08 03:48:17.259362:  
2023-08-08 03:48:17.259464: Epoch 966 
2023-08-08 03:48:17.259560: Current learning rate: 0.00055 
2023-08-08 03:49:20.791906: train_loss -0.3422 
2023-08-08 03:49:20.792060: val_loss -0.3115 
2023-08-08 03:49:20.792109: Pseudo dice [0.8233] 
2023-08-08 03:49:20.792157: Epoch time: 63.53 s 
2023-08-08 03:49:21.805360:  
2023-08-08 03:49:21.805457: Epoch 967 
2023-08-08 03:49:21.805530: Current learning rate: 0.00055 
2023-08-08 03:50:25.256883: train_loss -0.3184 
2023-08-08 03:50:25.257038: val_loss -0.3144 
2023-08-08 03:50:25.257090: Pseudo dice [0.8204] 
2023-08-08 03:50:25.257158: Epoch time: 63.45 s 
2023-08-08 03:50:26.295843:  
2023-08-08 03:50:26.295942: Epoch 968 
2023-08-08 03:50:26.296012: Current learning rate: 0.00055 
2023-08-08 03:51:29.660740: train_loss -0.347 
2023-08-08 03:51:29.660905: val_loss -0.3191 
2023-08-08 03:51:29.660958: Pseudo dice [0.6732] 
2023-08-08 03:51:29.661024: Epoch time: 63.37 s 
2023-08-08 03:51:30.699470:  
2023-08-08 03:51:30.699566: Epoch 969 
2023-08-08 03:51:30.699657: Current learning rate: 0.00055 
2023-08-08 03:52:34.062143: train_loss -0.3497 
2023-08-08 03:52:34.062294: val_loss -0.3528 
2023-08-08 03:52:34.062356: Pseudo dice [0.8335] 
2023-08-08 03:52:34.062406: Epoch time: 63.36 s 
2023-08-08 03:52:35.240780:  
2023-08-08 03:52:35.240884: Epoch 970 
2023-08-08 03:52:35.240959: Current learning rate: 0.00055 
2023-08-08 03:53:38.535305: train_loss -0.3597 
2023-08-08 03:53:38.535460: val_loss -0.4039 
2023-08-08 03:53:38.535514: Pseudo dice [0.8438] 
2023-08-08 03:53:38.535572: Epoch time: 63.3 s 
2023-08-08 03:53:39.578291:  
2023-08-08 03:53:39.578611: Epoch 971 
2023-08-08 03:53:39.578798: Current learning rate: 0.00055 
2023-08-08 03:54:42.909052: train_loss -0.3538 
2023-08-08 03:54:42.909198: val_loss -0.3544 
2023-08-08 03:54:42.909253: Pseudo dice [0.8051] 
2023-08-08 03:54:42.909303: Epoch time: 63.33 s 
2023-08-08 03:54:43.951504:  
2023-08-08 03:54:43.951615: Epoch 972 
2023-08-08 03:54:43.951704: Current learning rate: 0.00055 
2023-08-08 03:55:47.402914: train_loss -0.3441 
2023-08-08 03:55:47.403049: val_loss -0.3841 
2023-08-08 03:55:47.403100: Pseudo dice [0.9036] 
2023-08-08 03:55:47.403151: Epoch time: 63.45 s 
2023-08-08 03:55:48.420228:  
2023-08-08 03:55:48.425019: Epoch 973 
2023-08-08 03:55:48.425127: Current learning rate: 0.00055 
2023-08-08 03:56:51.870028: train_loss -0.3907 
2023-08-08 03:56:51.870195: val_loss -0.3769 
2023-08-08 03:56:51.870246: Pseudo dice [0.9299] 
2023-08-08 03:56:51.870296: Epoch time: 63.45 s 
2023-08-08 03:56:52.877193:  
2023-08-08 03:56:52.877291: Epoch 974 
2023-08-08 03:56:52.877363: Current learning rate: 0.00055 
2023-08-08 03:57:56.449420: train_loss -0.3595 
2023-08-08 03:57:56.449584: val_loss -0.3275 
2023-08-08 03:57:56.449638: Pseudo dice [0.8386] 
2023-08-08 03:57:56.449688: Epoch time: 63.57 s 
2023-08-08 03:57:57.624102:  
2023-08-08 03:57:57.624202: Epoch 975 
2023-08-08 03:57:57.624272: Current learning rate: 0.00055 
2023-08-08 03:59:01.206475: train_loss -0.3774 
2023-08-08 03:59:01.206642: val_loss -0.3576 
2023-08-08 03:59:01.206709: Pseudo dice [0.8621] 
2023-08-08 03:59:01.206760: Epoch time: 63.58 s 
2023-08-08 03:59:02.242045:  
2023-08-08 03:59:02.242141: Epoch 976 
2023-08-08 03:59:02.242218: Current learning rate: 0.00055 
2023-08-08 04:00:05.674603: train_loss -0.3564 
2023-08-08 04:00:05.674774: val_loss -0.441 
2023-08-08 04:00:05.674832: Pseudo dice [0.8644] 
2023-08-08 04:00:05.674883: Epoch time: 63.43 s 
2023-08-08 04:00:06.708468:  
2023-08-08 04:00:06.708795: Epoch 977 
2023-08-08 04:00:06.708874: Current learning rate: 0.00055 
2023-08-08 04:01:10.251960: train_loss -0.3621 
2023-08-08 04:01:10.252109: val_loss -0.4309 
2023-08-08 04:01:10.252163: Pseudo dice [0.8465] 
2023-08-08 04:01:10.252214: Epoch time: 63.54 s 
2023-08-08 04:01:11.293410:  
2023-08-08 04:01:11.293507: Epoch 978 
2023-08-08 04:01:11.293578: Current learning rate: 0.00055 
2023-08-08 04:02:14.930893: train_loss -0.325 
2023-08-08 04:02:14.931037: val_loss -0.4225 
2023-08-08 04:02:14.931103: Pseudo dice [0.7742] 
2023-08-08 04:02:14.931151: Epoch time: 63.64 s 
2023-08-08 04:02:15.944799:  
2023-08-08 04:02:15.944893: Epoch 979 
2023-08-08 04:02:15.944965: Current learning rate: 0.00055 
2023-08-08 04:03:19.308845: train_loss -0.3569 
2023-08-08 04:03:19.309026: val_loss -0.3836 
2023-08-08 04:03:19.309076: Pseudo dice [0.8655] 
2023-08-08 04:03:19.309128: Epoch time: 63.36 s 
2023-08-08 04:03:20.369683:  
2023-08-08 04:03:20.369777: Epoch 980 
2023-08-08 04:03:20.369864: Current learning rate: 0.00055 
2023-08-08 04:04:23.762029: train_loss -0.3392 
2023-08-08 04:04:23.762179: val_loss -0.338 
2023-08-08 04:04:23.762230: Pseudo dice [0.8186] 
2023-08-08 04:04:23.762298: Epoch time: 63.39 s 
2023-08-08 04:04:24.954369:  
2023-08-08 04:04:24.954467: Epoch 981 
2023-08-08 04:04:24.954545: Current learning rate: 0.00055 
2023-08-08 04:05:28.504742: train_loss -0.3364 
2023-08-08 04:05:28.504930: val_loss -0.3866 
2023-08-08 04:05:28.504985: Pseudo dice [0.8431] 
2023-08-08 04:05:28.505035: Epoch time: 63.55 s 
2023-08-08 04:05:29.524375:  
2023-08-08 04:05:29.524481: Epoch 982 
2023-08-08 04:05:29.524554: Current learning rate: 0.00054 
2023-08-08 04:06:32.999919: train_loss -0.358 
2023-08-08 04:06:33.000070: val_loss -0.3255 
2023-08-08 04:06:33.000137: Pseudo dice [0.8609] 
2023-08-08 04:06:33.000187: Epoch time: 63.48 s 
2023-08-08 04:06:34.053787:  
2023-08-08 04:06:34.053893: Epoch 983 
2023-08-08 04:06:34.053979: Current learning rate: 0.00054 
2023-08-08 04:07:37.502862: train_loss -0.3613 
2023-08-08 04:07:37.503017: val_loss -0.3702 
2023-08-08 04:07:37.503086: Pseudo dice [0.7794] 
2023-08-08 04:07:37.503137: Epoch time: 63.45 s 
2023-08-08 04:07:38.530797:  
2023-08-08 04:07:38.530896: Epoch 984 
2023-08-08 04:07:38.530966: Current learning rate: 0.00054 
2023-08-08 04:08:42.032172: train_loss -0.3467 
2023-08-08 04:08:42.032314: val_loss -0.3757 
2023-08-08 04:08:42.032365: Pseudo dice [0.7744] 
2023-08-08 04:08:42.032415: Epoch time: 63.5 s 
2023-08-08 04:08:43.058688:  
2023-08-08 04:08:43.058957: Epoch 985 
2023-08-08 04:08:43.059156: Current learning rate: 0.00054 
2023-08-08 04:09:46.480967: train_loss -0.3547 
2023-08-08 04:09:46.481114: val_loss -0.3356 
2023-08-08 04:09:46.481166: Pseudo dice [0.9076] 
2023-08-08 04:09:46.481217: Epoch time: 63.42 s 
2023-08-08 04:09:47.490193:  
2023-08-08 04:09:47.490292: Epoch 986 
2023-08-08 04:09:47.490361: Current learning rate: 0.00054 
2023-08-08 04:10:50.607022: train_loss -0.3738 
2023-08-08 04:10:50.607185: val_loss -0.3468 
2023-08-08 04:10:50.607238: Pseudo dice [0.8306] 
2023-08-08 04:10:50.607290: Epoch time: 63.12 s 
2023-08-08 04:10:51.801168:  
2023-08-08 04:10:51.801287: Epoch 987 
2023-08-08 04:10:51.801376: Current learning rate: 0.00054 
2023-08-08 04:11:55.396326: train_loss -0.3444 
2023-08-08 04:11:55.396475: val_loss -0.3676 
2023-08-08 04:11:55.396527: Pseudo dice [0.8271] 
2023-08-08 04:11:55.396578: Epoch time: 63.6 s 
2023-08-08 04:11:56.408125:  
2023-08-08 04:11:56.408323: Epoch 988 
2023-08-08 04:11:56.408399: Current learning rate: 0.00054 
2023-08-08 04:12:59.961921: train_loss -0.372 
2023-08-08 04:12:59.962065: val_loss -0.3636 
2023-08-08 04:12:59.962132: Pseudo dice [0.8581] 
2023-08-08 04:12:59.962182: Epoch time: 63.55 s 
2023-08-08 04:13:01.039104:  
2023-08-08 04:13:01.039203: Epoch 989 
2023-08-08 04:13:01.039273: Current learning rate: 0.00054 
2023-08-08 04:14:04.630946: train_loss -0.3513 
2023-08-08 04:14:04.631105: val_loss -0.3902 
2023-08-08 04:14:04.631155: Pseudo dice [0.8068] 
2023-08-08 04:14:04.631206: Epoch time: 63.59 s 
2023-08-08 04:14:05.676605:  
2023-08-08 04:14:05.676704: Epoch 990 
2023-08-08 04:14:05.676778: Current learning rate: 0.00054 
2023-08-08 04:15:09.058848: train_loss -0.3232 
2023-08-08 04:15:09.059003: val_loss -0.3102 
2023-08-08 04:15:09.059054: Pseudo dice [0.8291] 
2023-08-08 04:15:09.059121: Epoch time: 63.38 s 
2023-08-08 04:15:10.089192:  
2023-08-08 04:15:10.089287: Epoch 991 
2023-08-08 04:15:10.089359: Current learning rate: 0.00054 
2023-08-08 04:16:13.401908: train_loss -0.3702 
2023-08-08 04:16:13.402061: val_loss -0.4041 
2023-08-08 04:16:13.402112: Pseudo dice [0.8562] 
2023-08-08 04:16:13.402161: Epoch time: 63.31 s 
2023-08-08 04:16:14.437995:  
2023-08-08 04:16:14.438084: Epoch 992 
2023-08-08 04:16:14.438171: Current learning rate: 0.00054 
2023-08-08 04:17:17.758113: train_loss -0.327 
2023-08-08 04:17:17.758259: val_loss -0.3614 
2023-08-08 04:17:17.758308: Pseudo dice [0.8533] 
2023-08-08 04:17:17.758374: Epoch time: 63.32 s 
2023-08-08 04:17:18.937845:  
2023-08-08 04:17:18.937946: Epoch 993 
2023-08-08 04:17:18.938035: Current learning rate: 0.00054 
2023-08-08 04:18:22.252418: train_loss -0.3696 
2023-08-08 04:18:22.252569: val_loss -0.3 
2023-08-08 04:18:22.252621: Pseudo dice [0.7937] 
2023-08-08 04:18:22.252671: Epoch time: 63.32 s 
2023-08-08 04:18:23.266512:  
2023-08-08 04:18:23.266608: Epoch 994 
2023-08-08 04:18:23.266695: Current learning rate: 0.00054 
2023-08-08 04:19:26.618173: train_loss -0.3805 
2023-08-08 04:19:26.618324: val_loss -0.3677 
2023-08-08 04:19:26.618379: Pseudo dice [0.8378] 
2023-08-08 04:19:26.618429: Epoch time: 63.35 s 
2023-08-08 04:19:27.627851:  
2023-08-08 04:19:27.628031: Epoch 995 
2023-08-08 04:19:27.628110: Current learning rate: 0.00054 
2023-08-08 04:20:31.079855: train_loss -0.3533 
2023-08-08 04:20:31.080015: val_loss -0.3055 
2023-08-08 04:20:31.080069: Pseudo dice [0.8234] 
2023-08-08 04:20:31.080118: Epoch time: 63.45 s 
2023-08-08 04:20:32.096937:  
2023-08-08 04:20:32.097034: Epoch 996 
2023-08-08 04:20:32.097125: Current learning rate: 0.00054 
2023-08-08 04:21:35.471296: train_loss -0.3802 
2023-08-08 04:21:35.471445: val_loss -0.4673 
2023-08-08 04:21:35.471513: Pseudo dice [0.8223] 
2023-08-08 04:21:35.471568: Epoch time: 63.38 s 
2023-08-08 04:21:36.486895:  
2023-08-08 04:21:36.486990: Epoch 997 
2023-08-08 04:21:36.487060: Current learning rate: 0.00054 
2023-08-08 04:22:39.775810: train_loss -0.3466 
2023-08-08 04:22:39.775960: val_loss -0.3539 
2023-08-08 04:22:39.776012: Pseudo dice [0.8105] 
2023-08-08 04:22:39.776062: Epoch time: 63.29 s 
2023-08-08 04:22:40.789222:  
2023-08-08 04:22:40.789316: Epoch 998 
2023-08-08 04:22:40.789404: Current learning rate: 0.00054 
2023-08-08 04:23:44.213473: train_loss -0.3207 
2023-08-08 04:23:44.213620: val_loss -0.3845 
2023-08-08 04:23:44.213672: Pseudo dice [0.8915] 
2023-08-08 04:23:44.213737: Epoch time: 63.42 s 
2023-08-08 04:23:45.389938:  
2023-08-08 04:23:45.390236: Epoch 999 
2023-08-08 04:23:45.390402: Current learning rate: 0.00054 
2023-08-08 04:24:48.820581: train_loss -0.339 
2023-08-08 04:24:48.820855: val_loss -0.3712 
2023-08-08 04:24:48.820911: Pseudo dice [0.8217] 
2023-08-08 04:24:48.820961: Epoch time: 63.43 s 
2023-08-08 04:24:50.234932:  
2023-08-08 04:24:50.235040: Epoch 1000 
2023-08-08 04:24:50.235114: Current learning rate: 0.00054 
2023-08-08 04:25:53.728894: train_loss -0.3461 
2023-08-08 04:25:53.729054: val_loss -0.4097 
2023-08-08 04:25:53.729124: Pseudo dice [0.8251] 
2023-08-08 04:25:53.729176: Epoch time: 63.49 s 
2023-08-08 04:25:54.748658:  
2023-08-08 04:25:54.748762: Epoch 1001 
2023-08-08 04:25:54.748836: Current learning rate: 0.00054 
2023-08-08 04:26:58.111049: train_loss -0.3606 
2023-08-08 04:26:58.111198: val_loss -0.3236 
2023-08-08 04:26:58.111252: Pseudo dice [0.8388] 
2023-08-08 04:26:58.111303: Epoch time: 63.36 s 
2023-08-08 04:26:59.130250:  
2023-08-08 04:26:59.130359: Epoch 1002 
2023-08-08 04:26:59.130434: Current learning rate: 0.00053 
2023-08-08 04:28:02.479847: train_loss -0.4038 
2023-08-08 04:28:02.479994: val_loss -0.2926 
2023-08-08 04:28:02.480044: Pseudo dice [0.814] 
2023-08-08 04:28:02.480095: Epoch time: 63.35 s 
2023-08-08 04:28:03.524482:  
2023-08-08 04:28:03.524802: Epoch 1003 
2023-08-08 04:28:03.524898: Current learning rate: 0.00053 
2023-08-08 04:29:07.000433: train_loss -0.3584 
2023-08-08 04:29:07.000573: val_loss -0.363 
2023-08-08 04:29:07.000626: Pseudo dice [0.8943] 
2023-08-08 04:29:07.000677: Epoch time: 63.48 s 
2023-08-08 04:29:08.158077:  
2023-08-08 04:29:08.158280: Epoch 1004 
2023-08-08 04:29:08.158374: Current learning rate: 0.00053 
2023-08-08 04:30:11.798305: train_loss -0.3803 
2023-08-08 04:30:11.798459: val_loss -0.422 
2023-08-08 04:30:11.798512: Pseudo dice [0.8329] 
2023-08-08 04:30:11.798562: Epoch time: 63.64 s 
2023-08-08 04:30:12.857391:  
2023-08-08 04:30:12.857491: Epoch 1005 
2023-08-08 04:30:12.857579: Current learning rate: 0.00053 
2023-08-08 04:31:16.335308: train_loss -0.353 
2023-08-08 04:31:16.335460: val_loss -0.3456 
2023-08-08 04:31:16.335510: Pseudo dice [0.7841] 
2023-08-08 04:31:16.335583: Epoch time: 63.48 s 
2023-08-08 04:31:17.391573:  
2023-08-08 04:31:17.391927: Epoch 1006 
2023-08-08 04:31:17.392003: Current learning rate: 0.00053 
2023-08-08 04:32:20.821385: train_loss -0.3738 
2023-08-08 04:32:20.821530: val_loss -0.4268 
2023-08-08 04:32:20.821583: Pseudo dice [0.8897] 
2023-08-08 04:32:20.821649: Epoch time: 63.43 s 
2023-08-08 04:32:21.834440:  
2023-08-08 04:32:21.834536: Epoch 1007 
2023-08-08 04:32:21.834607: Current learning rate: 0.00053 
2023-08-08 04:33:25.062877: train_loss -0.3634 
2023-08-08 04:33:25.063034: val_loss -0.3737 
2023-08-08 04:33:25.063083: Pseudo dice [0.8322] 
2023-08-08 04:33:25.063159: Epoch time: 63.23 s 
2023-08-08 04:33:26.082219:  
2023-08-08 04:33:26.082317: Epoch 1008 
2023-08-08 04:33:26.082387: Current learning rate: 0.00053 
2023-08-08 04:34:29.543317: train_loss -0.3704 
2023-08-08 04:34:29.543473: val_loss -0.3534 
2023-08-08 04:34:29.543530: Pseudo dice [0.8777] 
2023-08-08 04:34:29.543596: Epoch time: 63.46 s 
2023-08-08 04:34:30.582900:  
2023-08-08 04:34:30.582989: Epoch 1009 
2023-08-08 04:34:30.583081: Current learning rate: 0.00053 
2023-08-08 04:35:34.174498: train_loss -0.3706 
2023-08-08 04:35:34.174663: val_loss -0.3694 
2023-08-08 04:35:34.174714: Pseudo dice [0.7955] 
2023-08-08 04:35:34.174765: Epoch time: 63.59 s 
2023-08-08 04:35:35.367369:  
2023-08-08 04:35:35.367564: Epoch 1010 
2023-08-08 04:35:35.367661: Current learning rate: 0.00053 
2023-08-08 04:36:38.974379: train_loss -0.3655 
2023-08-08 04:36:38.974528: val_loss -0.3129 
2023-08-08 04:36:38.974579: Pseudo dice [0.7664] 
2023-08-08 04:36:38.974646: Epoch time: 63.61 s 
2023-08-08 04:36:39.985147:  
2023-08-08 04:36:39.985354: Epoch 1011 
2023-08-08 04:36:39.985433: Current learning rate: 0.00053 
2023-08-08 04:37:43.528933: train_loss -0.3341 
2023-08-08 04:37:43.529099: val_loss -0.3744 
2023-08-08 04:37:43.529151: Pseudo dice [0.8479] 
2023-08-08 04:37:43.529203: Epoch time: 63.54 s 
2023-08-08 04:37:44.544911:  
2023-08-08 04:37:44.545014: Epoch 1012 
2023-08-08 04:37:44.545088: Current learning rate: 0.00053 
2023-08-08 04:38:48.049597: train_loss -0.3411 
2023-08-08 04:38:48.049761: val_loss -0.463 
2023-08-08 04:38:48.049814: Pseudo dice [0.9266] 
2023-08-08 04:38:48.049865: Epoch time: 63.51 s 
2023-08-08 04:38:49.071952:  
2023-08-08 04:38:49.072050: Epoch 1013 
2023-08-08 04:38:49.072123: Current learning rate: 0.00053 
2023-08-08 04:39:52.454555: train_loss -0.3786 
2023-08-08 04:39:52.454750: val_loss -0.4033 
2023-08-08 04:39:52.454803: Pseudo dice [0.8743] 
2023-08-08 04:39:52.454853: Epoch time: 63.38 s 
2023-08-08 04:39:53.509028:  
2023-08-08 04:39:53.509159: Epoch 1014 
2023-08-08 04:39:53.509309: Current learning rate: 0.00053 
2023-08-08 04:40:56.949515: train_loss -0.368 
2023-08-08 04:40:56.949672: val_loss -0.3519 
2023-08-08 04:40:56.949739: Pseudo dice [0.8654] 
2023-08-08 04:40:56.949790: Epoch time: 63.44 s 
2023-08-08 04:40:58.031196:  
2023-08-08 04:40:58.031286: Epoch 1015 
2023-08-08 04:40:58.031360: Current learning rate: 0.00053 
2023-08-08 04:42:01.602322: train_loss -0.3317 
2023-08-08 04:42:01.602476: val_loss -0.3163 
2023-08-08 04:42:01.602543: Pseudo dice [0.7913] 
2023-08-08 04:42:01.602593: Epoch time: 63.57 s 
2023-08-08 04:42:02.818340:  
2023-08-08 04:42:02.818437: Epoch 1016 
2023-08-08 04:42:02.818512: Current learning rate: 0.00053 
2023-08-08 04:43:06.195578: train_loss -0.383 
2023-08-08 04:43:06.195734: val_loss -0.3004 
2023-08-08 04:43:06.195785: Pseudo dice [0.7651] 
2023-08-08 04:43:06.195835: Epoch time: 63.38 s 
2023-08-08 04:43:07.242118:  
2023-08-08 04:43:07.242411: Epoch 1017 
2023-08-08 04:43:07.242537: Current learning rate: 0.00053 
2023-08-08 04:44:10.757946: train_loss -0.3213 
2023-08-08 04:44:10.758103: val_loss -0.2799 
2023-08-08 04:44:10.758157: Pseudo dice [0.8168] 
2023-08-08 04:44:10.758208: Epoch time: 63.52 s 
2023-08-08 04:44:11.790632:  
2023-08-08 04:44:11.790731: Epoch 1018 
2023-08-08 04:44:11.790820: Current learning rate: 0.00053 
2023-08-08 04:45:15.204243: train_loss -0.3622 
2023-08-08 04:45:15.204393: val_loss -0.3223 
2023-08-08 04:45:15.204446: Pseudo dice [0.8696] 
2023-08-08 04:45:15.204495: Epoch time: 63.41 s 
2023-08-08 04:45:16.236911:  
2023-08-08 04:45:16.237014: Epoch 1019 
2023-08-08 04:45:16.237091: Current learning rate: 0.00053 
2023-08-08 04:46:19.735931: train_loss -0.351 
2023-08-08 04:46:19.736087: val_loss -0.4217 
2023-08-08 04:46:19.736140: Pseudo dice [0.8817] 
2023-08-08 04:46:19.736191: Epoch time: 63.5 s 
2023-08-08 04:46:20.754382:  
2023-08-08 04:46:20.754481: Epoch 1020 
2023-08-08 04:46:20.754555: Current learning rate: 0.00053 
2023-08-08 04:47:24.118505: train_loss -0.3546 
2023-08-08 04:47:24.118676: val_loss -0.3145 
2023-08-08 04:47:24.118730: Pseudo dice [0.7865] 
2023-08-08 04:47:24.118796: Epoch time: 63.36 s 
2023-08-08 04:47:25.138126:  
2023-08-08 04:47:25.138217: Epoch 1021 
2023-08-08 04:47:25.138288: Current learning rate: 0.00053 
2023-08-08 04:48:28.466748: train_loss -0.3278 
2023-08-08 04:48:28.466897: val_loss -0.2946 
2023-08-08 04:48:28.466948: Pseudo dice [0.8197] 
2023-08-08 04:48:28.466996: Epoch time: 63.33 s 
2023-08-08 04:48:29.691588:  
2023-08-08 04:48:29.691706: Epoch 1022 
2023-08-08 04:48:29.691780: Current learning rate: 0.00053 
2023-08-08 04:49:33.160157: train_loss -0.374 
2023-08-08 04:49:33.160424: val_loss -0.3869 
2023-08-08 04:49:33.160480: Pseudo dice [0.8486] 
2023-08-08 04:49:33.160529: Epoch time: 63.47 s 
2023-08-08 04:49:34.175463:  
2023-08-08 04:49:34.175563: Epoch 1023 
2023-08-08 04:49:34.175672: Current learning rate: 0.00052 
2023-08-08 04:50:37.666464: train_loss -0.3262 
2023-08-08 04:50:37.666683: val_loss -0.3545 
2023-08-08 04:50:37.666792: Pseudo dice [0.8688] 
2023-08-08 04:50:37.666896: Epoch time: 63.49 s 
2023-08-08 04:50:38.698606:  
2023-08-08 04:50:38.698708: Epoch 1024 
2023-08-08 04:50:38.698780: Current learning rate: 0.00052 
2023-08-08 04:51:42.112194: train_loss -0.3166 
2023-08-08 04:51:42.112464: val_loss -0.4066 
2023-08-08 04:51:42.112523: Pseudo dice [0.8058] 
2023-08-08 04:51:42.112575: Epoch time: 63.41 s 
2023-08-08 04:51:43.150506:  
2023-08-08 04:51:43.150601: Epoch 1025 
2023-08-08 04:51:43.150676: Current learning rate: 0.00052 
2023-08-08 04:52:46.534032: train_loss -0.3466 
2023-08-08 04:52:46.534187: val_loss -0.4254 
2023-08-08 04:52:46.534242: Pseudo dice [0.9231] 
2023-08-08 04:52:46.534293: Epoch time: 63.38 s 
2023-08-08 04:52:47.584618:  
2023-08-08 04:52:47.584718: Epoch 1026 
2023-08-08 04:52:47.584799: Current learning rate: 0.00052 
2023-08-08 04:53:51.136004: train_loss -0.3429 
2023-08-08 04:53:51.136164: val_loss -0.3339 
2023-08-08 04:53:51.136220: Pseudo dice [0.8224] 
2023-08-08 04:53:51.136271: Epoch time: 63.55 s 
2023-08-08 04:53:52.298254:  
2023-08-08 04:53:52.298351: Epoch 1027 
2023-08-08 04:53:52.298427: Current learning rate: 0.00052 
2023-08-08 04:54:56.103300: train_loss -0.3577 
2023-08-08 04:54:56.103453: val_loss -0.3477 
2023-08-08 04:54:56.103505: Pseudo dice [0.8867] 
2023-08-08 04:54:56.103579: Epoch time: 63.81 s 
2023-08-08 04:54:57.133787:  
2023-08-08 04:54:57.133884: Epoch 1028 
2023-08-08 04:54:57.133956: Current learning rate: 0.00052 
2023-08-08 04:56:00.695050: train_loss -0.328 
2023-08-08 04:56:00.695189: val_loss -0.3748 
2023-08-08 04:56:00.695237: Pseudo dice [0.8376] 
2023-08-08 04:56:00.695302: Epoch time: 63.56 s 
2023-08-08 04:56:01.713700:  
2023-08-08 04:56:01.713794: Epoch 1029 
2023-08-08 04:56:01.713866: Current learning rate: 0.00052 
2023-08-08 04:57:05.251925: train_loss -0.3334 
2023-08-08 04:57:05.252075: val_loss -0.4489 
2023-08-08 04:57:05.252129: Pseudo dice [0.8707] 
2023-08-08 04:57:05.252180: Epoch time: 63.54 s 
2023-08-08 04:57:06.278813:  
2023-08-08 04:57:06.278992: Epoch 1030 
2023-08-08 04:57:06.279069: Current learning rate: 0.00052 
2023-08-08 04:58:09.779689: train_loss -0.39 
2023-08-08 04:58:09.779841: val_loss -0.3124 
2023-08-08 04:58:09.779893: Pseudo dice [0.8548] 
2023-08-08 04:58:09.779944: Epoch time: 63.5 s 
2023-08-08 04:58:10.801443:  
2023-08-08 04:58:10.801541: Epoch 1031 
2023-08-08 04:58:10.801614: Current learning rate: 0.00052 
2023-08-08 04:59:14.204221: train_loss -0.3506 
2023-08-08 04:59:14.204379: val_loss -0.2985 
2023-08-08 04:59:14.204431: Pseudo dice [0.8023] 
2023-08-08 04:59:14.204481: Epoch time: 63.4 s 
2023-08-08 04:59:15.253424:  
2023-08-08 04:59:15.253521: Epoch 1032 
2023-08-08 04:59:15.253609: Current learning rate: 0.00052 
2023-08-08 05:00:18.616837: train_loss -0.354 
2023-08-08 05:00:18.616990: val_loss -0.3272 
2023-08-08 05:00:18.617058: Pseudo dice [0.876] 
2023-08-08 05:00:18.617109: Epoch time: 63.36 s 
2023-08-08 05:00:19.794447:  
2023-08-08 05:00:19.794551: Epoch 1033 
2023-08-08 05:00:19.794645: Current learning rate: 0.00052 
2023-08-08 05:01:23.373606: train_loss -0.3781 
2023-08-08 05:01:23.373765: val_loss -0.3922 
2023-08-08 05:01:23.373836: Pseudo dice [0.7971] 
2023-08-08 05:01:23.373887: Epoch time: 63.58 s 
2023-08-08 05:01:24.410505:  
2023-08-08 05:01:24.410605: Epoch 1034 
2023-08-08 05:01:24.410677: Current learning rate: 0.00052 
2023-08-08 05:02:27.823252: train_loss -0.3661 
2023-08-08 05:02:27.823403: val_loss -0.3438 
2023-08-08 05:02:27.823455: Pseudo dice [0.8253] 
2023-08-08 05:02:27.823505: Epoch time: 63.41 s 
2023-08-08 05:02:28.878775:  
2023-08-08 05:02:28.878878: Epoch 1035 
2023-08-08 05:02:28.878969: Current learning rate: 0.00052 
2023-08-08 05:03:32.387811: train_loss -0.3459 
2023-08-08 05:03:32.387963: val_loss -0.417 
2023-08-08 05:03:32.388014: Pseudo dice [0.8858] 
2023-08-08 05:03:32.388064: Epoch time: 63.51 s 
2023-08-08 05:03:33.416027:  
2023-08-08 05:03:33.416131: Epoch 1036 
2023-08-08 05:03:33.416220: Current learning rate: 0.00052 
2023-08-08 05:04:36.806773: train_loss -0.3284 
2023-08-08 05:04:36.806921: val_loss -0.3668 
2023-08-08 05:04:36.806972: Pseudo dice [0.8805] 
2023-08-08 05:04:36.807021: Epoch time: 63.39 s 
2023-08-08 05:04:37.897465:  
2023-08-08 05:04:37.897566: Epoch 1037 
2023-08-08 05:04:37.897638: Current learning rate: 0.00052 
2023-08-08 05:05:41.264937: train_loss -0.3583 
2023-08-08 05:05:41.265097: val_loss -0.3243 
2023-08-08 05:05:41.265151: Pseudo dice [0.8232] 
2023-08-08 05:05:41.265202: Epoch time: 63.37 s 
2023-08-08 05:05:42.292771:  
2023-08-08 05:05:42.292869: Epoch 1038 
2023-08-08 05:05:42.293057: Current learning rate: 0.00052 
2023-08-08 05:06:45.671098: train_loss -0.3505 
2023-08-08 05:06:45.671245: val_loss -0.3701 
2023-08-08 05:06:45.671312: Pseudo dice [0.8545] 
2023-08-08 05:06:45.671361: Epoch time: 63.38 s 
2023-08-08 05:06:46.855457:  
2023-08-08 05:06:46.855569: Epoch 1039 
2023-08-08 05:06:46.855675: Current learning rate: 0.00052 
2023-08-08 05:07:50.296867: train_loss -0.3749 
2023-08-08 05:07:50.297022: val_loss -0.3137 
2023-08-08 05:07:50.297074: Pseudo dice [0.7922] 
2023-08-08 05:07:50.297140: Epoch time: 63.44 s 
2023-08-08 05:07:51.369441:  
2023-08-08 05:07:51.369543: Epoch 1040 
2023-08-08 05:07:51.369631: Current learning rate: 0.00052 
2023-08-08 05:08:54.770652: train_loss -0.3673 
2023-08-08 05:08:54.770802: val_loss -0.3649 
2023-08-08 05:08:54.770857: Pseudo dice [0.843] 
2023-08-08 05:08:54.770907: Epoch time: 63.4 s 
2023-08-08 05:08:55.807104:  
2023-08-08 05:08:55.807200: Epoch 1041 
2023-08-08 05:08:55.807273: Current learning rate: 0.00052 
2023-08-08 05:09:59.308851: train_loss -0.3502 
2023-08-08 05:09:59.309008: val_loss -0.354 
2023-08-08 05:09:59.309076: Pseudo dice [0.8406] 
2023-08-08 05:09:59.309128: Epoch time: 63.5 s 
2023-08-08 05:10:00.350958:  
2023-08-08 05:10:00.351054: Epoch 1042 
2023-08-08 05:10:00.351141: Current learning rate: 0.00052 
2023-08-08 05:11:04.049059: train_loss -0.3678 
2023-08-08 05:11:04.049237: val_loss -0.3785 
2023-08-08 05:11:04.049287: Pseudo dice [0.8217] 
2023-08-08 05:11:04.049352: Epoch time: 63.7 s 
2023-08-08 05:11:05.072092:  
2023-08-08 05:11:05.072187: Epoch 1043 
2023-08-08 05:11:05.072275: Current learning rate: 0.00052 
2023-08-08 05:12:08.760170: train_loss -0.3864 
2023-08-08 05:12:08.760316: val_loss -0.3357 
2023-08-08 05:12:08.760367: Pseudo dice [0.7918] 
2023-08-08 05:12:08.760417: Epoch time: 63.69 s 
2023-08-08 05:12:09.798337:  
2023-08-08 05:12:09.798433: Epoch 1044 
2023-08-08 05:12:09.798522: Current learning rate: 0.00051 
2023-08-08 05:13:13.251397: train_loss -0.3566 
2023-08-08 05:13:13.251545: val_loss -0.395 
2023-08-08 05:13:13.251623: Pseudo dice [0.8668] 
2023-08-08 05:13:13.251674: Epoch time: 63.45 s 
2023-08-08 05:13:14.437290:  
2023-08-08 05:13:14.437394: Epoch 1045 
2023-08-08 05:13:14.437466: Current learning rate: 0.00051 
2023-08-08 05:14:17.928062: train_loss -0.332 
2023-08-08 05:14:17.928341: val_loss -0.3945 
2023-08-08 05:14:17.928402: Pseudo dice [0.8548] 
2023-08-08 05:14:17.928454: Epoch time: 63.49 s 
2023-08-08 05:14:18.955502:  
2023-08-08 05:14:18.955624: Epoch 1046 
2023-08-08 05:14:18.955698: Current learning rate: 0.00051 
2023-08-08 05:15:22.457361: train_loss -0.379 
2023-08-08 05:15:22.457509: val_loss -0.3292 
2023-08-08 05:15:22.457558: Pseudo dice [0.8262] 
2023-08-08 05:15:22.457623: Epoch time: 63.5 s 
2023-08-08 05:15:23.485678:  
2023-08-08 05:15:23.485888: Epoch 1047 
2023-08-08 05:15:23.486068: Current learning rate: 0.00051 
2023-08-08 05:16:27.142432: train_loss -0.3332 
2023-08-08 05:16:27.142600: val_loss -0.3646 
2023-08-08 05:16:27.142653: Pseudo dice [0.8676] 
2023-08-08 05:16:27.142703: Epoch time: 63.66 s 
2023-08-08 05:16:28.188578:  
2023-08-08 05:16:28.188672: Epoch 1048 
2023-08-08 05:16:28.188743: Current learning rate: 0.00051 
2023-08-08 05:17:31.710283: train_loss -0.3983 
2023-08-08 05:17:31.710445: val_loss -0.3431 
2023-08-08 05:17:31.710496: Pseudo dice [0.7585] 
2023-08-08 05:17:31.710548: Epoch time: 63.52 s 
2023-08-08 05:17:32.734512:  
2023-08-08 05:17:32.734608: Epoch 1049 
2023-08-08 05:17:32.734679: Current learning rate: 0.00051 
2023-08-08 05:18:36.200973: train_loss -0.3616 
2023-08-08 05:18:36.201130: val_loss -0.3583 
2023-08-08 05:18:36.201199: Pseudo dice [0.8779] 
2023-08-08 05:18:36.201250: Epoch time: 63.47 s 
2023-08-08 05:18:37.754252:  
2023-08-08 05:18:37.754611: Epoch 1050 
2023-08-08 05:18:37.754691: Current learning rate: 0.00051 
2023-08-08 05:19:41.513028: train_loss -0.3162 
2023-08-08 05:19:41.513178: val_loss -0.3923 
2023-08-08 05:19:41.513231: Pseudo dice [0.7862] 
2023-08-08 05:19:41.513281: Epoch time: 63.76 s 
2023-08-08 05:19:42.599949:  
2023-08-08 05:19:42.600054: Epoch 1051 
2023-08-08 05:19:42.600131: Current learning rate: 0.00051 
2023-08-08 05:20:45.920229: train_loss -0.3557 
2023-08-08 05:20:45.920388: val_loss -0.4259 
2023-08-08 05:20:45.920449: Pseudo dice [0.8066] 
2023-08-08 05:20:45.920500: Epoch time: 63.32 s 
2023-08-08 05:20:46.950249:  
2023-08-08 05:20:46.950347: Epoch 1052 
2023-08-08 05:20:46.950418: Current learning rate: 0.00051 
2023-08-08 05:21:50.383451: train_loss -0.3314 
2023-08-08 05:21:50.383615: val_loss -0.325 
2023-08-08 05:21:50.383668: Pseudo dice [0.7968] 
2023-08-08 05:21:50.383719: Epoch time: 63.43 s 
2023-08-08 05:21:51.406844:  
2023-08-08 05:21:51.406938: Epoch 1053 
2023-08-08 05:21:51.407011: Current learning rate: 0.00051 
2023-08-08 05:22:54.715920: train_loss -0.3576 
2023-08-08 05:22:54.716068: val_loss -0.4087 
2023-08-08 05:22:54.716121: Pseudo dice [0.8781] 
2023-08-08 05:22:54.716172: Epoch time: 63.31 s 
2023-08-08 05:22:55.730803:  
2023-08-08 05:22:55.731019: Epoch 1054 
2023-08-08 05:22:55.731112: Current learning rate: 0.00051 
2023-08-08 05:23:59.169871: train_loss -0.3822 
2023-08-08 05:23:59.170027: val_loss -0.4276 
2023-08-08 05:23:59.170095: Pseudo dice [0.8566] 
2023-08-08 05:23:59.170146: Epoch time: 63.44 s 
2023-08-08 05:24:00.197674:  
2023-08-08 05:24:00.197766: Epoch 1055 
2023-08-08 05:24:00.197854: Current learning rate: 0.00051 
2023-08-08 05:25:03.460139: train_loss -0.3245 
2023-08-08 05:25:03.460287: val_loss -0.3569 
2023-08-08 05:25:03.460338: Pseudo dice [0.8822] 
2023-08-08 05:25:03.460388: Epoch time: 63.26 s 
2023-08-08 05:25:04.641778:  
2023-08-08 05:25:04.641886: Epoch 1056 
2023-08-08 05:25:04.641959: Current learning rate: 0.00051 
2023-08-08 05:26:08.137860: train_loss -0.3633 
2023-08-08 05:26:08.138008: val_loss -0.3293 
2023-08-08 05:26:08.138062: Pseudo dice [0.7932] 
2023-08-08 05:26:08.138128: Epoch time: 63.5 s 
2023-08-08 05:26:09.170099:  
2023-08-08 05:26:09.170222: Epoch 1057 
2023-08-08 05:26:09.170315: Current learning rate: 0.00051 
2023-08-08 05:27:12.624804: train_loss -0.392 
2023-08-08 05:27:12.624956: val_loss -0.2961 
2023-08-08 05:27:12.625013: Pseudo dice [0.8547] 
2023-08-08 05:27:12.625080: Epoch time: 63.46 s 
2023-08-08 05:27:13.700773:  
2023-08-08 05:27:13.700882: Epoch 1058 
2023-08-08 05:27:13.700957: Current learning rate: 0.00051 
2023-08-08 05:28:17.155509: train_loss -0.3289 
2023-08-08 05:28:17.155679: val_loss -0.3916 
2023-08-08 05:28:17.155741: Pseudo dice [0.8153] 
2023-08-08 05:28:17.155791: Epoch time: 63.46 s 
2023-08-08 05:28:18.178659:  
2023-08-08 05:28:18.178764: Epoch 1059 
2023-08-08 05:28:18.178837: Current learning rate: 0.00051 
2023-08-08 05:29:21.641733: train_loss -0.3449 
2023-08-08 05:29:21.641896: val_loss -0.4291 
2023-08-08 05:29:21.641946: Pseudo dice [0.8852] 
2023-08-08 05:29:21.641996: Epoch time: 63.46 s 
2023-08-08 05:29:22.676329:  
2023-08-08 05:29:22.676434: Epoch 1060 
2023-08-08 05:29:22.676509: Current learning rate: 0.00051 
2023-08-08 05:30:26.058988: train_loss -0.3986 
2023-08-08 05:30:26.059132: val_loss -0.3834 
2023-08-08 05:30:26.059210: Pseudo dice [0.8284] 
2023-08-08 05:30:26.059275: Epoch time: 63.38 s 
2023-08-08 05:30:27.085220:  
2023-08-08 05:30:27.085321: Epoch 1061 
2023-08-08 05:30:27.085394: Current learning rate: 0.00051 
2023-08-08 05:31:30.380227: train_loss -0.3725 
2023-08-08 05:31:30.380394: val_loss -0.3294 
2023-08-08 05:31:30.380446: Pseudo dice [0.8327] 
2023-08-08 05:31:30.380497: Epoch time: 63.3 s 
2023-08-08 05:31:31.566789:  
2023-08-08 05:31:31.566900: Epoch 1062 
2023-08-08 05:31:31.566972: Current learning rate: 0.00051 
2023-08-08 05:32:35.126231: train_loss -0.3741 
2023-08-08 05:32:35.126385: val_loss -0.3111 
2023-08-08 05:32:35.126438: Pseudo dice [0.91] 
2023-08-08 05:32:35.126487: Epoch time: 63.56 s 
2023-08-08 05:32:36.172632:  
2023-08-08 05:32:36.172730: Epoch 1063 
2023-08-08 05:32:36.172830: Current learning rate: 0.00051 
2023-08-08 05:33:39.792564: train_loss -0.3672 
2023-08-08 05:33:39.792713: val_loss -0.3667 
2023-08-08 05:33:39.792767: Pseudo dice [0.8079] 
2023-08-08 05:33:39.792816: Epoch time: 63.62 s 
2023-08-08 05:33:40.817703:  
2023-08-08 05:33:40.817806: Epoch 1064 
2023-08-08 05:33:40.817892: Current learning rate: 0.0005 
2023-08-08 05:34:44.413429: train_loss -0.3626 
2023-08-08 05:34:44.413581: val_loss -0.4377 
2023-08-08 05:34:44.413634: Pseudo dice [0.8325] 
2023-08-08 05:34:44.413701: Epoch time: 63.6 s 
2023-08-08 05:34:45.476367:  
2023-08-08 05:34:45.476465: Epoch 1065 
2023-08-08 05:34:45.476537: Current learning rate: 0.0005 
2023-08-08 05:35:48.972181: train_loss -0.3622 
2023-08-08 05:35:48.972331: val_loss -0.3866 
2023-08-08 05:35:48.972384: Pseudo dice [0.8572] 
2023-08-08 05:35:48.972434: Epoch time: 63.5 s 
2023-08-08 05:35:49.997888:  
2023-08-08 05:35:49.997987: Epoch 1066 
2023-08-08 05:35:49.998075: Current learning rate: 0.0005 
2023-08-08 05:36:53.342959: train_loss -0.363 
2023-08-08 05:36:53.343113: val_loss -0.3683 
2023-08-08 05:36:53.343182: Pseudo dice [0.883] 
2023-08-08 05:36:53.343234: Epoch time: 63.35 s 
2023-08-08 05:36:54.364706:  
2023-08-08 05:36:54.364923: Epoch 1067 
2023-08-08 05:36:54.365015: Current learning rate: 0.0005 
2023-08-08 05:37:57.781448: train_loss -0.3597 
2023-08-08 05:37:57.781606: val_loss -0.3541 
2023-08-08 05:37:57.781660: Pseudo dice [0.8676] 
2023-08-08 05:37:57.781713: Epoch time: 63.42 s 
2023-08-08 05:37:58.807982:  
2023-08-08 05:37:58.808083: Epoch 1068 
2023-08-08 05:37:58.808159: Current learning rate: 0.0005 
2023-08-08 05:39:02.219479: train_loss -0.3424 
2023-08-08 05:39:02.219650: val_loss -0.3676 
2023-08-08 05:39:02.219703: Pseudo dice [0.8979] 
2023-08-08 05:39:02.219754: Epoch time: 63.41 s 
2023-08-08 05:39:02.219796: Yayy! New best EMA pseudo Dice: 0.8533 
2023-08-08 05:39:03.612414:  
2023-08-08 05:39:03.612729: Epoch 1069 
2023-08-08 05:39:03.612811: Current learning rate: 0.0005 
2023-08-08 05:40:07.005484: train_loss -0.3578 
2023-08-08 05:40:07.005646: val_loss -0.4135 
2023-08-08 05:40:07.005699: Pseudo dice [0.8643] 
2023-08-08 05:40:07.005750: Epoch time: 63.39 s 
2023-08-08 05:40:07.005790: Yayy! New best EMA pseudo Dice: 0.8544 
2023-08-08 05:40:08.465615:  
2023-08-08 05:40:08.465824: Epoch 1070 
2023-08-08 05:40:08.465916: Current learning rate: 0.0005 
2023-08-08 05:41:11.957877: train_loss -0.3769 
2023-08-08 05:41:11.958048: val_loss -0.3926 
2023-08-08 05:41:11.958101: Pseudo dice [0.8321] 
2023-08-08 05:41:11.958151: Epoch time: 63.49 s 
2023-08-08 05:41:12.981654:  
2023-08-08 05:41:12.981753: Epoch 1071 
2023-08-08 05:41:12.981825: Current learning rate: 0.0005 
2023-08-08 05:42:16.450367: train_loss -0.3555 
2023-08-08 05:42:16.450516: val_loss -0.3294 
2023-08-08 05:42:16.450564: Pseudo dice [0.9125] 
2023-08-08 05:42:16.450630: Epoch time: 63.47 s 
2023-08-08 05:42:16.450670: Yayy! New best EMA pseudo Dice: 0.8582 
2023-08-08 05:42:18.041151:  
2023-08-08 05:42:18.041401: Epoch 1072 
2023-08-08 05:42:18.041646: Current learning rate: 0.0005 
2023-08-08 05:43:21.545729: train_loss -0.3476 
2023-08-08 05:43:21.545875: val_loss -0.3644 
2023-08-08 05:43:21.545941: Pseudo dice [0.8122] 
2023-08-08 05:43:21.545990: Epoch time: 63.51 s 
2023-08-08 05:43:22.597599:  
2023-08-08 05:43:22.597697: Epoch 1073 
2023-08-08 05:43:22.597785: Current learning rate: 0.0005 
2023-08-08 05:44:25.949650: train_loss -0.37 
2023-08-08 05:44:25.949830: val_loss -0.3877 
2023-08-08 05:44:25.949885: Pseudo dice [0.8242] 
2023-08-08 05:44:25.949936: Epoch time: 63.35 s 
2023-08-08 05:44:26.979473:  
2023-08-08 05:44:26.979577: Epoch 1074 
2023-08-08 05:44:26.979682: Current learning rate: 0.0005 
2023-08-08 05:45:30.343905: train_loss -0.3489 
2023-08-08 05:45:30.344065: val_loss -0.3371 
2023-08-08 05:45:30.344116: Pseudo dice [0.8663] 
2023-08-08 05:45:30.344169: Epoch time: 63.37 s 
2023-08-08 05:45:31.365136:  
2023-08-08 05:45:31.365236: Epoch 1075 
2023-08-08 05:45:31.365310: Current learning rate: 0.0005 
2023-08-08 05:46:34.918959: train_loss -0.3835 
2023-08-08 05:46:34.919137: val_loss -0.3734 
2023-08-08 05:46:34.919190: Pseudo dice [0.8176] 
2023-08-08 05:46:34.919240: Epoch time: 63.55 s 
2023-08-08 05:46:35.937682:  
2023-08-08 05:46:35.937866: Epoch 1076 
2023-08-08 05:46:35.937942: Current learning rate: 0.0005 
2023-08-08 05:47:39.335311: train_loss -0.3502 
2023-08-08 05:47:39.335464: val_loss -0.3636 
2023-08-08 05:47:39.335515: Pseudo dice [0.7912] 
2023-08-08 05:47:39.335573: Epoch time: 63.4 s 
2023-08-08 05:47:40.395447:  
2023-08-08 05:47:40.395539: Epoch 1077 
2023-08-08 05:47:40.395633: Current learning rate: 0.0005 
2023-08-08 05:48:43.802731: train_loss -0.3379 
2023-08-08 05:48:43.802884: val_loss -0.3366 
2023-08-08 05:48:43.802937: Pseudo dice [0.8536] 
2023-08-08 05:48:43.803003: Epoch time: 63.41 s 
2023-08-08 05:48:44.981242:  
2023-08-08 05:48:44.981342: Epoch 1078 
2023-08-08 05:48:44.981416: Current learning rate: 0.0005 
2023-08-08 05:49:48.517748: train_loss -0.36 
2023-08-08 05:49:48.517900: val_loss -0.2862 
2023-08-08 05:49:48.517954: Pseudo dice [0.7574] 
2023-08-08 05:49:48.518005: Epoch time: 63.54 s 
2023-08-08 05:49:49.560096:  
2023-08-08 05:49:49.560193: Epoch 1079 
2023-08-08 05:49:49.560291: Current learning rate: 0.0005 
2023-08-08 05:50:53.034121: train_loss -0.3743 
2023-08-08 05:50:53.034274: val_loss -0.3838 
2023-08-08 05:50:53.034327: Pseudo dice [0.8905] 
2023-08-08 05:50:53.034378: Epoch time: 63.47 s 
2023-08-08 05:50:54.056095:  
2023-08-08 05:50:54.056197: Epoch 1080 
2023-08-08 05:50:54.056270: Current learning rate: 0.0005 
2023-08-08 05:51:57.554622: train_loss -0.3448 
2023-08-08 05:51:57.554784: val_loss -0.4021 
2023-08-08 05:51:57.554836: Pseudo dice [0.8796] 
2023-08-08 05:51:57.554893: Epoch time: 63.5 s 
2023-08-08 05:51:58.578901:  
2023-08-08 05:51:58.579000: Epoch 1081 
2023-08-08 05:51:58.579073: Current learning rate: 0.0005 
2023-08-08 05:53:02.006969: train_loss -0.3579 
2023-08-08 05:53:02.007121: val_loss -0.3861 
2023-08-08 05:53:02.007178: Pseudo dice [0.8578] 
2023-08-08 05:53:02.007232: Epoch time: 63.43 s 
2023-08-08 05:53:03.115867:  
2023-08-08 05:53:03.115969: Epoch 1082 
2023-08-08 05:53:03.116045: Current learning rate: 0.0005 
2023-08-08 05:54:06.505933: train_loss -0.3636 
2023-08-08 05:54:06.506080: val_loss -0.3839 
2023-08-08 05:54:06.506134: Pseudo dice [0.9117] 
2023-08-08 05:54:06.506184: Epoch time: 63.39 s 
2023-08-08 05:54:07.523045:  
2023-08-08 05:54:07.523202: Epoch 1083 
2023-08-08 05:54:07.523360: Current learning rate: 0.0005 
2023-08-08 05:55:10.981545: train_loss -0.3237 
2023-08-08 05:55:10.981696: val_loss -0.3626 
2023-08-08 05:55:10.981744: Pseudo dice [0.8503] 
2023-08-08 05:55:10.981810: Epoch time: 63.46 s 
2023-08-08 05:55:12.172094:  
2023-08-08 05:55:12.172215: Epoch 1084 
2023-08-08 05:55:12.172303: Current learning rate: 0.0005 
2023-08-08 05:56:15.818132: train_loss -0.353 
2023-08-08 05:56:15.818283: val_loss -0.4104 
2023-08-08 05:56:15.818338: Pseudo dice [0.8861] 
2023-08-08 05:56:15.818407: Epoch time: 63.65 s 
2023-08-08 05:56:16.870424:  
2023-08-08 05:56:16.870535: Epoch 1085 
2023-08-08 05:56:16.870610: Current learning rate: 0.00049 
2023-08-08 05:57:20.291430: train_loss -0.3543 
2023-08-08 05:57:20.291584: val_loss -0.3915 
2023-08-08 05:57:20.291639: Pseudo dice [0.8533] 
2023-08-08 05:57:20.291689: Epoch time: 63.42 s 
2023-08-08 05:57:21.309072:  
2023-08-08 05:57:21.309170: Epoch 1086 
2023-08-08 05:57:21.309243: Current learning rate: 0.00049 
2023-08-08 05:58:24.786245: train_loss -0.3484 
2023-08-08 05:58:24.786410: val_loss -0.2938 
2023-08-08 05:58:24.786464: Pseudo dice [0.9017] 
2023-08-08 05:58:24.786515: Epoch time: 63.48 s 
2023-08-08 05:58:24.786554: Yayy! New best EMA pseudo Dice: 0.8601 
2023-08-08 05:58:26.212404:  
2023-08-08 05:58:26.212600: Epoch 1087 
2023-08-08 05:58:26.212680: Current learning rate: 0.00049 
2023-08-08 05:59:29.534661: train_loss -0.3485 
2023-08-08 05:59:29.534810: val_loss -0.3569 
2023-08-08 05:59:29.534859: Pseudo dice [0.8406] 
2023-08-08 05:59:29.534925: Epoch time: 63.32 s 
2023-08-08 05:59:30.558211:  
2023-08-08 05:59:30.558303: Epoch 1088 
2023-08-08 05:59:30.558375: Current learning rate: 0.00049 
2023-08-08 06:00:34.136927: train_loss -0.3268 
2023-08-08 06:00:34.137201: val_loss -0.4024 
2023-08-08 06:00:34.137258: Pseudo dice [0.8857] 
2023-08-08 06:00:34.137309: Epoch time: 63.58 s 
2023-08-08 06:00:34.137349: Yayy! New best EMA pseudo Dice: 0.8609 
2023-08-08 06:00:35.586287:  
2023-08-08 06:00:35.586465: Epoch 1089 
2023-08-08 06:00:35.586554: Current learning rate: 0.00049 
2023-08-08 06:01:39.282047: train_loss -0.356 
2023-08-08 06:01:39.282205: val_loss -0.4138 
2023-08-08 06:01:39.282261: Pseudo dice [0.8284] 
2023-08-08 06:01:39.282310: Epoch time: 63.7 s 
2023-08-08 06:01:40.303497:  
2023-08-08 06:01:40.303604: Epoch 1090 
2023-08-08 06:01:40.303694: Current learning rate: 0.00049 
2023-08-08 06:02:43.617635: train_loss -0.3703 
2023-08-08 06:02:43.617784: val_loss -0.3286 
2023-08-08 06:02:43.617834: Pseudo dice [0.8698] 
2023-08-08 06:02:43.617900: Epoch time: 63.31 s 
2023-08-08 06:02:44.664900:  
2023-08-08 06:02:44.664998: Epoch 1091 
2023-08-08 06:02:44.665113: Current learning rate: 0.00049 
2023-08-08 06:03:48.164027: train_loss -0.3783 
2023-08-08 06:03:48.164179: val_loss -0.3006 
2023-08-08 06:03:48.164231: Pseudo dice [0.8351] 
2023-08-08 06:03:48.164281: Epoch time: 63.5 s 
2023-08-08 06:03:49.215827:  
2023-08-08 06:03:49.215924: Epoch 1092 
2023-08-08 06:03:49.215999: Current learning rate: 0.00049 
2023-08-08 06:04:52.729781: train_loss -0.3278 
2023-08-08 06:04:52.729936: val_loss -0.3829 
2023-08-08 06:04:52.730006: Pseudo dice [0.8743] 
2023-08-08 06:04:52.730057: Epoch time: 63.51 s 
2023-08-08 06:04:53.794151:  
2023-08-08 06:04:53.794254: Epoch 1093 
2023-08-08 06:04:53.794343: Current learning rate: 0.00049 
2023-08-08 06:05:57.189323: train_loss -0.3296 
2023-08-08 06:05:57.189470: val_loss -0.3624 
2023-08-08 06:05:57.189523: Pseudo dice [0.8603] 
2023-08-08 06:05:57.189572: Epoch time: 63.4 s 
2023-08-08 06:05:58.237559:  
2023-08-08 06:05:58.237647: Epoch 1094 
2023-08-08 06:05:58.237717: Current learning rate: 0.00049 
2023-08-08 06:07:01.550854: train_loss -0.3606 
2023-08-08 06:07:01.550999: val_loss -0.3566 
2023-08-08 06:07:01.551052: Pseudo dice [0.8805] 
2023-08-08 06:07:01.551118: Epoch time: 63.31 s 
2023-08-08 06:07:02.728647:  
2023-08-08 06:07:02.728753: Epoch 1095 
2023-08-08 06:07:02.728827: Current learning rate: 0.00049 
2023-08-08 06:08:06.468947: train_loss -0.3744 
2023-08-08 06:08:06.469103: val_loss -0.3584 
2023-08-08 06:08:06.469153: Pseudo dice [0.8609] 
2023-08-08 06:08:06.469215: Epoch time: 63.74 s 
2023-08-08 06:08:07.519626:  
2023-08-08 06:08:07.519729: Epoch 1096 
2023-08-08 06:08:07.519819: Current learning rate: 0.00049 
2023-08-08 06:09:10.975960: train_loss -0.3568 
2023-08-08 06:09:10.976535: val_loss -0.3656 
2023-08-08 06:09:10.976621: Pseudo dice [0.8588] 
2023-08-08 06:09:10.976667: Epoch time: 63.46 s 
2023-08-08 06:09:11.993704:  
2023-08-08 06:09:11.993800: Epoch 1097 
2023-08-08 06:09:11.993871: Current learning rate: 0.00049 
2023-08-08 06:10:15.344817: train_loss -0.3543 
2023-08-08 06:10:15.344976: val_loss -0.3656 
2023-08-08 06:10:15.345029: Pseudo dice [0.8602] 
2023-08-08 06:10:15.345080: Epoch time: 63.35 s 
2023-08-08 06:10:16.359663:  
2023-08-08 06:10:16.359758: Epoch 1098 
2023-08-08 06:10:16.359844: Current learning rate: 0.00049 
2023-08-08 06:11:19.584281: train_loss -0.3572 
2023-08-08 06:11:19.584427: val_loss -0.3623 
2023-08-08 06:11:19.584477: Pseudo dice [0.8472] 
2023-08-08 06:11:19.584526: Epoch time: 63.23 s 
2023-08-08 06:11:20.676942:  
2023-08-08 06:11:20.677041: Epoch 1099 
2023-08-08 06:11:20.677116: Current learning rate: 0.00049 
2023-08-08 06:12:23.926893: train_loss -0.3429 
2023-08-08 06:12:23.927135: val_loss -0.3752 
2023-08-08 06:12:23.927189: Pseudo dice [0.8247] 
2023-08-08 06:12:23.927240: Epoch time: 63.25 s 
2023-08-08 06:12:25.464494:  
2023-08-08 06:12:25.464716: Epoch 1100 
2023-08-08 06:12:25.464848: Current learning rate: 0.00049 
2023-08-08 06:13:28.965736: train_loss -0.3556 
2023-08-08 06:13:28.965879: val_loss -0.318 
2023-08-08 06:13:28.965928: Pseudo dice [0.8527] 
2023-08-08 06:13:28.965977: Epoch time: 63.5 s 
2023-08-08 06:13:29.989664:  
2023-08-08 06:13:29.989763: Epoch 1101 
2023-08-08 06:13:29.989836: Current learning rate: 0.00049 
2023-08-08 06:14:33.472020: train_loss -0.3482 
2023-08-08 06:14:33.472178: val_loss -0.433 
2023-08-08 06:14:33.472232: Pseudo dice [0.8314] 
2023-08-08 06:14:33.472288: Epoch time: 63.48 s 
2023-08-08 06:14:34.500735:  
2023-08-08 06:14:34.500847: Epoch 1102 
2023-08-08 06:14:34.500938: Current learning rate: 0.00049 
2023-08-08 06:15:38.000324: train_loss -0.3788 
2023-08-08 06:15:38.000476: val_loss -0.3102 
2023-08-08 06:15:38.000533: Pseudo dice [0.873] 
2023-08-08 06:15:38.000584: Epoch time: 63.5 s 
2023-08-08 06:15:39.128239:  
2023-08-08 06:15:39.128332: Epoch 1103 
2023-08-08 06:15:39.128417: Current learning rate: 0.00049 
2023-08-08 06:16:42.721444: train_loss -0.3454 
2023-08-08 06:16:42.721597: val_loss -0.3972 
2023-08-08 06:16:42.721646: Pseudo dice [0.8754] 
2023-08-08 06:16:42.721711: Epoch time: 63.59 s 
2023-08-08 06:16:43.743149:  
2023-08-08 06:16:43.743258: Epoch 1104 
2023-08-08 06:16:43.743349: Current learning rate: 0.00049 
2023-08-08 06:17:47.089234: train_loss -0.3998 
2023-08-08 06:17:47.089399: val_loss -0.2972 
2023-08-08 06:17:47.089453: Pseudo dice [0.8112] 
2023-08-08 06:17:47.089504: Epoch time: 63.35 s 
2023-08-08 06:17:48.136189:  
2023-08-08 06:17:48.136281: Epoch 1105 
2023-08-08 06:17:48.136353: Current learning rate: 0.00048 
2023-08-08 06:18:51.622769: train_loss -0.3287 
2023-08-08 06:18:51.622988: val_loss -0.3903 
2023-08-08 06:18:51.623043: Pseudo dice [0.8677] 
2023-08-08 06:18:51.623393: Epoch time: 63.49 s 
2023-08-08 06:18:52.834064:  
2023-08-08 06:18:52.834167: Epoch 1106 
2023-08-08 06:18:52.834254: Current learning rate: 0.00048 
2023-08-08 06:19:56.258990: train_loss -0.3599 
2023-08-08 06:19:56.259136: val_loss -0.3136 
2023-08-08 06:19:56.259206: Pseudo dice [0.8665] 
2023-08-08 06:19:56.259257: Epoch time: 63.43 s 
2023-08-08 06:19:57.280558:  
2023-08-08 06:19:57.280655: Epoch 1107 
2023-08-08 06:19:57.280745: Current learning rate: 0.00048 
2023-08-08 06:21:00.810880: train_loss -0.3465 
2023-08-08 06:21:00.811059: val_loss -0.4022 
2023-08-08 06:21:00.811111: Pseudo dice [0.8325] 
2023-08-08 06:21:00.811161: Epoch time: 63.53 s 
2023-08-08 06:21:01.837106:  
2023-08-08 06:21:01.837208: Epoch 1108 
2023-08-08 06:21:01.837298: Current learning rate: 0.00048 
2023-08-08 06:22:05.157632: train_loss -0.3631 
2023-08-08 06:22:05.157910: val_loss -0.4455 
2023-08-08 06:22:05.158049: Pseudo dice [0.9162] 
2023-08-08 06:22:05.158197: Epoch time: 63.32 s 
2023-08-08 06:22:06.193320:  
2023-08-08 06:22:06.193416: Epoch 1109 
2023-08-08 06:22:06.193504: Current learning rate: 0.00048 
2023-08-08 06:23:09.604456: train_loss -0.3297 
2023-08-08 06:23:09.604601: val_loss -0.4333 
2023-08-08 06:23:09.604651: Pseudo dice [0.9449] 
2023-08-08 06:23:09.604700: Epoch time: 63.41 s 
2023-08-08 06:23:09.604740: Yayy! New best EMA pseudo Dice: 0.8678 
2023-08-08 06:23:10.992785:  
2023-08-08 06:23:10.992893: Epoch 1110 
2023-08-08 06:23:10.992966: Current learning rate: 0.00048 
2023-08-08 06:24:14.190778: train_loss -0.3399 
2023-08-08 06:24:14.190941: val_loss -0.3737 
2023-08-08 06:24:14.190995: Pseudo dice [0.8767] 
2023-08-08 06:24:14.191047: Epoch time: 63.2 s 
2023-08-08 06:24:14.191087: Yayy! New best EMA pseudo Dice: 0.8687 
2023-08-08 06:24:15.756188:  
2023-08-08 06:24:15.756305: Epoch 1111 
2023-08-08 06:24:15.756382: Current learning rate: 0.00048 
2023-08-08 06:25:18.985845: train_loss -0.3844 
2023-08-08 06:25:18.985991: val_loss -0.3888 
2023-08-08 06:25:18.986042: Pseudo dice [0.8463] 
2023-08-08 06:25:18.986092: Epoch time: 63.23 s 
2023-08-08 06:25:20.013326:  
2023-08-08 06:25:20.013431: Epoch 1112 
2023-08-08 06:25:20.013505: Current learning rate: 0.00048 
2023-08-08 06:26:23.379512: train_loss -0.344 
2023-08-08 06:26:23.379693: val_loss -0.3642 
2023-08-08 06:26:23.379748: Pseudo dice [0.856] 
2023-08-08 06:26:23.379797: Epoch time: 63.37 s 
2023-08-08 06:26:24.419457:  
2023-08-08 06:26:24.419569: Epoch 1113 
2023-08-08 06:26:24.419658: Current learning rate: 0.00048 
2023-08-08 06:27:27.798084: train_loss -0.3458 
2023-08-08 06:27:27.798237: val_loss -0.3444 
2023-08-08 06:27:27.798290: Pseudo dice [0.8657] 
2023-08-08 06:27:27.798339: Epoch time: 63.38 s 
2023-08-08 06:27:28.882437:  
2023-08-08 06:27:28.882667: Epoch 1114 
2023-08-08 06:27:28.882763: Current learning rate: 0.00048 
2023-08-08 06:28:32.302247: train_loss -0.3673 
2023-08-08 06:28:32.302407: val_loss -0.3759 
2023-08-08 06:28:32.302459: Pseudo dice [0.8258] 
2023-08-08 06:28:32.302510: Epoch time: 63.42 s 
2023-08-08 06:28:33.327208:  
2023-08-08 06:28:33.327307: Epoch 1115 
2023-08-08 06:28:33.327381: Current learning rate: 0.00048 
2023-08-08 06:29:36.774351: train_loss -0.3627 
2023-08-08 06:29:36.774512: val_loss -0.3895 
2023-08-08 06:29:36.774572: Pseudo dice [0.8888] 
2023-08-08 06:29:36.774626: Epoch time: 63.45 s 
2023-08-08 06:29:37.832105:  
2023-08-08 06:29:37.832300: Epoch 1116 
2023-08-08 06:29:37.832476: Current learning rate: 0.00048 
2023-08-08 06:30:41.250247: train_loss -0.3801 
2023-08-08 06:30:41.250405: val_loss -0.3542 
2023-08-08 06:30:41.250458: Pseudo dice [0.8781] 
2023-08-08 06:30:41.250508: Epoch time: 63.42 s 
2023-08-08 06:30:42.436670:  
2023-08-08 06:30:42.436770: Epoch 1117 
2023-08-08 06:30:42.436856: Current learning rate: 0.00048 
2023-08-08 06:31:45.748393: train_loss -0.3671 
2023-08-08 06:31:45.748544: val_loss -0.3212 
2023-08-08 06:31:45.748598: Pseudo dice [0.8467] 
2023-08-08 06:31:45.748647: Epoch time: 63.31 s 
2023-08-08 06:31:46.834063:  
2023-08-08 06:31:46.834165: Epoch 1118 
2023-08-08 06:31:46.834237: Current learning rate: 0.00048 
2023-08-08 06:32:50.225433: train_loss -0.3542 
2023-08-08 06:32:50.225580: val_loss -0.3505 
2023-08-08 06:32:50.233932: Pseudo dice [0.8011] 
2023-08-08 06:32:50.234074: Epoch time: 63.39 s 
2023-08-08 06:32:51.262695:  
2023-08-08 06:32:51.262794: Epoch 1119 
2023-08-08 06:32:51.262864: Current learning rate: 0.00048 
2023-08-08 06:33:54.652809: train_loss -0.3388 
2023-08-08 06:33:54.652972: val_loss -0.34 
2023-08-08 06:33:54.653024: Pseudo dice [0.8776] 
2023-08-08 06:33:54.653076: Epoch time: 63.39 s 
2023-08-08 06:33:55.702335:  
2023-08-08 06:33:55.702437: Epoch 1120 
2023-08-08 06:33:55.702512: Current learning rate: 0.00048 
2023-08-08 06:34:59.201119: train_loss -0.3838 
2023-08-08 06:34:59.201328: val_loss -0.2823 
2023-08-08 06:34:59.201434: Pseudo dice [0.831] 
2023-08-08 06:34:59.201525: Epoch time: 63.5 s 
2023-08-08 06:35:00.267766:  
2023-08-08 06:35:00.267876: Epoch 1121 
2023-08-08 06:35:00.267967: Current learning rate: 0.00048 
2023-08-08 06:36:03.741496: train_loss -0.366 
2023-08-08 06:36:03.741672: val_loss -0.4141 
2023-08-08 06:36:03.741747: Pseudo dice [0.8934] 
2023-08-08 06:36:03.741820: Epoch time: 63.47 s 
2023-08-08 06:36:04.919835:  
2023-08-08 06:36:04.919943: Epoch 1122 
2023-08-08 06:36:04.920030: Current learning rate: 0.00048 
2023-08-08 06:37:08.503747: train_loss -0.3712 
2023-08-08 06:37:08.503897: val_loss -0.2811 
2023-08-08 06:37:08.503951: Pseudo dice [0.8177] 
2023-08-08 06:37:08.504000: Epoch time: 63.58 s 
2023-08-08 06:37:09.519410:  
2023-08-08 06:37:09.519507: Epoch 1123 
2023-08-08 06:37:09.519598: Current learning rate: 0.00048 
2023-08-08 06:38:12.932561: train_loss -0.3767 
2023-08-08 06:38:12.932709: val_loss -0.4116 
2023-08-08 06:38:12.932760: Pseudo dice [0.8742] 
2023-08-08 06:38:12.932809: Epoch time: 63.41 s 
2023-08-08 06:38:14.019459:  
2023-08-08 06:38:14.019565: Epoch 1124 
2023-08-08 06:38:14.019674: Current learning rate: 0.00048 
2023-08-08 06:39:17.414929: train_loss -0.3459 
2023-08-08 06:39:17.415078: val_loss -0.3391 
2023-08-08 06:39:17.415131: Pseudo dice [0.8467] 
2023-08-08 06:39:17.415182: Epoch time: 63.4 s 
2023-08-08 06:39:18.472880:  
2023-08-08 06:39:18.472980: Epoch 1125 
2023-08-08 06:39:18.473097: Current learning rate: 0.00048 
2023-08-08 06:40:22.028002: train_loss -0.3632 
2023-08-08 06:40:22.028162: val_loss -0.3842 
2023-08-08 06:40:22.028216: Pseudo dice [0.8458] 
2023-08-08 06:40:22.028267: Epoch time: 63.56 s 
2023-08-08 06:40:23.052463:  
2023-08-08 06:40:23.052559: Epoch 1126 
2023-08-08 06:40:23.052631: Current learning rate: 0.00047 
2023-08-08 06:41:26.545108: train_loss -0.3414 
2023-08-08 06:41:26.545261: val_loss -0.3825 
2023-08-08 06:41:26.545322: Pseudo dice [0.8927] 
2023-08-08 06:41:26.545373: Epoch time: 63.49 s 
2023-08-08 06:41:27.591829:  
2023-08-08 06:41:27.591925: Epoch 1127 
2023-08-08 06:41:27.591995: Current learning rate: 0.00047 
2023-08-08 06:42:31.117454: train_loss -0.3465 
2023-08-08 06:42:31.117600: val_loss -0.4033 
2023-08-08 06:42:31.117652: Pseudo dice [0.8573] 
2023-08-08 06:42:31.117717: Epoch time: 63.53 s 
2023-08-08 06:42:32.325550:  
2023-08-08 06:42:32.325648: Epoch 1128 
2023-08-08 06:42:32.325717: Current learning rate: 0.00047 
2023-08-08 06:43:35.655743: train_loss -0.377 
2023-08-08 06:43:35.655891: val_loss -0.3868 
2023-08-08 06:43:35.655942: Pseudo dice [0.8096] 
2023-08-08 06:43:35.655992: Epoch time: 63.33 s 
2023-08-08 06:43:36.735964:  
2023-08-08 06:43:36.736065: Epoch 1129 
2023-08-08 06:43:36.736152: Current learning rate: 0.00047 
2023-08-08 06:44:40.288095: train_loss -0.3637 
2023-08-08 06:44:40.288247: val_loss -0.3484 
2023-08-08 06:44:40.288298: Pseudo dice [0.8297] 
2023-08-08 06:44:40.288348: Epoch time: 63.55 s 
2023-08-08 06:44:41.384271:  
2023-08-08 06:44:41.384371: Epoch 1130 
2023-08-08 06:44:41.384457: Current learning rate: 0.00047 
2023-08-08 06:45:44.752305: train_loss -0.3507 
2023-08-08 06:45:44.752467: val_loss -0.3486 
2023-08-08 06:45:44.752521: Pseudo dice [0.7933] 
2023-08-08 06:45:44.752575: Epoch time: 63.37 s 
2023-08-08 06:45:45.797121:  
2023-08-08 06:45:45.797226: Epoch 1131 
2023-08-08 06:45:45.797318: Current learning rate: 0.00047 
2023-08-08 06:46:49.148835: train_loss -0.3588 
2023-08-08 06:46:49.148980: val_loss -0.4072 
2023-08-08 06:46:49.149033: Pseudo dice [0.7898] 
2023-08-08 06:46:49.149081: Epoch time: 63.35 s 
2023-08-08 06:46:50.197394:  
2023-08-08 06:46:50.197682: Epoch 1132 
2023-08-08 06:46:50.197845: Current learning rate: 0.00047 
2023-08-08 06:47:53.511280: train_loss -0.3512 
2023-08-08 06:47:53.511449: val_loss -0.4512 
2023-08-08 06:47:53.511501: Pseudo dice [0.9086] 
2023-08-08 06:47:53.511560: Epoch time: 63.31 s 
2023-08-08 06:47:54.539077:  
2023-08-08 06:47:54.539175: Epoch 1133 
2023-08-08 06:47:54.539248: Current learning rate: 0.00047 
2023-08-08 06:48:57.939766: train_loss -0.3775 
2023-08-08 06:48:57.939913: val_loss -0.4141 
2023-08-08 06:48:57.939967: Pseudo dice [0.8754] 
2023-08-08 06:48:57.940017: Epoch time: 63.4 s 
2023-08-08 06:48:59.126667:  
2023-08-08 06:48:59.126768: Epoch 1134 
2023-08-08 06:48:59.126856: Current learning rate: 0.00047 
2023-08-08 06:50:02.592823: train_loss -0.3644 
2023-08-08 06:50:02.592990: val_loss -0.3059 
2023-08-08 06:50:02.593043: Pseudo dice [0.7931] 
2023-08-08 06:50:02.593093: Epoch time: 63.47 s 
2023-08-08 06:50:03.609232:  
2023-08-08 06:50:03.609511: Epoch 1135 
2023-08-08 06:50:03.609704: Current learning rate: 0.00047 
2023-08-08 06:51:07.153377: train_loss -0.359 
2023-08-08 06:51:07.153535: val_loss -0.3617 
2023-08-08 06:51:07.153587: Pseudo dice [0.9273] 
2023-08-08 06:51:07.153637: Epoch time: 63.54 s 
2023-08-08 06:51:08.216911:  
2023-08-08 06:51:08.217007: Epoch 1136 
2023-08-08 06:51:08.217078: Current learning rate: 0.00047 
2023-08-08 06:52:11.752217: train_loss -0.4074 
2023-08-08 06:52:11.752373: val_loss -0.409 
2023-08-08 06:52:11.752426: Pseudo dice [0.8324] 
2023-08-08 06:52:11.752479: Epoch time: 63.54 s 
2023-08-08 06:52:12.806630:  
2023-08-08 06:52:12.806728: Epoch 1137 
2023-08-08 06:52:12.806814: Current learning rate: 0.00047 
2023-08-08 06:53:16.164439: train_loss -0.3607 
2023-08-08 06:53:16.164597: val_loss -0.3255 
2023-08-08 06:53:16.164650: Pseudo dice [0.8434] 
2023-08-08 06:53:16.164701: Epoch time: 63.36 s 
2023-08-08 06:53:17.192403:  
2023-08-08 06:53:17.192502: Epoch 1138 
2023-08-08 06:53:17.192594: Current learning rate: 0.00047 
2023-08-08 06:54:20.525316: train_loss -0.3339 
2023-08-08 06:54:20.525462: val_loss -0.3268 
2023-08-08 06:54:20.525512: Pseudo dice [0.8884] 
2023-08-08 06:54:20.525562: Epoch time: 63.33 s 
2023-08-08 06:54:21.538340:  
2023-08-08 06:54:21.538433: Epoch 1139 
2023-08-08 06:54:21.538521: Current learning rate: 0.00047 
2023-08-08 06:55:24.964592: train_loss -0.3762 
2023-08-08 06:55:24.964733: val_loss -0.2878 
2023-08-08 06:55:24.964786: Pseudo dice [0.7744] 
2023-08-08 06:55:24.964836: Epoch time: 63.43 s 
2023-08-08 06:55:26.150071:  
2023-08-08 06:55:26.150177: Epoch 1140 
2023-08-08 06:55:26.150250: Current learning rate: 0.00047 
2023-08-08 06:56:29.457953: train_loss -0.3333 
2023-08-08 06:56:29.458107: val_loss -0.3536 
2023-08-08 06:56:29.458160: Pseudo dice [0.907] 
2023-08-08 06:56:29.458210: Epoch time: 63.31 s 
2023-08-08 06:56:30.480955:  
2023-08-08 06:56:30.481230: Epoch 1141 
2023-08-08 06:56:30.481357: Current learning rate: 0.00047 
2023-08-08 06:57:33.793663: train_loss -0.3684 
2023-08-08 06:57:33.793808: val_loss -0.3095 
2023-08-08 06:57:33.793858: Pseudo dice [0.8273] 
2023-08-08 06:57:33.793907: Epoch time: 63.31 s 
2023-08-08 06:57:34.820759:  
2023-08-08 06:57:34.820863: Epoch 1142 
2023-08-08 06:57:34.820935: Current learning rate: 0.00047 
2023-08-08 06:58:38.154913: train_loss -0.3337 
2023-08-08 06:58:38.155059: val_loss -0.4187 
2023-08-08 06:58:38.155115: Pseudo dice [0.8982] 
2023-08-08 06:58:38.155167: Epoch time: 63.33 s 
2023-08-08 06:58:39.177091:  
2023-08-08 06:58:39.177188: Epoch 1143 
2023-08-08 06:58:39.177259: Current learning rate: 0.00047 
2023-08-08 06:59:42.683407: train_loss -0.3554 
2023-08-08 06:59:42.683563: val_loss -0.3759 
2023-08-08 06:59:42.683632: Pseudo dice [0.7929] 
2023-08-08 06:59:42.683682: Epoch time: 63.51 s 
2023-08-08 06:59:43.725439:  
2023-08-08 06:59:43.725538: Epoch 1144 
2023-08-08 06:59:43.725625: Current learning rate: 0.00047 
2023-08-08 07:00:47.022838: train_loss -0.3765 
2023-08-08 07:00:47.022993: val_loss -0.3772 
2023-08-08 07:00:47.023063: Pseudo dice [0.8514] 
2023-08-08 07:00:47.023116: Epoch time: 63.3 s 
2023-08-08 07:00:48.083260:  
2023-08-08 07:00:48.083353: Epoch 1145 
2023-08-08 07:00:48.083424: Current learning rate: 0.00047 
2023-08-08 07:01:51.589787: train_loss -0.3751 
2023-08-08 07:01:51.589933: val_loss -0.3519 
2023-08-08 07:01:51.590000: Pseudo dice [0.8169] 
2023-08-08 07:01:51.590050: Epoch time: 63.51 s 
2023-08-08 07:01:52.789173:  
2023-08-08 07:01:52.789282: Epoch 1146 
2023-08-08 07:01:52.789373: Current learning rate: 0.00046 
2023-08-08 07:02:56.275258: train_loss -0.3542 
2023-08-08 07:02:56.275466: val_loss -0.3635 
2023-08-08 07:02:56.275568: Pseudo dice [0.9187] 
2023-08-08 07:02:56.275658: Epoch time: 63.49 s 
2023-08-08 07:02:57.354823:  
2023-08-08 07:02:57.354924: Epoch 1147 
2023-08-08 07:02:57.355000: Current learning rate: 0.00046 
2023-08-08 07:04:00.739705: train_loss -0.36 
2023-08-08 07:04:00.739861: val_loss -0.3615 
2023-08-08 07:04:00.739919: Pseudo dice [0.8621] 
2023-08-08 07:04:00.739970: Epoch time: 63.39 s 
2023-08-08 07:04:01.797127:  
2023-08-08 07:04:01.797227: Epoch 1148 
2023-08-08 07:04:01.797302: Current learning rate: 0.00046 
2023-08-08 07:05:05.163524: train_loss -0.3856 
2023-08-08 07:05:05.163707: val_loss -0.335 
2023-08-08 07:05:05.163760: Pseudo dice [0.8884] 
2023-08-08 07:05:05.163812: Epoch time: 63.37 s 
2023-08-08 07:05:06.206121:  
2023-08-08 07:05:06.206218: Epoch 1149 
2023-08-08 07:05:06.206287: Current learning rate: 0.00046 
2023-08-08 07:06:09.778076: train_loss -0.3946 
2023-08-08 07:06:09.778229: val_loss -0.3306 
2023-08-08 07:06:09.778281: Pseudo dice [0.8151] 
2023-08-08 07:06:09.778331: Epoch time: 63.57 s 
2023-08-08 07:06:11.204517:  
2023-08-08 07:06:11.204634: Epoch 1150 
2023-08-08 07:06:11.204735: Current learning rate: 0.00046 
2023-08-08 07:07:14.467538: train_loss -0.3379 
2023-08-08 07:07:14.467695: val_loss -0.3126 
2023-08-08 07:07:14.467745: Pseudo dice [0.7907] 
2023-08-08 07:07:14.467795: Epoch time: 63.26 s 
2023-08-08 07:07:15.653059:  
2023-08-08 07:07:15.653164: Epoch 1151 
2023-08-08 07:07:15.653238: Current learning rate: 0.00046 
2023-08-08 07:08:19.023885: train_loss -0.3848 
2023-08-08 07:08:19.024032: val_loss -0.4241 
2023-08-08 07:08:19.024082: Pseudo dice [0.8632] 
2023-08-08 07:08:19.024132: Epoch time: 63.37 s 
2023-08-08 07:08:20.067438:  
2023-08-08 07:08:20.067539: Epoch 1152 
2023-08-08 07:08:20.067621: Current learning rate: 0.00046 
2023-08-08 07:09:23.825386: train_loss -0.3407 
2023-08-08 07:09:23.825557: val_loss -0.4361 
2023-08-08 07:09:23.825609: Pseudo dice [0.8513] 
2023-08-08 07:09:23.825661: Epoch time: 63.76 s 
2023-08-08 07:09:24.894302:  
2023-08-08 07:09:24.894403: Epoch 1153 
2023-08-08 07:09:24.894492: Current learning rate: 0.00046 
2023-08-08 07:10:28.547976: train_loss -0.368 
2023-08-08 07:10:28.548121: val_loss -0.3343 
2023-08-08 07:10:28.548176: Pseudo dice [0.8488] 
2023-08-08 07:10:28.548226: Epoch time: 63.65 s 
2023-08-08 07:10:29.611736:  
2023-08-08 07:10:29.611836: Epoch 1154 
2023-08-08 07:10:29.611927: Current learning rate: 0.00046 
2023-08-08 07:11:33.138021: train_loss -0.3453 
2023-08-08 07:11:33.138164: val_loss -0.3341 
2023-08-08 07:11:33.138232: Pseudo dice [0.864] 
2023-08-08 07:11:33.138283: Epoch time: 63.53 s 
2023-08-08 07:11:34.235344:  
2023-08-08 07:11:34.235457: Epoch 1155 
2023-08-08 07:11:34.235529: Current learning rate: 0.00046 
2023-08-08 07:12:37.691013: train_loss -0.3734 
2023-08-08 07:12:37.691161: val_loss -0.3383 
2023-08-08 07:12:37.691211: Pseudo dice [0.8446] 
2023-08-08 07:12:37.691278: Epoch time: 63.46 s 
2023-08-08 07:12:38.750803:  
2023-08-08 07:12:38.750900: Epoch 1156 
2023-08-08 07:12:38.750987: Current learning rate: 0.00046 
2023-08-08 07:13:42.291866: train_loss -0.3803 
2023-08-08 07:13:42.292011: val_loss -0.3562 
2023-08-08 07:13:42.292064: Pseudo dice [0.8423] 
2023-08-08 07:13:42.292113: Epoch time: 63.54 s 
2023-08-08 07:13:43.495061:  
2023-08-08 07:13:43.495167: Epoch 1157 
2023-08-08 07:13:43.495255: Current learning rate: 0.00046 
2023-08-08 07:14:46.882726: train_loss -0.3272 
2023-08-08 07:14:46.882879: val_loss -0.3799 
2023-08-08 07:14:46.882933: Pseudo dice [0.9136] 
2023-08-08 07:14:46.882983: Epoch time: 63.39 s 
2023-08-08 07:14:47.964971:  
2023-08-08 07:14:47.965071: Epoch 1158 
2023-08-08 07:14:47.965140: Current learning rate: 0.00046 
2023-08-08 07:15:51.301486: train_loss -0.3739 
2023-08-08 07:15:51.301634: val_loss -0.2944 
2023-08-08 07:15:51.301686: Pseudo dice [0.8813] 
2023-08-08 07:15:51.301745: Epoch time: 63.34 s 
2023-08-08 07:15:52.342615:  
2023-08-08 07:15:52.342717: Epoch 1159 
2023-08-08 07:15:52.342831: Current learning rate: 0.00046 
2023-08-08 07:16:55.797966: train_loss -0.3475 
2023-08-08 07:16:55.798126: val_loss -0.4243 
2023-08-08 07:16:55.798177: Pseudo dice [0.8143] 
2023-08-08 07:16:55.798229: Epoch time: 63.46 s 
2023-08-08 07:16:56.847485:  
2023-08-08 07:16:56.847594: Epoch 1160 
2023-08-08 07:16:56.847667: Current learning rate: 0.00046 
2023-08-08 07:18:00.311224: train_loss -0.3624 
2023-08-08 07:18:00.311384: val_loss -0.2811 
2023-08-08 07:18:00.311433: Pseudo dice [0.8576] 
2023-08-08 07:18:00.311499: Epoch time: 63.46 s 
2023-08-08 07:18:01.350785:  
2023-08-08 07:18:01.350886: Epoch 1161 
2023-08-08 07:18:01.350958: Current learning rate: 0.00046 
2023-08-08 07:19:04.673658: train_loss -0.3669 
2023-08-08 07:19:04.673810: val_loss -0.3632 
2023-08-08 07:19:04.673863: Pseudo dice [0.9001] 
2023-08-08 07:19:04.673914: Epoch time: 63.32 s 
2023-08-08 07:19:05.719497:  
2023-08-08 07:19:05.719631: Epoch 1162 
2023-08-08 07:19:05.719707: Current learning rate: 0.00046 
2023-08-08 07:20:09.028314: train_loss -0.3583 
2023-08-08 07:20:09.028468: val_loss -0.3808 
2023-08-08 07:20:09.028522: Pseudo dice [0.7999] 
2023-08-08 07:20:09.028572: Epoch time: 63.31 s 
2023-08-08 07:20:10.322250:  
2023-08-08 07:20:10.322371: Epoch 1163 
2023-08-08 07:20:10.322446: Current learning rate: 0.00046 
2023-08-08 07:21:13.755751: train_loss -0.3546 
2023-08-08 07:21:13.755900: val_loss -0.365 
2023-08-08 07:21:13.755950: Pseudo dice [0.8909] 
2023-08-08 07:21:13.755999: Epoch time: 63.43 s 
2023-08-08 07:21:14.832192:  
2023-08-08 07:21:14.832440: Epoch 1164 
2023-08-08 07:21:14.832595: Current learning rate: 0.00046 
2023-08-08 07:22:18.260721: train_loss -0.3682 
2023-08-08 07:22:18.260892: val_loss -0.3956 
2023-08-08 07:22:18.260953: Pseudo dice [0.8963] 
2023-08-08 07:22:18.261020: Epoch time: 63.43 s 
2023-08-08 07:22:19.299742:  
2023-08-08 07:22:19.299840: Epoch 1165 
2023-08-08 07:22:19.299911: Current learning rate: 0.00046 
2023-08-08 07:23:22.847598: train_loss -0.3654 
2023-08-08 07:23:22.847773: val_loss -0.3737 
2023-08-08 07:23:22.847824: Pseudo dice [0.9215] 
2023-08-08 07:23:22.847875: Epoch time: 63.55 s 
2023-08-08 07:23:23.888080:  
2023-08-08 07:23:23.888178: Epoch 1166 
2023-08-08 07:23:23.888250: Current learning rate: 0.00046 
2023-08-08 07:24:27.356089: train_loss -0.371 
2023-08-08 07:24:27.356232: val_loss -0.3512 
2023-08-08 07:24:27.356285: Pseudo dice [0.8159] 
2023-08-08 07:24:27.356336: Epoch time: 63.47 s 
2023-08-08 07:24:28.406528:  
2023-08-08 07:24:28.406624: Epoch 1167 
2023-08-08 07:24:28.406693: Current learning rate: 0.00045 
2023-08-08 07:25:31.884794: train_loss -0.3603 
2023-08-08 07:25:31.884941: val_loss -0.4175 
2023-08-08 07:25:31.884991: Pseudo dice [0.8832] 
2023-08-08 07:25:31.885042: Epoch time: 63.48 s 
2023-08-08 07:25:33.110504:  
2023-08-08 07:25:33.110612: Epoch 1168 
2023-08-08 07:25:33.110700: Current learning rate: 0.00045 
2023-08-08 07:26:36.735729: train_loss -0.3432 
2023-08-08 07:26:36.735884: val_loss -0.3326 
2023-08-08 07:26:36.735937: Pseudo dice [0.8506] 
2023-08-08 07:26:36.735988: Epoch time: 63.63 s 
2023-08-08 07:26:37.770995:  
2023-08-08 07:26:37.771095: Epoch 1169 
2023-08-08 07:26:37.771167: Current learning rate: 0.00045 
2023-08-08 07:27:41.327585: train_loss -0.3366 
2023-08-08 07:27:41.327752: val_loss -0.3858 
2023-08-08 07:27:41.327804: Pseudo dice [0.8187] 
2023-08-08 07:27:41.327854: Epoch time: 63.56 s 
2023-08-08 07:27:42.364263:  
2023-08-08 07:27:42.364441: Epoch 1170 
2023-08-08 07:27:42.364515: Current learning rate: 0.00045 
2023-08-08 07:28:45.771426: train_loss -0.3786 
2023-08-08 07:28:45.771574: val_loss -0.3844 
2023-08-08 07:28:45.771645: Pseudo dice [0.8216] 
2023-08-08 07:28:45.771695: Epoch time: 63.41 s 
2023-08-08 07:28:46.813442:  
2023-08-08 07:28:46.813543: Epoch 1171 
2023-08-08 07:28:46.813614: Current learning rate: 0.00045 
2023-08-08 07:29:50.116631: train_loss -0.3525 
2023-08-08 07:29:50.116797: val_loss -0.3731 
2023-08-08 07:29:50.116849: Pseudo dice [0.8224] 
2023-08-08 07:29:50.116915: Epoch time: 63.3 s 
2023-08-08 07:29:51.187247:  
2023-08-08 07:29:51.187344: Epoch 1172 
2023-08-08 07:29:51.187416: Current learning rate: 0.00045 
2023-08-08 07:30:54.543312: train_loss -0.3527 
2023-08-08 07:30:54.543459: val_loss -0.3675 
2023-08-08 07:30:54.543510: Pseudo dice [0.8609] 
2023-08-08 07:30:54.543570: Epoch time: 63.36 s 
2023-08-08 07:30:55.761969:  
2023-08-08 07:30:55.762075: Epoch 1173 
2023-08-08 07:30:55.762176: Current learning rate: 0.00045 
2023-08-08 07:31:59.082929: train_loss -0.3847 
2023-08-08 07:31:59.083082: val_loss -0.3778 
2023-08-08 07:31:59.083130: Pseudo dice [0.8951] 
2023-08-08 07:31:59.083195: Epoch time: 63.32 s 
2023-08-08 07:32:00.150398:  
2023-08-08 07:32:00.150493: Epoch 1174 
2023-08-08 07:32:00.150582: Current learning rate: 0.00045 
2023-08-08 07:33:03.524505: train_loss -0.351 
2023-08-08 07:33:03.524653: val_loss -0.3204 
2023-08-08 07:33:03.524705: Pseudo dice [0.8657] 
2023-08-08 07:33:03.524755: Epoch time: 63.37 s 
2023-08-08 07:33:04.564292:  
2023-08-08 07:33:04.564391: Epoch 1175 
2023-08-08 07:33:04.564463: Current learning rate: 0.00045 
2023-08-08 07:34:07.756261: train_loss -0.3817 
2023-08-08 07:34:07.756407: val_loss -0.3195 
2023-08-08 07:34:07.756460: Pseudo dice [0.8639] 
2023-08-08 07:34:07.756510: Epoch time: 63.19 s 
2023-08-08 07:34:08.804334:  
2023-08-08 07:34:08.804429: Epoch 1176 
2023-08-08 07:34:08.804504: Current learning rate: 0.00045 
2023-08-08 07:35:12.105340: train_loss -0.3305 
2023-08-08 07:35:12.105488: val_loss -0.374 
2023-08-08 07:35:12.105537: Pseudo dice [0.8663] 
2023-08-08 07:35:12.105585: Epoch time: 63.3 s 
2023-08-08 07:35:13.151793:  
2023-08-08 07:35:13.151891: Epoch 1177 
2023-08-08 07:35:13.151978: Current learning rate: 0.00045 
2023-08-08 07:36:16.472241: train_loss -0.3377 
2023-08-08 07:36:16.472394: val_loss -0.348 
2023-08-08 07:36:16.472444: Pseudo dice [0.861] 
2023-08-08 07:36:16.472494: Epoch time: 63.32 s 
2023-08-08 07:36:17.510813:  
2023-08-08 07:36:17.510991: Epoch 1178 
2023-08-08 07:36:17.511081: Current learning rate: 0.00045 
2023-08-08 07:37:20.998743: train_loss -0.3579 
2023-08-08 07:37:20.998907: val_loss -0.3226 
2023-08-08 07:37:20.998959: Pseudo dice [0.7737] 
2023-08-08 07:37:20.999025: Epoch time: 63.49 s 
2023-08-08 07:37:22.216025:  
2023-08-08 07:37:22.216137: Epoch 1179 
2023-08-08 07:37:22.216217: Current learning rate: 0.00045 
2023-08-08 07:38:25.646812: train_loss -0.3775 
2023-08-08 07:38:25.646977: val_loss -0.3514 
2023-08-08 07:38:25.647029: Pseudo dice [0.808] 
2023-08-08 07:38:25.647080: Epoch time: 63.43 s 
2023-08-08 07:38:26.690568:  
2023-08-08 07:38:26.690673: Epoch 1180 
2023-08-08 07:38:26.690748: Current learning rate: 0.00045 
2023-08-08 07:39:30.087830: train_loss -0.3718 
2023-08-08 07:39:30.087981: val_loss -0.4008 
2023-08-08 07:39:30.088036: Pseudo dice [0.878] 
2023-08-08 07:39:30.088086: Epoch time: 63.4 s 
2023-08-08 07:39:31.166881:  
2023-08-08 07:39:31.166980: Epoch 1181 
2023-08-08 07:39:31.167068: Current learning rate: 0.00045 
2023-08-08 07:40:34.773450: train_loss -0.3728 
2023-08-08 07:40:34.773623: val_loss -0.4312 
2023-08-08 07:40:34.773692: Pseudo dice [0.8868] 
2023-08-08 07:40:34.773745: Epoch time: 63.61 s 
2023-08-08 07:40:35.817879:  
2023-08-08 07:40:35.817979: Epoch 1182 
2023-08-08 07:40:35.818094: Current learning rate: 0.00045 
2023-08-08 07:41:39.239139: train_loss -0.3691 
2023-08-08 07:41:39.239374: val_loss -0.3429 
2023-08-08 07:41:39.239433: Pseudo dice [0.8413] 
2023-08-08 07:41:39.239486: Epoch time: 63.42 s 
2023-08-08 07:41:40.295143:  
2023-08-08 07:41:40.295238: Epoch 1183 
2023-08-08 07:41:40.295311: Current learning rate: 0.00045 
2023-08-08 07:42:43.596950: train_loss -0.4007 
2023-08-08 07:42:43.597096: val_loss -0.4163 
2023-08-08 07:42:43.597163: Pseudo dice [0.8828] 
2023-08-08 07:42:43.597213: Epoch time: 63.3 s 
2023-08-08 07:42:44.788707:  
2023-08-08 07:42:44.788818: Epoch 1184 
2023-08-08 07:42:44.788912: Current learning rate: 0.00045 
2023-08-08 07:43:48.164168: train_loss -0.3232 
2023-08-08 07:43:48.164321: val_loss -0.4143 
2023-08-08 07:43:48.164375: Pseudo dice [0.8825] 
2023-08-08 07:43:48.164426: Epoch time: 63.38 s 
2023-08-08 07:43:49.225996:  
2023-08-08 07:43:49.226095: Epoch 1185 
2023-08-08 07:43:49.226166: Current learning rate: 0.00045 
2023-08-08 07:44:52.540541: train_loss -0.356 
2023-08-08 07:44:52.540693: val_loss -0.4346 
2023-08-08 07:44:52.540743: Pseudo dice [0.8009] 
2023-08-08 07:44:52.540794: Epoch time: 63.32 s 
2023-08-08 07:44:53.598515:  
2023-08-08 07:44:53.598622: Epoch 1186 
2023-08-08 07:44:53.598711: Current learning rate: 0.00045 
2023-08-08 07:45:57.006920: train_loss -0.3812 
2023-08-08 07:45:57.007077: val_loss -0.411 
2023-08-08 07:45:57.007145: Pseudo dice [0.877] 
2023-08-08 07:45:57.007195: Epoch time: 63.41 s 
2023-08-08 07:45:58.086047:  
2023-08-08 07:45:58.086249: Epoch 1187 
2023-08-08 07:45:58.086343: Current learning rate: 0.00044 
2023-08-08 07:47:01.604723: train_loss -0.3923 
2023-08-08 07:47:01.604872: val_loss -0.3604 
2023-08-08 07:47:01.604921: Pseudo dice [0.8398] 
2023-08-08 07:47:01.604972: Epoch time: 63.52 s 
2023-08-08 07:47:02.732011:  
2023-08-08 07:47:02.732107: Epoch 1188 
2023-08-08 07:47:02.732180: Current learning rate: 0.00044 
2023-08-08 07:48:06.190898: train_loss -0.3583 
2023-08-08 07:48:06.191055: val_loss -0.3626 
2023-08-08 07:48:06.191109: Pseudo dice [0.8562] 
2023-08-08 07:48:06.191176: Epoch time: 63.46 s 
2023-08-08 07:48:07.255382:  
2023-08-08 07:48:07.255476: Epoch 1189 
2023-08-08 07:48:07.255570: Current learning rate: 0.00044 
2023-08-08 07:49:10.776268: train_loss -0.3316 
2023-08-08 07:49:10.776418: val_loss -0.3037 
2023-08-08 07:49:10.776472: Pseudo dice [0.8844] 
2023-08-08 07:49:10.776522: Epoch time: 63.52 s 
2023-08-08 07:49:11.983800:  
2023-08-08 07:49:11.983899: Epoch 1190 
2023-08-08 07:49:11.983974: Current learning rate: 0.00044 
2023-08-08 07:50:15.437106: train_loss -0.3478 
2023-08-08 07:50:15.437254: val_loss -0.3131 
2023-08-08 07:50:15.437321: Pseudo dice [0.7454] 
2023-08-08 07:50:15.437371: Epoch time: 63.45 s 
2023-08-08 07:50:16.485735:  
2023-08-08 07:50:16.485837: Epoch 1191 
2023-08-08 07:50:16.485909: Current learning rate: 0.00044 
2023-08-08 07:51:19.845762: train_loss -0.366 
2023-08-08 07:51:19.845923: val_loss -0.3026 
2023-08-08 07:51:19.845981: Pseudo dice [0.8242] 
2023-08-08 07:51:19.846033: Epoch time: 63.36 s 
2023-08-08 07:51:20.922144:  
2023-08-08 07:51:20.922244: Epoch 1192 
2023-08-08 07:51:20.922315: Current learning rate: 0.00044 
2023-08-08 07:52:24.564307: train_loss -0.3661 
2023-08-08 07:52:24.564456: val_loss -0.4559 
2023-08-08 07:52:24.564507: Pseudo dice [0.8856] 
2023-08-08 07:52:24.564557: Epoch time: 63.64 s 
2023-08-08 07:52:25.613392:  
2023-08-08 07:52:25.613492: Epoch 1193 
2023-08-08 07:52:25.613563: Current learning rate: 0.00044 
2023-08-08 07:53:28.746616: train_loss -0.3398 
2023-08-08 07:53:28.746781: val_loss -0.3515 
2023-08-08 07:53:28.746833: Pseudo dice [0.7742] 
2023-08-08 07:53:28.746883: Epoch time: 63.13 s 
2023-08-08 07:53:29.792404:  
2023-08-08 07:53:29.792505: Epoch 1194 
2023-08-08 07:53:29.792577: Current learning rate: 0.00044 
2023-08-08 07:54:33.223806: train_loss -0.3488 
2023-08-08 07:54:33.223960: val_loss -0.3722 
2023-08-08 07:54:33.224015: Pseudo dice [0.8396] 
2023-08-08 07:54:33.224067: Epoch time: 63.43 s 
2023-08-08 07:54:34.455258:  
2023-08-08 07:54:34.455355: Epoch 1195 
2023-08-08 07:54:34.455427: Current learning rate: 0.00044 
2023-08-08 07:55:37.912148: train_loss -0.3521 
2023-08-08 07:55:37.912297: val_loss -0.4 
2023-08-08 07:55:37.912350: Pseudo dice [0.878] 
2023-08-08 07:55:37.912400: Epoch time: 63.46 s 
2023-08-08 07:55:39.013657:  
2023-08-08 07:55:39.013755: Epoch 1196 
2023-08-08 07:55:39.013844: Current learning rate: 0.00044 
2023-08-08 07:56:42.360235: train_loss -0.354 
2023-08-08 07:56:42.360380: val_loss -0.4007 
2023-08-08 07:56:42.360434: Pseudo dice [0.8585] 
2023-08-08 07:56:42.360483: Epoch time: 63.35 s 
2023-08-08 07:56:43.402795:  
2023-08-08 07:56:43.402890: Epoch 1197 
2023-08-08 07:56:43.402976: Current learning rate: 0.00044 
2023-08-08 07:57:46.825763: train_loss -0.3601 
2023-08-08 07:57:46.825922: val_loss -0.3574 
2023-08-08 07:57:46.825980: Pseudo dice [0.8735] 
2023-08-08 07:57:46.826047: Epoch time: 63.42 s 
2023-08-08 07:57:47.874937:  
2023-08-08 07:57:47.875037: Epoch 1198 
2023-08-08 07:57:47.875112: Current learning rate: 0.00044 
2023-08-08 07:58:51.229580: train_loss -0.3659 
2023-08-08 07:58:51.229727: val_loss -0.3619 
2023-08-08 07:58:51.229796: Pseudo dice [0.9172] 
2023-08-08 07:58:51.229846: Epoch time: 63.36 s 
2023-08-08 07:58:52.287068:  
2023-08-08 07:58:52.287279: Epoch 1199 
2023-08-08 07:58:52.287357: Current learning rate: 0.00044 
2023-08-08 07:59:55.575587: train_loss -0.369 
2023-08-08 07:59:55.575752: val_loss -0.3355 
2023-08-08 07:59:55.575803: Pseudo dice [0.8119] 
2023-08-08 07:59:55.575853: Epoch time: 63.29 s 
2023-08-08 07:59:56.993044:  
2023-08-08 07:59:56.993137: Epoch 1200 
2023-08-08 07:59:56.993210: Current learning rate: 0.00044 
2023-08-08 08:01:00.288896: train_loss -0.3376 
2023-08-08 08:01:00.289047: val_loss -0.3568 
2023-08-08 08:01:00.289099: Pseudo dice [0.8547] 
2023-08-08 08:01:00.289150: Epoch time: 63.3 s 
2023-08-08 08:01:01.519709:  
2023-08-08 08:01:01.519814: Epoch 1201 
2023-08-08 08:01:01.519889: Current learning rate: 0.00044 
2023-08-08 08:02:04.812319: train_loss -0.4056 
2023-08-08 08:02:04.812471: val_loss -0.4226 
2023-08-08 08:02:04.812524: Pseudo dice [0.8869] 
2023-08-08 08:02:04.812574: Epoch time: 63.29 s 
2023-08-08 08:02:05.870552:  
2023-08-08 08:02:05.870649: Epoch 1202 
2023-08-08 08:02:05.870722: Current learning rate: 0.00044 
2023-08-08 08:03:09.195836: train_loss -0.3286 
2023-08-08 08:03:09.195998: val_loss -0.3677 
2023-08-08 08:03:09.196051: Pseudo dice [0.865] 
2023-08-08 08:03:09.196102: Epoch time: 63.33 s 
2023-08-08 08:03:10.262288:  
2023-08-08 08:03:10.262387: Epoch 1203 
2023-08-08 08:03:10.262459: Current learning rate: 0.00044 
2023-08-08 08:04:13.652655: train_loss -0.3453 
2023-08-08 08:04:13.652805: val_loss -0.3426 
2023-08-08 08:04:13.652857: Pseudo dice [0.8937] 
2023-08-08 08:04:13.652907: Epoch time: 63.39 s 
2023-08-08 08:04:14.698082:  
2023-08-08 08:04:14.698189: Epoch 1204 
2023-08-08 08:04:14.698260: Current learning rate: 0.00044 
2023-08-08 08:05:18.148438: train_loss -0.3724 
2023-08-08 08:05:18.148608: val_loss -0.2881 
2023-08-08 08:05:18.148663: Pseudo dice [0.8692] 
2023-08-08 08:05:18.148715: Epoch time: 63.45 s 
2023-08-08 08:05:19.193224:  
2023-08-08 08:05:19.193427: Epoch 1205 
2023-08-08 08:05:19.193519: Current learning rate: 0.00044 
2023-08-08 08:06:22.712466: train_loss -0.349 
2023-08-08 08:06:22.712619: val_loss -0.3597 
2023-08-08 08:06:22.712672: Pseudo dice [0.8347] 
2023-08-08 08:06:22.712721: Epoch time: 63.52 s 
2023-08-08 08:06:23.912548:  
2023-08-08 08:06:23.912644: Epoch 1206 
2023-08-08 08:06:23.912733: Current learning rate: 0.00044 
2023-08-08 08:07:27.432328: train_loss -0.3476 
2023-08-08 08:07:27.432477: val_loss -0.3844 
2023-08-08 08:07:27.432529: Pseudo dice [0.8617] 
2023-08-08 08:07:27.432579: Epoch time: 63.52 s 
2023-08-08 08:07:28.531267:  
2023-08-08 08:07:28.531366: Epoch 1207 
2023-08-08 08:07:28.531438: Current learning rate: 0.00043 
2023-08-08 08:08:31.972340: train_loss -0.3622 
2023-08-08 08:08:31.972492: val_loss -0.3132 
2023-08-08 08:08:31.972544: Pseudo dice [0.8135] 
2023-08-08 08:08:31.972595: Epoch time: 63.44 s 
2023-08-08 08:08:33.054238:  
2023-08-08 08:08:33.054337: Epoch 1208 
2023-08-08 08:08:33.054426: Current learning rate: 0.00043 
2023-08-08 08:09:36.420052: train_loss -0.3765 
2023-08-08 08:09:36.420210: val_loss -0.331 
2023-08-08 08:09:36.420265: Pseudo dice [0.8874] 
2023-08-08 08:09:36.420316: Epoch time: 63.37 s 
2023-08-08 08:09:37.465774:  
2023-08-08 08:09:37.465890: Epoch 1209 
2023-08-08 08:09:37.465963: Current learning rate: 0.00043 
2023-08-08 08:10:40.871042: train_loss -0.3591 
2023-08-08 08:10:40.871185: val_loss -0.4258 
2023-08-08 08:10:40.871247: Pseudo dice [0.8445] 
2023-08-08 08:10:40.871315: Epoch time: 63.41 s 
2023-08-08 08:10:41.935003:  
2023-08-08 08:10:41.935098: Epoch 1210 
2023-08-08 08:10:41.935185: Current learning rate: 0.00043 
2023-08-08 08:11:45.307518: train_loss -0.3741 
2023-08-08 08:11:45.307701: val_loss -0.3781 
2023-08-08 08:11:45.307754: Pseudo dice [0.8547] 
2023-08-08 08:11:45.307804: Epoch time: 63.37 s 
2023-08-08 08:11:46.505039:  
2023-08-08 08:11:46.505142: Epoch 1211 
2023-08-08 08:11:46.505231: Current learning rate: 0.00043 
2023-08-08 08:12:49.902996: train_loss -0.385 
2023-08-08 08:12:49.903146: val_loss -0.4678 
2023-08-08 08:12:49.903214: Pseudo dice [0.844] 
2023-08-08 08:12:49.903263: Epoch time: 63.4 s 
2023-08-08 08:12:50.959648:  
2023-08-08 08:12:50.959747: Epoch 1212 
2023-08-08 08:12:50.959819: Current learning rate: 0.00043 
2023-08-08 08:13:54.360389: train_loss -0.3301 
2023-08-08 08:13:54.360547: val_loss -0.3482 
2023-08-08 08:13:54.360601: Pseudo dice [0.8561] 
2023-08-08 08:13:54.360651: Epoch time: 63.4 s 
2023-08-08 08:13:55.406657:  
2023-08-08 08:13:55.406755: Epoch 1213 
2023-08-08 08:13:55.406829: Current learning rate: 0.00043 
2023-08-08 08:14:58.628072: train_loss -0.3383 
2023-08-08 08:14:58.628225: val_loss -0.3308 
2023-08-08 08:14:58.628279: Pseudo dice [0.8028] 
2023-08-08 08:14:58.628330: Epoch time: 63.22 s 
2023-08-08 08:14:59.673938:  
2023-08-08 08:14:59.674036: Epoch 1214 
2023-08-08 08:14:59.674113: Current learning rate: 0.00043 
2023-08-08 08:16:02.922545: train_loss -0.3657 
2023-08-08 08:16:02.922692: val_loss -0.3968 
2023-08-08 08:16:02.922742: Pseudo dice [0.9107] 
2023-08-08 08:16:02.922792: Epoch time: 63.25 s 
2023-08-08 08:16:03.966477:  
2023-08-08 08:16:03.966570: Epoch 1215 
2023-08-08 08:16:03.966639: Current learning rate: 0.00043 
2023-08-08 08:17:07.101330: train_loss -0.3586 
2023-08-08 08:17:07.101550: val_loss -0.3467 
2023-08-08 08:17:07.101648: Pseudo dice [0.8961] 
2023-08-08 08:17:07.101744: Epoch time: 63.14 s 
2023-08-08 08:17:08.187700:  
2023-08-08 08:17:08.187792: Epoch 1216 
2023-08-08 08:17:08.187863: Current learning rate: 0.00043 
2023-08-08 08:18:11.566368: train_loss -0.341 
2023-08-08 08:18:11.566517: val_loss -0.3987 
2023-08-08 08:18:11.566570: Pseudo dice [0.8581] 
2023-08-08 08:18:11.566620: Epoch time: 63.38 s 
2023-08-08 08:18:12.789596:  
2023-08-08 08:18:12.789694: Epoch 1217 
2023-08-08 08:18:12.789767: Current learning rate: 0.00043 
2023-08-08 08:19:16.161946: train_loss -0.3687 
2023-08-08 08:19:16.162104: val_loss -0.3681 
2023-08-08 08:19:16.162158: Pseudo dice [0.8218] 
2023-08-08 08:19:16.162210: Epoch time: 63.37 s 
2023-08-08 08:19:17.209347:  
2023-08-08 08:19:17.209446: Epoch 1218 
2023-08-08 08:19:17.209516: Current learning rate: 0.00043 
2023-08-08 08:20:20.613688: train_loss -0.3742 
2023-08-08 08:20:20.613843: val_loss -0.3766 
2023-08-08 08:20:20.613914: Pseudo dice [0.9037] 
2023-08-08 08:20:20.613967: Epoch time: 63.41 s 
2023-08-08 08:20:21.649942:  
2023-08-08 08:20:21.650046: Epoch 1219 
2023-08-08 08:20:21.650120: Current learning rate: 0.00043 
2023-08-08 08:21:25.184216: train_loss -0.3711 
2023-08-08 08:21:25.184357: val_loss -0.3474 
2023-08-08 08:21:25.184407: Pseudo dice [0.852] 
2023-08-08 08:21:25.184457: Epoch time: 63.54 s 
2023-08-08 08:21:26.242215:  
2023-08-08 08:21:26.242312: Epoch 1220 
2023-08-08 08:21:26.242383: Current learning rate: 0.00043 
2023-08-08 08:22:29.449330: train_loss -0.3636 
2023-08-08 08:22:29.449479: val_loss -0.3048 
2023-08-08 08:22:29.449548: Pseudo dice [0.8163] 
2023-08-08 08:22:29.449599: Epoch time: 63.21 s 
2023-08-08 08:22:30.500019:  
2023-08-08 08:22:30.500113: Epoch 1221 
2023-08-08 08:22:30.500204: Current learning rate: 0.00043 
2023-08-08 08:23:33.776729: train_loss -0.338 
2023-08-08 08:23:33.776886: val_loss -0.2847 
2023-08-08 08:23:33.776941: Pseudo dice [0.8114] 
2023-08-08 08:23:33.776993: Epoch time: 63.28 s 
2023-08-08 08:23:34.972905:  
2023-08-08 08:23:34.973003: Epoch 1222 
2023-08-08 08:23:34.973078: Current learning rate: 0.00043 
2023-08-08 08:24:38.371453: train_loss -0.3694 
2023-08-08 08:24:38.371632: val_loss -0.3792 
2023-08-08 08:24:38.371691: Pseudo dice [0.8908] 
2023-08-08 08:24:38.371743: Epoch time: 63.4 s 
2023-08-08 08:24:39.423302:  
2023-08-08 08:24:39.423404: Epoch 1223 
2023-08-08 08:24:39.423478: Current learning rate: 0.00043 
2023-08-08 08:25:42.918866: train_loss -0.3399 
2023-08-08 08:25:42.919013: val_loss -0.3183 
2023-08-08 08:25:42.919060: Pseudo dice [0.8173] 
2023-08-08 08:25:42.919126: Epoch time: 63.5 s 
2023-08-08 08:25:43.969689:  
2023-08-08 08:25:43.969786: Epoch 1224 
2023-08-08 08:25:43.969858: Current learning rate: 0.00043 
2023-08-08 08:26:47.311707: train_loss -0.3733 
2023-08-08 08:26:47.311860: val_loss -0.3048 
2023-08-08 08:26:47.311913: Pseudo dice [0.8412] 
2023-08-08 08:26:47.311964: Epoch time: 63.34 s 
2023-08-08 08:26:48.386009:  
2023-08-08 08:26:48.386102: Epoch 1225 
2023-08-08 08:26:48.386189: Current learning rate: 0.00043 
2023-08-08 08:27:51.815817: train_loss -0.361 
2023-08-08 08:27:51.815965: val_loss -0.353 
2023-08-08 08:27:51.816017: Pseudo dice [0.8418] 
2023-08-08 08:27:51.816068: Epoch time: 63.43 s 
2023-08-08 08:27:52.897153:  
2023-08-08 08:27:52.897249: Epoch 1226 
2023-08-08 08:27:52.897326: Current learning rate: 0.00043 
2023-08-08 08:28:56.212516: train_loss -0.3578 
2023-08-08 08:28:56.212669: val_loss -0.251 
2023-08-08 08:28:56.212718: Pseudo dice [0.8664] 
2023-08-08 08:28:56.212768: Epoch time: 63.32 s 
2023-08-08 08:28:57.319545:  
2023-08-08 08:28:57.319774: Epoch 1227 
2023-08-08 08:28:57.319870: Current learning rate: 0.00043 
2023-08-08 08:30:00.817058: train_loss -0.3398 
2023-08-08 08:30:00.817215: val_loss -0.3707 
2023-08-08 08:30:00.817266: Pseudo dice [0.8554] 
2023-08-08 08:30:00.817316: Epoch time: 63.5 s 
2023-08-08 08:30:02.058830:  
2023-08-08 08:30:02.058929: Epoch 1228 
2023-08-08 08:30:02.059001: Current learning rate: 0.00042 
2023-08-08 08:31:05.347257: train_loss -0.3809 
2023-08-08 08:31:05.347409: val_loss -0.2982 
2023-08-08 08:31:05.347479: Pseudo dice [0.8553] 
2023-08-08 08:31:05.347529: Epoch time: 63.29 s 
2023-08-08 08:31:06.403541:  
2023-08-08 08:31:06.403662: Epoch 1229 
2023-08-08 08:31:06.403737: Current learning rate: 0.00042 
2023-08-08 08:32:09.905409: train_loss -0.3663 
2023-08-08 08:32:09.905666: val_loss -0.308 
2023-08-08 08:32:09.905723: Pseudo dice [0.8942] 
2023-08-08 08:32:09.905773: Epoch time: 63.5 s 
2023-08-08 08:32:10.949016:  
2023-08-08 08:32:10.949111: Epoch 1230 
2023-08-08 08:32:10.949183: Current learning rate: 0.00042 
2023-08-08 08:33:14.343703: train_loss -0.3569 
2023-08-08 08:33:14.343860: val_loss -0.2485 
2023-08-08 08:33:14.343913: Pseudo dice [0.8535] 
2023-08-08 08:33:14.343966: Epoch time: 63.4 s 
2023-08-08 08:33:15.401135:  
2023-08-08 08:33:15.401229: Epoch 1231 
2023-08-08 08:33:15.401299: Current learning rate: 0.00042 
2023-08-08 08:34:18.819976: train_loss -0.3741 
2023-08-08 08:34:18.820137: val_loss -0.3669 
2023-08-08 08:34:18.820194: Pseudo dice [0.9212] 
2023-08-08 08:34:18.820246: Epoch time: 63.42 s 
2023-08-08 08:34:19.870570:  
2023-08-08 08:34:19.870664: Epoch 1232 
2023-08-08 08:34:19.870736: Current learning rate: 0.00042 
2023-08-08 08:35:23.178530: train_loss -0.352 
2023-08-08 08:35:23.178682: val_loss -0.3635 
2023-08-08 08:35:23.178735: Pseudo dice [0.8453] 
2023-08-08 08:35:23.178786: Epoch time: 63.31 s 
2023-08-08 08:35:24.448821:  
2023-08-08 08:35:24.448943: Epoch 1233 
2023-08-08 08:35:24.449020: Current learning rate: 0.00042 
2023-08-08 08:36:27.888990: train_loss -0.3789 
2023-08-08 08:36:27.889132: val_loss -0.3772 
2023-08-08 08:36:27.889184: Pseudo dice [0.8781] 
2023-08-08 08:36:27.889250: Epoch time: 63.44 s 
2023-08-08 08:36:29.006490:  
2023-08-08 08:36:29.006607: Epoch 1234 
2023-08-08 08:36:29.006698: Current learning rate: 0.00042 
2023-08-08 08:37:32.546908: train_loss -0.3421 
2023-08-08 08:37:32.547057: val_loss -0.3699 
2023-08-08 08:37:32.547124: Pseudo dice [0.8204] 
2023-08-08 08:37:32.547175: Epoch time: 63.54 s 
2023-08-08 08:37:33.628570:  
2023-08-08 08:37:33.628676: Epoch 1235 
2023-08-08 08:37:33.628792: Current learning rate: 0.00042 
2023-08-08 08:38:36.841738: train_loss -0.3768 
2023-08-08 08:38:36.841887: val_loss -0.391 
2023-08-08 08:38:36.841937: Pseudo dice [0.9055] 
2023-08-08 08:38:36.842002: Epoch time: 63.21 s 
2023-08-08 08:38:37.880544:  
2023-08-08 08:38:37.880642: Epoch 1236 
2023-08-08 08:38:37.880713: Current learning rate: 0.00042 
2023-08-08 08:39:41.291485: train_loss -0.3674 
2023-08-08 08:39:41.291668: val_loss -0.4337 
2023-08-08 08:39:41.291722: Pseudo dice [0.8687] 
2023-08-08 08:39:41.291773: Epoch time: 63.41 s 
2023-08-08 08:39:42.370365:  
2023-08-08 08:39:42.370456: Epoch 1237 
2023-08-08 08:39:42.370545: Current learning rate: 0.00042 
2023-08-08 08:40:45.752529: train_loss -0.3663 
2023-08-08 08:40:45.752676: val_loss -0.3165 
2023-08-08 08:40:45.752727: Pseudo dice [0.8274] 
2023-08-08 08:40:45.752777: Epoch time: 63.38 s 
2023-08-08 08:40:46.942620:  
2023-08-08 08:40:46.942731: Epoch 1238 
2023-08-08 08:40:46.942821: Current learning rate: 0.00042 
2023-08-08 08:41:50.374906: train_loss -0.4263 
2023-08-08 08:41:50.375062: val_loss -0.3521 
2023-08-08 08:41:50.375115: Pseudo dice [0.8961] 
2023-08-08 08:41:50.375167: Epoch time: 63.43 s 
2023-08-08 08:41:51.417430:  
2023-08-08 08:41:51.417530: Epoch 1239 
2023-08-08 08:41:51.417615: Current learning rate: 0.00042 
2023-08-08 08:42:54.832566: train_loss -0.3685 
2023-08-08 08:42:54.832716: val_loss -0.3428 
2023-08-08 08:42:54.832767: Pseudo dice [0.851] 
2023-08-08 08:42:54.832816: Epoch time: 63.42 s 
2023-08-08 08:42:55.914548:  
2023-08-08 08:42:55.914643: Epoch 1240 
2023-08-08 08:42:55.914718: Current learning rate: 0.00042 
2023-08-08 08:43:59.358130: train_loss -0.3523 
2023-08-08 08:43:59.358274: val_loss -0.2791 
2023-08-08 08:43:59.358341: Pseudo dice [0.9066] 
2023-08-08 08:43:59.358390: Epoch time: 63.44 s 
2023-08-08 08:44:00.410325:  
2023-08-08 08:44:00.410420: Epoch 1241 
2023-08-08 08:44:00.410489: Current learning rate: 0.00042 
2023-08-08 08:45:03.968469: train_loss -0.3643 
2023-08-08 08:45:03.968614: val_loss -0.3626 
2023-08-08 08:45:03.968667: Pseudo dice [0.8781] 
2023-08-08 08:45:03.968717: Epoch time: 63.56 s 
2023-08-08 08:45:05.023860:  
2023-08-08 08:45:05.023957: Epoch 1242 
2023-08-08 08:45:05.024029: Current learning rate: 0.00042 
2023-08-08 08:46:08.422852: train_loss -0.3256 
2023-08-08 08:46:08.423022: val_loss -0.336 
2023-08-08 08:46:08.423075: Pseudo dice [0.868] 
2023-08-08 08:46:08.423125: Epoch time: 63.4 s 
2023-08-08 08:46:09.502826:  
2023-08-08 08:46:09.502923: Epoch 1243 
2023-08-08 08:46:09.502993: Current learning rate: 0.00042 
2023-08-08 08:47:13.054981: train_loss -0.3981 
2023-08-08 08:47:13.055139: val_loss -0.4306 
2023-08-08 08:47:13.055191: Pseudo dice [0.8469] 
2023-08-08 08:47:13.055241: Epoch time: 63.55 s 
2023-08-08 08:47:14.293004:  
2023-08-08 08:47:14.293098: Epoch 1244 
2023-08-08 08:47:14.293186: Current learning rate: 0.00042 
2023-08-08 08:48:17.797151: train_loss -0.3478 
2023-08-08 08:48:17.797292: val_loss -0.3943 
2023-08-08 08:48:17.797362: Pseudo dice [0.8462] 
2023-08-08 08:48:17.797413: Epoch time: 63.5 s 
2023-08-08 08:48:18.854131:  
2023-08-08 08:48:18.854233: Epoch 1245 
2023-08-08 08:48:18.854321: Current learning rate: 0.00042 
2023-08-08 08:49:22.277000: train_loss -0.3387 
2023-08-08 08:49:22.277147: val_loss -0.321 
2023-08-08 08:49:22.277199: Pseudo dice [0.8488] 
2023-08-08 08:49:22.277267: Epoch time: 63.42 s 
2023-08-08 08:49:23.366590:  
2023-08-08 08:49:23.366689: Epoch 1246 
2023-08-08 08:49:23.366778: Current learning rate: 0.00042 
2023-08-08 08:50:27.043184: train_loss -0.3519 
2023-08-08 08:50:27.043329: val_loss -0.3695 
2023-08-08 08:50:27.043384: Pseudo dice [0.8299] 
2023-08-08 08:50:27.043437: Epoch time: 63.68 s 
2023-08-08 08:50:28.133969:  
2023-08-08 08:50:28.134075: Epoch 1247 
2023-08-08 08:50:28.134200: Current learning rate: 0.00042 
2023-08-08 08:51:31.456978: train_loss -0.3676 
2023-08-08 08:51:31.457256: val_loss -0.3275 
2023-08-08 08:51:31.457320: Pseudo dice [0.8521] 
2023-08-08 08:51:31.457373: Epoch time: 63.32 s 
2023-08-08 08:51:32.519257:  
2023-08-08 08:51:32.519536: Epoch 1248 
2023-08-08 08:51:32.519740: Current learning rate: 0.00041 
2023-08-08 08:52:36.099085: train_loss -0.3553 
2023-08-08 08:52:36.099234: val_loss -0.3726 
2023-08-08 08:52:36.099287: Pseudo dice [0.8589] 
2023-08-08 08:52:36.099356: Epoch time: 63.58 s 
2023-08-08 08:52:37.303094:  
2023-08-08 08:52:37.303187: Epoch 1249 
2023-08-08 08:52:37.303279: Current learning rate: 0.00041 
2023-08-08 08:53:40.756117: train_loss -0.3465 
2023-08-08 08:53:40.756314: val_loss -0.3467 
2023-08-08 08:53:40.756366: Pseudo dice [0.895] 
2023-08-08 08:53:40.756416: Epoch time: 63.45 s 
2023-08-08 08:53:42.170764:  
2023-08-08 08:53:42.170863: Epoch 1250 
2023-08-08 08:53:42.170934: Current learning rate: 0.00041 
2023-08-08 08:54:45.719885: train_loss -0.3643 
2023-08-08 08:54:45.720029: val_loss -0.3457 
2023-08-08 08:54:45.720079: Pseudo dice [0.8723] 
2023-08-08 08:54:45.720129: Epoch time: 63.55 s 
2023-08-08 08:54:46.766844:  
2023-08-08 08:54:46.766943: Epoch 1251 
2023-08-08 08:54:46.767031: Current learning rate: 0.00041 
2023-08-08 08:55:50.261346: train_loss -0.3181 
2023-08-08 08:55:50.261596: val_loss -0.2953 
2023-08-08 08:55:50.261709: Pseudo dice [0.8168] 
2023-08-08 08:55:50.261820: Epoch time: 63.5 s 
2023-08-08 08:55:51.351865:  
2023-08-08 08:55:51.351963: Epoch 1252 
2023-08-08 08:55:51.352037: Current learning rate: 0.00041 
2023-08-08 08:56:54.841327: train_loss -0.35 
2023-08-08 08:56:54.841472: val_loss -0.3117 
2023-08-08 08:56:54.841540: Pseudo dice [0.8633] 
2023-08-08 08:56:54.841589: Epoch time: 63.49 s 
2023-08-08 08:56:55.930396:  
2023-08-08 08:56:55.930498: Epoch 1253 
2023-08-08 08:56:55.930586: Current learning rate: 0.00041 
2023-08-08 08:57:59.352134: train_loss -0.3569 
2023-08-08 08:57:59.352597: val_loss -0.2998 
2023-08-08 08:57:59.352677: Pseudo dice [0.8276] 
2023-08-08 08:57:59.352739: Epoch time: 63.42 s 
2023-08-08 08:58:00.422068:  
2023-08-08 08:58:00.422164: Epoch 1254 
2023-08-08 08:58:00.422235: Current learning rate: 0.00041 
2023-08-08 08:59:04.041368: train_loss -0.3209 
2023-08-08 08:59:04.041532: val_loss -0.2662 
2023-08-08 08:59:04.041583: Pseudo dice [0.8927] 
2023-08-08 08:59:04.041650: Epoch time: 63.62 s 
2023-08-08 08:59:05.115384:  
2023-08-08 08:59:05.115485: Epoch 1255 
2023-08-08 08:59:05.115563: Current learning rate: 0.00041 
2023-08-08 09:00:08.318408: train_loss -0.3391 
2023-08-08 09:00:08.318555: val_loss -0.3452 
2023-08-08 09:00:08.318622: Pseudo dice [0.8593] 
2023-08-08 09:00:08.318673: Epoch time: 63.2 s 
2023-08-08 09:00:09.401581:  
2023-08-08 09:00:09.401695: Epoch 1256 
2023-08-08 09:00:09.401770: Current learning rate: 0.00041 
2023-08-08 09:01:12.834843: train_loss -0.3465 
2023-08-08 09:01:12.834992: val_loss -0.3732 
2023-08-08 09:01:12.835057: Pseudo dice [0.8267] 
2023-08-08 09:01:12.835107: Epoch time: 63.43 s 
2023-08-08 09:01:13.900100:  
2023-08-08 09:01:13.900202: Epoch 1257 
2023-08-08 09:01:13.900277: Current learning rate: 0.00041 
2023-08-08 09:02:17.201056: train_loss -0.4129 
2023-08-08 09:02:17.201527: val_loss -0.4394 
2023-08-08 09:02:17.201608: Pseudo dice [0.8922] 
2023-08-08 09:02:17.201667: Epoch time: 63.3 s 
2023-08-08 09:02:18.256668:  
2023-08-08 09:02:18.256776: Epoch 1258 
2023-08-08 09:02:18.256866: Current learning rate: 0.00041 
2023-08-08 09:03:21.703341: train_loss -0.2943 
2023-08-08 09:03:21.703487: val_loss -0.3512 
2023-08-08 09:03:21.703537: Pseudo dice [0.8307] 
2023-08-08 09:03:21.703596: Epoch time: 63.45 s 
2023-08-08 09:03:22.840219:  
2023-08-08 09:03:22.840315: Epoch 1259 
2023-08-08 09:03:22.840388: Current learning rate: 0.00041 
2023-08-08 09:04:26.069629: train_loss -0.3707 
2023-08-08 09:04:26.069779: val_loss -0.4832 
2023-08-08 09:04:26.069849: Pseudo dice [0.8559] 
2023-08-08 09:04:26.069900: Epoch time: 63.23 s 
2023-08-08 09:04:27.313729:  
2023-08-08 09:04:27.313831: Epoch 1260 
2023-08-08 09:04:27.313903: Current learning rate: 0.00041 
2023-08-08 09:05:30.756287: train_loss -0.3557 
2023-08-08 09:05:30.756444: val_loss -0.3613 
2023-08-08 09:05:30.756497: Pseudo dice [0.8624] 
2023-08-08 09:05:30.756547: Epoch time: 63.44 s 
2023-08-08 09:05:31.816370:  
2023-08-08 09:05:31.816473: Epoch 1261 
2023-08-08 09:05:31.816548: Current learning rate: 0.00041 
2023-08-08 09:06:35.247441: train_loss -0.3325 
2023-08-08 09:06:35.247606: val_loss -0.3265 
2023-08-08 09:06:35.247663: Pseudo dice [0.8267] 
2023-08-08 09:06:35.247715: Epoch time: 63.43 s 
2023-08-08 09:06:36.337827:  
2023-08-08 09:06:36.337927: Epoch 1262 
2023-08-08 09:06:36.338017: Current learning rate: 0.00041 
2023-08-08 09:07:39.636723: train_loss -0.3313 
2023-08-08 09:07:39.636877: val_loss -0.3719 
2023-08-08 09:07:39.636928: Pseudo dice [0.8789] 
2023-08-08 09:07:39.636978: Epoch time: 63.3 s 
2023-08-08 09:07:40.736373:  
2023-08-08 09:07:40.736472: Epoch 1263 
2023-08-08 09:07:40.736549: Current learning rate: 0.00041 
2023-08-08 09:08:44.145123: train_loss -0.3567 
2023-08-08 09:08:44.145288: val_loss -0.3507 
2023-08-08 09:08:44.145339: Pseudo dice [0.9013] 
2023-08-08 09:08:44.145405: Epoch time: 63.41 s 
2023-08-08 09:08:45.220444:  
2023-08-08 09:08:45.220539: Epoch 1264 
2023-08-08 09:08:45.220616: Current learning rate: 0.00041 
2023-08-08 09:09:48.558450: train_loss -0.3271 
2023-08-08 09:09:48.558614: val_loss -0.3955 
2023-08-08 09:09:48.558666: Pseudo dice [0.9023] 
2023-08-08 09:09:48.558716: Epoch time: 63.34 s 
2023-08-08 09:09:49.768828:  
2023-08-08 09:09:49.768930: Epoch 1265 
2023-08-08 09:09:49.769021: Current learning rate: 0.00041 
2023-08-08 09:10:53.292284: train_loss -0.3842 
2023-08-08 09:10:53.292430: val_loss -0.4364 
2023-08-08 09:10:53.292484: Pseudo dice [0.8356] 
2023-08-08 09:10:53.292533: Epoch time: 63.52 s 
2023-08-08 09:10:54.399763:  
2023-08-08 09:10:54.399859: Epoch 1266 
2023-08-08 09:10:54.399948: Current learning rate: 0.00041 
2023-08-08 09:11:57.870696: train_loss -0.3491 
2023-08-08 09:11:57.870853: val_loss -0.3426 
2023-08-08 09:11:57.870905: Pseudo dice [0.8664] 
2023-08-08 09:11:57.870955: Epoch time: 63.47 s 
2023-08-08 09:11:58.943711:  
2023-08-08 09:11:58.943808: Epoch 1267 
2023-08-08 09:11:58.943880: Current learning rate: 0.00041 
2023-08-08 09:13:02.591324: train_loss -0.3388 
2023-08-08 09:13:02.591471: val_loss -0.3062 
2023-08-08 09:13:02.591522: Pseudo dice [0.8303] 
2023-08-08 09:13:02.591598: Epoch time: 63.65 s 
2023-08-08 09:13:03.640098:  
2023-08-08 09:13:03.640198: Epoch 1268 
2023-08-08 09:13:03.640271: Current learning rate: 0.0004 
2023-08-08 09:14:07.106056: train_loss -0.3678 
2023-08-08 09:14:07.106200: val_loss -0.3306 
2023-08-08 09:14:07.106267: Pseudo dice [0.8952] 
2023-08-08 09:14:07.106319: Epoch time: 63.47 s 
2023-08-08 09:14:08.157819:  
2023-08-08 09:14:08.157924: Epoch 1269 
2023-08-08 09:14:08.157994: Current learning rate: 0.0004 
2023-08-08 09:15:11.729845: train_loss -0.3453 
2023-08-08 09:15:11.729996: val_loss -0.3787 
2023-08-08 09:15:11.730066: Pseudo dice [0.8777] 
2023-08-08 09:15:11.730118: Epoch time: 63.57 s 
2023-08-08 09:15:12.930311:  
2023-08-08 09:15:12.930409: Epoch 1270 
2023-08-08 09:15:12.930524: Current learning rate: 0.0004 
2023-08-08 09:16:16.557426: train_loss -0.344 
2023-08-08 09:16:16.557645: val_loss -0.3489 
2023-08-08 09:16:16.557700: Pseudo dice [0.8619] 
2023-08-08 09:16:16.557750: Epoch time: 63.63 s 
2023-08-08 09:16:17.604199:  
2023-08-08 09:16:17.604295: Epoch 1271 
2023-08-08 09:16:17.604369: Current learning rate: 0.0004 
2023-08-08 09:17:21.282236: train_loss -0.3343 
2023-08-08 09:17:21.282401: val_loss -0.3484 
2023-08-08 09:17:21.282453: Pseudo dice [0.8532] 
2023-08-08 09:17:21.282505: Epoch time: 63.68 s 
2023-08-08 09:17:22.354408:  
2023-08-08 09:17:22.354586: Epoch 1272 
2023-08-08 09:17:22.354679: Current learning rate: 0.0004 
2023-08-08 09:18:25.882417: train_loss -0.3385 
2023-08-08 09:18:25.882568: val_loss -0.438 
2023-08-08 09:18:25.882623: Pseudo dice [0.8263] 
2023-08-08 09:18:25.882672: Epoch time: 63.53 s 
2023-08-08 09:18:26.924353:  
2023-08-08 09:18:26.924461: Epoch 1273 
2023-08-08 09:18:26.924551: Current learning rate: 0.0004 
2023-08-08 09:19:30.279933: train_loss -0.3643 
2023-08-08 09:19:30.280092: val_loss -0.3465 
2023-08-08 09:19:30.280143: Pseudo dice [0.9241] 
2023-08-08 09:19:30.280195: Epoch time: 63.36 s 
2023-08-08 09:19:31.350216:  
2023-08-08 09:19:31.350310: Epoch 1274 
2023-08-08 09:19:31.350397: Current learning rate: 0.0004 
2023-08-08 09:20:34.791115: train_loss -0.3584 
2023-08-08 09:20:34.791264: val_loss -0.4566 
2023-08-08 09:20:34.791318: Pseudo dice [0.8707] 
2023-08-08 09:20:34.791385: Epoch time: 63.44 s 
2023-08-08 09:20:35.860397:  
2023-08-08 09:20:35.860496: Epoch 1275 
2023-08-08 09:20:35.860570: Current learning rate: 0.0004 
2023-08-08 09:21:39.275321: train_loss -0.3454 
2023-08-08 09:21:39.275470: val_loss -0.3898 
2023-08-08 09:21:39.275522: Pseudo dice [0.8608] 
2023-08-08 09:21:39.275579: Epoch time: 63.42 s 
2023-08-08 09:21:40.503065:  
2023-08-08 09:21:40.503168: Epoch 1276 
2023-08-08 09:21:40.503244: Current learning rate: 0.0004 
2023-08-08 09:22:43.914734: train_loss -0.3452 
2023-08-08 09:22:43.914885: val_loss -0.4177 
2023-08-08 09:22:43.914939: Pseudo dice [0.8486] 
2023-08-08 09:22:43.914989: Epoch time: 63.41 s 
2023-08-08 09:22:44.971193:  
2023-08-08 09:22:44.971293: Epoch 1277 
2023-08-08 09:22:44.971380: Current learning rate: 0.0004 
2023-08-08 09:23:48.629043: train_loss -0.3742 
2023-08-08 09:23:48.629191: val_loss -0.3801 
2023-08-08 09:23:48.629244: Pseudo dice [0.8489] 
2023-08-08 09:23:48.629294: Epoch time: 63.66 s 
2023-08-08 09:23:49.677162:  
2023-08-08 09:23:49.677265: Epoch 1278 
2023-08-08 09:23:49.677353: Current learning rate: 0.0004 
2023-08-08 09:24:53.101566: train_loss -0.3813 
2023-08-08 09:24:53.101723: val_loss -0.3954 
2023-08-08 09:24:53.101793: Pseudo dice [0.8569] 
2023-08-08 09:24:53.101844: Epoch time: 63.43 s 
2023-08-08 09:24:54.152112:  
2023-08-08 09:24:54.152210: Epoch 1279 
2023-08-08 09:24:54.152282: Current learning rate: 0.0004 
2023-08-08 09:25:57.692078: train_loss -0.3542 
2023-08-08 09:25:57.692224: val_loss -0.3697 
2023-08-08 09:25:57.692276: Pseudo dice [0.8247] 
2023-08-08 09:25:57.692325: Epoch time: 63.54 s 
2023-08-08 09:25:58.765311:  
2023-08-08 09:25:58.765408: Epoch 1280 
2023-08-08 09:25:58.765481: Current learning rate: 0.0004 
2023-08-08 09:27:02.070024: train_loss -0.3296 
2023-08-08 09:27:02.070170: val_loss -0.3027 
2023-08-08 09:27:02.070220: Pseudo dice [0.8432] 
2023-08-08 09:27:02.070286: Epoch time: 63.31 s 
2023-08-08 09:27:03.265481:  
2023-08-08 09:27:03.265605: Epoch 1281 
2023-08-08 09:27:03.265678: Current learning rate: 0.0004 
2023-08-08 09:28:06.881868: train_loss -0.3452 
2023-08-08 09:28:06.882023: val_loss -0.4001 
2023-08-08 09:28:06.882095: Pseudo dice [0.8656] 
2023-08-08 09:28:06.882147: Epoch time: 63.62 s 
2023-08-08 09:28:07.952757:  
2023-08-08 09:28:07.952853: Epoch 1282 
2023-08-08 09:28:07.952925: Current learning rate: 0.0004 
2023-08-08 09:29:11.461571: train_loss -0.3437 
2023-08-08 09:29:11.461731: val_loss -0.4164 
2023-08-08 09:29:11.461783: Pseudo dice [0.8427] 
2023-08-08 09:29:11.461852: Epoch time: 63.51 s 
2023-08-08 09:29:12.539139:  
2023-08-08 09:29:12.539240: Epoch 1283 
2023-08-08 09:29:12.539313: Current learning rate: 0.0004 
2023-08-08 09:30:16.086721: train_loss -0.3697 
2023-08-08 09:30:16.086871: val_loss -0.3183 
2023-08-08 09:30:16.086921: Pseudo dice [0.8091] 
2023-08-08 09:30:16.086972: Epoch time: 63.55 s 
2023-08-08 09:30:17.131539:  
2023-08-08 09:30:17.131660: Epoch 1284 
2023-08-08 09:30:17.131731: Current learning rate: 0.0004 
2023-08-08 09:31:20.569162: train_loss -0.3268 
2023-08-08 09:31:20.569307: val_loss -0.3949 
2023-08-08 09:31:20.569360: Pseudo dice [0.8777] 
2023-08-08 09:31:20.569411: Epoch time: 63.44 s 
2023-08-08 09:31:21.634855:  
2023-08-08 09:31:21.634950: Epoch 1285 
2023-08-08 09:31:21.635023: Current learning rate: 0.0004 
2023-08-08 09:32:25.042742: train_loss -0.3742 
2023-08-08 09:32:25.042885: val_loss -0.3662 
2023-08-08 09:32:25.042938: Pseudo dice [0.8394] 
2023-08-08 09:32:25.042997: Epoch time: 63.41 s 
2023-08-08 09:32:26.236166:  
2023-08-08 09:32:26.236272: Epoch 1286 
2023-08-08 09:32:26.236364: Current learning rate: 0.0004 
2023-08-08 09:33:29.618601: train_loss -0.3479 
2023-08-08 09:33:29.618746: val_loss -0.3665 
2023-08-08 09:33:29.618798: Pseudo dice [0.8837] 
2023-08-08 09:33:29.618848: Epoch time: 63.38 s 
2023-08-08 09:33:30.670137:  
2023-08-08 09:33:30.670236: Epoch 1287 
2023-08-08 09:33:30.670309: Current learning rate: 0.0004 
2023-08-08 09:34:34.075776: train_loss -0.4035 
2023-08-08 09:34:34.075929: val_loss -0.407 
2023-08-08 09:34:34.075984: Pseudo dice [0.9029] 
2023-08-08 09:34:34.076035: Epoch time: 63.41 s 
2023-08-08 09:34:35.148330:  
2023-08-08 09:34:35.148426: Epoch 1288 
2023-08-08 09:34:35.148499: Current learning rate: 0.00039 
2023-08-08 09:35:38.378036: train_loss -0.3812 
2023-08-08 09:35:38.378203: val_loss -0.4261 
2023-08-08 09:35:38.378271: Pseudo dice [0.8793] 
2023-08-08 09:35:38.378323: Epoch time: 63.23 s 
2023-08-08 09:35:39.427476:  
2023-08-08 09:35:39.427596: Epoch 1289 
2023-08-08 09:35:39.427687: Current learning rate: 0.00039 
2023-08-08 09:36:42.828781: train_loss -0.3838 
2023-08-08 09:36:42.829051: val_loss -0.3535 
2023-08-08 09:36:42.829105: Pseudo dice [0.837] 
2023-08-08 09:36:42.829156: Epoch time: 63.4 s 
2023-08-08 09:36:43.917204:  
2023-08-08 09:36:43.917303: Epoch 1290 
2023-08-08 09:36:43.917373: Current learning rate: 0.00039 
2023-08-08 09:37:47.387352: train_loss -0.3814 
2023-08-08 09:37:47.387507: val_loss -0.4001 
2023-08-08 09:37:47.387566: Pseudo dice [0.8737] 
2023-08-08 09:37:47.387618: Epoch time: 63.47 s 
2023-08-08 09:37:48.430887:  
2023-08-08 09:37:48.430979: Epoch 1291 
2023-08-08 09:37:48.431064: Current learning rate: 0.00039 
2023-08-08 09:38:51.799983: train_loss -0.3631 
2023-08-08 09:38:51.800134: val_loss -0.3474 
2023-08-08 09:38:51.800188: Pseudo dice [0.8962] 
2023-08-08 09:38:51.800239: Epoch time: 63.37 s 
2023-08-08 09:38:53.054011:  
2023-08-08 09:38:53.054109: Epoch 1292 
2023-08-08 09:38:53.054180: Current learning rate: 0.00039 
2023-08-08 09:39:56.407181: train_loss -0.3377 
2023-08-08 09:39:56.407347: val_loss -0.2793 
2023-08-08 09:39:56.407402: Pseudo dice [0.8081] 
2023-08-08 09:39:56.407454: Epoch time: 63.35 s 
2023-08-08 09:39:57.489013:  
2023-08-08 09:39:57.489113: Epoch 1293 
2023-08-08 09:39:57.489186: Current learning rate: 0.00039 
2023-08-08 09:41:00.889240: train_loss -0.3626 
2023-08-08 09:41:00.889388: val_loss -0.4204 
2023-08-08 09:41:00.889439: Pseudo dice [0.9051] 
2023-08-08 09:41:00.889489: Epoch time: 63.4 s 
2023-08-08 09:41:01.940713:  
2023-08-08 09:41:01.940807: Epoch 1294 
2023-08-08 09:41:01.940878: Current learning rate: 0.00039 
2023-08-08 09:42:05.342842: train_loss -0.3369 
2023-08-08 09:42:05.342996: val_loss -0.3482 
2023-08-08 09:42:05.343064: Pseudo dice [0.9155] 
2023-08-08 09:42:05.343113: Epoch time: 63.4 s 
2023-08-08 09:42:05.343152: Yayy! New best EMA pseudo Dice: 0.8688 
2023-08-08 09:42:06.775182:  
2023-08-08 09:42:06.775357: Epoch 1295 
2023-08-08 09:42:06.775448: Current learning rate: 0.00039 
2023-08-08 09:43:10.343043: train_loss -0.3448 
2023-08-08 09:43:10.343189: val_loss -0.3404 
2023-08-08 09:43:10.343240: Pseudo dice [0.865] 
2023-08-08 09:43:10.343305: Epoch time: 63.57 s 
2023-08-08 09:43:11.390672:  
2023-08-08 09:43:11.390768: Epoch 1296 
2023-08-08 09:43:11.390839: Current learning rate: 0.00039 
2023-08-08 09:44:14.848897: train_loss -0.3793 
2023-08-08 09:44:14.849068: val_loss -0.389 
2023-08-08 09:44:14.849125: Pseudo dice [0.8482] 
2023-08-08 09:44:14.849176: Epoch time: 63.46 s 
2023-08-08 09:44:16.039151:  
2023-08-08 09:44:16.039250: Epoch 1297 
2023-08-08 09:44:16.039346: Current learning rate: 0.00039 
2023-08-08 09:45:19.536565: train_loss -0.3284 
2023-08-08 09:45:19.536723: val_loss -0.266 
2023-08-08 09:45:19.536775: Pseudo dice [0.8953] 
2023-08-08 09:45:19.536824: Epoch time: 63.5 s 
2023-08-08 09:45:19.536865: Yayy! New best EMA pseudo Dice: 0.8693 
2023-08-08 09:45:20.979575:  
2023-08-08 09:45:20.979670: Epoch 1298 
2023-08-08 09:45:20.979764: Current learning rate: 0.00039 
2023-08-08 09:46:24.392434: train_loss -0.3611 
2023-08-08 09:46:24.392584: val_loss -0.2792 
2023-08-08 09:46:24.392637: Pseudo dice [0.7789] 
2023-08-08 09:46:24.392687: Epoch time: 63.41 s 
2023-08-08 09:46:25.437209:  
2023-08-08 09:46:25.437308: Epoch 1299 
2023-08-08 09:46:25.437382: Current learning rate: 0.00039 
2023-08-08 09:47:28.775857: train_loss -0.3673 
2023-08-08 09:47:28.776015: val_loss -0.3266 
2023-08-08 09:47:28.776072: Pseudo dice [0.8543] 
2023-08-08 09:47:28.776122: Epoch time: 63.34 s 
2023-08-08 09:47:30.250547:  
2023-08-08 09:47:30.250661: Epoch 1300 
2023-08-08 09:47:30.250737: Current learning rate: 0.00039 
2023-08-08 09:48:33.666777: train_loss -0.3369 
2023-08-08 09:48:33.666940: val_loss -0.3656 
2023-08-08 09:48:33.666994: Pseudo dice [0.7988] 
2023-08-08 09:48:33.667045: Epoch time: 63.42 s 
2023-08-08 09:48:34.731182:  
2023-08-08 09:48:34.731281: Epoch 1301 
2023-08-08 09:48:34.731351: Current learning rate: 0.00039 
2023-08-08 09:49:38.136078: train_loss -0.3755 
2023-08-08 09:49:38.136241: val_loss -0.3381 
2023-08-08 09:49:38.136294: Pseudo dice [0.8124] 
2023-08-08 09:49:38.136345: Epoch time: 63.41 s 
2023-08-08 09:49:39.329049:  
2023-08-08 09:49:39.329163: Epoch 1302 
2023-08-08 09:49:39.329237: Current learning rate: 0.00039 
2023-08-08 09:50:42.999396: train_loss -0.3818 
2023-08-08 09:50:42.999560: val_loss -0.3627 
2023-08-08 09:50:43.007957: Pseudo dice [0.8834] 
2023-08-08 09:50:43.008152: Epoch time: 63.67 s 
2023-08-08 09:50:44.114364:  
2023-08-08 09:50:44.114461: Epoch 1303 
2023-08-08 09:50:44.114531: Current learning rate: 0.00039 
2023-08-08 09:51:47.708701: train_loss -0.3456 
2023-08-08 09:51:47.708847: val_loss -0.378 
2023-08-08 09:51:47.708898: Pseudo dice [0.841] 
2023-08-08 09:51:47.708947: Epoch time: 63.6 s 
2023-08-08 09:51:48.791287:  
2023-08-08 09:51:48.791391: Epoch 1304 
2023-08-08 09:51:48.791463: Current learning rate: 0.00039 
2023-08-08 09:52:52.417088: train_loss -0.3545 
2023-08-08 09:52:52.417245: val_loss -0.3141 
2023-08-08 09:52:52.417315: Pseudo dice [0.7896] 
2023-08-08 09:52:52.417365: Epoch time: 63.63 s 
2023-08-08 09:52:53.471802:  
2023-08-08 09:52:53.471915: Epoch 1305 
2023-08-08 09:52:53.471989: Current learning rate: 0.00039 
2023-08-08 09:53:57.063869: train_loss -0.3791 
2023-08-08 09:53:57.064014: val_loss -0.3875 
2023-08-08 09:53:57.064065: Pseudo dice [0.863] 
2023-08-08 09:53:57.064114: Epoch time: 63.59 s 
2023-08-08 09:53:58.113587:  
2023-08-08 09:53:58.113677: Epoch 1306 
2023-08-08 09:53:58.113761: Current learning rate: 0.00039 
2023-08-08 09:55:01.598684: train_loss -0.3536 
2023-08-08 09:55:01.598845: val_loss -0.4029 
2023-08-08 09:55:01.598899: Pseudo dice [0.8391] 
2023-08-08 09:55:01.598950: Epoch time: 63.49 s 
2023-08-08 09:55:02.649628:  
2023-08-08 09:55:02.649720: Epoch 1307 
2023-08-08 09:55:02.649805: Current learning rate: 0.00039 
2023-08-08 09:56:06.143849: train_loss -0.3255 
2023-08-08 09:56:06.144004: val_loss -0.3194 
2023-08-08 09:56:06.144058: Pseudo dice [0.8579] 
2023-08-08 09:56:06.144109: Epoch time: 63.49 s 
2023-08-08 09:56:07.383215:  
2023-08-08 09:56:07.383311: Epoch 1308 
2023-08-08 09:56:07.383387: Current learning rate: 0.00038 
2023-08-08 09:57:10.790070: train_loss -0.3381 
2023-08-08 09:57:10.790225: val_loss -0.3205 
2023-08-08 09:57:10.790294: Pseudo dice [0.9048] 
2023-08-08 09:57:10.790344: Epoch time: 63.41 s 
2023-08-08 09:57:11.838208:  
2023-08-08 09:57:11.838308: Epoch 1309 
2023-08-08 09:57:11.838381: Current learning rate: 0.00038 
2023-08-08 09:58:15.440120: train_loss -0.3895 
2023-08-08 09:58:15.440269: val_loss -0.3106 
2023-08-08 09:58:15.440323: Pseudo dice [0.8358] 
2023-08-08 09:58:15.440372: Epoch time: 63.6 s 
2023-08-08 09:58:16.545377:  
2023-08-08 09:58:16.545474: Epoch 1310 
2023-08-08 09:58:16.545562: Current learning rate: 0.00038 
2023-08-08 09:59:20.013206: train_loss -0.3443 
2023-08-08 09:59:20.013381: val_loss -0.3605 
2023-08-08 09:59:20.013435: Pseudo dice [0.8782] 
2023-08-08 09:59:20.013497: Epoch time: 63.47 s 
2023-08-08 09:59:21.066655:  
2023-08-08 09:59:21.066754: Epoch 1311 
2023-08-08 09:59:21.066824: Current learning rate: 0.00038 
2023-08-08 10:00:24.421289: train_loss -0.337 
2023-08-08 10:00:24.421426: val_loss -0.3254 
2023-08-08 10:00:24.421474: Pseudo dice [0.8821] 
2023-08-08 10:00:24.421540: Epoch time: 63.36 s 
2023-08-08 10:00:25.474871:  
2023-08-08 10:00:25.474971: Epoch 1312 
2023-08-08 10:00:25.475040: Current learning rate: 0.00038 
2023-08-08 10:01:28.945195: train_loss -0.3433 
2023-08-08 10:01:28.945348: val_loss -0.3913 
2023-08-08 10:01:28.945401: Pseudo dice [0.8995] 
2023-08-08 10:01:28.945451: Epoch time: 63.47 s 
2023-08-08 10:01:30.035775:  
2023-08-08 10:01:30.035870: Epoch 1313 
2023-08-08 10:01:30.035958: Current learning rate: 0.00038 
2023-08-08 10:02:33.388877: train_loss -0.3459 
2023-08-08 10:02:33.389019: val_loss -0.3466 
2023-08-08 10:02:33.389091: Pseudo dice [0.8736] 
2023-08-08 10:02:33.389142: Epoch time: 63.35 s 
2023-08-08 10:02:34.599207:  
2023-08-08 10:02:34.599311: Epoch 1314 
2023-08-08 10:02:34.599382: Current learning rate: 0.00038 
2023-08-08 10:03:38.114586: train_loss -0.337 
2023-08-08 10:03:38.114743: val_loss -0.3481 
2023-08-08 10:03:38.114811: Pseudo dice [0.7751] 
2023-08-08 10:03:38.114860: Epoch time: 63.52 s 
2023-08-08 10:03:39.168690:  
2023-08-08 10:03:39.168788: Epoch 1315 
2023-08-08 10:03:39.168860: Current learning rate: 0.00038 
2023-08-08 10:04:42.880537: train_loss -0.3461 
2023-08-08 10:04:42.880687: val_loss -0.4099 
2023-08-08 10:04:42.880740: Pseudo dice [0.8611] 
2023-08-08 10:04:42.880789: Epoch time: 63.71 s 
2023-08-08 10:04:43.932587:  
2023-08-08 10:04:43.932689: Epoch 1316 
2023-08-08 10:04:43.932777: Current learning rate: 0.00038 
2023-08-08 10:05:47.697745: train_loss -0.3762 
2023-08-08 10:05:47.697910: val_loss -0.3628 
2023-08-08 10:05:47.697968: Pseudo dice [0.8779] 
2023-08-08 10:05:47.698024: Epoch time: 63.77 s 
2023-08-08 10:05:48.791183:  
2023-08-08 10:05:48.791382: Epoch 1317 
2023-08-08 10:05:48.791465: Current learning rate: 0.00038 
2023-08-08 10:06:52.170044: train_loss -0.357 
2023-08-08 10:06:52.170211: val_loss -0.3486 
2023-08-08 10:06:52.170264: Pseudo dice [0.9011] 
2023-08-08 10:06:52.170315: Epoch time: 63.38 s 
2023-08-08 10:06:53.223938:  
2023-08-08 10:06:53.224031: Epoch 1318 
2023-08-08 10:06:53.224105: Current learning rate: 0.00038 
2023-08-08 10:07:56.660120: train_loss -0.3823 
2023-08-08 10:07:56.660260: val_loss -0.4204 
2023-08-08 10:07:56.660310: Pseudo dice [0.8336] 
2023-08-08 10:07:56.660359: Epoch time: 63.44 s 
2023-08-08 10:07:57.871927:  
2023-08-08 10:07:57.872024: Epoch 1319 
2023-08-08 10:07:57.872102: Current learning rate: 0.00038 
2023-08-08 10:09:01.360261: train_loss -0.3635 
2023-08-08 10:09:01.360412: val_loss -0.3459 
2023-08-08 10:09:01.360463: Pseudo dice [0.8666] 
2023-08-08 10:09:01.360512: Epoch time: 63.49 s 
2023-08-08 10:09:02.427784:  
2023-08-08 10:09:02.427883: Epoch 1320 
2023-08-08 10:09:02.427970: Current learning rate: 0.00038 
2023-08-08 10:10:06.091686: train_loss -0.4019 
2023-08-08 10:10:06.091834: val_loss -0.3525 
2023-08-08 10:10:06.091887: Pseudo dice [0.83] 
2023-08-08 10:10:06.091937: Epoch time: 63.66 s 
2023-08-08 10:10:07.161026:  
2023-08-08 10:10:07.161125: Epoch 1321 
2023-08-08 10:10:07.161196: Current learning rate: 0.00038 
2023-08-08 10:11:10.706806: train_loss -0.3623 
2023-08-08 10:11:10.707083: val_loss -0.3549 
2023-08-08 10:11:10.707221: Pseudo dice [0.8171] 
2023-08-08 10:11:10.707370: Epoch time: 63.55 s 
2023-08-08 10:11:11.760622:  
2023-08-08 10:11:11.760720: Epoch 1322 
2023-08-08 10:11:11.760792: Current learning rate: 0.00038 
2023-08-08 10:12:15.290047: train_loss -0.3695 
2023-08-08 10:12:15.290198: val_loss -0.4303 
2023-08-08 10:12:15.290250: Pseudo dice [0.8448] 
2023-08-08 10:12:15.290301: Epoch time: 63.53 s 
2023-08-08 10:12:16.362334:  
2023-08-08 10:12:16.362431: Epoch 1323 
2023-08-08 10:12:16.362506: Current learning rate: 0.00038 
2023-08-08 10:13:19.931110: train_loss -0.3725 
2023-08-08 10:13:19.931283: val_loss -0.343 
2023-08-08 10:13:19.931337: Pseudo dice [0.8247] 
2023-08-08 10:13:19.931388: Epoch time: 63.57 s 
2023-08-08 10:13:21.019274:  
2023-08-08 10:13:21.019377: Epoch 1324 
2023-08-08 10:13:21.019464: Current learning rate: 0.00038 
2023-08-08 10:14:24.486317: train_loss -0.3472 
2023-08-08 10:14:24.486599: val_loss -0.46 
2023-08-08 10:14:24.486654: Pseudo dice [0.8679] 
2023-08-08 10:14:24.486706: Epoch time: 63.47 s 
2023-08-08 10:14:25.715953:  
2023-08-08 10:14:25.716075: Epoch 1325 
2023-08-08 10:14:25.716149: Current learning rate: 0.00038 
2023-08-08 10:15:29.409361: train_loss -0.3785 
2023-08-08 10:15:29.409506: val_loss -0.4408 
2023-08-08 10:15:29.409560: Pseudo dice [0.9157] 
2023-08-08 10:15:29.409609: Epoch time: 63.69 s 
2023-08-08 10:15:30.460185:  
2023-08-08 10:15:30.460281: Epoch 1326 
2023-08-08 10:15:30.460356: Current learning rate: 0.00038 
2023-08-08 10:16:34.000659: train_loss -0.3486 
2023-08-08 10:16:34.000820: val_loss -0.3544 
2023-08-08 10:16:34.009341: Pseudo dice [0.9096] 
2023-08-08 10:16:34.009570: Epoch time: 63.54 s 
2023-08-08 10:16:35.091646:  
2023-08-08 10:16:35.091746: Epoch 1327 
2023-08-08 10:16:35.091818: Current learning rate: 0.00038 
2023-08-08 10:17:38.578160: train_loss -0.3467 
2023-08-08 10:17:38.578319: val_loss -0.3896 
2023-08-08 10:17:38.578389: Pseudo dice [0.8902] 
2023-08-08 10:17:38.578440: Epoch time: 63.49 s 
2023-08-08 10:17:39.629866:  
2023-08-08 10:17:39.629965: Epoch 1328 
2023-08-08 10:17:39.630038: Current learning rate: 0.00037 
2023-08-08 10:18:43.045701: train_loss -0.354 
2023-08-08 10:18:43.045845: val_loss -0.3172 
2023-08-08 10:18:43.045896: Pseudo dice [0.841] 
2023-08-08 10:18:43.045962: Epoch time: 63.42 s 
2023-08-08 10:18:44.136381:  
2023-08-08 10:18:44.136473: Epoch 1329 
2023-08-08 10:18:44.136563: Current learning rate: 0.00037 
2023-08-08 10:19:47.576830: train_loss -0.324 
2023-08-08 10:19:47.576980: val_loss -0.3575 
2023-08-08 10:19:47.577033: Pseudo dice [0.8213] 
2023-08-08 10:19:47.577084: Epoch time: 63.44 s 
2023-08-08 10:19:48.786380:  
2023-08-08 10:19:48.786483: Epoch 1330 
2023-08-08 10:19:48.786582: Current learning rate: 0.00037 
2023-08-08 10:20:52.386896: train_loss -0.3593 
2023-08-08 10:20:52.387049: val_loss -0.3252 
2023-08-08 10:20:52.387117: Pseudo dice [0.8188] 
2023-08-08 10:20:52.387169: Epoch time: 63.6 s 
2023-08-08 10:20:53.453091:  
2023-08-08 10:20:53.453195: Epoch 1331 
2023-08-08 10:20:53.453286: Current learning rate: 0.00037 
2023-08-08 10:21:57.010162: train_loss -0.3737 
2023-08-08 10:21:57.010317: val_loss -0.3054 
2023-08-08 10:21:57.010386: Pseudo dice [0.8601] 
2023-08-08 10:21:57.010437: Epoch time: 63.56 s 
2023-08-08 10:21:58.091118:  
2023-08-08 10:21:58.091215: Epoch 1332 
2023-08-08 10:21:58.091286: Current learning rate: 0.00037 
2023-08-08 10:23:01.695310: train_loss -0.3558 
2023-08-08 10:23:01.695460: val_loss -0.3203 
2023-08-08 10:23:01.695514: Pseudo dice [0.8137] 
2023-08-08 10:23:01.695572: Epoch time: 63.6 s 
2023-08-08 10:23:02.747847:  
2023-08-08 10:23:02.747944: Epoch 1333 
2023-08-08 10:23:02.748017: Current learning rate: 0.00037 
2023-08-08 10:24:06.171345: train_loss -0.3643 
2023-08-08 10:24:06.171528: val_loss -0.4147 
2023-08-08 10:24:06.171614: Pseudo dice [0.9017] 
2023-08-08 10:24:06.171666: Epoch time: 63.42 s 
2023-08-08 10:24:07.235198:  
2023-08-08 10:24:07.235391: Epoch 1334 
2023-08-08 10:24:07.235480: Current learning rate: 0.00037 
2023-08-08 10:25:10.772791: train_loss -0.3663 
2023-08-08 10:25:10.772954: val_loss -0.3887 
2023-08-08 10:25:10.773006: Pseudo dice [0.8641] 
2023-08-08 10:25:10.773056: Epoch time: 63.54 s 
2023-08-08 10:25:12.010471:  
2023-08-08 10:25:12.010572: Epoch 1335 
2023-08-08 10:25:12.010660: Current learning rate: 0.00037 
2023-08-08 10:26:15.595285: train_loss -0.3465 
2023-08-08 10:26:15.595435: val_loss -0.3464 
2023-08-08 10:26:15.595507: Pseudo dice [0.869] 
2023-08-08 10:26:15.595564: Epoch time: 63.59 s 
2023-08-08 10:26:16.674372:  
2023-08-08 10:26:16.674476: Epoch 1336 
2023-08-08 10:26:16.674569: Current learning rate: 0.00037 
2023-08-08 10:27:20.180424: train_loss -0.3823 
2023-08-08 10:27:20.180572: val_loss -0.3217 
2023-08-08 10:27:20.180621: Pseudo dice [0.8518] 
2023-08-08 10:27:20.180669: Epoch time: 63.51 s 
2023-08-08 10:27:21.254702:  
2023-08-08 10:27:21.254796: Epoch 1337 
2023-08-08 10:27:21.254899: Current learning rate: 0.00037 
2023-08-08 10:28:24.710284: train_loss -0.3494 
2023-08-08 10:28:24.710436: val_loss -0.3471 
2023-08-08 10:28:24.710490: Pseudo dice [0.8817] 
2023-08-08 10:28:24.710540: Epoch time: 63.46 s 
2023-08-08 10:28:25.794436:  
2023-08-08 10:28:25.794536: Epoch 1338 
2023-08-08 10:28:25.794611: Current learning rate: 0.00037 
2023-08-08 10:29:29.231763: train_loss -0.3407 
2023-08-08 10:29:29.231926: val_loss -0.3576 
2023-08-08 10:29:29.231979: Pseudo dice [0.8338] 
2023-08-08 10:29:29.232030: Epoch time: 63.44 s 
2023-08-08 10:29:30.372122:  
2023-08-08 10:29:30.372215: Epoch 1339 
2023-08-08 10:29:30.372291: Current learning rate: 0.00037 
2023-08-08 10:30:33.733093: train_loss -0.3483 
2023-08-08 10:30:33.733252: val_loss -0.4006 
2023-08-08 10:30:33.733304: Pseudo dice [0.8468] 
2023-08-08 10:30:33.733353: Epoch time: 63.36 s 
2023-08-08 10:30:34.816242:  
2023-08-08 10:30:34.816338: Epoch 1340 
2023-08-08 10:30:34.816412: Current learning rate: 0.00037 
2023-08-08 10:31:38.197755: train_loss -0.3687 
2023-08-08 10:31:38.197900: val_loss -0.3409 
2023-08-08 10:31:38.197949: Pseudo dice [0.8736] 
2023-08-08 10:31:38.198014: Epoch time: 63.38 s 
2023-08-08 10:31:39.432796:  
2023-08-08 10:31:39.432899: Epoch 1341 
2023-08-08 10:31:39.432976: Current learning rate: 0.00037 
2023-08-08 10:32:42.620189: train_loss -0.3459 
2023-08-08 10:32:42.620341: val_loss -0.4124 
2023-08-08 10:32:42.620394: Pseudo dice [0.8825] 
2023-08-08 10:32:42.620446: Epoch time: 63.19 s 
2023-08-08 10:32:43.689867:  
2023-08-08 10:32:43.689975: Epoch 1342 
2023-08-08 10:32:43.690047: Current learning rate: 0.00037 
2023-08-08 10:33:47.136828: train_loss -0.3719 
2023-08-08 10:33:47.136980: val_loss -0.2957 
2023-08-08 10:33:47.137043: Pseudo dice [0.8314] 
2023-08-08 10:33:47.137092: Epoch time: 63.45 s 
2023-08-08 10:33:48.201952:  
2023-08-08 10:33:48.202051: Epoch 1343 
2023-08-08 10:33:48.202141: Current learning rate: 0.00037 
2023-08-08 10:34:51.647121: train_loss -0.369 
2023-08-08 10:34:51.647274: val_loss -0.306 
2023-08-08 10:34:51.647343: Pseudo dice [0.7661] 
2023-08-08 10:34:51.647392: Epoch time: 63.45 s 
2023-08-08 10:34:52.724266:  
2023-08-08 10:34:52.724442: Epoch 1344 
2023-08-08 10:34:52.724517: Current learning rate: 0.00037 
2023-08-08 10:35:56.109643: train_loss -0.3551 
2023-08-08 10:35:56.109794: val_loss -0.3604 
2023-08-08 10:35:56.109843: Pseudo dice [0.86] 
2023-08-08 10:35:56.109893: Epoch time: 63.39 s 
2023-08-08 10:35:57.176893:  
2023-08-08 10:35:57.176988: Epoch 1345 
2023-08-08 10:35:57.177077: Current learning rate: 0.00037 
2023-08-08 10:37:00.502707: train_loss -0.3682 
2023-08-08 10:37:00.502860: val_loss -0.3896 
2023-08-08 10:37:00.502918: Pseudo dice [0.8972] 
2023-08-08 10:37:00.502968: Epoch time: 63.33 s 
2023-08-08 10:37:01.770106:  
2023-08-08 10:37:01.770213: Epoch 1346 
2023-08-08 10:37:01.770303: Current learning rate: 0.00037 
2023-08-08 10:38:05.213372: train_loss -0.3425 
2023-08-08 10:38:05.213531: val_loss -0.3929 
2023-08-08 10:38:05.213585: Pseudo dice [0.9203] 
2023-08-08 10:38:05.213635: Epoch time: 63.44 s 
2023-08-08 10:38:06.286275:  
2023-08-08 10:38:06.286377: Epoch 1347 
2023-08-08 10:38:06.286494: Current learning rate: 0.00037 
2023-08-08 10:39:09.697838: train_loss -0.3458 
2023-08-08 10:39:09.698025: val_loss -0.3554 
2023-08-08 10:39:09.698103: Pseudo dice [0.8882] 
2023-08-08 10:39:09.698155: Epoch time: 63.41 s 
2023-08-08 10:39:10.780777:  
2023-08-08 10:39:10.780881: Epoch 1348 
2023-08-08 10:39:10.780953: Current learning rate: 0.00036 
2023-08-08 10:40:14.352421: train_loss -0.3454 
2023-08-08 10:40:14.352582: val_loss -0.3547 
2023-08-08 10:40:14.352633: Pseudo dice [0.9011] 
2023-08-08 10:40:14.352684: Epoch time: 63.57 s 
2023-08-08 10:40:15.494292:  
2023-08-08 10:40:15.494566: Epoch 1349 
2023-08-08 10:40:15.494745: Current learning rate: 0.00036 
2023-08-08 10:41:18.943492: train_loss -0.3264 
2023-08-08 10:41:18.943650: val_loss -0.3613 
2023-08-08 10:41:18.943701: Pseudo dice [0.8001] 
2023-08-08 10:41:18.943751: Epoch time: 63.45 s 
2023-08-08 10:41:20.441233:  
2023-08-08 10:41:20.441328: Epoch 1350 
2023-08-08 10:41:20.441417: Current learning rate: 0.00036 
2023-08-08 10:42:23.778134: train_loss -0.3459 
2023-08-08 10:42:23.778284: val_loss -0.3973 
2023-08-08 10:42:23.778334: Pseudo dice [0.8234] 
2023-08-08 10:42:23.778399: Epoch time: 63.34 s 
2023-08-08 10:42:25.024311:  
2023-08-08 10:42:25.024421: Epoch 1351 
2023-08-08 10:42:25.024512: Current learning rate: 0.00036 
2023-08-08 10:43:28.609653: train_loss -0.3386 
2023-08-08 10:43:28.609800: val_loss -0.398 
2023-08-08 10:43:28.609854: Pseudo dice [0.8603] 
2023-08-08 10:43:28.609903: Epoch time: 63.59 s 
2023-08-08 10:43:29.681171:  
2023-08-08 10:43:29.681273: Epoch 1352 
2023-08-08 10:43:29.681347: Current learning rate: 0.00036 
2023-08-08 10:44:33.291539: train_loss -0.3666 
2023-08-08 10:44:33.291698: val_loss -0.3547 
2023-08-08 10:44:33.291749: Pseudo dice [0.8382] 
2023-08-08 10:44:33.291800: Epoch time: 63.61 s 
2023-08-08 10:44:34.373147:  
2023-08-08 10:44:34.373246: Epoch 1353 
2023-08-08 10:44:34.373334: Current learning rate: 0.00036 
2023-08-08 10:45:37.843714: train_loss -0.3593 
2023-08-08 10:45:37.843866: val_loss -0.3713 
2023-08-08 10:45:37.843922: Pseudo dice [0.8577] 
2023-08-08 10:45:37.843977: Epoch time: 63.47 s 
2023-08-08 10:45:38.941658:  
2023-08-08 10:45:38.941766: Epoch 1354 
2023-08-08 10:45:38.941841: Current learning rate: 0.00036 
2023-08-08 10:46:42.394383: train_loss -0.3741 
2023-08-08 10:46:42.394537: val_loss -0.3073 
2023-08-08 10:46:42.394595: Pseudo dice [0.8834] 
2023-08-08 10:46:42.394646: Epoch time: 63.45 s 
2023-08-08 10:46:43.520391:  
2023-08-08 10:46:43.520487: Epoch 1355 
2023-08-08 10:46:43.520559: Current learning rate: 0.00036 
2023-08-08 10:47:47.233356: train_loss -0.3613 
2023-08-08 10:47:47.233518: val_loss -0.3422 
2023-08-08 10:47:47.233573: Pseudo dice [0.8774] 
2023-08-08 10:47:47.233623: Epoch time: 63.71 s 
2023-08-08 10:47:48.485692:  
2023-08-08 10:47:48.485794: Epoch 1356 
2023-08-08 10:47:48.485886: Current learning rate: 0.00036 
2023-08-08 10:48:52.206689: train_loss -0.3702 
2023-08-08 10:48:52.206870: val_loss -0.3665 
2023-08-08 10:48:52.206931: Pseudo dice [0.8541] 
2023-08-08 10:48:52.206982: Epoch time: 63.72 s 
2023-08-08 10:48:53.301344:  
2023-08-08 10:48:53.301446: Epoch 1357 
2023-08-08 10:48:53.301534: Current learning rate: 0.00036 
2023-08-08 10:49:56.864220: train_loss -0.3198 
2023-08-08 10:49:56.864369: val_loss -0.3474 
2023-08-08 10:49:56.864421: Pseudo dice [0.9161] 
2023-08-08 10:49:56.864473: Epoch time: 63.56 s 
2023-08-08 10:49:57.936825:  
2023-08-08 10:49:57.936925: Epoch 1358 
2023-08-08 10:49:57.937015: Current learning rate: 0.00036 
2023-08-08 10:51:01.651711: train_loss -0.347 
2023-08-08 10:51:01.651863: val_loss -0.3321 
2023-08-08 10:51:01.652024: Pseudo dice [0.8938] 
2023-08-08 10:51:01.652077: Epoch time: 63.72 s 
2023-08-08 10:51:02.718531:  
2023-08-08 10:51:02.718625: Epoch 1359 
2023-08-08 10:51:02.718697: Current learning rate: 0.00036 
2023-08-08 10:52:06.265630: train_loss -0.3851 
2023-08-08 10:52:06.265786: val_loss -0.4109 
2023-08-08 10:52:06.265839: Pseudo dice [0.8825] 
2023-08-08 10:52:06.265908: Epoch time: 63.55 s 
2023-08-08 10:52:06.265949: Yayy! New best EMA pseudo Dice: 0.8696 
2023-08-08 10:52:07.730330:  
2023-08-08 10:52:07.730421: Epoch 1360 
2023-08-08 10:52:07.730492: Current learning rate: 0.00036 
2023-08-08 10:53:11.229531: train_loss -0.3741 
2023-08-08 10:53:11.229679: val_loss -0.2723 
2023-08-08 10:53:11.229732: Pseudo dice [0.8439] 
2023-08-08 10:53:11.229782: Epoch time: 63.5 s 
2023-08-08 10:53:12.483849:  
2023-08-08 10:53:12.483963: Epoch 1361 
2023-08-08 10:53:12.484052: Current learning rate: 0.00036 
2023-08-08 10:54:16.132475: train_loss -0.3648 
2023-08-08 10:54:16.132624: val_loss -0.447 
2023-08-08 10:54:16.132676: Pseudo dice [0.861] 
2023-08-08 10:54:16.132726: Epoch time: 63.65 s 
2023-08-08 10:54:17.198320:  
2023-08-08 10:54:17.198422: Epoch 1362 
2023-08-08 10:54:17.198492: Current learning rate: 0.00036 
2023-08-08 10:55:20.558521: train_loss -0.3172 
2023-08-08 10:55:20.558670: val_loss -0.4069 
2023-08-08 10:55:20.558726: Pseudo dice [0.8925] 
2023-08-08 10:55:20.558793: Epoch time: 63.36 s 
2023-08-08 10:55:21.682057:  
2023-08-08 10:55:21.682163: Epoch 1363 
2023-08-08 10:55:21.682237: Current learning rate: 0.00036 
2023-08-08 10:56:25.379400: train_loss -0.3366 
2023-08-08 10:56:25.379563: val_loss -0.3049 
2023-08-08 10:56:25.379619: Pseudo dice [0.8653] 
2023-08-08 10:56:25.379671: Epoch time: 63.7 s 
2023-08-08 10:56:26.448498:  
2023-08-08 10:56:26.448601: Epoch 1364 
2023-08-08 10:56:26.448674: Current learning rate: 0.00036 
2023-08-08 10:57:29.872512: train_loss -0.3541 
2023-08-08 10:57:29.872655: val_loss -0.3846 
2023-08-08 10:57:29.872707: Pseudo dice [0.8429] 
2023-08-08 10:57:29.872756: Epoch time: 63.42 s 
2023-08-08 10:57:30.944362:  
2023-08-08 10:57:30.944465: Epoch 1365 
2023-08-08 10:57:30.944553: Current learning rate: 0.00036 
2023-08-08 10:58:34.366255: train_loss -0.3594 
2023-08-08 10:58:34.366404: val_loss -0.3814 
2023-08-08 10:58:34.366457: Pseudo dice [0.8318] 
2023-08-08 10:58:34.366508: Epoch time: 63.42 s 
2023-08-08 10:58:35.439648:  
2023-08-08 10:58:35.439745: Epoch 1366 
2023-08-08 10:58:35.439834: Current learning rate: 0.00036 
2023-08-08 10:59:38.895760: train_loss -0.3374 
2023-08-08 10:59:38.895902: val_loss -0.2855 
2023-08-08 10:59:38.895954: Pseudo dice [0.8333] 
2023-08-08 10:59:38.896004: Epoch time: 63.46 s 
2023-08-08 10:59:40.148714:  
2023-08-08 10:59:40.148830: Epoch 1367 
2023-08-08 10:59:40.148902: Current learning rate: 0.00036 
2023-08-08 11:00:43.827158: train_loss -0.3841 
2023-08-08 11:00:43.827309: val_loss -0.3385 
2023-08-08 11:00:43.827359: Pseudo dice [0.8183] 
2023-08-08 11:00:43.827411: Epoch time: 63.68 s 
2023-08-08 11:00:44.911919:  
2023-08-08 11:00:44.912024: Epoch 1368 
2023-08-08 11:00:44.912096: Current learning rate: 0.00035 
2023-08-08 11:01:48.361433: train_loss -0.3342 
2023-08-08 11:01:48.361578: val_loss -0.3084 
2023-08-08 11:01:48.361628: Pseudo dice [0.8402] 
2023-08-08 11:01:48.361678: Epoch time: 63.45 s 
2023-08-08 11:01:49.424003:  
2023-08-08 11:01:49.424104: Epoch 1369 
2023-08-08 11:01:49.424176: Current learning rate: 0.00035 
2023-08-08 11:02:52.964328: train_loss -0.3724 
2023-08-08 11:02:52.964479: val_loss -0.2564 
2023-08-08 11:02:52.964531: Pseudo dice [0.8385] 
2023-08-08 11:02:52.964581: Epoch time: 63.54 s 
2023-08-08 11:02:54.076764:  
2023-08-08 11:02:54.076871: Epoch 1370 
2023-08-08 11:02:54.076959: Current learning rate: 0.00035 
2023-08-08 11:03:57.552551: train_loss -0.357 
2023-08-08 11:03:57.552705: val_loss -0.4038 
2023-08-08 11:03:57.552758: Pseudo dice [0.9385] 
2023-08-08 11:03:57.552809: Epoch time: 63.48 s 
2023-08-08 11:03:58.628959:  
2023-08-08 11:03:58.629055: Epoch 1371 
2023-08-08 11:03:58.629125: Current learning rate: 0.00035 
2023-08-08 11:05:02.188469: train_loss -0.3502 
2023-08-08 11:05:02.188618: val_loss -0.2932 
2023-08-08 11:05:02.188673: Pseudo dice [0.8514] 
2023-08-08 11:05:02.188724: Epoch time: 63.56 s 
2023-08-08 11:05:03.421783:  
2023-08-08 11:05:03.421889: Epoch 1372 
2023-08-08 11:05:03.421977: Current learning rate: 0.00035 
2023-08-08 11:06:06.943122: train_loss -0.389 
2023-08-08 11:06:06.943276: val_loss -0.3325 
2023-08-08 11:06:06.943327: Pseudo dice [0.8185] 
2023-08-08 11:06:06.943378: Epoch time: 63.52 s 
2023-08-08 11:06:08.014588:  
2023-08-08 11:06:08.014689: Epoch 1373 
2023-08-08 11:06:08.014761: Current learning rate: 0.00035 
2023-08-08 11:07:11.462747: train_loss -0.3586 
2023-08-08 11:07:11.462900: val_loss -0.316 
2023-08-08 11:07:11.462952: Pseudo dice [0.8276] 
2023-08-08 11:07:11.463002: Epoch time: 63.45 s 
2023-08-08 11:07:12.567640:  
2023-08-08 11:07:12.567743: Epoch 1374 
2023-08-08 11:07:12.567817: Current learning rate: 0.00035 
2023-08-08 11:08:15.969459: train_loss -0.3525 
2023-08-08 11:08:15.969605: val_loss -0.3493 
2023-08-08 11:08:15.969656: Pseudo dice [0.8231] 
2023-08-08 11:08:15.969724: Epoch time: 63.4 s 
2023-08-08 11:08:17.038576:  
2023-08-08 11:08:17.038668: Epoch 1375 
2023-08-08 11:08:17.038737: Current learning rate: 0.00035 
2023-08-08 11:09:20.600018: train_loss -0.3464 
2023-08-08 11:09:20.600169: val_loss -0.3282 
2023-08-08 11:09:20.600221: Pseudo dice [0.8936] 
2023-08-08 11:09:20.600272: Epoch time: 63.56 s 
2023-08-08 11:09:21.664858:  
2023-08-08 11:09:21.664953: Epoch 1376 
2023-08-08 11:09:21.665025: Current learning rate: 0.00035 
2023-08-08 11:10:24.858697: train_loss -0.3339 
2023-08-08 11:10:24.858845: val_loss -0.3891 
2023-08-08 11:10:24.858898: Pseudo dice [0.896] 
2023-08-08 11:10:24.858963: Epoch time: 63.19 s 
2023-08-08 11:10:26.119157:  
2023-08-08 11:10:26.119255: Epoch 1377 
2023-08-08 11:10:26.119346: Current learning rate: 0.00035 
2023-08-08 11:11:29.486210: train_loss -0.3757 
2023-08-08 11:11:29.486378: val_loss -0.285 
2023-08-08 11:11:29.486431: Pseudo dice [0.8558] 
2023-08-08 11:11:29.486482: Epoch time: 63.37 s 
2023-08-08 11:11:30.559409:  
2023-08-08 11:11:30.559503: Epoch 1378 
2023-08-08 11:11:30.559600: Current learning rate: 0.00035 
2023-08-08 11:12:34.040240: train_loss -0.3751 
2023-08-08 11:12:34.040393: val_loss -0.522 
2023-08-08 11:12:34.040444: Pseudo dice [0.8497] 
2023-08-08 11:12:34.040495: Epoch time: 63.48 s 
2023-08-08 11:12:35.107699:  
2023-08-08 11:12:35.107798: Epoch 1379 
2023-08-08 11:12:35.107885: Current learning rate: 0.00035 
2023-08-08 11:13:38.549080: train_loss -0.3224 
2023-08-08 11:13:38.549242: val_loss -0.2953 
2023-08-08 11:13:38.549296: Pseudo dice [0.9031] 
2023-08-08 11:13:38.549347: Epoch time: 63.44 s 
2023-08-08 11:13:39.635303:  
2023-08-08 11:13:39.635400: Epoch 1380 
2023-08-08 11:13:39.635487: Current learning rate: 0.00035 
2023-08-08 11:14:43.151018: train_loss -0.3587 
2023-08-08 11:14:43.151160: val_loss -0.4162 
2023-08-08 11:14:43.151209: Pseudo dice [0.8589] 
2023-08-08 11:14:43.151275: Epoch time: 63.52 s 
2023-08-08 11:14:44.212002:  
2023-08-08 11:14:44.212098: Epoch 1381 
2023-08-08 11:14:44.212186: Current learning rate: 0.00035 
2023-08-08 11:15:47.702768: train_loss -0.3712 
2023-08-08 11:15:47.702912: val_loss -0.3387 
2023-08-08 11:15:47.702965: Pseudo dice [0.8351] 
2023-08-08 11:15:47.703015: Epoch time: 63.49 s 
2023-08-08 11:15:48.911148:  
2023-08-08 11:15:48.911245: Epoch 1382 
2023-08-08 11:15:48.911339: Current learning rate: 0.00035 
2023-08-08 11:16:52.449493: train_loss -0.358 
2023-08-08 11:16:52.449661: val_loss -0.4233 
2023-08-08 11:16:52.449740: Pseudo dice [0.8764] 
2023-08-08 11:16:52.449790: Epoch time: 63.54 s 
2023-08-08 11:16:53.567355:  
2023-08-08 11:16:53.567838: Epoch 1383 
2023-08-08 11:16:53.568084: Current learning rate: 0.00035 
2023-08-08 11:17:57.062623: train_loss -0.3833 
2023-08-08 11:17:57.062784: val_loss -0.3692 
2023-08-08 11:17:57.062837: Pseudo dice [0.8161] 
2023-08-08 11:17:57.062887: Epoch time: 63.5 s 
2023-08-08 11:17:58.182851:  
2023-08-08 11:17:58.183232: Epoch 1384 
2023-08-08 11:17:58.183309: Current learning rate: 0.00035 
2023-08-08 11:19:01.564738: train_loss -0.3504 
2023-08-08 11:19:01.564893: val_loss -0.287 
2023-08-08 11:19:01.564952: Pseudo dice [0.7937] 
2023-08-08 11:19:01.565003: Epoch time: 63.38 s 
2023-08-08 11:19:02.622098:  
2023-08-08 11:19:02.622193: Epoch 1385 
2023-08-08 11:19:02.622265: Current learning rate: 0.00035 
2023-08-08 11:20:06.080989: train_loss -0.3698 
2023-08-08 11:20:06.081147: val_loss -0.4306 
2023-08-08 11:20:06.081200: Pseudo dice [0.9081] 
2023-08-08 11:20:06.081252: Epoch time: 63.46 s 
2023-08-08 11:20:07.170454:  
2023-08-08 11:20:07.170550: Epoch 1386 
2023-08-08 11:20:07.170622: Current learning rate: 0.00035 
2023-08-08 11:21:10.815692: train_loss -0.3669 
2023-08-08 11:21:10.815848: val_loss -0.4172 
2023-08-08 11:21:10.815897: Pseudo dice [0.8645] 
2023-08-08 11:21:10.815957: Epoch time: 63.65 s 
2023-08-08 11:21:11.919397:  
2023-08-08 11:21:11.919571: Epoch 1387 
2023-08-08 11:21:11.919665: Current learning rate: 0.00034 
2023-08-08 11:22:15.292651: train_loss -0.373 
2023-08-08 11:22:15.292798: val_loss -0.4018 
2023-08-08 11:22:15.292849: Pseudo dice [0.8992] 
2023-08-08 11:22:15.292899: Epoch time: 63.37 s 
2023-08-08 11:22:16.578859:  
2023-08-08 11:22:16.578962: Epoch 1388 
2023-08-08 11:22:16.579053: Current learning rate: 0.00034 
2023-08-08 11:23:20.039176: train_loss -0.3552 
2023-08-08 11:23:20.039332: val_loss -0.3909 
2023-08-08 11:23:20.039402: Pseudo dice [0.864] 
2023-08-08 11:23:20.039452: Epoch time: 63.46 s 
2023-08-08 11:23:21.104678:  
2023-08-08 11:23:21.104779: Epoch 1389 
2023-08-08 11:23:21.104861: Current learning rate: 0.00034 
2023-08-08 11:24:24.542852: train_loss -0.3572 
2023-08-08 11:24:24.542997: val_loss -0.3054 
2023-08-08 11:24:24.543046: Pseudo dice [0.8637] 
2023-08-08 11:24:24.543112: Epoch time: 63.44 s 
2023-08-08 11:24:25.602715:  
2023-08-08 11:24:25.602814: Epoch 1390 
2023-08-08 11:24:25.602887: Current learning rate: 0.00034 
2023-08-08 11:25:29.090589: train_loss -0.4039 
2023-08-08 11:25:29.090736: val_loss -0.4042 
2023-08-08 11:25:29.090785: Pseudo dice [0.896] 
2023-08-08 11:25:29.090850: Epoch time: 63.49 s 
2023-08-08 11:25:30.167081:  
2023-08-08 11:25:30.167179: Epoch 1391 
2023-08-08 11:25:30.167267: Current learning rate: 0.00034 
2023-08-08 11:26:33.655326: train_loss -0.3629 
2023-08-08 11:26:33.655465: val_loss -0.365 
2023-08-08 11:26:33.655516: Pseudo dice [0.8148] 
2023-08-08 11:26:33.655572: Epoch time: 63.49 s 
2023-08-08 11:26:34.727037:  
2023-08-08 11:26:34.727134: Epoch 1392 
2023-08-08 11:26:34.727222: Current learning rate: 0.00034 
2023-08-08 11:27:38.353549: train_loss -0.3408 
2023-08-08 11:27:38.353734: val_loss -0.3423 
2023-08-08 11:27:38.353806: Pseudo dice [0.9091] 
2023-08-08 11:27:38.353878: Epoch time: 63.63 s 
2023-08-08 11:27:39.599224:  
2023-08-08 11:27:39.599408: Epoch 1393 
2023-08-08 11:27:39.599499: Current learning rate: 0.00034 
2023-08-08 11:28:43.213446: train_loss -0.3844 
2023-08-08 11:28:43.213589: val_loss -0.3435 
2023-08-08 11:28:43.213638: Pseudo dice [0.8702] 
2023-08-08 11:28:43.213704: Epoch time: 63.61 s 
2023-08-08 11:28:44.284321:  
2023-08-08 11:28:44.284421: Epoch 1394 
2023-08-08 11:28:44.284509: Current learning rate: 0.00034 
2023-08-08 11:29:48.037152: train_loss -0.3737 
2023-08-08 11:29:48.037301: val_loss -0.3586 
2023-08-08 11:29:48.037351: Pseudo dice [0.9582] 
2023-08-08 11:29:48.037400: Epoch time: 63.75 s 
2023-08-08 11:29:48.037439: Yayy! New best EMA pseudo Dice: 0.8747 
2023-08-08 11:29:49.509884:  
2023-08-08 11:29:49.510136: Epoch 1395 
2023-08-08 11:29:49.510347: Current learning rate: 0.00034 
2023-08-08 11:30:52.932006: train_loss -0.388 
2023-08-08 11:30:52.932144: val_loss -0.4158 
2023-08-08 11:30:52.932197: Pseudo dice [0.8821] 
2023-08-08 11:30:52.932247: Epoch time: 63.42 s 
2023-08-08 11:30:52.932287: Yayy! New best EMA pseudo Dice: 0.8754 
2023-08-08 11:30:54.408823:  
2023-08-08 11:30:54.408922: Epoch 1396 
2023-08-08 11:30:54.408996: Current learning rate: 0.00034 
2023-08-08 11:31:58.083015: train_loss -0.3832 
2023-08-08 11:31:58.083165: val_loss -0.4922 
2023-08-08 11:31:58.083215: Pseudo dice [0.8893] 
2023-08-08 11:31:58.083265: Epoch time: 63.67 s 
2023-08-08 11:31:58.083305: Yayy! New best EMA pseudo Dice: 0.8768 
2023-08-08 11:31:59.609772:  
2023-08-08 11:31:59.609871: Epoch 1397 
2023-08-08 11:31:59.609945: Current learning rate: 0.00034 
2023-08-08 11:33:02.979257: train_loss -0.3459 
2023-08-08 11:33:02.979409: val_loss -0.4264 
2023-08-08 11:33:02.979459: Pseudo dice [0.9223] 
2023-08-08 11:33:02.979507: Epoch time: 63.37 s 
2023-08-08 11:33:02.979547: Yayy! New best EMA pseudo Dice: 0.8814 
2023-08-08 11:33:04.688486:  
2023-08-08 11:33:04.688595: Epoch 1398 
2023-08-08 11:33:04.688669: Current learning rate: 0.00034 
2023-08-08 11:34:08.258921: train_loss -0.3411 
2023-08-08 11:34:08.259069: val_loss -0.3929 
2023-08-08 11:34:08.259129: Pseudo dice [0.8665] 
2023-08-08 11:34:08.259196: Epoch time: 63.57 s 
2023-08-08 11:34:09.368948:  
2023-08-08 11:34:09.369054: Epoch 1399 
2023-08-08 11:34:09.369125: Current learning rate: 0.00034 
2023-08-08 11:35:13.001559: train_loss -0.3937 
2023-08-08 11:35:13.001701: val_loss -0.3522 
2023-08-08 11:35:13.001750: Pseudo dice [0.8655] 
2023-08-08 11:35:13.001816: Epoch time: 63.63 s 
2023-08-08 11:35:14.458474:  
2023-08-08 11:35:14.458570: Epoch 1400 
2023-08-08 11:35:14.458659: Current learning rate: 0.00034 
2023-08-08 11:36:18.033789: train_loss -0.3529 
2023-08-08 11:36:18.033963: val_loss -0.3572 
2023-08-08 11:36:18.042376: Pseudo dice [0.8803] 
2023-08-08 11:36:18.042624: Epoch time: 63.58 s 
2023-08-08 11:36:19.124328:  
2023-08-08 11:36:19.124430: Epoch 1401 
2023-08-08 11:36:19.124518: Current learning rate: 0.00034 
2023-08-08 11:37:22.695282: train_loss -0.3553 
2023-08-08 11:37:22.695428: val_loss -0.3606 
2023-08-08 11:37:22.695498: Pseudo dice [0.842] 
2023-08-08 11:37:22.695549: Epoch time: 63.57 s 
2023-08-08 11:37:23.783810:  
2023-08-08 11:37:23.783906: Epoch 1402 
2023-08-08 11:37:23.783995: Current learning rate: 0.00034 
2023-08-08 11:38:27.299947: train_loss -0.3767 
2023-08-08 11:38:27.300092: val_loss -0.3217 
2023-08-08 11:38:27.300144: Pseudo dice [0.8642] 
2023-08-08 11:38:27.300195: Epoch time: 63.52 s 
2023-08-08 11:38:28.574778:  
2023-08-08 11:38:28.574987: Epoch 1403 
2023-08-08 11:38:28.575080: Current learning rate: 0.00034 
2023-08-08 11:39:32.073546: train_loss -0.4078 
2023-08-08 11:39:32.073699: val_loss -0.3678 
2023-08-08 11:39:32.073750: Pseudo dice [0.9245] 
2023-08-08 11:39:32.073801: Epoch time: 63.5 s 
2023-08-08 11:39:33.172991:  
2023-08-08 11:39:33.173198: Epoch 1404 
2023-08-08 11:39:33.173275: Current learning rate: 0.00034 
2023-08-08 11:40:36.669882: train_loss -0.3451 
2023-08-08 11:40:36.670032: val_loss -0.3755 
2023-08-08 11:40:36.670101: Pseudo dice [0.9293] 
2023-08-08 11:40:36.670154: Epoch time: 63.5 s 
2023-08-08 11:40:36.670195: Yayy! New best EMA pseudo Dice: 0.884 
2023-08-08 11:40:38.119679:  
2023-08-08 11:40:38.119916: Epoch 1405 
2023-08-08 11:40:38.120009: Current learning rate: 0.00034 
2023-08-08 11:41:41.573788: train_loss -0.35 
2023-08-08 11:41:41.573940: val_loss -0.3279 
2023-08-08 11:41:41.573990: Pseudo dice [0.8379] 
2023-08-08 11:41:41.574055: Epoch time: 63.45 s 
2023-08-08 11:41:42.660703:  
2023-08-08 11:41:42.660802: Epoch 1406 
2023-08-08 11:41:42.660891: Current learning rate: 0.00034 
2023-08-08 11:42:46.240010: train_loss -0.3686 
2023-08-08 11:42:46.240200: val_loss -0.3675 
2023-08-08 11:42:46.240259: Pseudo dice [0.9039] 
2023-08-08 11:42:46.240312: Epoch time: 63.58 s 
2023-08-08 11:42:47.307918:  
2023-08-08 11:42:47.308013: Epoch 1407 
2023-08-08 11:42:47.308099: Current learning rate: 0.00033 
2023-08-08 11:43:51.083181: train_loss -0.3733 
2023-08-08 11:43:51.083329: val_loss -0.3623 
2023-08-08 11:43:51.083398: Pseudo dice [0.8866] 
2023-08-08 11:43:51.083447: Epoch time: 63.78 s 
2023-08-08 11:43:52.351514:  
2023-08-08 11:43:52.351625: Epoch 1408 
2023-08-08 11:43:52.351733: Current learning rate: 0.00033 
2023-08-08 11:44:56.033061: train_loss -0.3533 
2023-08-08 11:44:56.033215: val_loss -0.3742 
2023-08-08 11:44:56.033274: Pseudo dice [0.8921] 
2023-08-08 11:44:56.033326: Epoch time: 63.68 s 
2023-08-08 11:44:57.096400:  
2023-08-08 11:44:57.096501: Epoch 1409 
2023-08-08 11:44:57.096573: Current learning rate: 0.00033 
2023-08-08 11:46:00.621393: train_loss -0.3727 
2023-08-08 11:46:00.621546: val_loss -0.3304 
2023-08-08 11:46:00.621597: Pseudo dice [0.781] 
2023-08-08 11:46:00.621647: Epoch time: 63.53 s 
2023-08-08 11:46:01.688930:  
2023-08-08 11:46:01.689027: Epoch 1410 
2023-08-08 11:46:01.689114: Current learning rate: 0.00033 
2023-08-08 11:47:05.095814: train_loss -0.362 
2023-08-08 11:47:05.096010: val_loss -0.3364 
2023-08-08 11:47:05.096166: Pseudo dice [0.9155] 
2023-08-08 11:47:05.096220: Epoch time: 63.41 s 
2023-08-08 11:47:06.249092:  
2023-08-08 11:47:06.249191: Epoch 1411 
2023-08-08 11:47:06.249285: Current learning rate: 0.00033 
2023-08-08 11:48:09.908075: train_loss -0.343 
2023-08-08 11:48:09.908227: val_loss -0.3146 
2023-08-08 11:48:09.908280: Pseudo dice [0.8249] 
2023-08-08 11:48:09.908330: Epoch time: 63.66 s 
2023-08-08 11:48:11.033874:  
2023-08-08 11:48:11.033967: Epoch 1412 
2023-08-08 11:48:11.034056: Current learning rate: 0.00033 
2023-08-08 11:49:14.411882: train_loss -0.3498 
2023-08-08 11:49:14.412034: val_loss -0.3556 
2023-08-08 11:49:14.412086: Pseudo dice [0.893] 
2023-08-08 11:49:14.412137: Epoch time: 63.38 s 
2023-08-08 11:49:15.481175:  
2023-08-08 11:49:15.481271: Epoch 1413 
2023-08-08 11:49:15.481347: Current learning rate: 0.00033 
2023-08-08 11:50:18.809859: train_loss -0.3528 
2023-08-08 11:50:18.810039: val_loss -0.343 
2023-08-08 11:50:18.810091: Pseudo dice [0.856] 
2023-08-08 11:50:18.810140: Epoch time: 63.33 s 
2023-08-08 11:50:20.048370:  
2023-08-08 11:50:20.048473: Epoch 1414 
2023-08-08 11:50:20.048548: Current learning rate: 0.00033 
2023-08-08 11:51:23.499051: train_loss -0.384 
2023-08-08 11:51:23.499206: val_loss -0.3261 
2023-08-08 11:51:23.499256: Pseudo dice [0.9265] 
2023-08-08 11:51:23.499322: Epoch time: 63.45 s 
2023-08-08 11:51:24.573020:  
2023-08-08 11:51:24.573125: Epoch 1415 
2023-08-08 11:51:24.573197: Current learning rate: 0.00033 
2023-08-08 11:52:28.067004: train_loss -0.3775 
2023-08-08 11:52:28.067148: val_loss -0.4032 
2023-08-08 11:52:28.067201: Pseudo dice [0.8695] 
2023-08-08 11:52:28.067269: Epoch time: 63.49 s 
2023-08-08 11:52:29.161966:  
2023-08-08 11:52:29.162060: Epoch 1416 
2023-08-08 11:52:29.162131: Current learning rate: 0.00033 
2023-08-08 11:53:32.673648: train_loss -0.3493 
2023-08-08 11:53:32.673829: val_loss -0.3689 
2023-08-08 11:53:32.673883: Pseudo dice [0.8479] 
2023-08-08 11:53:32.673933: Epoch time: 63.51 s 
2023-08-08 11:53:33.749063:  
2023-08-08 11:53:33.749156: Epoch 1417 
2023-08-08 11:53:33.749243: Current learning rate: 0.00033 
2023-08-08 11:54:37.314251: train_loss -0.3682 
2023-08-08 11:54:37.314403: val_loss -0.3409 
2023-08-08 11:54:37.314453: Pseudo dice [0.8801] 
2023-08-08 11:54:37.314521: Epoch time: 63.57 s 
2023-08-08 11:54:38.383261:  
2023-08-08 11:54:38.383353: Epoch 1418 
2023-08-08 11:54:38.383423: Current learning rate: 0.00033 
2023-08-08 11:55:42.007921: train_loss -0.393 
2023-08-08 11:55:42.008074: val_loss -0.3956 
2023-08-08 11:55:42.008131: Pseudo dice [0.8967] 
2023-08-08 11:55:42.008183: Epoch time: 63.63 s 
2023-08-08 11:55:43.243675:  
2023-08-08 11:55:43.243774: Epoch 1419 
2023-08-08 11:55:43.243861: Current learning rate: 0.00033 
2023-08-08 11:56:46.751550: train_loss -0.3714 
2023-08-08 11:56:46.751735: val_loss -0.3853 
2023-08-08 11:56:46.751787: Pseudo dice [0.8318] 
2023-08-08 11:56:46.751838: Epoch time: 63.51 s 
2023-08-08 11:56:47.857342:  
2023-08-08 11:56:47.857451: Epoch 1420 
2023-08-08 11:56:47.857541: Current learning rate: 0.00033 
2023-08-08 11:57:51.224974: train_loss -0.3518 
2023-08-08 11:57:51.225120: val_loss -0.3995 
2023-08-08 11:57:51.225173: Pseudo dice [0.9151] 
2023-08-08 11:57:51.225223: Epoch time: 63.37 s 
2023-08-08 11:57:52.343957:  
2023-08-08 11:57:52.344057: Epoch 1421 
2023-08-08 11:57:52.344132: Current learning rate: 0.00033 
2023-08-08 11:58:55.940136: train_loss -0.3686 
2023-08-08 11:58:55.940442: val_loss -0.3698 
2023-08-08 11:58:55.940583: Pseudo dice [0.8708] 
2023-08-08 11:58:55.940733: Epoch time: 63.6 s 
2023-08-08 11:58:57.043602:  
2023-08-08 11:58:57.043715: Epoch 1422 
2023-08-08 11:58:57.043788: Current learning rate: 0.00033 
2023-08-08 12:00:00.429030: train_loss -0.3431 
2023-08-08 12:00:00.429180: val_loss -0.3623 
2023-08-08 12:00:00.429259: Pseudo dice [0.8869] 
2023-08-08 12:00:00.429307: Epoch time: 63.39 s 
2023-08-08 12:00:01.526345:  
2023-08-08 12:00:01.526453: Epoch 1423 
2023-08-08 12:00:01.526541: Current learning rate: 0.00033 
2023-08-08 12:01:05.153963: train_loss -0.3544 
2023-08-08 12:01:05.154110: val_loss -0.4225 
2023-08-08 12:01:05.154163: Pseudo dice [0.8564] 
2023-08-08 12:01:05.154222: Epoch time: 63.63 s 
2023-08-08 12:01:06.223814:  
2023-08-08 12:01:06.223913: Epoch 1424 
2023-08-08 12:01:06.223985: Current learning rate: 0.00033 
2023-08-08 12:02:09.665867: train_loss -0.3273 
2023-08-08 12:02:09.666018: val_loss -0.3574 
2023-08-08 12:02:09.666073: Pseudo dice [0.8304] 
2023-08-08 12:02:09.666124: Epoch time: 63.44 s 
2023-08-08 12:02:10.745094:  
2023-08-08 12:02:10.745197: Epoch 1425 
2023-08-08 12:02:10.745272: Current learning rate: 0.00033 
2023-08-08 12:03:14.209776: train_loss -0.3653 
2023-08-08 12:03:14.209939: val_loss -0.362 
2023-08-08 12:03:14.209992: Pseudo dice [0.8393] 
2023-08-08 12:03:14.210042: Epoch time: 63.47 s 
2023-08-08 12:03:15.284434:  
2023-08-08 12:03:15.284533: Epoch 1426 
2023-08-08 12:03:15.284607: Current learning rate: 0.00033 
2023-08-08 12:04:18.624898: train_loss -0.3738 
2023-08-08 12:04:18.625065: val_loss -0.3981 
2023-08-08 12:04:18.633541: Pseudo dice [0.8742] 
2023-08-08 12:04:18.633771: Epoch time: 63.34 s 
2023-08-08 12:04:19.732285:  
2023-08-08 12:04:19.732385: Epoch 1427 
2023-08-08 12:04:19.732458: Current learning rate: 0.00032 
2023-08-08 12:05:23.248335: train_loss -0.3715 
2023-08-08 12:05:23.248492: val_loss -0.3681 
2023-08-08 12:05:23.248545: Pseudo dice [0.8419] 
2023-08-08 12:05:23.248595: Epoch time: 63.52 s 
2023-08-08 12:05:24.359860:  
2023-08-08 12:05:24.359954: Epoch 1428 
2023-08-08 12:05:24.360044: Current learning rate: 0.00032 
2023-08-08 12:06:28.089175: train_loss -0.4009 
2023-08-08 12:06:28.089327: val_loss -0.2987 
2023-08-08 12:06:28.089394: Pseudo dice [0.9065] 
2023-08-08 12:06:28.089445: Epoch time: 63.73 s 
2023-08-08 12:06:29.159635:  
2023-08-08 12:06:29.159730: Epoch 1429 
2023-08-08 12:06:29.159801: Current learning rate: 0.00032 
2023-08-08 12:07:32.473881: train_loss -0.3746 
2023-08-08 12:07:32.474047: val_loss -0.3728 
2023-08-08 12:07:32.474101: Pseudo dice [0.8567] 
2023-08-08 12:07:32.474151: Epoch time: 63.31 s 
2023-08-08 12:07:33.592040:  
2023-08-08 12:07:33.592150: Epoch 1430 
2023-08-08 12:07:33.592226: Current learning rate: 0.00032 
2023-08-08 12:08:37.164607: train_loss -0.3519 
2023-08-08 12:08:37.164772: val_loss -0.4313 
2023-08-08 12:08:37.164824: Pseudo dice [0.8608] 
2023-08-08 12:08:37.164876: Epoch time: 63.57 s 
2023-08-08 12:08:38.255412:  
2023-08-08 12:08:38.255848: Epoch 1431 
2023-08-08 12:08:38.256076: Current learning rate: 0.00032 
2023-08-08 12:09:41.756740: train_loss -0.3584 
2023-08-08 12:09:41.756902: val_loss -0.3804 
2023-08-08 12:09:41.756971: Pseudo dice [0.9179] 
2023-08-08 12:09:41.757022: Epoch time: 63.5 s 
2023-08-08 12:09:42.840076:  
2023-08-08 12:09:42.840173: Epoch 1432 
2023-08-08 12:09:42.840248: Current learning rate: 0.00032 
2023-08-08 12:10:46.549395: train_loss -0.3966 
2023-08-08 12:10:46.549553: val_loss -0.3868 
2023-08-08 12:10:46.549607: Pseudo dice [0.8504] 
2023-08-08 12:10:46.549659: Epoch time: 63.71 s 
2023-08-08 12:10:47.624256:  
2023-08-08 12:10:47.624355: Epoch 1433 
2023-08-08 12:10:47.624425: Current learning rate: 0.00032 
2023-08-08 12:11:51.230715: train_loss -0.3514 
2023-08-08 12:11:51.230867: val_loss -0.4292 
2023-08-08 12:11:51.230936: Pseudo dice [0.8245] 
2023-08-08 12:11:51.230985: Epoch time: 63.61 s 
2023-08-08 12:11:52.320171:  
2023-08-08 12:11:52.320399: Epoch 1434 
2023-08-08 12:11:52.320477: Current learning rate: 0.00032 
2023-08-08 12:12:55.837268: train_loss -0.3369 
2023-08-08 12:12:55.837428: val_loss -0.3838 
2023-08-08 12:12:55.837482: Pseudo dice [0.8291] 
2023-08-08 12:12:55.837695: Epoch time: 63.52 s 
2023-08-08 12:12:56.911483:  
2023-08-08 12:12:56.911604: Epoch 1435 
2023-08-08 12:12:56.911697: Current learning rate: 0.00032 
2023-08-08 12:14:00.343122: train_loss -0.3721 
2023-08-08 12:14:00.343271: val_loss -0.3758 
2023-08-08 12:14:00.343324: Pseudo dice [0.8913] 
2023-08-08 12:14:00.343390: Epoch time: 63.43 s 
2023-08-08 12:14:01.440131:  
2023-08-08 12:14:01.440228: Epoch 1436 
2023-08-08 12:14:01.440318: Current learning rate: 0.00032 
2023-08-08 12:15:04.905409: train_loss -0.3608 
2023-08-08 12:15:04.905568: val_loss -0.2917 
2023-08-08 12:15:04.905621: Pseudo dice [0.8443] 
2023-08-08 12:15:04.905671: Epoch time: 63.47 s 
2023-08-08 12:15:05.985059:  
2023-08-08 12:15:05.985160: Epoch 1437 
2023-08-08 12:15:05.985233: Current learning rate: 0.00032 
2023-08-08 12:16:09.471692: train_loss -0.3902 
2023-08-08 12:16:09.471841: val_loss -0.3646 
2023-08-08 12:16:09.471894: Pseudo dice [0.8897] 
2023-08-08 12:16:09.471944: Epoch time: 63.49 s 
2023-08-08 12:16:10.563967:  
2023-08-08 12:16:10.564059: Epoch 1438 
2023-08-08 12:16:10.564132: Current learning rate: 0.00032 
2023-08-08 12:17:14.241282: train_loss -0.3606 
2023-08-08 12:17:14.241444: val_loss -0.4028 
2023-08-08 12:17:14.241498: Pseudo dice [0.8805] 
2023-08-08 12:17:14.241549: Epoch time: 63.68 s 
2023-08-08 12:17:15.359510:  
2023-08-08 12:17:15.359619: Epoch 1439 
2023-08-08 12:17:15.359695: Current learning rate: 0.00032 
2023-08-08 12:18:18.762236: train_loss -0.3631 
2023-08-08 12:18:18.762403: val_loss -0.3576 
2023-08-08 12:18:18.762468: Pseudo dice [0.8634] 
2023-08-08 12:18:18.762530: Epoch time: 63.4 s 
2023-08-08 12:18:19.834872:  
2023-08-08 12:18:19.834966: Epoch 1440 
2023-08-08 12:18:19.835037: Current learning rate: 0.00032 
2023-08-08 12:19:23.439421: train_loss -0.4227 
2023-08-08 12:19:23.439584: val_loss -0.3875 
2023-08-08 12:19:23.439656: Pseudo dice [0.8732] 
2023-08-08 12:19:23.439706: Epoch time: 63.61 s 
2023-08-08 12:19:24.518884:  
2023-08-08 12:19:24.518981: Epoch 1441 
2023-08-08 12:19:24.519055: Current learning rate: 0.00032 
2023-08-08 12:20:28.065223: train_loss -0.3842 
2023-08-08 12:20:28.065393: val_loss -0.4091 
2023-08-08 12:20:28.065443: Pseudo dice [0.8785] 
2023-08-08 12:20:28.065494: Epoch time: 63.55 s 
2023-08-08 12:20:29.133579:  
2023-08-08 12:20:29.133686: Epoch 1442 
2023-08-08 12:20:29.133772: Current learning rate: 0.00032 
2023-08-08 12:21:32.616491: train_loss -0.3596 
2023-08-08 12:21:32.616646: val_loss -0.3714 
2023-08-08 12:21:32.616697: Pseudo dice [0.908] 
2023-08-08 12:21:32.616747: Epoch time: 63.48 s 
2023-08-08 12:21:33.722423:  
2023-08-08 12:21:33.722640: Epoch 1443 
2023-08-08 12:21:33.722721: Current learning rate: 0.00032 
2023-08-08 12:22:37.329099: train_loss -0.3677 
2023-08-08 12:22:37.329245: val_loss -0.3716 
2023-08-08 12:22:37.329297: Pseudo dice [0.8845] 
2023-08-08 12:22:37.329347: Epoch time: 63.61 s 
2023-08-08 12:22:38.467740:  
2023-08-08 12:22:38.467840: Epoch 1444 
2023-08-08 12:22:38.467913: Current learning rate: 0.00032 
2023-08-08 12:23:41.924770: train_loss -0.333 
2023-08-08 12:23:41.924914: val_loss -0.3006 
2023-08-08 12:23:41.924963: Pseudo dice [0.8305] 
2023-08-08 12:23:41.925013: Epoch time: 63.46 s 
2023-08-08 12:23:42.997602:  
2023-08-08 12:23:42.997703: Epoch 1445 
2023-08-08 12:23:42.997775: Current learning rate: 0.00032 
2023-08-08 12:24:46.438941: train_loss -0.3461 
2023-08-08 12:24:46.439098: val_loss -0.3181 
2023-08-08 12:24:46.439166: Pseudo dice [0.8549] 
2023-08-08 12:24:46.439218: Epoch time: 63.44 s 
2023-08-08 12:24:47.518764:  
2023-08-08 12:24:47.518861: Epoch 1446 
2023-08-08 12:24:47.518934: Current learning rate: 0.00031 
2023-08-08 12:25:51.089876: train_loss -0.3909 
2023-08-08 12:25:51.090028: val_loss -0.4009 
2023-08-08 12:25:51.090096: Pseudo dice [0.8638] 
2023-08-08 12:25:51.090147: Epoch time: 63.57 s 
2023-08-08 12:25:52.183043:  
2023-08-08 12:25:52.183143: Epoch 1447 
2023-08-08 12:25:52.183230: Current learning rate: 0.00031 
2023-08-08 12:26:55.719466: train_loss -0.3736 
2023-08-08 12:26:55.719625: val_loss -0.3184 
2023-08-08 12:26:55.719677: Pseudo dice [0.8056] 
2023-08-08 12:26:55.719728: Epoch time: 63.54 s 
2023-08-08 12:26:56.845688:  
2023-08-08 12:26:56.845782: Epoch 1448 
2023-08-08 12:26:56.845872: Current learning rate: 0.00031 
2023-08-08 12:28:00.490021: train_loss -0.3192 
2023-08-08 12:28:00.490171: val_loss -0.333 
2023-08-08 12:28:00.490224: Pseudo dice [0.8785] 
2023-08-08 12:28:00.490273: Epoch time: 63.65 s 
2023-08-08 12:28:01.582429:  
2023-08-08 12:28:01.582531: Epoch 1449 
2023-08-08 12:28:01.582626: Current learning rate: 0.00031 
2023-08-08 12:29:05.324978: train_loss -0.3728 
2023-08-08 12:29:05.325145: val_loss -0.429 
2023-08-08 12:29:05.325197: Pseudo dice [0.8721] 
2023-08-08 12:29:05.325252: Epoch time: 63.74 s 
2023-08-08 12:29:06.846585:  
2023-08-08 12:29:06.846690: Epoch 1450 
2023-08-08 12:29:06.846780: Current learning rate: 0.00031 
2023-08-08 12:30:10.523441: train_loss -0.3303 
2023-08-08 12:30:10.523595: val_loss -0.4383 
2023-08-08 12:30:10.523665: Pseudo dice [0.8589] 
2023-08-08 12:30:10.523715: Epoch time: 63.68 s 
2023-08-08 12:30:11.598147:  
2023-08-08 12:30:11.598241: Epoch 1451 
2023-08-08 12:30:11.598312: Current learning rate: 0.00031 
2023-08-08 12:31:15.116373: train_loss -0.3247 
2023-08-08 12:31:15.116532: val_loss -0.3183 
2023-08-08 12:31:15.116586: Pseudo dice [0.8646] 
2023-08-08 12:31:15.116637: Epoch time: 63.52 s 
2023-08-08 12:31:16.193332:  
2023-08-08 12:31:16.193433: Epoch 1452 
2023-08-08 12:31:16.193506: Current learning rate: 0.00031 
2023-08-08 12:32:19.679237: train_loss -0.3874 
2023-08-08 12:32:19.679397: val_loss -0.33 
2023-08-08 12:32:19.679451: Pseudo dice [0.9026] 
2023-08-08 12:32:19.679502: Epoch time: 63.49 s 
2023-08-08 12:32:20.760269:  
2023-08-08 12:32:20.760371: Epoch 1453 
2023-08-08 12:32:20.760446: Current learning rate: 0.00031 
2023-08-08 12:33:24.390861: train_loss -0.3869 
2023-08-08 12:33:24.391015: val_loss -0.3644 
2023-08-08 12:33:24.391065: Pseudo dice [0.8879] 
2023-08-08 12:33:24.391115: Epoch time: 63.63 s 
2023-08-08 12:33:25.468453:  
2023-08-08 12:33:25.468558: Epoch 1454 
2023-08-08 12:33:25.468631: Current learning rate: 0.00031 
2023-08-08 12:34:28.903182: train_loss -0.332 
2023-08-08 12:34:28.903365: val_loss -0.3938 
2023-08-08 12:34:28.903442: Pseudo dice [0.8666] 
2023-08-08 12:34:28.903515: Epoch time: 63.44 s 
2023-08-08 12:34:29.995784:  
2023-08-08 12:34:29.995993: Epoch 1455 
2023-08-08 12:34:29.996072: Current learning rate: 0.00031 
2023-08-08 12:35:33.686878: train_loss -0.3735 
2023-08-08 12:35:33.687040: val_loss -0.4248 
2023-08-08 12:35:33.687094: Pseudo dice [0.8501] 
2023-08-08 12:35:33.687145: Epoch time: 63.69 s 
2023-08-08 12:35:34.792609:  
2023-08-08 12:35:34.792702: Epoch 1456 
2023-08-08 12:35:34.792792: Current learning rate: 0.00031 
2023-08-08 12:36:38.252395: train_loss -0.374 
2023-08-08 12:36:38.252539: val_loss -0.3363 
2023-08-08 12:36:38.252589: Pseudo dice [0.8573] 
2023-08-08 12:36:38.252639: Epoch time: 63.46 s 
2023-08-08 12:36:39.377106:  
2023-08-08 12:36:39.377210: Epoch 1457 
2023-08-08 12:36:39.377290: Current learning rate: 0.00031 
2023-08-08 12:37:42.900353: train_loss -0.3449 
2023-08-08 12:37:42.900505: val_loss -0.3225 
2023-08-08 12:37:42.900556: Pseudo dice [0.8562] 
2023-08-08 12:37:42.900606: Epoch time: 63.52 s 
2023-08-08 12:37:44.009412:  
2023-08-08 12:37:44.009507: Epoch 1458 
2023-08-08 12:37:44.009576: Current learning rate: 0.00031 
2023-08-08 12:38:47.604122: train_loss -0.3437 
2023-08-08 12:38:47.604275: val_loss -0.4161 
2023-08-08 12:38:47.604330: Pseudo dice [0.938] 
2023-08-08 12:38:47.604381: Epoch time: 63.6 s 
2023-08-08 12:38:48.689315:  
2023-08-08 12:38:48.689519: Epoch 1459 
2023-08-08 12:38:48.689611: Current learning rate: 0.00031 
2023-08-08 12:39:52.218714: train_loss -0.3969 
2023-08-08 12:39:52.218884: val_loss -0.4291 
2023-08-08 12:39:52.218935: Pseudo dice [0.909] 
2023-08-08 12:39:52.218986: Epoch time: 63.53 s 
2023-08-08 12:39:53.328876:  
2023-08-08 12:39:53.328990: Epoch 1460 
2023-08-08 12:39:53.329079: Current learning rate: 0.00031 
2023-08-08 12:40:56.569967: train_loss -0.3547 
2023-08-08 12:40:56.570117: val_loss -0.3415 
2023-08-08 12:40:56.570168: Pseudo dice [0.8714] 
2023-08-08 12:40:56.570234: Epoch time: 63.24 s 
2023-08-08 12:40:57.638509:  
2023-08-08 12:40:57.638610: Epoch 1461 
2023-08-08 12:40:57.638685: Current learning rate: 0.00031 
2023-08-08 12:42:00.987808: train_loss -0.3699 
2023-08-08 12:42:00.987951: val_loss -0.3749 
2023-08-08 12:42:00.988003: Pseudo dice [0.8252] 
2023-08-08 12:42:00.988054: Epoch time: 63.35 s 
2023-08-08 12:42:02.059788:  
2023-08-08 12:42:02.059885: Epoch 1462 
2023-08-08 12:42:02.059958: Current learning rate: 0.00031 
2023-08-08 12:43:05.462692: train_loss -0.3515 
2023-08-08 12:43:05.462839: val_loss -0.3487 
2023-08-08 12:43:05.462892: Pseudo dice [0.8756] 
2023-08-08 12:43:05.462957: Epoch time: 63.4 s 
2023-08-08 12:43:06.572207:  
2023-08-08 12:43:06.572304: Epoch 1463 
2023-08-08 12:43:06.572376: Current learning rate: 0.00031 
2023-08-08 12:44:10.230730: train_loss -0.3737 
2023-08-08 12:44:10.230887: val_loss -0.4112 
2023-08-08 12:44:10.230943: Pseudo dice [0.9057] 
2023-08-08 12:44:10.231011: Epoch time: 63.66 s 
2023-08-08 12:44:11.298330:  
2023-08-08 12:44:11.298432: Epoch 1464 
2023-08-08 12:44:11.298506: Current learning rate: 0.00031 
2023-08-08 12:45:14.650140: train_loss -0.3831 
2023-08-08 12:45:14.650290: val_loss -0.4514 
2023-08-08 12:45:14.650342: Pseudo dice [0.9394] 
2023-08-08 12:45:14.650393: Epoch time: 63.35 s 
2023-08-08 12:45:15.722631:  
2023-08-08 12:45:15.722736: Epoch 1465 
2023-08-08 12:45:15.722809: Current learning rate: 0.00031 
2023-08-08 12:46:19.230109: train_loss -0.3755 
2023-08-08 12:46:19.230265: val_loss -0.4398 
2023-08-08 12:46:19.230333: Pseudo dice [0.8508] 
2023-08-08 12:46:19.230384: Epoch time: 63.51 s 
2023-08-08 12:46:20.330633:  
2023-08-08 12:46:20.330729: Epoch 1466 
2023-08-08 12:46:20.330819: Current learning rate: 0.0003 
2023-08-08 12:47:23.892388: train_loss -0.3894 
2023-08-08 12:47:23.892536: val_loss -0.3666 
2023-08-08 12:47:23.892587: Pseudo dice [0.9096] 
2023-08-08 12:47:23.892638: Epoch time: 63.56 s 
2023-08-08 12:47:25.001898:  
2023-08-08 12:47:25.001999: Epoch 1467 
2023-08-08 12:47:25.002072: Current learning rate: 0.0003 
2023-08-08 12:48:28.701413: train_loss -0.3417 
2023-08-08 12:48:28.701565: val_loss -0.3392 
2023-08-08 12:48:28.701616: Pseudo dice [0.7978] 
2023-08-08 12:48:28.701665: Epoch time: 63.7 s 
2023-08-08 12:48:29.807259:  
2023-08-08 12:48:29.807356: Epoch 1468 
2023-08-08 12:48:29.807428: Current learning rate: 0.0003 
2023-08-08 12:49:33.577267: train_loss -0.3676 
2023-08-08 12:49:33.577436: val_loss -0.3491 
2023-08-08 12:49:33.577503: Pseudo dice [0.8579] 
2023-08-08 12:49:33.577556: Epoch time: 63.77 s 
2023-08-08 12:49:34.651252:  
2023-08-08 12:49:34.651346: Epoch 1469 
2023-08-08 12:49:34.651418: Current learning rate: 0.0003 
2023-08-08 12:50:38.169367: train_loss -0.3688 
2023-08-08 12:50:38.169659: val_loss -0.2812 
2023-08-08 12:50:38.169803: Pseudo dice [0.898] 
2023-08-08 12:50:38.169954: Epoch time: 63.52 s 
2023-08-08 12:50:39.300366:  
2023-08-08 12:50:39.300463: Epoch 1470 
2023-08-08 12:50:39.300535: Current learning rate: 0.0003 
2023-08-08 12:51:42.861908: train_loss -0.3815 
2023-08-08 12:51:42.862063: val_loss -0.3485 
2023-08-08 12:51:42.862113: Pseudo dice [0.8943] 
2023-08-08 12:51:42.862166: Epoch time: 63.56 s 
2023-08-08 12:51:43.930491:  
2023-08-08 12:51:43.930587: Epoch 1471 
2023-08-08 12:51:43.930675: Current learning rate: 0.0003 
2023-08-08 12:52:47.604240: train_loss -0.3513 
2023-08-08 12:52:47.604392: val_loss -0.3157 
2023-08-08 12:52:47.604448: Pseudo dice [0.8925] 
2023-08-08 12:52:47.604499: Epoch time: 63.67 s 
2023-08-08 12:52:48.677721:  
2023-08-08 12:52:48.677830: Epoch 1472 
2023-08-08 12:52:48.677904: Current learning rate: 0.0003 
2023-08-08 12:53:52.221181: train_loss -0.3851 
2023-08-08 12:53:52.221466: val_loss -0.3622 
2023-08-08 12:53:52.221520: Pseudo dice [0.8979] 
2023-08-08 12:53:52.221571: Epoch time: 63.54 s 
2023-08-08 12:53:53.305749:  
2023-08-08 12:53:53.306178: Epoch 1473 
2023-08-08 12:53:53.306390: Current learning rate: 0.0003 
2023-08-08 12:54:56.958088: train_loss -0.3653 
2023-08-08 12:54:56.958231: val_loss -0.3706 
2023-08-08 12:54:56.958280: Pseudo dice [0.8555] 
2023-08-08 12:54:56.958346: Epoch time: 63.65 s 
2023-08-08 12:54:58.027435:  
2023-08-08 12:54:58.027533: Epoch 1474 
2023-08-08 12:54:58.027646: Current learning rate: 0.0003 
2023-08-08 12:56:01.705920: train_loss -0.3789 
2023-08-08 12:56:01.706089: val_loss -0.4469 
2023-08-08 12:56:01.706151: Pseudo dice [0.8619] 
2023-08-08 12:56:01.706203: Epoch time: 63.68 s 
2023-08-08 12:56:02.814963:  
2023-08-08 12:56:02.815063: Epoch 1475 
2023-08-08 12:56:02.815135: Current learning rate: 0.0003 
2023-08-08 12:57:06.300333: train_loss -0.3686 
2023-08-08 12:57:06.300490: val_loss -0.2726 
2023-08-08 12:57:06.300542: Pseudo dice [0.8892] 
2023-08-08 12:57:06.300593: Epoch time: 63.49 s 
2023-08-08 12:57:07.393033:  
2023-08-08 12:57:07.393128: Epoch 1476 
2023-08-08 12:57:07.393215: Current learning rate: 0.0003 
2023-08-08 12:58:11.005985: train_loss -0.3945 
2023-08-08 12:58:11.006134: val_loss -0.3606 
2023-08-08 12:58:11.006183: Pseudo dice [0.8977] 
2023-08-08 12:58:11.006250: Epoch time: 63.61 s 
2023-08-08 12:58:12.077896:  
2023-08-08 12:58:12.077991: Epoch 1477 
2023-08-08 12:58:12.078105: Current learning rate: 0.0003 
2023-08-08 12:59:15.519137: train_loss -0.3328 
2023-08-08 12:59:15.519291: val_loss -0.3159 
2023-08-08 12:59:15.519343: Pseudo dice [0.9305] 
2023-08-08 12:59:15.519394: Epoch time: 63.44 s 
2023-08-08 12:59:15.519434: Yayy! New best EMA pseudo Dice: 0.8843 
2023-08-08 12:59:16.973249:  
2023-08-08 12:59:16.973343: Epoch 1478 
2023-08-08 12:59:16.973416: Current learning rate: 0.0003 
2023-08-08 13:00:20.693856: train_loss -0.3405 
2023-08-08 13:00:20.694008: val_loss -0.4292 
2023-08-08 13:00:20.694062: Pseudo dice [0.901] 
2023-08-08 13:00:20.694112: Epoch time: 63.72 s 
2023-08-08 13:00:20.694151: Yayy! New best EMA pseudo Dice: 0.886 
2023-08-08 13:00:22.223325:  
2023-08-08 13:00:22.223426: Epoch 1479 
2023-08-08 13:00:22.223498: Current learning rate: 0.0003 
2023-08-08 13:01:25.813960: train_loss -0.3585 
2023-08-08 13:01:25.814125: val_loss -0.3762 
2023-08-08 13:01:25.814179: Pseudo dice [0.826] 
2023-08-08 13:01:25.814229: Epoch time: 63.59 s 
2023-08-08 13:01:26.940250:  
2023-08-08 13:01:26.940354: Epoch 1480 
2023-08-08 13:01:26.940426: Current learning rate: 0.0003 
2023-08-08 13:02:30.270569: train_loss -0.3199 
2023-08-08 13:02:30.270722: val_loss -0.3406 
2023-08-08 13:02:30.270790: Pseudo dice [0.9117] 
2023-08-08 13:02:30.270839: Epoch time: 63.33 s 
2023-08-08 13:02:31.348250:  
2023-08-08 13:02:31.348356: Epoch 1481 
2023-08-08 13:02:31.348445: Current learning rate: 0.0003 
2023-08-08 13:03:34.884448: train_loss -0.32 
2023-08-08 13:03:34.884594: val_loss -0.4075 
2023-08-08 13:03:34.884647: Pseudo dice [0.92] 
2023-08-08 13:03:34.884696: Epoch time: 63.54 s 
2023-08-08 13:03:34.884736: Yayy! New best EMA pseudo Dice: 0.8868 
2023-08-08 13:03:36.385497:  
2023-08-08 13:03:36.385591: Epoch 1482 
2023-08-08 13:03:36.385680: Current learning rate: 0.0003 
2023-08-08 13:04:39.715698: train_loss -0.3237 
2023-08-08 13:04:39.715850: val_loss -0.3935 
2023-08-08 13:04:39.715904: Pseudo dice [0.8453] 
2023-08-08 13:04:39.715953: Epoch time: 63.33 s 
2023-08-08 13:04:40.932714:  
2023-08-08 13:04:40.932822: Epoch 1483 
2023-08-08 13:04:40.932895: Current learning rate: 0.0003 
2023-08-08 13:05:44.532793: train_loss -0.3706 
2023-08-08 13:05:44.532942: val_loss -0.3845 
2023-08-08 13:05:44.532994: Pseudo dice [0.868] 
2023-08-08 13:05:44.533064: Epoch time: 63.6 s 
2023-08-08 13:05:45.639623:  
2023-08-08 13:05:45.639728: Epoch 1484 
2023-08-08 13:05:45.639800: Current learning rate: 0.0003 
2023-08-08 13:06:49.261642: train_loss -0.382 
2023-08-08 13:06:49.261791: val_loss -0.3446 
2023-08-08 13:06:49.261841: Pseudo dice [0.8436] 
2023-08-08 13:06:49.261907: Epoch time: 63.62 s 
2023-08-08 13:06:50.363069:  
2023-08-08 13:06:50.363166: Epoch 1485 
2023-08-08 13:06:50.363237: Current learning rate: 0.00029 
2023-08-08 13:07:53.776366: train_loss -0.3445 
2023-08-08 13:07:53.776514: val_loss -0.3317 
2023-08-08 13:07:53.776566: Pseudo dice [0.8782] 
2023-08-08 13:07:53.776616: Epoch time: 63.41 s 
2023-08-08 13:07:54.848319:  
2023-08-08 13:07:54.848415: Epoch 1486 
2023-08-08 13:07:54.848507: Current learning rate: 0.00029 
2023-08-08 13:08:58.257740: train_loss -0.3564 
2023-08-08 13:08:58.257886: val_loss -0.4406 
2023-08-08 13:08:58.257954: Pseudo dice [0.9015] 
2023-08-08 13:08:58.258013: Epoch time: 63.41 s 
2023-08-08 13:08:59.356586:  
2023-08-08 13:08:59.356678: Epoch 1487 
2023-08-08 13:08:59.356774: Current learning rate: 0.00029 
2023-08-08 13:10:03.002601: train_loss -0.3418 
2023-08-08 13:10:03.002749: val_loss -0.33 
2023-08-08 13:10:03.002798: Pseudo dice [0.8764] 
2023-08-08 13:10:03.002863: Epoch time: 63.65 s 
2023-08-08 13:10:04.101466:  
2023-08-08 13:10:04.101561: Epoch 1488 
2023-08-08 13:10:04.101634: Current learning rate: 0.00029 
2023-08-08 13:11:07.896033: train_loss -0.4169 
2023-08-08 13:11:07.896306: val_loss -0.3639 
2023-08-08 13:11:07.896360: Pseudo dice [0.8468] 
2023-08-08 13:11:07.896410: Epoch time: 63.8 s 
2023-08-08 13:11:08.979681:  
2023-08-08 13:11:08.979868: Epoch 1489 
2023-08-08 13:11:08.979948: Current learning rate: 0.00029 
2023-08-08 13:12:12.381087: train_loss -0.3422 
2023-08-08 13:12:12.381240: val_loss -0.341 
2023-08-08 13:12:12.381309: Pseudo dice [0.8098] 
2023-08-08 13:12:12.381360: Epoch time: 63.4 s 
2023-08-08 13:12:13.484793:  
2023-08-08 13:12:13.484905: Epoch 1490 
2023-08-08 13:12:13.484977: Current learning rate: 0.00029 
2023-08-08 13:13:17.011483: train_loss -0.3357 
2023-08-08 13:13:17.011653: val_loss -0.4651 
2023-08-08 13:13:17.011707: Pseudo dice [0.9375] 
2023-08-08 13:13:17.011758: Epoch time: 63.53 s 
2023-08-08 13:13:18.084726:  
2023-08-08 13:13:18.084825: Epoch 1491 
2023-08-08 13:13:18.084914: Current learning rate: 0.00029 
2023-08-08 13:14:21.674552: train_loss -0.34 
2023-08-08 13:14:21.674702: val_loss -0.3505 
2023-08-08 13:14:21.674756: Pseudo dice [0.9199] 
2023-08-08 13:14:21.674805: Epoch time: 63.59 s 
2023-08-08 13:14:22.749528:  
2023-08-08 13:14:22.749632: Epoch 1492 
2023-08-08 13:14:22.749705: Current learning rate: 0.00029 
2023-08-08 13:15:26.175078: train_loss -0.3721 
2023-08-08 13:15:26.175226: val_loss -0.3452 
2023-08-08 13:15:26.183527: Pseudo dice [0.9057] 
2023-08-08 13:15:26.183587: Epoch time: 63.43 s 
2023-08-08 13:15:27.279723:  
2023-08-08 13:15:27.279818: Epoch 1493 
2023-08-08 13:15:27.279891: Current learning rate: 0.00029 
2023-08-08 13:16:30.858383: train_loss -0.343 
2023-08-08 13:16:30.858538: val_loss -0.312 
2023-08-08 13:16:30.858608: Pseudo dice [0.8874] 
2023-08-08 13:16:30.858658: Epoch time: 63.58 s 
2023-08-08 13:16:31.941776:  
2023-08-08 13:16:31.941869: Epoch 1494 
2023-08-08 13:16:31.941956: Current learning rate: 0.00029 
2023-08-08 13:17:35.329936: train_loss -0.3811 
2023-08-08 13:17:35.330086: val_loss -0.3313 
2023-08-08 13:17:35.330135: Pseudo dice [0.7976] 
2023-08-08 13:17:35.330201: Epoch time: 63.39 s 
2023-08-08 13:17:36.432002:  
2023-08-08 13:17:36.432099: Epoch 1495 
2023-08-08 13:17:36.432171: Current learning rate: 0.00029 
2023-08-08 13:18:39.613572: train_loss -0.3724 
2023-08-08 13:18:39.613738: val_loss -0.3192 
2023-08-08 13:18:39.613790: Pseudo dice [0.8398] 
2023-08-08 13:18:39.613840: Epoch time: 63.18 s 
2023-08-08 13:18:40.705301:  
2023-08-08 13:18:40.705401: Epoch 1496 
2023-08-08 13:18:40.705492: Current learning rate: 0.00029 
2023-08-08 13:19:44.158547: train_loss -0.3383 
2023-08-08 13:19:44.158712: val_loss -0.3631 
2023-08-08 13:19:44.158765: Pseudo dice [0.9248] 
2023-08-08 13:19:44.158815: Epoch time: 63.45 s 
2023-08-08 13:19:45.285450:  
2023-08-08 13:19:45.285544: Epoch 1497 
2023-08-08 13:19:45.285633: Current learning rate: 0.00029 
2023-08-08 13:20:48.640735: train_loss -0.4059 
2023-08-08 13:20:48.640889: val_loss -0.303 
2023-08-08 13:20:48.640945: Pseudo dice [0.8748] 
2023-08-08 13:20:48.640997: Epoch time: 63.36 s 
2023-08-08 13:20:49.723542:  
2023-08-08 13:20:49.723648: Epoch 1498 
2023-08-08 13:20:49.723722: Current learning rate: 0.00029 
2023-08-08 13:21:53.439394: train_loss -0.3708 
2023-08-08 13:21:53.439574: val_loss -0.2848 
2023-08-08 13:21:53.439630: Pseudo dice [0.8892] 
2023-08-08 13:21:53.439682: Epoch time: 63.72 s 
2023-08-08 13:21:54.511294:  
2023-08-08 13:21:54.511393: Epoch 1499 
2023-08-08 13:21:54.511482: Current learning rate: 0.00029 
2023-08-08 13:22:58.009382: train_loss -0.3482 
2023-08-08 13:22:58.009538: val_loss -0.3873 
2023-08-08 13:22:58.009592: Pseudo dice [0.8301] 
2023-08-08 13:22:58.009643: Epoch time: 63.5 s 
2023-08-08 13:22:59.508324:  
2023-08-08 13:22:59.508534: Epoch 1500 
2023-08-08 13:22:59.508609: Current learning rate: 0.00029 
2023-08-08 13:24:02.769844: train_loss -0.3673 
2023-08-08 13:24:02.770000: val_loss -0.3555 
2023-08-08 13:24:02.770052: Pseudo dice [0.9089] 
2023-08-08 13:24:02.770103: Epoch time: 63.26 s 
2023-08-08 13:24:03.836288:  
2023-08-08 13:24:03.836386: Epoch 1501 
2023-08-08 13:24:03.836460: Current learning rate: 0.00029 
2023-08-08 13:25:07.323547: train_loss -0.3619 
2023-08-08 13:25:07.323708: val_loss -0.3241 
2023-08-08 13:25:07.323761: Pseudo dice [0.8451] 
2023-08-08 13:25:07.323813: Epoch time: 63.49 s 
2023-08-08 13:25:08.420569:  
2023-08-08 13:25:08.420669: Epoch 1502 
2023-08-08 13:25:08.420758: Current learning rate: 0.00029 
2023-08-08 13:26:11.803071: train_loss -0.3522 
2023-08-08 13:26:11.803223: val_loss -0.3754 
2023-08-08 13:26:11.803288: Pseudo dice [0.8511] 
2023-08-08 13:26:11.803339: Epoch time: 63.38 s 
2023-08-08 13:26:12.876500:  
2023-08-08 13:26:12.876595: Epoch 1503 
2023-08-08 13:26:12.876668: Current learning rate: 0.00029 
2023-08-08 13:27:16.637336: train_loss -0.3587 
2023-08-08 13:27:16.637492: val_loss -0.3725 
2023-08-08 13:27:16.637544: Pseudo dice [0.8848] 
2023-08-08 13:27:16.637613: Epoch time: 63.76 s 
2023-08-08 13:27:17.729883:  
2023-08-08 13:27:17.729976: Epoch 1504 
2023-08-08 13:27:17.730045: Current learning rate: 0.00029 
2023-08-08 13:28:21.350306: train_loss -0.3881 
2023-08-08 13:28:21.350474: val_loss -0.3144 
2023-08-08 13:28:21.350526: Pseudo dice [0.8588] 
2023-08-08 13:28:21.350575: Epoch time: 63.62 s 
2023-08-08 13:28:22.472203:  
2023-08-08 13:28:22.472298: Epoch 1505 
2023-08-08 13:28:22.472389: Current learning rate: 0.00028 
2023-08-08 13:29:26.050561: train_loss -0.3498 
2023-08-08 13:29:26.050707: val_loss -0.3583 
2023-08-08 13:29:26.050757: Pseudo dice [0.9007] 
2023-08-08 13:29:26.050822: Epoch time: 63.58 s 
2023-08-08 13:29:27.145468:  
2023-08-08 13:29:27.145559: Epoch 1506 
2023-08-08 13:29:27.145646: Current learning rate: 0.00028 
2023-08-08 13:30:30.674323: train_loss -0.3107 
2023-08-08 13:30:30.674490: val_loss -0.3386 
2023-08-08 13:30:30.674550: Pseudo dice [0.8523] 
2023-08-08 13:30:30.674607: Epoch time: 63.53 s 
2023-08-08 13:30:31.779127:  
2023-08-08 13:30:31.779218: Epoch 1507 
2023-08-08 13:30:31.779306: Current learning rate: 0.00028 
2023-08-08 13:31:35.283186: train_loss -0.3284 
2023-08-08 13:31:35.283337: val_loss -0.3941 
2023-08-08 13:31:35.283394: Pseudo dice [0.8519] 
2023-08-08 13:31:35.283445: Epoch time: 63.5 s 
2023-08-08 13:31:36.384810:  
2023-08-08 13:31:36.384929: Epoch 1508 
2023-08-08 13:31:36.385002: Current learning rate: 0.00028 
2023-08-08 13:32:40.005691: train_loss -0.3255 
2023-08-08 13:32:40.005835: val_loss -0.4197 
2023-08-08 13:32:40.005901: Pseudo dice [0.8434] 
2023-08-08 13:32:40.005951: Epoch time: 63.62 s 
2023-08-08 13:32:41.107462:  
2023-08-08 13:32:41.107569: Epoch 1509 
2023-08-08 13:32:41.107675: Current learning rate: 0.00028 
2023-08-08 13:33:44.663264: train_loss -0.3792 
2023-08-08 13:33:44.663426: val_loss -0.4054 
2023-08-08 13:33:44.663480: Pseudo dice [0.9503] 
2023-08-08 13:33:44.663531: Epoch time: 63.56 s 
2023-08-08 13:33:45.766929:  
2023-08-08 13:33:45.767030: Epoch 1510 
2023-08-08 13:33:45.767120: Current learning rate: 0.00028 
2023-08-08 13:34:49.198669: train_loss -0.4019 
2023-08-08 13:34:49.198815: val_loss -0.4516 
2023-08-08 13:34:49.198883: Pseudo dice [0.8461] 
2023-08-08 13:34:49.198932: Epoch time: 63.43 s 
2023-08-08 13:34:50.266030:  
2023-08-08 13:34:50.266127: Epoch 1511 
2023-08-08 13:34:50.266199: Current learning rate: 0.00028 
2023-08-08 13:35:53.962874: train_loss -0.365 
2023-08-08 13:35:53.963046: val_loss -0.3621 
2023-08-08 13:35:53.963097: Pseudo dice [0.8328] 
2023-08-08 13:35:53.963147: Epoch time: 63.7 s 
2023-08-08 13:35:55.037662:  
2023-08-08 13:35:55.037757: Epoch 1512 
2023-08-08 13:35:55.037833: Current learning rate: 0.00028 
2023-08-08 13:36:58.543194: train_loss -0.3244 
2023-08-08 13:36:58.543347: val_loss -0.3475 
2023-08-08 13:36:58.543397: Pseudo dice [0.8865] 
2023-08-08 13:36:58.543462: Epoch time: 63.51 s 
2023-08-08 13:36:59.611682:  
2023-08-08 13:36:59.611778: Epoch 1513 
2023-08-08 13:36:59.611865: Current learning rate: 0.00028 
2023-08-08 13:38:03.488726: train_loss -0.3549 
2023-08-08 13:38:03.488868: val_loss -0.3008 
2023-08-08 13:38:03.488918: Pseudo dice [0.8999] 
2023-08-08 13:38:03.488967: Epoch time: 63.88 s 
2023-08-08 13:38:04.575052:  
2023-08-08 13:38:04.575155: Epoch 1514 
2023-08-08 13:38:04.575233: Current learning rate: 0.00028 
2023-08-08 13:39:08.237249: train_loss -0.3734 
2023-08-08 13:39:08.237415: val_loss -0.3883 
2023-08-08 13:39:08.237479: Pseudo dice [0.9173] 
2023-08-08 13:39:08.237547: Epoch time: 63.66 s 
2023-08-08 13:39:09.315648:  
2023-08-08 13:39:09.315747: Epoch 1515 
2023-08-08 13:39:09.315820: Current learning rate: 0.00028 
2023-08-08 13:40:12.947474: train_loss -0.3452 
2023-08-08 13:40:12.947654: val_loss -0.3941 
2023-08-08 13:40:12.947705: Pseudo dice [0.8646] 
2023-08-08 13:40:12.947754: Epoch time: 63.63 s 
2023-08-08 13:40:14.022359:  
2023-08-08 13:40:14.022458: Epoch 1516 
2023-08-08 13:40:14.022528: Current learning rate: 0.00028 
2023-08-08 13:41:17.425894: train_loss -0.3834 
2023-08-08 13:41:17.426044: val_loss -0.4 
2023-08-08 13:41:17.426096: Pseudo dice [0.8947] 
2023-08-08 13:41:17.426146: Epoch time: 63.4 s 
2023-08-08 13:41:18.495043:  
2023-08-08 13:41:18.495141: Epoch 1517 
2023-08-08 13:41:18.495226: Current learning rate: 0.00028 
2023-08-08 13:42:22.088178: train_loss -0.3862 
2023-08-08 13:42:22.088333: val_loss -0.4336 
2023-08-08 13:42:22.088385: Pseudo dice [0.892] 
2023-08-08 13:42:22.088435: Epoch time: 63.59 s 
2023-08-08 13:42:23.161039:  
2023-08-08 13:42:23.161131: Epoch 1518 
2023-08-08 13:42:23.161217: Current learning rate: 0.00028 
2023-08-08 13:43:26.782909: train_loss -0.3718 
2023-08-08 13:43:26.783071: val_loss -0.4003 
2023-08-08 13:43:26.783123: Pseudo dice [0.9385] 
2023-08-08 13:43:26.783191: Epoch time: 63.62 s 
2023-08-08 13:43:27.895031:  
2023-08-08 13:43:27.895127: Epoch 1519 
2023-08-08 13:43:27.895198: Current learning rate: 0.00028 
2023-08-08 13:44:31.535726: train_loss -0.3387 
2023-08-08 13:44:31.535883: val_loss -0.4226 
2023-08-08 13:44:31.535934: Pseudo dice [0.8876] 
2023-08-08 13:44:31.535984: Epoch time: 63.64 s 
2023-08-08 13:44:32.628008:  
2023-08-08 13:44:32.628105: Epoch 1520 
2023-08-08 13:44:32.628180: Current learning rate: 0.00028 
2023-08-08 13:45:36.085006: train_loss -0.3664 
2023-08-08 13:45:36.085158: val_loss -0.4018 
2023-08-08 13:45:36.085211: Pseudo dice [0.8512] 
2023-08-08 13:45:36.085262: Epoch time: 63.46 s 
2023-08-08 13:45:37.161351:  
2023-08-08 13:45:37.161443: Epoch 1521 
2023-08-08 13:45:37.161530: Current learning rate: 0.00028 
2023-08-08 13:46:40.851612: train_loss -0.3968 
2023-08-08 13:46:40.851756: val_loss -0.3231 
2023-08-08 13:46:40.851827: Pseudo dice [0.8488] 
2023-08-08 13:46:40.851882: Epoch time: 63.69 s 
2023-08-08 13:46:42.003339:  
2023-08-08 13:46:42.003439: Epoch 1522 
2023-08-08 13:46:42.003510: Current learning rate: 0.00028 
2023-08-08 13:47:45.251085: train_loss -0.3527 
2023-08-08 13:47:45.251242: val_loss -0.3083 
2023-08-08 13:47:45.251297: Pseudo dice [0.7989] 
2023-08-08 13:47:45.251348: Epoch time: 63.25 s 
2023-08-08 13:47:46.361346:  
2023-08-08 13:47:46.361444: Epoch 1523 
2023-08-08 13:47:46.361515: Current learning rate: 0.00028 
2023-08-08 13:48:50.143913: train_loss -0.3521 
2023-08-08 13:48:50.144063: val_loss -0.3426 
2023-08-08 13:48:50.144116: Pseudo dice [0.8373] 
2023-08-08 13:48:50.144166: Epoch time: 63.78 s 
2023-08-08 13:48:51.218982:  
2023-08-08 13:48:51.219080: Epoch 1524 
2023-08-08 13:48:51.219151: Current learning rate: 0.00027 
2023-08-08 13:49:54.432007: train_loss -0.3292 
2023-08-08 13:49:54.432158: val_loss -0.3498 
2023-08-08 13:49:54.432209: Pseudo dice [0.8531] 
2023-08-08 13:49:54.432260: Epoch time: 63.21 s 
2023-08-08 13:49:55.551138:  
2023-08-08 13:49:55.551238: Epoch 1525 
2023-08-08 13:49:55.551307: Current learning rate: 0.00027 
2023-08-08 13:50:58.867826: train_loss -0.3377 
2023-08-08 13:50:58.867985: val_loss -0.2981 
2023-08-08 13:50:58.868038: Pseudo dice [0.8288] 
2023-08-08 13:50:58.868089: Epoch time: 63.32 s 
2023-08-08 13:50:59.958000:  
2023-08-08 13:50:59.958097: Epoch 1526 
2023-08-08 13:50:59.958186: Current learning rate: 0.00027 
2023-08-08 13:52:03.520707: train_loss -0.3824 
2023-08-08 13:52:03.520869: val_loss -0.4888 
2023-08-08 13:52:03.520921: Pseudo dice [0.9022] 
2023-08-08 13:52:03.520987: Epoch time: 63.56 s 
2023-08-08 13:52:04.616248:  
2023-08-08 13:52:04.616351: Epoch 1527 
2023-08-08 13:52:04.616440: Current learning rate: 0.00027 
2023-08-08 13:53:08.228721: train_loss -0.3625 
2023-08-08 13:53:08.228861: val_loss -0.4826 
2023-08-08 13:53:08.228909: Pseudo dice [0.8671] 
2023-08-08 13:53:08.228975: Epoch time: 63.61 s 
2023-08-08 13:53:09.481695:  
2023-08-08 13:53:09.481808: Epoch 1528 
2023-08-08 13:53:09.481896: Current learning rate: 0.00027 
2023-08-08 13:54:13.128007: train_loss -0.3479 
2023-08-08 13:54:13.128168: val_loss -0.445 
2023-08-08 13:54:13.128218: Pseudo dice [0.8945] 
2023-08-08 13:54:13.128267: Epoch time: 63.65 s 
2023-08-08 13:54:14.238973:  
2023-08-08 13:54:14.239070: Epoch 1529 
2023-08-08 13:54:14.239159: Current learning rate: 0.00027 
2023-08-08 13:55:17.873309: train_loss -0.3651 
2023-08-08 13:55:17.873457: val_loss -0.3107 
2023-08-08 13:55:17.873509: Pseudo dice [0.8786] 
2023-08-08 13:55:17.873558: Epoch time: 63.64 s 
2023-08-08 13:55:18.989069:  
2023-08-08 13:55:18.989165: Epoch 1530 
2023-08-08 13:55:18.989235: Current learning rate: 0.00027 
2023-08-08 13:56:22.658778: train_loss -0.3632 
2023-08-08 13:56:22.658923: val_loss -0.3937 
2023-08-08 13:56:22.658973: Pseudo dice [0.8916] 
2023-08-08 13:56:22.659024: Epoch time: 63.67 s 
2023-08-08 13:56:23.752739:  
2023-08-08 13:56:23.752848: Epoch 1531 
2023-08-08 13:56:23.752919: Current learning rate: 0.00027 
2023-08-08 13:57:27.332831: train_loss -0.3535 
2023-08-08 13:57:27.332979: val_loss -0.4628 
2023-08-08 13:57:27.333032: Pseudo dice [0.8882] 
2023-08-08 13:57:27.333083: Epoch time: 63.58 s 
2023-08-08 13:57:28.463483:  
2023-08-08 13:57:28.463598: Epoch 1532 
2023-08-08 13:57:28.463675: Current learning rate: 0.00027 
2023-08-08 13:58:31.852953: train_loss -0.3236 
2023-08-08 13:58:31.853104: val_loss -0.4101 
2023-08-08 13:58:31.853154: Pseudo dice [0.9089] 
2023-08-08 13:58:31.853204: Epoch time: 63.39 s 
2023-08-08 13:58:32.966996:  
2023-08-08 13:58:32.967088: Epoch 1533 
2023-08-08 13:58:32.967174: Current learning rate: 0.00027 
2023-08-08 13:59:36.503029: train_loss -0.3766 
2023-08-08 13:59:36.503195: val_loss -0.3854 
2023-08-08 13:59:36.503246: Pseudo dice [0.892] 
2023-08-08 13:59:36.503295: Epoch time: 63.54 s 
2023-08-08 13:59:37.769960:  
2023-08-08 13:59:37.770064: Epoch 1534 
2023-08-08 13:59:37.770133: Current learning rate: 0.00027 
2023-08-08 14:00:41.322954: train_loss -0.3568 
2023-08-08 14:00:41.323107: val_loss -0.4098 
2023-08-08 14:00:41.323160: Pseudo dice [0.9227] 
2023-08-08 14:00:41.323210: Epoch time: 63.55 s 
2023-08-08 14:00:42.433252:  
2023-08-08 14:00:42.433349: Epoch 1535 
2023-08-08 14:00:42.433421: Current learning rate: 0.00027 
2023-08-08 14:01:46.104825: train_loss -0.3534 
2023-08-08 14:01:46.104973: val_loss -0.3302 
2023-08-08 14:01:46.105022: Pseudo dice [0.8536] 
2023-08-08 14:01:46.105088: Epoch time: 63.67 s 
2023-08-08 14:01:47.212502:  
2023-08-08 14:01:47.212605: Epoch 1536 
2023-08-08 14:01:47.212680: Current learning rate: 0.00027 
2023-08-08 14:02:50.654419: train_loss -0.3649 
2023-08-08 14:02:50.654564: val_loss -0.2945 
2023-08-08 14:02:50.654632: Pseudo dice [0.7859] 
2023-08-08 14:02:50.654684: Epoch time: 63.44 s 
2023-08-08 14:02:51.765833:  
2023-08-08 14:02:51.765932: Epoch 1537 
2023-08-08 14:02:51.766022: Current learning rate: 0.00027 
2023-08-08 14:03:55.193528: train_loss -0.3493 
2023-08-08 14:03:55.193694: val_loss -0.3731 
2023-08-08 14:03:55.193749: Pseudo dice [0.8703] 
2023-08-08 14:03:55.193799: Epoch time: 63.43 s 
2023-08-08 14:03:56.278881:  
2023-08-08 14:03:56.278976: Epoch 1538 
2023-08-08 14:03:56.279063: Current learning rate: 0.00027 
2023-08-08 14:04:59.525514: train_loss -0.4073 
2023-08-08 14:04:59.525675: val_loss -0.4276 
2023-08-08 14:04:59.525729: Pseudo dice [0.8645] 
2023-08-08 14:04:59.525796: Epoch time: 63.25 s 
2023-08-08 14:05:00.801501:  
2023-08-08 14:05:00.801620: Epoch 1539 
2023-08-08 14:05:00.801709: Current learning rate: 0.00027 
2023-08-08 14:06:04.283766: train_loss -0.3946 
2023-08-08 14:06:04.283918: val_loss -0.3306 
2023-08-08 14:06:04.283976: Pseudo dice [0.8963] 
2023-08-08 14:06:04.284027: Epoch time: 63.48 s 
2023-08-08 14:06:05.389756:  
2023-08-08 14:06:05.389861: Epoch 1540 
2023-08-08 14:06:05.389934: Current learning rate: 0.00027 
2023-08-08 14:07:08.835427: train_loss -0.3851 
2023-08-08 14:07:08.835599: val_loss -0.3625 
2023-08-08 14:07:08.835670: Pseudo dice [0.8685] 
2023-08-08 14:07:08.835778: Epoch time: 63.45 s 
2023-08-08 14:07:09.961763:  
2023-08-08 14:07:09.961861: Epoch 1541 
2023-08-08 14:07:09.961931: Current learning rate: 0.00027 
2023-08-08 14:08:13.302457: train_loss -0.3776 
2023-08-08 14:08:13.302610: val_loss -0.3065 
2023-08-08 14:08:13.302664: Pseudo dice [0.8953] 
2023-08-08 14:08:13.302714: Epoch time: 63.34 s 
2023-08-08 14:08:14.423141:  
2023-08-08 14:08:14.423238: Epoch 1542 
2023-08-08 14:08:14.423324: Current learning rate: 0.00027 
2023-08-08 14:09:18.050794: train_loss -0.3511 
2023-08-08 14:09:18.050952: val_loss -0.3155 
2023-08-08 14:09:18.051009: Pseudo dice [0.8771] 
2023-08-08 14:09:18.051061: Epoch time: 63.63 s 
2023-08-08 14:09:19.208220:  
2023-08-08 14:09:19.208315: Epoch 1543 
2023-08-08 14:09:19.208388: Current learning rate: 0.00026 
2023-08-08 14:10:23.028147: train_loss -0.3318 
2023-08-08 14:10:23.028301: val_loss -0.3696 
2023-08-08 14:10:23.028357: Pseudo dice [0.8906] 
2023-08-08 14:10:23.028407: Epoch time: 63.82 s 
2023-08-08 14:10:24.118133:  
2023-08-08 14:10:24.118237: Epoch 1544 
2023-08-08 14:10:24.118349: Current learning rate: 0.00026 
2023-08-08 14:11:27.762725: train_loss -0.3548 
2023-08-08 14:11:27.762897: val_loss -0.3575 
2023-08-08 14:11:27.762952: Pseudo dice [0.8772] 
2023-08-08 14:11:27.763003: Epoch time: 63.65 s 
2023-08-08 14:11:28.927569:  
2023-08-08 14:11:28.927783: Epoch 1545 
2023-08-08 14:11:28.927919: Current learning rate: 0.00026 
2023-08-08 14:12:32.759362: train_loss -0.3909 
2023-08-08 14:12:32.759508: val_loss -0.393 
2023-08-08 14:12:32.759563: Pseudo dice [0.8709] 
2023-08-08 14:12:32.759617: Epoch time: 63.83 s 
2023-08-08 14:12:33.857328:  
2023-08-08 14:12:33.857428: Epoch 1546 
2023-08-08 14:12:33.857501: Current learning rate: 0.00026 
2023-08-08 14:13:37.645207: train_loss -0.3506 
2023-08-08 14:13:37.645349: val_loss -0.3682 
2023-08-08 14:13:37.645415: Pseudo dice [0.9091] 
2023-08-08 14:13:37.645464: Epoch time: 63.79 s 
2023-08-08 14:13:38.736297:  
2023-08-08 14:13:38.736389: Epoch 1547 
2023-08-08 14:13:38.736477: Current learning rate: 0.00026 
2023-08-08 14:14:42.115697: train_loss -0.333 
2023-08-08 14:14:42.115858: val_loss -0.3281 
2023-08-08 14:14:42.115913: Pseudo dice [0.9078] 
2023-08-08 14:14:42.115964: Epoch time: 63.38 s 
2023-08-08 14:14:43.337569:  
2023-08-08 14:14:43.337776: Epoch 1548 
2023-08-08 14:14:43.337871: Current learning rate: 0.00026 
2023-08-08 14:15:46.786793: train_loss -0.3462 
2023-08-08 14:15:46.786943: val_loss -0.3352 
2023-08-08 14:15:46.786994: Pseudo dice [0.8751] 
2023-08-08 14:15:46.787060: Epoch time: 63.45 s 
2023-08-08 14:15:47.879085:  
2023-08-08 14:15:47.879188: Epoch 1549 
2023-08-08 14:15:47.879259: Current learning rate: 0.00026 
2023-08-08 14:16:51.607638: train_loss -0.346 
2023-08-08 14:16:51.607917: val_loss -0.3989 
2023-08-08 14:16:51.607973: Pseudo dice [0.8888] 
2023-08-08 14:16:51.608025: Epoch time: 63.73 s 
2023-08-08 14:16:53.096293:  
2023-08-08 14:16:53.096396: Epoch 1550 
2023-08-08 14:16:53.096487: Current learning rate: 0.00026 
2023-08-08 14:17:56.729263: train_loss -0.3737 
2023-08-08 14:17:56.729415: val_loss -0.4718 
2023-08-08 14:17:56.729484: Pseudo dice [0.8854] 
2023-08-08 14:17:56.729534: Epoch time: 63.63 s 
2023-08-08 14:17:57.820579:  
2023-08-08 14:17:57.820678: Epoch 1551 
2023-08-08 14:17:57.820748: Current learning rate: 0.00026 
2023-08-08 14:19:01.587415: train_loss -0.3628 
2023-08-08 14:19:01.587570: val_loss -0.3664 
2023-08-08 14:19:01.587627: Pseudo dice [0.8886] 
2023-08-08 14:19:01.587677: Epoch time: 63.77 s 
2023-08-08 14:19:02.776901:  
2023-08-08 14:19:02.776992: Epoch 1552 
2023-08-08 14:19:02.777079: Current learning rate: 0.00026 
2023-08-08 14:20:06.303572: train_loss -0.366 
2023-08-08 14:20:06.303727: val_loss -0.4173 
2023-08-08 14:20:06.303778: Pseudo dice [0.8969] 
2023-08-08 14:20:06.303828: Epoch time: 63.53 s 
2023-08-08 14:20:07.427569:  
2023-08-08 14:20:07.427675: Epoch 1553 
2023-08-08 14:20:07.427747: Current learning rate: 0.00026 
2023-08-08 14:21:10.806830: train_loss -0.3477 
2023-08-08 14:21:10.806984: val_loss -0.3427 
2023-08-08 14:21:10.807194: Pseudo dice [0.8707] 
2023-08-08 14:21:10.807252: Epoch time: 63.38 s 
2023-08-08 14:21:12.071682:  
2023-08-08 14:21:12.071788: Epoch 1554 
2023-08-08 14:21:12.071877: Current learning rate: 0.00026 
2023-08-08 14:22:15.459686: train_loss -0.3867 
2023-08-08 14:22:15.459832: val_loss -0.3925 
2023-08-08 14:22:15.459884: Pseudo dice [0.8972] 
2023-08-08 14:22:15.459935: Epoch time: 63.39 s 
2023-08-08 14:22:16.550523:  
2023-08-08 14:22:16.550627: Epoch 1555 
2023-08-08 14:22:16.550698: Current learning rate: 0.00026 
2023-08-08 14:23:20.002620: train_loss -0.3564 
2023-08-08 14:23:20.002782: val_loss -0.4116 
2023-08-08 14:23:20.002836: Pseudo dice [0.9075] 
2023-08-08 14:23:20.002887: Epoch time: 63.45 s 
2023-08-08 14:23:21.116777:  
2023-08-08 14:23:21.116890: Epoch 1556 
2023-08-08 14:23:21.116964: Current learning rate: 0.00026 
2023-08-08 14:24:24.506367: train_loss -0.387 
2023-08-08 14:24:24.506514: val_loss -0.3943 
2023-08-08 14:24:24.506566: Pseudo dice [0.8161] 
2023-08-08 14:24:24.506615: Epoch time: 63.39 s 
2023-08-08 14:24:25.609360:  
2023-08-08 14:24:25.609539: Epoch 1557 
2023-08-08 14:24:25.609696: Current learning rate: 0.00026 
2023-08-08 14:25:29.432717: train_loss -0.3477 
2023-08-08 14:25:29.432878: val_loss -0.4172 
2023-08-08 14:25:29.432928: Pseudo dice [0.8591] 
2023-08-08 14:25:29.432994: Epoch time: 63.83 s 
2023-08-08 14:25:30.526685:  
2023-08-08 14:25:30.526781: Epoch 1558 
2023-08-08 14:25:30.526895: Current learning rate: 0.00026 
2023-08-08 14:26:34.072028: train_loss -0.3571 
2023-08-08 14:26:34.072174: val_loss -0.2763 
2023-08-08 14:26:34.072227: Pseudo dice [0.9121] 
2023-08-08 14:26:34.072277: Epoch time: 63.55 s 
2023-08-08 14:26:35.326799:  
2023-08-08 14:26:35.326902: Epoch 1559 
2023-08-08 14:26:35.326973: Current learning rate: 0.00026 
2023-08-08 14:27:38.886858: train_loss -0.3866 
2023-08-08 14:27:38.887004: val_loss -0.3246 
2023-08-08 14:27:38.887072: Pseudo dice [0.9] 
2023-08-08 14:27:38.887123: Epoch time: 63.56 s 
2023-08-08 14:27:39.981328:  
2023-08-08 14:27:39.981430: Epoch 1560 
2023-08-08 14:27:39.981502: Current learning rate: 0.00026 
2023-08-08 14:28:43.470154: train_loss -0.3835 
2023-08-08 14:28:43.470311: val_loss -0.3466 
2023-08-08 14:28:43.470366: Pseudo dice [0.8399] 
2023-08-08 14:28:43.470415: Epoch time: 63.49 s 
2023-08-08 14:28:44.646744:  
2023-08-08 14:28:44.646843: Epoch 1561 
2023-08-08 14:28:44.646933: Current learning rate: 0.00026 
2023-08-08 14:29:48.251836: train_loss -0.3816 
2023-08-08 14:29:48.251980: val_loss -0.3961 
2023-08-08 14:29:48.252033: Pseudo dice [0.8371] 
2023-08-08 14:29:48.252083: Epoch time: 63.61 s 
2023-08-08 14:29:49.344823:  
2023-08-08 14:29:49.344919: Epoch 1562 
2023-08-08 14:29:49.344988: Current learning rate: 0.00025 
2023-08-08 14:30:52.909225: train_loss -0.3429 
2023-08-08 14:30:52.909369: val_loss -0.3981 
2023-08-08 14:30:52.909437: Pseudo dice [0.9096] 
2023-08-08 14:30:52.909487: Epoch time: 63.57 s 
2023-08-08 14:30:54.008847:  
2023-08-08 14:30:54.008947: Epoch 1563 
2023-08-08 14:30:54.009022: Current learning rate: 0.00025 
2023-08-08 14:31:57.895653: train_loss -0.347 
2023-08-08 14:31:57.895803: val_loss -0.4097 
2023-08-08 14:31:57.895853: Pseudo dice [0.8494] 
2023-08-08 14:31:57.895902: Epoch time: 63.89 s 
2023-08-08 14:31:58.977135:  
2023-08-08 14:31:58.977236: Epoch 1564 
2023-08-08 14:31:58.977305: Current learning rate: 0.00025 
2023-08-08 14:33:02.557357: train_loss -0.3679 
2023-08-08 14:33:02.557521: val_loss -0.2865 
2023-08-08 14:33:02.557572: Pseudo dice [0.8895] 
2023-08-08 14:33:02.557623: Epoch time: 63.58 s 
2023-08-08 14:33:03.643525:  
2023-08-08 14:33:03.643636: Epoch 1565 
2023-08-08 14:33:03.643726: Current learning rate: 0.00025 
2023-08-08 14:34:07.148231: train_loss -0.3634 
2023-08-08 14:34:07.148390: val_loss -0.3992 
2023-08-08 14:34:07.148443: Pseudo dice [0.8849] 
2023-08-08 14:34:07.148494: Epoch time: 63.51 s 
2023-08-08 14:34:08.266179:  
2023-08-08 14:34:08.266357: Epoch 1566 
2023-08-08 14:34:08.266434: Current learning rate: 0.00025 
2023-08-08 14:35:11.678069: train_loss -0.3611 
2023-08-08 14:35:11.678247: val_loss -0.4717 
2023-08-08 14:35:11.686704: Pseudo dice [0.891] 
2023-08-08 14:35:11.686938: Epoch time: 63.41 s 
2023-08-08 14:35:12.804090:  
2023-08-08 14:35:12.804203: Epoch 1567 
2023-08-08 14:35:12.804276: Current learning rate: 0.00025 
2023-08-08 14:36:16.292680: train_loss -0.3655 
2023-08-08 14:36:16.292834: val_loss -0.3355 
2023-08-08 14:36:16.292886: Pseudo dice [0.8515] 
2023-08-08 14:36:16.292938: Epoch time: 63.49 s 
2023-08-08 14:36:17.539961:  
2023-08-08 14:36:17.540061: Epoch 1568 
2023-08-08 14:36:17.540152: Current learning rate: 0.00025 
2023-08-08 14:37:20.881561: train_loss -0.3392 
2023-08-08 14:37:20.881737: val_loss -0.4005 
2023-08-08 14:37:20.881796: Pseudo dice [0.849] 
2023-08-08 14:37:20.881848: Epoch time: 63.34 s 
2023-08-08 14:37:22.032557:  
2023-08-08 14:37:22.032659: Epoch 1569 
2023-08-08 14:37:22.032749: Current learning rate: 0.00025 
2023-08-08 14:38:25.667921: train_loss -0.4043 
2023-08-08 14:38:25.668079: val_loss -0.4341 
2023-08-08 14:38:25.668133: Pseudo dice [0.8937] 
2023-08-08 14:38:25.668184: Epoch time: 63.64 s 
2023-08-08 14:38:26.761406:  
2023-08-08 14:38:26.761507: Epoch 1570 
2023-08-08 14:38:26.761580: Current learning rate: 0.00025 
2023-08-08 14:39:30.173783: train_loss -0.3568 
2023-08-08 14:39:30.174065: val_loss -0.3798 
2023-08-08 14:39:30.174204: Pseudo dice [0.9092] 
2023-08-08 14:39:30.174353: Epoch time: 63.41 s 
2023-08-08 14:39:31.278933:  
2023-08-08 14:39:31.279031: Epoch 1571 
2023-08-08 14:39:31.279122: Current learning rate: 0.00025 
2023-08-08 14:40:34.913104: train_loss -0.3708 
2023-08-08 14:40:34.913248: val_loss -0.3451 
2023-08-08 14:40:34.913300: Pseudo dice [0.8933] 
2023-08-08 14:40:34.913350: Epoch time: 63.63 s 
2023-08-08 14:40:36.006872:  
2023-08-08 14:40:36.006981: Epoch 1572 
2023-08-08 14:40:36.007055: Current learning rate: 0.00025 
2023-08-08 14:41:39.499517: train_loss -0.3706 
2023-08-08 14:41:39.499678: val_loss -0.3869 
2023-08-08 14:41:39.499732: Pseudo dice [0.933] 
2023-08-08 14:41:39.499782: Epoch time: 63.49 s 
2023-08-08 14:41:40.632167:  
2023-08-08 14:41:40.632269: Epoch 1573 
2023-08-08 14:41:40.632341: Current learning rate: 0.00025 
2023-08-08 14:42:44.176505: train_loss -0.3755 
2023-08-08 14:42:44.176663: val_loss -0.3881 
2023-08-08 14:42:44.176717: Pseudo dice [0.9198] 
2023-08-08 14:42:44.176768: Epoch time: 63.55 s 
2023-08-08 14:42:44.176808: Yayy! New best EMA pseudo Dice: 0.8889 
2023-08-08 14:42:45.822338:  
2023-08-08 14:42:45.822697: Epoch 1574 
2023-08-08 14:42:45.822776: Current learning rate: 0.00025 
2023-08-08 14:43:49.366596: train_loss -0.3627 
2023-08-08 14:43:49.366745: val_loss -0.4821 
2023-08-08 14:43:49.366796: Pseudo dice [0.8762] 
2023-08-08 14:43:49.366845: Epoch time: 63.54 s 
2023-08-08 14:43:50.459731:  
2023-08-08 14:43:50.459834: Epoch 1575 
2023-08-08 14:43:50.459907: Current learning rate: 0.00025 
2023-08-08 14:44:53.890135: train_loss -0.3547 
2023-08-08 14:44:53.890298: val_loss -0.4032 
2023-08-08 14:44:53.890354: Pseudo dice [0.8944] 
2023-08-08 14:44:53.890406: Epoch time: 63.43 s 
2023-08-08 14:44:54.977542:  
2023-08-08 14:44:54.977640: Epoch 1576 
2023-08-08 14:44:54.977726: Current learning rate: 0.00025 
2023-08-08 14:45:58.629449: train_loss -0.3291 
2023-08-08 14:45:58.629606: val_loss -0.3769 
2023-08-08 14:45:58.629660: Pseudo dice [0.8508] 
2023-08-08 14:45:58.629712: Epoch time: 63.65 s 
2023-08-08 14:45:59.736087:  
2023-08-08 14:45:59.736191: Epoch 1577 
2023-08-08 14:45:59.736266: Current learning rate: 0.00025 
2023-08-08 14:47:03.358354: train_loss -0.3641 
2023-08-08 14:47:03.358509: val_loss -0.3533 
2023-08-08 14:47:03.358562: Pseudo dice [0.8744] 
2023-08-08 14:47:03.358613: Epoch time: 63.62 s 
2023-08-08 14:47:04.465652:  
2023-08-08 14:47:04.465751: Epoch 1578 
2023-08-08 14:47:04.465826: Current learning rate: 0.00025 
2023-08-08 14:48:08.198751: train_loss -0.391 
2023-08-08 14:48:08.198907: val_loss -0.3938 
2023-08-08 14:48:08.198979: Pseudo dice [0.8861] 
2023-08-08 14:48:08.199029: Epoch time: 63.73 s 
2023-08-08 14:48:09.445820:  
2023-08-08 14:48:09.445921: Epoch 1579 
2023-08-08 14:48:09.445992: Current learning rate: 0.00025 
2023-08-08 14:49:12.807413: train_loss -0.3962 
2023-08-08 14:49:12.807581: val_loss -0.376 
2023-08-08 14:49:12.807654: Pseudo dice [0.7961] 
2023-08-08 14:49:12.807706: Epoch time: 63.36 s 
2023-08-08 14:49:13.905661:  
2023-08-08 14:49:13.905972: Epoch 1580 
2023-08-08 14:49:13.906054: Current learning rate: 0.00025 
2023-08-08 14:50:17.587607: train_loss -0.3523 
2023-08-08 14:50:17.587776: val_loss -0.3567 
2023-08-08 14:50:17.587828: Pseudo dice [0.8962] 
2023-08-08 14:50:17.587880: Epoch time: 63.68 s 
2023-08-08 14:50:18.679074:  
2023-08-08 14:50:18.679173: Epoch 1581 
2023-08-08 14:50:18.679263: Current learning rate: 0.00024 
2023-08-08 14:51:22.243518: train_loss -0.3742 
2023-08-08 14:51:22.243697: val_loss -0.3762 
2023-08-08 14:51:22.243754: Pseudo dice [0.8247] 
2023-08-08 14:51:22.243805: Epoch time: 63.57 s 
2023-08-08 14:51:23.329709:  
2023-08-08 14:51:23.329804: Epoch 1582 
2023-08-08 14:51:23.329873: Current learning rate: 0.00024 
2023-08-08 14:52:27.020931: train_loss -0.3727 
2023-08-08 14:52:27.021090: val_loss -0.33 
2023-08-08 14:52:27.021155: Pseudo dice [0.8543] 
2023-08-08 14:52:27.021206: Epoch time: 63.69 s 
2023-08-08 14:52:28.184592:  
2023-08-08 14:52:28.184688: Epoch 1583 
2023-08-08 14:52:28.184757: Current learning rate: 0.00024 
2023-08-08 14:53:31.960663: train_loss -0.3913 
2023-08-08 14:53:31.960819: val_loss -0.3616 
2023-08-08 14:53:31.960887: Pseudo dice [0.9038] 
2023-08-08 14:53:31.960937: Epoch time: 63.78 s 
2023-08-08 14:53:33.085542:  
2023-08-08 14:53:33.085633: Epoch 1584 
2023-08-08 14:53:33.085703: Current learning rate: 0.00024 
2023-08-08 14:54:36.692085: train_loss -0.3797 
2023-08-08 14:54:36.692222: val_loss -0.3859 
2023-08-08 14:54:36.692274: Pseudo dice [0.8722] 
2023-08-08 14:54:36.692324: Epoch time: 63.61 s 
2023-08-08 14:54:37.784982:  
2023-08-08 14:54:37.785096: Epoch 1585 
2023-08-08 14:54:37.785182: Current learning rate: 0.00024 
2023-08-08 14:55:41.403217: train_loss -0.3712 
2023-08-08 14:55:41.403367: val_loss -0.4046 
2023-08-08 14:55:41.403435: Pseudo dice [0.9137] 
2023-08-08 14:55:41.403484: Epoch time: 63.62 s 
2023-08-08 14:55:42.485780:  
2023-08-08 14:55:42.485875: Epoch 1586 
2023-08-08 14:55:42.485962: Current learning rate: 0.00024 
2023-08-08 14:56:46.160071: train_loss -0.4004 
2023-08-08 14:56:46.160224: val_loss -0.3896 
2023-08-08 14:56:46.160276: Pseudo dice [0.8661] 
2023-08-08 14:56:46.160325: Epoch time: 63.67 s 
2023-08-08 14:56:47.268293:  
2023-08-08 14:56:47.268391: Epoch 1587 
2023-08-08 14:56:47.268481: Current learning rate: 0.00024 
2023-08-08 14:57:50.785475: train_loss -0.3838 
2023-08-08 14:57:50.785637: val_loss -0.4259 
2023-08-08 14:57:50.785689: Pseudo dice [0.7933] 
2023-08-08 14:57:50.785755: Epoch time: 63.52 s 
2023-08-08 14:57:52.078238:  
2023-08-08 14:57:52.078346: Epoch 1588 
2023-08-08 14:57:52.078440: Current learning rate: 0.00024 
2023-08-08 14:58:55.670450: train_loss -0.3982 
2023-08-08 14:58:55.670604: val_loss -0.4291 
2023-08-08 14:58:55.670659: Pseudo dice [0.8955] 
2023-08-08 14:58:55.670711: Epoch time: 63.59 s 
2023-08-08 14:58:56.769152:  
2023-08-08 14:58:56.769257: Epoch 1589 
2023-08-08 14:58:56.769330: Current learning rate: 0.00024 
2023-08-08 15:00:00.512542: train_loss -0.3801 
2023-08-08 15:00:00.512704: val_loss -0.4179 
2023-08-08 15:00:00.512760: Pseudo dice [0.8669] 
2023-08-08 15:00:00.512811: Epoch time: 63.74 s 
2023-08-08 15:00:01.610265:  
2023-08-08 15:00:01.610368: Epoch 1590 
2023-08-08 15:00:01.610440: Current learning rate: 0.00024 
2023-08-08 15:01:05.225678: train_loss -0.4364 
2023-08-08 15:01:05.225825: val_loss -0.4419 
2023-08-08 15:01:05.225878: Pseudo dice [0.9085] 
2023-08-08 15:01:05.225929: Epoch time: 63.62 s 
2023-08-08 15:01:06.320615:  
2023-08-08 15:01:06.320714: Epoch 1591 
2023-08-08 15:01:06.320813: Current learning rate: 0.00024 
2023-08-08 15:02:10.088145: train_loss -0.3691 
2023-08-08 15:02:10.088302: val_loss -0.4108 
2023-08-08 15:02:10.088355: Pseudo dice [0.9128] 
2023-08-08 15:02:10.088406: Epoch time: 63.77 s 
2023-08-08 15:02:11.185073:  
2023-08-08 15:02:11.185171: Epoch 1592 
2023-08-08 15:02:11.185260: Current learning rate: 0.00024 
2023-08-08 15:03:14.947381: train_loss -0.4288 
2023-08-08 15:03:14.947535: val_loss -0.3679 
2023-08-08 15:03:14.947597: Pseudo dice [0.8849] 
2023-08-08 15:03:14.947648: Epoch time: 63.76 s 
2023-08-08 15:03:16.052981:  
2023-08-08 15:03:16.053077: Epoch 1593 
2023-08-08 15:03:16.053165: Current learning rate: 0.00024 
2023-08-08 15:04:19.640261: train_loss -0.4141 
2023-08-08 15:04:19.640406: val_loss -0.4484 
2023-08-08 15:04:19.640455: Pseudo dice [0.88] 
2023-08-08 15:04:19.640506: Epoch time: 63.59 s 
2023-08-08 15:04:20.898453:  
2023-08-08 15:04:20.898559: Epoch 1594 
2023-08-08 15:04:20.898635: Current learning rate: 0.00024 
2023-08-08 15:05:24.415294: train_loss -0.4226 
2023-08-08 15:05:24.415484: val_loss -0.3986 
2023-08-08 15:05:24.415537: Pseudo dice [0.8618] 
2023-08-08 15:05:24.415599: Epoch time: 63.52 s 
2023-08-08 15:05:25.513699:  
2023-08-08 15:05:25.513801: Epoch 1595 
2023-08-08 15:05:25.513889: Current learning rate: 0.00024 
2023-08-08 15:06:29.219287: train_loss -0.4145 
2023-08-08 15:06:29.219453: val_loss -0.4397 
2023-08-08 15:06:29.219521: Pseudo dice [0.8712] 
2023-08-08 15:06:29.219579: Epoch time: 63.71 s 
2023-08-08 15:06:30.332427:  
2023-08-08 15:06:30.332521: Epoch 1596 
2023-08-08 15:06:30.332608: Current learning rate: 0.00024 
2023-08-08 15:07:33.805088: train_loss -0.3911 
2023-08-08 15:07:33.805237: val_loss -0.4321 
2023-08-08 15:07:33.805285: Pseudo dice [0.8664] 
2023-08-08 15:07:33.805350: Epoch time: 63.47 s 
2023-08-08 15:07:34.898537:  
2023-08-08 15:07:34.898633: Epoch 1597 
2023-08-08 15:07:34.898720: Current learning rate: 0.00024 
2023-08-08 15:08:38.527410: train_loss -0.4143 
2023-08-08 15:08:38.527566: val_loss -0.4138 
2023-08-08 15:08:38.527623: Pseudo dice [0.8898] 
2023-08-08 15:08:38.527674: Epoch time: 63.63 s 
2023-08-08 15:08:39.638906:  
2023-08-08 15:08:39.639004: Epoch 1598 
2023-08-08 15:08:39.639076: Current learning rate: 0.00024 
2023-08-08 15:09:43.408439: train_loss -0.4115 
2023-08-08 15:09:43.408590: val_loss -0.381 
2023-08-08 15:09:43.408643: Pseudo dice [0.8931] 
2023-08-08 15:09:43.408694: Epoch time: 63.77 s 
2023-08-08 15:09:44.658956:  
2023-08-08 15:09:44.659061: Epoch 1599 
2023-08-08 15:09:44.659151: Current learning rate: 0.00024 
2023-08-08 15:10:48.300871: train_loss -0.3762 
2023-08-08 15:10:48.301038: val_loss -0.3061 
2023-08-08 15:10:48.301092: Pseudo dice [0.8362] 
2023-08-08 15:10:48.301142: Epoch time: 63.64 s 
2023-08-08 15:10:49.803378:  
2023-08-08 15:10:49.803484: Epoch 1600 
2023-08-08 15:10:49.803584: Current learning rate: 0.00023 
2023-08-08 15:11:53.439858: train_loss -0.3983 
2023-08-08 15:11:53.440014: val_loss -0.335 
2023-08-08 15:11:53.440066: Pseudo dice [0.8868] 
2023-08-08 15:11:53.440126: Epoch time: 63.64 s 
2023-08-08 15:11:54.564055:  
2023-08-08 15:11:54.564152: Epoch 1601 
2023-08-08 15:11:54.564228: Current learning rate: 0.00023 
2023-08-08 15:12:58.131740: train_loss -0.3893 
2023-08-08 15:12:58.131890: val_loss -0.3634 
2023-08-08 15:12:58.131941: Pseudo dice [0.8695] 
2023-08-08 15:12:58.131992: Epoch time: 63.57 s 
2023-08-08 15:12:59.358064:  
2023-08-08 15:12:59.358160: Epoch 1602 
2023-08-08 15:12:59.358232: Current learning rate: 0.00023 
2023-08-08 15:14:02.861268: train_loss -0.3971 
2023-08-08 15:14:02.861416: val_loss -0.4064 
2023-08-08 15:14:02.861471: Pseudo dice [0.869] 
2023-08-08 15:14:02.861522: Epoch time: 63.5 s 
2023-08-08 15:14:03.973306:  
2023-08-08 15:14:03.973396: Epoch 1603 
2023-08-08 15:14:03.973506: Current learning rate: 0.00023 
2023-08-08 15:15:07.582929: train_loss -0.41 
2023-08-08 15:15:07.583075: val_loss -0.4194 
2023-08-08 15:15:07.583143: Pseudo dice [0.9134] 
2023-08-08 15:15:07.583194: Epoch time: 63.61 s 
2023-08-08 15:15:08.843533:  
2023-08-08 15:15:08.843851: Epoch 1604 
2023-08-08 15:15:08.844008: Current learning rate: 0.00023 
2023-08-08 15:16:12.428230: train_loss -0.3746 
2023-08-08 15:16:12.428389: val_loss -0.3724 
2023-08-08 15:16:12.428444: Pseudo dice [0.9096] 
2023-08-08 15:16:12.428494: Epoch time: 63.59 s 
2023-08-08 15:16:13.540464:  
2023-08-08 15:16:13.540567: Epoch 1605 
2023-08-08 15:16:13.540640: Current learning rate: 0.00023 
2023-08-08 15:17:17.233445: train_loss -0.3962 
2023-08-08 15:17:17.233615: val_loss -0.3324 
2023-08-08 15:17:17.233669: Pseudo dice [0.8515] 
2023-08-08 15:17:17.233719: Epoch time: 63.69 s 
2023-08-08 15:17:18.343821:  
2023-08-08 15:17:18.344151: Epoch 1606 
2023-08-08 15:17:18.344230: Current learning rate: 0.00023 
2023-08-08 15:18:21.810657: train_loss -0.3823 
2023-08-08 15:18:21.810922: val_loss -0.4596 
2023-08-08 15:18:21.811012: Pseudo dice [0.8489] 
2023-08-08 15:18:21.811064: Epoch time: 63.47 s 
2023-08-08 15:18:22.943033:  
2023-08-08 15:18:22.943125: Epoch 1607 
2023-08-08 15:18:22.943199: Current learning rate: 0.00023 
2023-08-08 15:19:26.485076: train_loss -0.3916 
2023-08-08 15:19:26.485249: val_loss -0.4071 
2023-08-08 15:19:26.485303: Pseudo dice [0.8521] 
2023-08-08 15:19:26.485354: Epoch time: 63.54 s 
2023-08-08 15:19:27.615363:  
2023-08-08 15:19:27.615457: Epoch 1608 
2023-08-08 15:19:27.615528: Current learning rate: 0.00023 
2023-08-08 15:20:31.112272: train_loss -0.407 
2023-08-08 15:20:31.112422: val_loss -0.3819 
2023-08-08 15:20:31.112622: Pseudo dice [0.8983] 
2023-08-08 15:20:31.112675: Epoch time: 63.5 s 
2023-08-08 15:20:32.369858:  
2023-08-08 15:20:32.369960: Epoch 1609 
2023-08-08 15:20:32.370048: Current learning rate: 0.00023 
2023-08-08 15:21:36.132722: train_loss -0.3923 
2023-08-08 15:21:36.132879: val_loss -0.4448 
2023-08-08 15:21:36.132945: Pseudo dice [0.8751] 
2023-08-08 15:21:36.132995: Epoch time: 63.76 s 
2023-08-08 15:21:37.234499:  
2023-08-08 15:21:37.234601: Epoch 1610 
2023-08-08 15:21:37.234674: Current learning rate: 0.00023 
2023-08-08 15:22:40.973083: train_loss -0.3969 
2023-08-08 15:22:40.973235: val_loss -0.3988 
2023-08-08 15:22:40.973289: Pseudo dice [0.8815] 
2023-08-08 15:22:40.973339: Epoch time: 63.74 s 
2023-08-08 15:22:42.066845:  
2023-08-08 15:22:42.066942: Epoch 1611 
2023-08-08 15:22:42.067011: Current learning rate: 0.00023 
2023-08-08 15:23:45.884572: train_loss -0.4188 
2023-08-08 15:23:45.884816: val_loss -0.4169 
2023-08-08 15:23:45.884869: Pseudo dice [0.8722] 
2023-08-08 15:23:45.884920: Epoch time: 63.82 s 
2023-08-08 15:23:46.982583:  
2023-08-08 15:23:46.982680: Epoch 1612 
2023-08-08 15:23:46.982768: Current learning rate: 0.00023 
2023-08-08 15:24:50.725627: train_loss -0.4163 
2023-08-08 15:24:50.725773: val_loss -0.3797 
2023-08-08 15:24:50.725825: Pseudo dice [0.8751] 
2023-08-08 15:24:50.725876: Epoch time: 63.74 s 
2023-08-08 15:24:51.825780:  
2023-08-08 15:24:51.825874: Epoch 1613 
2023-08-08 15:24:51.825963: Current learning rate: 0.00023 
2023-08-08 15:25:55.417238: train_loss -0.3686 
2023-08-08 15:25:55.417409: val_loss -0.4064 
2023-08-08 15:25:55.417462: Pseudo dice [0.8897] 
2023-08-08 15:25:55.417513: Epoch time: 63.59 s 
2023-08-08 15:25:56.747978:  
2023-08-08 15:25:56.748162: Epoch 1614 
2023-08-08 15:25:56.748260: Current learning rate: 0.00023 
2023-08-08 15:27:00.672495: train_loss -0.4232 
2023-08-08 15:27:00.672641: val_loss -0.4254 
2023-08-08 15:27:00.681099: Pseudo dice [0.9511] 
2023-08-08 15:27:00.681333: Epoch time: 63.93 s 
2023-08-08 15:27:01.848181:  
2023-08-08 15:27:01.848292: Epoch 1615 
2023-08-08 15:27:01.848408: Current learning rate: 0.00023 
2023-08-08 15:28:05.387844: train_loss -0.3926 
2023-08-08 15:28:05.387996: val_loss -0.4893 
2023-08-08 15:28:05.388048: Pseudo dice [0.867] 
2023-08-08 15:28:05.388098: Epoch time: 63.54 s 
2023-08-08 15:28:06.503637:  
2023-08-08 15:28:06.503742: Epoch 1616 
2023-08-08 15:28:06.503816: Current learning rate: 0.00023 
2023-08-08 15:29:10.069788: train_loss -0.3797 
2023-08-08 15:29:10.069935: val_loss -0.4793 
2023-08-08 15:29:10.069987: Pseudo dice [0.9341] 
2023-08-08 15:29:10.070036: Epoch time: 63.57 s 
2023-08-08 15:29:11.204091:  
2023-08-08 15:29:11.204192: Epoch 1617 
2023-08-08 15:29:11.204265: Current learning rate: 0.00023 
2023-08-08 15:30:14.728844: train_loss -0.3566 
2023-08-08 15:30:14.729084: val_loss -0.3978 
2023-08-08 15:30:14.729154: Pseudo dice [0.8509] 
2023-08-08 15:30:14.729205: Epoch time: 63.53 s 
2023-08-08 15:30:15.825963:  
2023-08-08 15:30:15.826063: Epoch 1618 
2023-08-08 15:30:15.826133: Current learning rate: 0.00023 
2023-08-08 15:31:19.676748: train_loss -0.3909 
2023-08-08 15:31:19.676898: val_loss -0.4106 
2023-08-08 15:31:19.676949: Pseudo dice [0.8668] 
2023-08-08 15:31:19.676999: Epoch time: 63.85 s 
2023-08-08 15:31:20.774808:  
2023-08-08 15:31:20.774903: Epoch 1619 
2023-08-08 15:31:20.774974: Current learning rate: 0.00022 
2023-08-08 15:32:24.426804: train_loss -0.3989 
2023-08-08 15:32:24.426947: val_loss -0.2999 
2023-08-08 15:32:24.426996: Pseudo dice [0.905] 
2023-08-08 15:32:24.427061: Epoch time: 63.65 s 
2023-08-08 15:32:25.721397:  
2023-08-08 15:32:25.721744: Epoch 1620 
2023-08-08 15:32:25.721970: Current learning rate: 0.00022 
2023-08-08 15:33:29.174493: train_loss -0.3662 
2023-08-08 15:33:29.174647: val_loss -0.3704 
2023-08-08 15:33:29.174697: Pseudo dice [0.9398] 
2023-08-08 15:33:29.174749: Epoch time: 63.46 s 
2023-08-08 15:33:29.174789: Yayy! New best EMA pseudo Dice: 0.8902 
2023-08-08 15:33:30.651172:  
2023-08-08 15:33:30.651277: Epoch 1621 
2023-08-08 15:33:30.651365: Current learning rate: 0.00022 
2023-08-08 15:34:34.234661: train_loss -0.381 
2023-08-08 15:34:34.234814: val_loss -0.3904 
2023-08-08 15:34:34.234868: Pseudo dice [0.8535] 
2023-08-08 15:34:34.235097: Epoch time: 63.58 s 
2023-08-08 15:34:35.335251:  
2023-08-08 15:34:35.335353: Epoch 1622 
2023-08-08 15:34:35.335425: Current learning rate: 0.00022 
2023-08-08 15:35:38.929869: train_loss -0.4147 
2023-08-08 15:35:38.930032: val_loss -0.3557 
2023-08-08 15:35:38.930084: Pseudo dice [0.8708] 
2023-08-08 15:35:38.930135: Epoch time: 63.6 s 
2023-08-08 15:35:40.033954:  
2023-08-08 15:35:40.034049: Epoch 1623 
2023-08-08 15:35:40.034122: Current learning rate: 0.00022 
2023-08-08 15:36:43.625392: train_loss -0.4105 
2023-08-08 15:36:43.625535: val_loss -0.3211 
2023-08-08 15:36:43.625602: Pseudo dice [0.8714] 
2023-08-08 15:36:43.625654: Epoch time: 63.59 s 
2023-08-08 15:36:44.761201:  
2023-08-08 15:36:44.761297: Epoch 1624 
2023-08-08 15:36:44.761368: Current learning rate: 0.00022 
2023-08-08 15:37:48.479759: train_loss -0.4132 
2023-08-08 15:37:48.479916: val_loss -0.3922 
2023-08-08 15:37:48.479969: Pseudo dice [0.8772] 
2023-08-08 15:37:48.480018: Epoch time: 63.72 s 
2023-08-08 15:37:49.576006:  
2023-08-08 15:37:49.576127: Epoch 1625 
2023-08-08 15:37:49.576200: Current learning rate: 0.00022 
2023-08-08 15:38:53.002273: train_loss -0.3832 
2023-08-08 15:38:53.002420: val_loss -0.4133 
2023-08-08 15:38:53.002474: Pseudo dice [0.8945] 
2023-08-08 15:38:53.002524: Epoch time: 63.43 s 
2023-08-08 15:38:54.137234:  
2023-08-08 15:38:54.137335: Epoch 1626 
2023-08-08 15:38:54.137422: Current learning rate: 0.00022 
2023-08-08 15:39:57.486239: train_loss -0.4151 
2023-08-08 15:39:57.486389: val_loss -0.3725 
2023-08-08 15:39:57.486440: Pseudo dice [0.8442] 
2023-08-08 15:39:57.486511: Epoch time: 63.35 s 
2023-08-08 15:39:58.578694:  
2023-08-08 15:39:58.578813: Epoch 1627 
2023-08-08 15:39:58.578882: Current learning rate: 0.00022 
2023-08-08 15:41:02.201154: train_loss -0.3884 
2023-08-08 15:41:02.201301: val_loss -0.3787 
2023-08-08 15:41:02.201352: Pseudo dice [0.8899] 
2023-08-08 15:41:02.201403: Epoch time: 63.62 s 
2023-08-08 15:41:03.288240:  
2023-08-08 15:41:03.288337: Epoch 1628 
2023-08-08 15:41:03.288424: Current learning rate: 0.00022 
2023-08-08 15:42:06.841434: train_loss -0.3962 
2023-08-08 15:42:06.841592: val_loss -0.3676 
2023-08-08 15:42:06.841645: Pseudo dice [0.8691] 
2023-08-08 15:42:06.841695: Epoch time: 63.55 s 
2023-08-08 15:42:08.074598:  
2023-08-08 15:42:08.074693: Epoch 1629 
2023-08-08 15:42:08.074786: Current learning rate: 0.00022 
2023-08-08 15:43:11.882030: train_loss -0.3806 
2023-08-08 15:43:11.882183: val_loss -0.3922 
2023-08-08 15:43:11.882232: Pseudo dice [0.8744] 
2023-08-08 15:43:11.882299: Epoch time: 63.81 s 
2023-08-08 15:43:12.984290:  
2023-08-08 15:43:12.984385: Epoch 1630 
2023-08-08 15:43:12.984458: Current learning rate: 0.00022 
2023-08-08 15:44:16.530001: train_loss -0.4137 
2023-08-08 15:44:16.530160: val_loss -0.3169 
2023-08-08 15:44:16.530212: Pseudo dice [0.8684] 
2023-08-08 15:44:16.530261: Epoch time: 63.55 s 
2023-08-08 15:44:17.671001:  
2023-08-08 15:44:17.671094: Epoch 1631 
2023-08-08 15:44:17.671180: Current learning rate: 0.00022 
2023-08-08 15:45:21.320871: train_loss -0.4124 
2023-08-08 15:45:21.321031: val_loss -0.4248 
2023-08-08 15:45:21.321083: Pseudo dice [0.8958] 
2023-08-08 15:45:21.321133: Epoch time: 63.65 s 
2023-08-08 15:45:22.419619:  
2023-08-08 15:45:22.419713: Epoch 1632 
2023-08-08 15:45:22.419787: Current learning rate: 0.00022 
2023-08-08 15:46:25.929513: train_loss -0.4101 
2023-08-08 15:46:25.929712: val_loss -0.4043 
2023-08-08 15:46:25.929802: Pseudo dice [0.8721] 
2023-08-08 15:46:25.930076: Epoch time: 63.51 s 
2023-08-08 15:46:27.030875:  
2023-08-08 15:46:27.030971: Epoch 1633 
2023-08-08 15:46:27.031044: Current learning rate: 0.00022 
2023-08-08 15:47:30.687525: train_loss -0.3773 
2023-08-08 15:47:30.687686: val_loss -0.4199 
2023-08-08 15:47:30.687739: Pseudo dice [0.9553] 
2023-08-08 15:47:30.687807: Epoch time: 63.66 s 
2023-08-08 15:47:31.804264:  
2023-08-08 15:47:31.804356: Epoch 1634 
2023-08-08 15:47:31.804430: Current learning rate: 0.00022 
2023-08-08 15:48:35.485599: train_loss -0.4112 
2023-08-08 15:48:35.485763: val_loss -0.438 
2023-08-08 15:48:35.485821: Pseudo dice [0.9053] 
2023-08-08 15:48:35.485871: Epoch time: 63.68 s 
2023-08-08 15:48:36.831702:  
2023-08-08 15:48:36.831802: Epoch 1635 
2023-08-08 15:48:36.831876: Current learning rate: 0.00022 
2023-08-08 15:49:40.409316: train_loss -0.3868 
2023-08-08 15:49:40.409469: val_loss -0.3722 
2023-08-08 15:49:40.409522: Pseudo dice [0.9262] 
2023-08-08 15:49:40.409573: Epoch time: 63.58 s 
2023-08-08 15:49:40.409613: Yayy! New best EMA pseudo Dice: 0.8924 
2023-08-08 15:49:41.965008:  
2023-08-08 15:49:41.965115: Epoch 1636 
2023-08-08 15:49:41.965202: Current learning rate: 0.00022 
2023-08-08 15:50:45.552516: train_loss -0.4025 
2023-08-08 15:50:45.552674: val_loss -0.4547 
2023-08-08 15:50:45.552734: Pseudo dice [0.8264] 
2023-08-08 15:50:45.552790: Epoch time: 63.59 s 
2023-08-08 15:50:46.646789:  
2023-08-08 15:50:46.646890: Epoch 1637 
2023-08-08 15:50:46.646976: Current learning rate: 0.00022 
2023-08-08 15:51:50.274643: train_loss -0.3781 
2023-08-08 15:51:50.274795: val_loss -0.4336 
2023-08-08 15:51:50.274845: Pseudo dice [0.9019] 
2023-08-08 15:51:50.274911: Epoch time: 63.63 s 
2023-08-08 15:51:51.382402:  
2023-08-08 15:51:51.382501: Epoch 1638 
2023-08-08 15:51:51.382575: Current learning rate: 0.00021 
2023-08-08 15:52:54.942727: train_loss -0.4052 
2023-08-08 15:52:54.942897: val_loss -0.4565 
2023-08-08 15:52:54.942950: Pseudo dice [0.9079] 
2023-08-08 15:52:54.943000: Epoch time: 63.56 s 
2023-08-08 15:52:56.010067:  
2023-08-08 15:52:56.010168: Epoch 1639 
2023-08-08 15:52:56.010257: Current learning rate: 0.00021 
2023-08-08 15:53:59.493464: train_loss -0.4235 
2023-08-08 15:53:59.493606: val_loss -0.3938 
2023-08-08 15:53:59.493673: Pseudo dice [0.8973] 
2023-08-08 15:53:59.493723: Epoch time: 63.48 s 
2023-08-08 15:54:00.711880:  
2023-08-08 15:54:00.711986: Epoch 1640 
2023-08-08 15:54:00.712058: Current learning rate: 0.00021 
2023-08-08 15:55:04.328386: train_loss -0.4076 
2023-08-08 15:55:04.328549: val_loss -0.3883 
2023-08-08 15:55:04.328601: Pseudo dice [0.9001] 
2023-08-08 15:55:04.328651: Epoch time: 63.62 s 
2023-08-08 15:55:05.389844:  
2023-08-08 15:55:05.389946: Epoch 1641 
2023-08-08 15:55:05.390018: Current learning rate: 0.00021 
2023-08-08 15:56:08.855246: train_loss -0.4135 
2023-08-08 15:56:08.855403: val_loss -0.3827 
2023-08-08 15:56:08.855456: Pseudo dice [0.9096] 
2023-08-08 15:56:08.855507: Epoch time: 63.47 s 
2023-08-08 15:56:08.855548: Yayy! New best EMA pseudo Dice: 0.8931 
2023-08-08 15:56:10.340579:  
2023-08-08 15:56:10.340679: Epoch 1642 
2023-08-08 15:56:10.340768: Current learning rate: 0.00021 
2023-08-08 15:57:14.057295: train_loss -0.413 
2023-08-08 15:57:14.057462: val_loss -0.4453 
2023-08-08 15:57:14.057515: Pseudo dice [0.8734] 
2023-08-08 15:57:14.057564: Epoch time: 63.72 s 
2023-08-08 15:57:15.114566:  
2023-08-08 15:57:15.114659: Epoch 1643 
2023-08-08 15:57:15.114728: Current learning rate: 0.00021 
2023-08-08 15:58:18.589233: train_loss -0.4095 
2023-08-08 15:58:18.589510: val_loss -0.4287 
2023-08-08 15:58:18.589564: Pseudo dice [0.8657] 
2023-08-08 15:58:18.589613: Epoch time: 63.48 s 
2023-08-08 15:58:19.678215:  
2023-08-08 15:58:19.678539: Epoch 1644 
2023-08-08 15:58:19.678619: Current learning rate: 0.00021 
2023-08-08 15:59:23.053943: train_loss -0.3901 
2023-08-08 15:59:23.054102: val_loss -0.444 
2023-08-08 15:59:23.054152: Pseudo dice [0.8818] 
2023-08-08 15:59:23.054218: Epoch time: 63.38 s 
2023-08-08 15:59:24.283017:  
2023-08-08 15:59:24.283124: Epoch 1645 
2023-08-08 15:59:24.283196: Current learning rate: 0.00021 
2023-08-08 16:00:27.799011: train_loss -0.3718 
2023-08-08 16:00:27.799288: val_loss -0.478 
2023-08-08 16:00:27.799343: Pseudo dice [0.8823] 
2023-08-08 16:00:27.799394: Epoch time: 63.52 s 
2023-08-08 16:00:28.865471:  
2023-08-08 16:00:28.865573: Epoch 1646 
2023-08-08 16:00:28.865664: Current learning rate: 0.00021 
2023-08-08 16:01:32.509023: train_loss -0.3898 
2023-08-08 16:01:32.509172: val_loss -0.3122 
2023-08-08 16:01:32.509223: Pseudo dice [0.8567] 
2023-08-08 16:01:32.509273: Epoch time: 63.64 s 
2023-08-08 16:01:33.574017:  
2023-08-08 16:01:33.574116: Epoch 1647 
2023-08-08 16:01:33.574185: Current learning rate: 0.00021 
2023-08-08 16:02:37.359994: train_loss -0.4261 
2023-08-08 16:02:37.360143: val_loss -0.3961 
2023-08-08 16:02:37.360197: Pseudo dice [0.8668] 
2023-08-08 16:02:37.360247: Epoch time: 63.79 s 
2023-08-08 16:02:38.451760:  
2023-08-08 16:02:38.451855: Epoch 1648 
2023-08-08 16:02:38.451928: Current learning rate: 0.00021 
2023-08-08 16:03:42.176694: train_loss -0.3992 
2023-08-08 16:03:42.176855: val_loss -0.4217 
2023-08-08 16:03:42.176904: Pseudo dice [0.8432] 
2023-08-08 16:03:42.176969: Epoch time: 63.73 s 
2023-08-08 16:03:43.235360:  
2023-08-08 16:03:43.235455: Epoch 1649 
2023-08-08 16:03:43.235547: Current learning rate: 0.00021 
2023-08-08 16:04:46.720624: train_loss -0.3955 
2023-08-08 16:04:46.720777: val_loss -0.3497 
2023-08-08 16:04:46.720830: Pseudo dice [0.9115] 
2023-08-08 16:04:46.720882: Epoch time: 63.49 s 
2023-08-08 16:04:48.337378:  
2023-08-08 16:04:48.337587: Epoch 1650 
2023-08-08 16:04:48.337680: Current learning rate: 0.00021 
2023-08-08 16:05:51.783242: train_loss -0.3948 
2023-08-08 16:05:51.783392: val_loss -0.4076 
2023-08-08 16:05:51.783446: Pseudo dice [0.8577] 
2023-08-08 16:05:51.783514: Epoch time: 63.45 s 
2023-08-08 16:05:52.854614:  
2023-08-08 16:05:52.854719: Epoch 1651 
2023-08-08 16:05:52.854792: Current learning rate: 0.00021 
2023-08-08 16:06:56.569654: train_loss -0.3869 
2023-08-08 16:06:56.569803: val_loss -0.371 
2023-08-08 16:06:56.569853: Pseudo dice [0.8626] 
2023-08-08 16:06:56.569918: Epoch time: 63.72 s 
2023-08-08 16:06:57.658749:  
2023-08-08 16:06:57.658845: Epoch 1652 
2023-08-08 16:06:57.658934: Current learning rate: 0.00021 
2023-08-08 16:08:01.267848: train_loss -0.3751 
2023-08-08 16:08:01.268005: val_loss -0.3576 
2023-08-08 16:08:01.268058: Pseudo dice [0.8278] 
2023-08-08 16:08:01.268109: Epoch time: 63.61 s 
2023-08-08 16:08:02.346895:  
2023-08-08 16:08:02.346991: Epoch 1653 
2023-08-08 16:08:02.347063: Current learning rate: 0.00021 
2023-08-08 16:09:06.090465: train_loss -0.426 
2023-08-08 16:09:06.090615: val_loss -0.4557 
2023-08-08 16:09:06.090683: Pseudo dice [0.8759] 
2023-08-08 16:09:06.090733: Epoch time: 63.74 s 
2023-08-08 16:09:07.154992:  
2023-08-08 16:09:07.155088: Epoch 1654 
2023-08-08 16:09:07.155162: Current learning rate: 0.00021 
2023-08-08 16:10:10.649223: train_loss -0.4088 
2023-08-08 16:10:10.649368: val_loss -0.4434 
2023-08-08 16:10:10.649418: Pseudo dice [0.8864] 
2023-08-08 16:10:10.649484: Epoch time: 63.49 s 
2023-08-08 16:10:11.870304:  
2023-08-08 16:10:11.870409: Epoch 1655 
2023-08-08 16:10:11.870496: Current learning rate: 0.00021 
2023-08-08 16:11:15.763873: train_loss -0.418 
2023-08-08 16:11:15.764024: val_loss -0.3678 
2023-08-08 16:11:15.764080: Pseudo dice [0.8807] 
2023-08-08 16:11:15.764130: Epoch time: 63.89 s 
2023-08-08 16:11:16.850157:  
2023-08-08 16:11:16.850261: Epoch 1656 
2023-08-08 16:11:16.850331: Current learning rate: 0.00021 
2023-08-08 16:12:20.546179: train_loss -0.4427 
2023-08-08 16:12:20.546335: val_loss -0.4532 
2023-08-08 16:12:20.546393: Pseudo dice [0.9116] 
2023-08-08 16:12:20.546449: Epoch time: 63.7 s 
2023-08-08 16:12:21.605386:  
2023-08-08 16:12:21.605487: Epoch 1657 
2023-08-08 16:12:21.605559: Current learning rate: 0.0002 
2023-08-08 16:13:25.275019: train_loss -0.3888 
2023-08-08 16:13:25.275194: val_loss -0.4066 
2023-08-08 16:13:25.275249: Pseudo dice [0.8671] 
2023-08-08 16:13:25.275302: Epoch time: 63.67 s 
2023-08-08 16:13:26.370141:  
2023-08-08 16:13:26.370235: Epoch 1658 
2023-08-08 16:13:26.370307: Current learning rate: 0.0002 
2023-08-08 16:14:29.988616: train_loss -0.3615 
2023-08-08 16:14:29.988775: val_loss -0.4427 
2023-08-08 16:14:29.997204: Pseudo dice [0.8985] 
2023-08-08 16:14:29.997314: Epoch time: 63.62 s 
2023-08-08 16:14:31.081234:  
2023-08-08 16:14:31.081334: Epoch 1659 
2023-08-08 16:14:31.081407: Current learning rate: 0.0002 
2023-08-08 16:15:34.645151: train_loss -0.4107 
2023-08-08 16:15:34.645305: val_loss -0.4644 
2023-08-08 16:15:34.645361: Pseudo dice [0.9093] 
2023-08-08 16:15:34.645417: Epoch time: 63.56 s 
2023-08-08 16:15:35.884995:  
2023-08-08 16:15:35.885104: Epoch 1660 
2023-08-08 16:15:35.885193: Current learning rate: 0.0002 
2023-08-08 16:16:39.937453: train_loss -0.4232 
2023-08-08 16:16:39.937604: val_loss -0.4178 
2023-08-08 16:16:39.937675: Pseudo dice [0.8867] 
2023-08-08 16:16:39.937725: Epoch time: 64.05 s 
2023-08-08 16:16:41.111922:  
2023-08-08 16:16:41.112028: Epoch 1661 
2023-08-08 16:16:41.112104: Current learning rate: 0.0002 
2023-08-08 16:17:44.836345: train_loss -0.3774 
2023-08-08 16:17:44.836544: val_loss -0.4682 
2023-08-08 16:17:44.836631: Pseudo dice [0.8674] 
2023-08-08 16:17:44.836713: Epoch time: 63.73 s 
2023-08-08 16:17:45.964328:  
2023-08-08 16:17:45.964427: Epoch 1662 
2023-08-08 16:17:45.964517: Current learning rate: 0.0002 
2023-08-08 16:18:49.705058: train_loss -0.3853 
2023-08-08 16:18:49.705213: val_loss -0.4929 
2023-08-08 16:18:49.705266: Pseudo dice [0.8612] 
2023-08-08 16:18:49.705316: Epoch time: 63.74 s 
2023-08-08 16:18:50.764097:  
2023-08-08 16:18:50.764199: Epoch 1663 
2023-08-08 16:18:50.764273: Current learning rate: 0.0002 
2023-08-08 16:19:54.247881: train_loss -0.3909 
2023-08-08 16:19:54.248038: val_loss -0.477 
2023-08-08 16:19:54.248103: Pseudo dice [0.8862] 
2023-08-08 16:19:54.248155: Epoch time: 63.48 s 
2023-08-08 16:19:55.326086:  
2023-08-08 16:19:55.326175: Epoch 1664 
2023-08-08 16:19:55.326263: Current learning rate: 0.0002 
2023-08-08 16:20:59.037276: train_loss -0.3769 
2023-08-08 16:20:59.037423: val_loss -0.4026 
2023-08-08 16:20:59.037475: Pseudo dice [0.8876] 
2023-08-08 16:20:59.037539: Epoch time: 63.71 s 
2023-08-08 16:21:00.130772:  
2023-08-08 16:21:00.130862: Epoch 1665 
2023-08-08 16:21:00.130933: Current learning rate: 0.0002 
2023-08-08 16:22:03.778480: train_loss -0.3922 
2023-08-08 16:22:03.778627: val_loss -0.4393 
2023-08-08 16:22:03.778676: Pseudo dice [0.9309] 
2023-08-08 16:22:03.778742: Epoch time: 63.65 s 
2023-08-08 16:22:05.081571:  
2023-08-08 16:22:05.081948: Epoch 1666 
2023-08-08 16:22:05.082030: Current learning rate: 0.0002 
2023-08-08 16:23:08.717939: train_loss -0.4147 
2023-08-08 16:23:08.718096: val_loss -0.4268 
2023-08-08 16:23:08.718150: Pseudo dice [0.8453] 
2023-08-08 16:23:08.718201: Epoch time: 63.64 s 
2023-08-08 16:23:09.844733:  
2023-08-08 16:23:09.844837: Epoch 1667 
2023-08-08 16:23:09.844911: Current learning rate: 0.0002 
2023-08-08 16:24:13.556447: train_loss -0.3826 
2023-08-08 16:24:13.556589: val_loss -0.339 
2023-08-08 16:24:13.556641: Pseudo dice [0.8259] 
2023-08-08 16:24:13.556690: Epoch time: 63.71 s 
2023-08-08 16:24:14.715490:  
2023-08-08 16:24:14.715949: Epoch 1668 
2023-08-08 16:24:14.716161: Current learning rate: 0.0002 
2023-08-08 16:25:18.323342: train_loss -0.4015 
2023-08-08 16:25:18.323522: val_loss -0.4064 
2023-08-08 16:25:18.323586: Pseudo dice [0.9304] 
2023-08-08 16:25:18.323640: Epoch time: 63.61 s 
2023-08-08 16:25:19.407389:  
2023-08-08 16:25:19.407500: Epoch 1669 
2023-08-08 16:25:19.407594: Current learning rate: 0.0002 
2023-08-08 16:26:23.065121: train_loss -0.3957 
2023-08-08 16:26:23.065284: val_loss -0.4252 
2023-08-08 16:26:23.065336: Pseudo dice [0.9019] 
2023-08-08 16:26:23.065386: Epoch time: 63.66 s 
2023-08-08 16:26:24.150728:  
2023-08-08 16:26:24.150830: Epoch 1670 
2023-08-08 16:26:24.150944: Current learning rate: 0.0002 
2023-08-08 16:27:27.775751: train_loss -0.4043 
2023-08-08 16:27:27.775907: val_loss -0.3728 
2023-08-08 16:27:27.775962: Pseudo dice [0.8913] 
2023-08-08 16:27:27.776013: Epoch time: 63.63 s 
2023-08-08 16:27:29.009399:  
2023-08-08 16:27:29.009504: Epoch 1671 
2023-08-08 16:27:29.009592: Current learning rate: 0.0002 
2023-08-08 16:28:32.812562: train_loss -0.3976 
2023-08-08 16:28:32.812710: val_loss -0.3704 
2023-08-08 16:28:32.812765: Pseudo dice [0.8793] 
2023-08-08 16:28:32.812816: Epoch time: 63.8 s 
2023-08-08 16:28:33.931321:  
2023-08-08 16:28:33.931427: Epoch 1672 
2023-08-08 16:28:33.931516: Current learning rate: 0.0002 
2023-08-08 16:29:37.534328: train_loss -0.4107 
2023-08-08 16:29:37.534487: val_loss -0.4001 
2023-08-08 16:29:37.534546: Pseudo dice [0.9219] 
2023-08-08 16:29:37.534604: Epoch time: 63.6 s 
2023-08-08 16:29:38.645877:  
2023-08-08 16:29:38.646195: Epoch 1673 
2023-08-08 16:29:38.646274: Current learning rate: 0.0002 
2023-08-08 16:30:42.243186: train_loss -0.3985 
2023-08-08 16:30:42.243346: val_loss -0.4447 
2023-08-08 16:30:42.243401: Pseudo dice [0.894] 
2023-08-08 16:30:42.243452: Epoch time: 63.6 s 
2023-08-08 16:30:43.330921:  
2023-08-08 16:30:43.331017: Epoch 1674 
2023-08-08 16:30:43.331087: Current learning rate: 0.0002 
2023-08-08 16:31:47.130293: train_loss -0.3889 
2023-08-08 16:31:47.130446: val_loss -0.392 
2023-08-08 16:31:47.130495: Pseudo dice [0.904] 
2023-08-08 16:31:47.130560: Epoch time: 63.8 s 
2023-08-08 16:31:48.206027:  
2023-08-08 16:31:48.206120: Epoch 1675 
2023-08-08 16:31:48.206193: Current learning rate: 0.00019 
2023-08-08 16:32:51.797948: train_loss -0.3936 
2023-08-08 16:32:51.798111: val_loss -0.483 
2023-08-08 16:32:51.798161: Pseudo dice [0.8647] 
2023-08-08 16:32:51.798211: Epoch time: 63.59 s 
2023-08-08 16:32:52.896276:  
2023-08-08 16:32:52.896370: Epoch 1676 
2023-08-08 16:32:52.896444: Current learning rate: 0.00019 
2023-08-08 16:33:56.844167: train_loss -0.4143 
2023-08-08 16:33:56.844319: val_loss -0.4411 
2023-08-08 16:33:56.844392: Pseudo dice [0.8843] 
2023-08-08 16:33:56.844445: Epoch time: 63.95 s 
2023-08-08 16:33:57.942193:  
2023-08-08 16:33:57.942293: Epoch 1677 
2023-08-08 16:33:57.942398: Current learning rate: 0.00019 
2023-08-08 16:35:01.422870: train_loss -0.4055 
2023-08-08 16:35:01.423025: val_loss -0.3753 
2023-08-08 16:35:01.423096: Pseudo dice [0.9111] 
2023-08-08 16:35:01.423147: Epoch time: 63.48 s 
2023-08-08 16:35:02.505589:  
2023-08-08 16:35:02.505689: Epoch 1678 
2023-08-08 16:35:02.505774: Current learning rate: 0.00019 
2023-08-08 16:36:05.951975: train_loss -0.3975 
2023-08-08 16:36:05.952127: val_loss -0.3439 
2023-08-08 16:36:05.952181: Pseudo dice [0.8508] 
2023-08-08 16:36:05.952231: Epoch time: 63.45 s 
2023-08-08 16:36:07.030374:  
2023-08-08 16:36:07.030471: Epoch 1679 
2023-08-08 16:36:07.030559: Current learning rate: 0.00019 
2023-08-08 16:37:10.703808: train_loss -0.3986 
2023-08-08 16:37:10.703959: val_loss -0.4052 
2023-08-08 16:37:10.704012: Pseudo dice [0.8455] 
2023-08-08 16:37:10.704063: Epoch time: 63.67 s 
2023-08-08 16:37:11.779405:  
2023-08-08 16:37:11.779832: Epoch 1680 
2023-08-08 16:37:11.780134: Current learning rate: 0.00019 
2023-08-08 16:38:15.262655: train_loss -0.3835 
2023-08-08 16:38:15.262800: val_loss -0.3355 
2023-08-08 16:38:15.262849: Pseudo dice [0.8687] 
2023-08-08 16:38:15.262913: Epoch time: 63.48 s 
2023-08-08 16:38:16.478442:  
2023-08-08 16:38:16.478546: Epoch 1681 
2023-08-08 16:38:16.478637: Current learning rate: 0.00019 
2023-08-08 16:39:19.989197: train_loss -0.4027 
2023-08-08 16:39:19.989352: val_loss -0.4559 
2023-08-08 16:39:19.989405: Pseudo dice [0.9124] 
2023-08-08 16:39:19.989455: Epoch time: 63.51 s 
2023-08-08 16:39:21.100089:  
2023-08-08 16:39:21.100327: Epoch 1682 
2023-08-08 16:39:21.100413: Current learning rate: 0.00019 
2023-08-08 16:40:24.487643: train_loss -0.4173 
2023-08-08 16:40:24.487801: val_loss -0.4785 
2023-08-08 16:40:24.487852: Pseudo dice [0.871] 
2023-08-08 16:40:24.487904: Epoch time: 63.39 s 
2023-08-08 16:40:25.591317:  
2023-08-08 16:40:25.591417: Epoch 1683 
2023-08-08 16:40:25.591504: Current learning rate: 0.00019 
2023-08-08 16:41:29.168381: train_loss -0.4087 
2023-08-08 16:41:29.168544: val_loss -0.4055 
2023-08-08 16:41:29.168597: Pseudo dice [0.9178] 
2023-08-08 16:41:29.168648: Epoch time: 63.58 s 
2023-08-08 16:41:30.273945:  
2023-08-08 16:41:30.274038: Epoch 1684 
2023-08-08 16:41:30.274149: Current learning rate: 0.00019 
2023-08-08 16:42:33.852090: train_loss -0.4193 
2023-08-08 16:42:33.852239: val_loss -0.4871 
2023-08-08 16:42:33.852289: Pseudo dice [0.946] 
2023-08-08 16:42:33.852339: Epoch time: 63.58 s 
2023-08-08 16:42:34.985955:  
2023-08-08 16:42:34.986046: Epoch 1685 
2023-08-08 16:42:34.986118: Current learning rate: 0.00019 
2023-08-08 16:43:38.405576: train_loss -0.409 
2023-08-08 16:43:38.405729: val_loss -0.4053 
2023-08-08 16:43:38.405781: Pseudo dice [0.8744] 
2023-08-08 16:43:38.405832: Epoch time: 63.42 s 
2023-08-08 16:43:39.481276:  
2023-08-08 16:43:39.481369: Epoch 1686 
2023-08-08 16:43:39.481441: Current learning rate: 0.00019 
2023-08-08 16:44:42.760228: train_loss -0.3962 
2023-08-08 16:44:42.760376: val_loss -0.3753 
2023-08-08 16:44:42.760427: Pseudo dice [0.9155] 
2023-08-08 16:44:42.760477: Epoch time: 63.28 s 
2023-08-08 16:44:44.051001:  
2023-08-08 16:44:44.051101: Epoch 1687 
2023-08-08 16:44:44.051174: Current learning rate: 0.00019 
2023-08-08 16:45:47.689606: train_loss -0.3832 
2023-08-08 16:45:47.689772: val_loss -0.3618 
2023-08-08 16:45:47.689824: Pseudo dice [0.9014] 
2023-08-08 16:45:47.689873: Epoch time: 63.64 s 
2023-08-08 16:45:47.689914: Yayy! New best EMA pseudo Dice: 0.8935 
2023-08-08 16:45:49.191541:  
2023-08-08 16:45:49.191851: Epoch 1688 
2023-08-08 16:45:49.192095: Current learning rate: 0.00019 
2023-08-08 16:46:52.784985: train_loss -0.4017 
2023-08-08 16:46:52.785131: val_loss -0.3485 
2023-08-08 16:46:52.785183: Pseudo dice [0.8377] 
2023-08-08 16:46:52.785231: Epoch time: 63.59 s 
2023-08-08 16:46:53.863939:  
2023-08-08 16:46:53.864036: Epoch 1689 
2023-08-08 16:46:53.864111: Current learning rate: 0.00019 
2023-08-08 16:47:57.422996: train_loss -0.3919 
2023-08-08 16:47:57.423158: val_loss -0.3901 
2023-08-08 16:47:57.423225: Pseudo dice [0.921] 
2023-08-08 16:47:57.423275: Epoch time: 63.56 s 
2023-08-08 16:47:58.509567:  
2023-08-08 16:47:58.509659: Epoch 1690 
2023-08-08 16:47:58.509748: Current learning rate: 0.00019 
2023-08-08 16:49:02.124370: train_loss -0.4325 
2023-08-08 16:49:02.124522: val_loss -0.4088 
2023-08-08 16:49:02.124576: Pseudo dice [0.9065] 
2023-08-08 16:49:02.124626: Epoch time: 63.62 s 
2023-08-08 16:49:03.196185:  
2023-08-08 16:49:03.196278: Epoch 1691 
2023-08-08 16:49:03.196350: Current learning rate: 0.00019 
2023-08-08 16:50:06.628271: train_loss -0.4025 
2023-08-08 16:50:06.628415: val_loss -0.4168 
2023-08-08 16:50:06.628467: Pseudo dice [0.9083] 
2023-08-08 16:50:06.628518: Epoch time: 63.43 s 
2023-08-08 16:50:06.628558: Yayy! New best EMA pseudo Dice: 0.8943 
2023-08-08 16:50:08.277833:  
2023-08-08 16:50:08.277936: Epoch 1692 
2023-08-08 16:50:08.278010: Current learning rate: 0.00019 
2023-08-08 16:51:11.916281: train_loss -0.4561 
2023-08-08 16:51:11.916423: val_loss -0.4047 
2023-08-08 16:51:11.916476: Pseudo dice [0.9122] 
2023-08-08 16:51:11.916526: Epoch time: 63.64 s 
2023-08-08 16:51:11.916584: Yayy! New best EMA pseudo Dice: 0.8961 
2023-08-08 16:51:13.419337:  
2023-08-08 16:51:13.419440: Epoch 1693 
2023-08-08 16:51:13.419513: Current learning rate: 0.00019 
2023-08-08 16:52:16.971987: train_loss -0.3882 
2023-08-08 16:52:16.972134: val_loss -0.3939 
2023-08-08 16:52:16.972184: Pseudo dice [0.858] 
2023-08-08 16:52:16.972234: Epoch time: 63.55 s 
2023-08-08 16:52:18.048926:  
2023-08-08 16:52:18.049019: Epoch 1694 
2023-08-08 16:52:18.049109: Current learning rate: 0.00018 
2023-08-08 16:53:21.661457: train_loss -0.4103 
2023-08-08 16:53:21.661614: val_loss -0.4073 
2023-08-08 16:53:21.661668: Pseudo dice [0.9061] 
2023-08-08 16:53:21.661719: Epoch time: 63.61 s 
2023-08-08 16:53:22.742046:  
2023-08-08 16:53:22.742144: Epoch 1695 
2023-08-08 16:53:22.742232: Current learning rate: 0.00018 
2023-08-08 16:54:26.189991: train_loss -0.3688 
2023-08-08 16:54:26.190142: val_loss -0.4303 
2023-08-08 16:54:26.190197: Pseudo dice [0.8792] 
2023-08-08 16:54:26.190247: Epoch time: 63.45 s 
2023-08-08 16:54:27.415808:  
2023-08-08 16:54:27.415914: Epoch 1696 
2023-08-08 16:54:27.415987: Current learning rate: 0.00018 
2023-08-08 16:55:31.085414: train_loss -0.3955 
2023-08-08 16:55:31.085565: val_loss -0.4982 
2023-08-08 16:55:31.085613: Pseudo dice [0.8952] 
2023-08-08 16:55:31.085677: Epoch time: 63.67 s 
2023-08-08 16:55:32.185586:  
2023-08-08 16:55:32.185692: Epoch 1697 
2023-08-08 16:55:32.185781: Current learning rate: 0.00018 
2023-08-08 16:56:35.899859: train_loss -0.4006 
2023-08-08 16:56:35.900012: val_loss -0.3746 
2023-08-08 16:56:35.900069: Pseudo dice [0.9138] 
2023-08-08 16:56:35.900120: Epoch time: 63.72 s 
2023-08-08 16:56:36.988753:  
2023-08-08 16:56:36.988864: Epoch 1698 
2023-08-08 16:56:36.988936: Current learning rate: 0.00018 
2023-08-08 16:57:40.634785: train_loss -0.4203 
2023-08-08 16:57:40.635234: val_loss -0.4258 
2023-08-08 16:57:40.635324: Pseudo dice [0.9284] 
2023-08-08 16:57:40.635376: Epoch time: 63.65 s 
2023-08-08 16:57:40.635423: Yayy! New best EMA pseudo Dice: 0.898 
2023-08-08 16:57:42.172598:  
2023-08-08 16:57:42.172817: Epoch 1699 
2023-08-08 16:57:42.172897: Current learning rate: 0.00018 
2023-08-08 16:58:45.773225: train_loss -0.4114 
2023-08-08 16:58:45.773368: val_loss -0.3857 
2023-08-08 16:58:45.773418: Pseudo dice [0.8967] 
2023-08-08 16:58:45.773482: Epoch time: 63.6 s 
2023-08-08 16:58:47.284871:  
2023-08-08 16:58:47.284968: Epoch 1700 
2023-08-08 16:58:47.285041: Current learning rate: 0.00018 
2023-08-08 16:59:50.652441: train_loss -0.3892 
2023-08-08 16:59:50.652584: val_loss -0.3683 
2023-08-08 16:59:50.652637: Pseudo dice [0.9535] 
2023-08-08 16:59:50.652686: Epoch time: 63.37 s 
2023-08-08 16:59:50.652737: Yayy! New best EMA pseudo Dice: 0.9035 
2023-08-08 16:59:52.272824:  
2023-08-08 16:59:52.272931: Epoch 1701 
2023-08-08 16:59:52.273021: Current learning rate: 0.00018 
2023-08-08 17:00:55.863397: train_loss -0.415 
2023-08-08 17:00:55.863550: val_loss -0.4289 
2023-08-08 17:00:55.863629: Pseudo dice [0.905] 
2023-08-08 17:00:55.863682: Epoch time: 63.59 s 
2023-08-08 17:00:55.863722: Yayy! New best EMA pseudo Dice: 0.9036 
2023-08-08 17:00:57.385006:  
2023-08-08 17:00:57.385200: Epoch 1702 
2023-08-08 17:00:57.385305: Current learning rate: 0.00018 
2023-08-08 17:02:00.943155: train_loss -0.3602 
2023-08-08 17:02:00.943303: val_loss -0.3897 
2023-08-08 17:02:00.943354: Pseudo dice [0.9153] 
2023-08-08 17:02:00.943404: Epoch time: 63.56 s 
2023-08-08 17:02:00.943444: Yayy! New best EMA pseudo Dice: 0.9048 
2023-08-08 17:02:02.419540:  
2023-08-08 17:02:02.419801: Epoch 1703 
2023-08-08 17:02:02.419933: Current learning rate: 0.00018 
2023-08-08 17:03:06.062868: train_loss -0.4313 
2023-08-08 17:03:06.063013: val_loss -0.4064 
2023-08-08 17:03:06.063062: Pseudo dice [0.8731] 
2023-08-08 17:03:06.063128: Epoch time: 63.64 s 
2023-08-08 17:03:07.208184:  
2023-08-08 17:03:07.208361: Epoch 1704 
2023-08-08 17:03:07.208435: Current learning rate: 0.00018 
2023-08-08 17:04:10.728371: train_loss -0.3744 
2023-08-08 17:04:10.728595: val_loss -0.4353 
2023-08-08 17:04:10.737061: Pseudo dice [0.8902] 
2023-08-08 17:04:10.737273: Epoch time: 63.52 s 
2023-08-08 17:04:11.828334:  
2023-08-08 17:04:11.828435: Epoch 1705 
2023-08-08 17:04:11.828508: Current learning rate: 0.00018 
2023-08-08 17:05:15.299378: train_loss -0.3582 
2023-08-08 17:05:15.299525: val_loss -0.4053 
2023-08-08 17:05:15.299601: Pseudo dice [0.8862] 
2023-08-08 17:05:15.299653: Epoch time: 63.47 s 
2023-08-08 17:05:16.523508:  
2023-08-08 17:05:16.523616: Epoch 1706 
2023-08-08 17:05:16.523711: Current learning rate: 0.00018 
2023-08-08 17:06:20.112115: train_loss -0.3996 
2023-08-08 17:06:20.112264: val_loss -0.3829 
2023-08-08 17:06:20.112318: Pseudo dice [0.8788] 
2023-08-08 17:06:20.112368: Epoch time: 63.59 s 
2023-08-08 17:06:21.220102:  
2023-08-08 17:06:21.220207: Epoch 1707 
2023-08-08 17:06:21.220283: Current learning rate: 0.00018 
2023-08-08 17:07:24.779204: train_loss -0.4039 
2023-08-08 17:07:24.779351: val_loss -0.423 
2023-08-08 17:07:24.779400: Pseudo dice [0.8917] 
2023-08-08 17:07:24.779466: Epoch time: 63.56 s 
2023-08-08 17:07:25.867622:  
2023-08-08 17:07:25.867722: Epoch 1708 
2023-08-08 17:07:25.867794: Current learning rate: 0.00018 
2023-08-08 17:08:29.610022: train_loss -0.392 
2023-08-08 17:08:29.610185: val_loss -0.4328 
2023-08-08 17:08:29.610241: Pseudo dice [0.89] 
2023-08-08 17:08:29.610294: Epoch time: 63.74 s 
2023-08-08 17:08:30.685441:  
2023-08-08 17:08:30.685532: Epoch 1709 
2023-08-08 17:08:30.685605: Current learning rate: 0.00018 
2023-08-08 17:09:34.410503: train_loss -0.4111 
2023-08-08 17:09:34.410721: val_loss -0.3684 
2023-08-08 17:09:34.410777: Pseudo dice [0.8277] 
2023-08-08 17:09:34.410829: Epoch time: 63.73 s 
2023-08-08 17:09:35.483066:  
2023-08-08 17:09:35.483160: Epoch 1710 
2023-08-08 17:09:35.483232: Current learning rate: 0.00018 
2023-08-08 17:10:39.116866: train_loss -0.4335 
2023-08-08 17:10:39.117013: val_loss -0.464 
2023-08-08 17:10:39.117062: Pseudo dice [0.9196] 
2023-08-08 17:10:39.117112: Epoch time: 63.63 s 
2023-08-08 17:10:40.219770:  
2023-08-08 17:10:40.219863: Epoch 1711 
2023-08-08 17:10:40.219952: Current learning rate: 0.00018 
2023-08-08 17:11:43.772880: train_loss -0.4078 
2023-08-08 17:11:43.773032: val_loss -0.4237 
2023-08-08 17:11:43.773081: Pseudo dice [0.8517] 
2023-08-08 17:11:43.773148: Epoch time: 63.55 s 
2023-08-08 17:11:45.024974:  
2023-08-08 17:11:45.025076: Epoch 1712 
2023-08-08 17:11:45.025148: Current learning rate: 0.00017 
2023-08-08 17:12:48.598221: train_loss -0.3774 
2023-08-08 17:12:48.598366: val_loss -0.4628 
2023-08-08 17:12:48.598436: Pseudo dice [0.8998] 
2023-08-08 17:12:48.598486: Epoch time: 63.57 s 
2023-08-08 17:12:49.691436:  
2023-08-08 17:12:49.691540: Epoch 1713 
2023-08-08 17:12:49.691638: Current learning rate: 0.00017 
2023-08-08 17:13:53.350898: train_loss -0.4532 
2023-08-08 17:13:53.351164: val_loss -0.3947 
2023-08-08 17:13:53.351221: Pseudo dice [0.902] 
2023-08-08 17:13:53.351272: Epoch time: 63.66 s 
2023-08-08 17:13:54.424002:  
2023-08-08 17:13:54.424102: Epoch 1714 
2023-08-08 17:13:54.424174: Current learning rate: 0.00017 
2023-08-08 17:14:58.334549: train_loss -0.3904 
2023-08-08 17:14:58.334709: val_loss -0.45 
2023-08-08 17:14:58.334759: Pseudo dice [0.9097] 
2023-08-08 17:14:58.334808: Epoch time: 63.91 s 
2023-08-08 17:14:59.406409:  
2023-08-08 17:14:59.406503: Epoch 1715 
2023-08-08 17:14:59.406590: Current learning rate: 0.00017 
2023-08-08 17:16:03.623911: train_loss -0.4317 
2023-08-08 17:16:03.624056: val_loss -0.4223 
2023-08-08 17:16:03.624105: Pseudo dice [0.8861] 
2023-08-08 17:16:03.624155: Epoch time: 64.22 s 
2023-08-08 17:16:04.709085:  
2023-08-08 17:16:04.709175: Epoch 1716 
2023-08-08 17:16:04.709264: Current learning rate: 0.00017 
2023-08-08 17:17:09.028074: train_loss -0.4163 
2023-08-08 17:17:09.028227: val_loss -0.4978 
2023-08-08 17:17:09.028279: Pseudo dice [0.908] 
2023-08-08 17:17:09.028329: Epoch time: 64.32 s 
2023-08-08 17:17:10.332783:  
2023-08-08 17:17:10.333007: Epoch 1717 
2023-08-08 17:17:10.333089: Current learning rate: 0.00017 
2023-08-08 17:18:14.428451: train_loss -0.4194 
2023-08-08 17:18:14.428602: val_loss -0.3829 
2023-08-08 17:18:14.428654: Pseudo dice [0.9117] 
2023-08-08 17:18:14.428703: Epoch time: 64.1 s 
2023-08-08 17:18:15.551859:  
2023-08-08 17:18:15.551963: Epoch 1718 
2023-08-08 17:18:15.552033: Current learning rate: 0.00017 
2023-08-08 17:19:19.707775: train_loss -0.4428 
2023-08-08 17:19:19.707931: val_loss -0.4024 
2023-08-08 17:19:19.707984: Pseudo dice [0.8704] 
2023-08-08 17:19:19.708033: Epoch time: 64.16 s 
2023-08-08 17:19:20.843357:  
2023-08-08 17:19:20.843456: Epoch 1719 
2023-08-08 17:19:20.843527: Current learning rate: 0.00017 
2023-08-08 17:20:25.013714: train_loss -0.3944 
2023-08-08 17:20:25.013873: val_loss -0.3348 
2023-08-08 17:20:25.013927: Pseudo dice [0.8769] 
2023-08-08 17:20:25.013977: Epoch time: 64.17 s 
2023-08-08 17:20:26.097495:  
2023-08-08 17:20:26.097897: Epoch 1720 
2023-08-08 17:20:26.098050: Current learning rate: 0.00017 
2023-08-08 17:21:30.216281: train_loss -0.4155 
2023-08-08 17:21:30.216435: val_loss -0.4094 
2023-08-08 17:21:30.216485: Pseudo dice [0.8917] 
2023-08-08 17:21:30.216536: Epoch time: 64.12 s 
2023-08-08 17:21:31.306354:  
2023-08-08 17:21:31.306452: Epoch 1721 
2023-08-08 17:21:31.306526: Current learning rate: 0.00017 
2023-08-08 17:22:35.258013: train_loss -0.3659 
2023-08-08 17:22:35.258160: val_loss -0.3929 
2023-08-08 17:22:35.258212: Pseudo dice [0.8679] 
2023-08-08 17:22:35.258262: Epoch time: 63.95 s 
2023-08-08 17:22:36.349297:  
2023-08-08 17:22:36.349393: Epoch 1722 
2023-08-08 17:22:36.349481: Current learning rate: 0.00017 
2023-08-08 17:23:40.464884: train_loss -0.4163 
2023-08-08 17:23:40.465044: val_loss -0.4105 
2023-08-08 17:23:40.465110: Pseudo dice [0.9076] 
2023-08-08 17:23:40.465159: Epoch time: 64.12 s 
2023-08-08 17:23:41.729013:  
2023-08-08 17:23:41.729115: Epoch 1723 
2023-08-08 17:23:41.729187: Current learning rate: 0.00017 
2023-08-08 17:24:45.861789: train_loss -0.3732 
2023-08-08 17:24:45.861938: val_loss -0.3689 
2023-08-08 17:24:45.861991: Pseudo dice [0.8783] 
2023-08-08 17:24:45.862041: Epoch time: 64.13 s 
2023-08-08 17:24:46.950285:  
2023-08-08 17:24:46.950384: Epoch 1724 
2023-08-08 17:24:46.950472: Current learning rate: 0.00017 
2023-08-08 17:25:50.953338: train_loss -0.4049 
2023-08-08 17:25:50.953506: val_loss -0.3679 
2023-08-08 17:25:50.953558: Pseudo dice [0.9233] 
2023-08-08 17:25:50.953607: Epoch time: 64.0 s 
2023-08-08 17:25:52.052166:  
2023-08-08 17:25:52.052266: Epoch 1725 
2023-08-08 17:25:52.052357: Current learning rate: 0.00017 
2023-08-08 17:26:56.253819: train_loss -0.4277 
2023-08-08 17:26:56.253968: val_loss -0.4022 
2023-08-08 17:26:56.254038: Pseudo dice [0.8912] 
2023-08-08 17:26:56.254097: Epoch time: 64.2 s 
2023-08-08 17:26:57.318459:  
2023-08-08 17:26:57.318554: Epoch 1726 
2023-08-08 17:26:57.318642: Current learning rate: 0.00017 
2023-08-08 17:28:01.437919: train_loss -0.4402 
2023-08-08 17:28:01.438065: val_loss -0.4037 
2023-08-08 17:28:01.438240: Pseudo dice [0.8773] 
2023-08-08 17:28:01.438294: Epoch time: 64.12 s 
2023-08-08 17:28:02.516409:  
2023-08-08 17:28:02.516503: Epoch 1727 
2023-08-08 17:28:02.516573: Current learning rate: 0.00017 
2023-08-08 17:29:06.750533: train_loss -0.4165 
2023-08-08 17:29:06.750676: val_loss -0.4108 
2023-08-08 17:29:06.750743: Pseudo dice [0.9109] 
2023-08-08 17:29:06.750794: Epoch time: 64.23 s 
2023-08-08 17:29:07.962773:  
2023-08-08 17:29:07.962878: Epoch 1728 
2023-08-08 17:29:07.962967: Current learning rate: 0.00017 
2023-08-08 17:30:12.098121: train_loss -0.3871 
2023-08-08 17:30:12.098265: val_loss -0.3886 
2023-08-08 17:30:12.098335: Pseudo dice [0.8978] 
2023-08-08 17:30:12.098385: Epoch time: 64.14 s 
2023-08-08 17:30:13.179101:  
2023-08-08 17:30:13.179201: Epoch 1729 
2023-08-08 17:30:13.179272: Current learning rate: 0.00017 
2023-08-08 17:31:17.482486: train_loss -0.3922 
2023-08-08 17:31:17.482635: val_loss -0.3918 
2023-08-08 17:31:17.482687: Pseudo dice [0.8872] 
2023-08-08 17:31:17.482738: Epoch time: 64.3 s 
2023-08-08 17:31:18.554779:  
2023-08-08 17:31:18.554875: Epoch 1730 
2023-08-08 17:31:18.554947: Current learning rate: 0.00016 
2023-08-08 17:32:22.913908: train_loss -0.4186 
2023-08-08 17:32:22.914056: val_loss -0.3607 
2023-08-08 17:32:22.914107: Pseudo dice [0.9465] 
2023-08-08 17:32:22.914174: Epoch time: 64.36 s 
2023-08-08 17:32:23.989086:  
2023-08-08 17:32:23.989188: Epoch 1731 
2023-08-08 17:32:23.989276: Current learning rate: 0.00016 
2023-08-08 17:33:28.196393: train_loss -0.3799 
2023-08-08 17:33:28.196541: val_loss -0.4065 
2023-08-08 17:33:28.196594: Pseudo dice [0.9103] 
2023-08-08 17:33:28.196644: Epoch time: 64.21 s 
2023-08-08 17:33:29.278105:  
2023-08-08 17:33:29.278201: Epoch 1732 
2023-08-08 17:33:29.278289: Current learning rate: 0.00016 
2023-08-08 17:34:33.573362: train_loss -0.3784 
2023-08-08 17:34:33.573508: val_loss -0.4288 
2023-08-08 17:34:33.573558: Pseudo dice [0.8509] 
2023-08-08 17:34:33.573608: Epoch time: 64.3 s 
2023-08-08 17:34:34.645682:  
2023-08-08 17:34:34.645776: Epoch 1733 
2023-08-08 17:34:34.645864: Current learning rate: 0.00016 
2023-08-08 17:35:38.747081: train_loss -0.4169 
2023-08-08 17:35:38.747225: val_loss -0.4749 
2023-08-08 17:35:38.747277: Pseudo dice [0.9102] 
2023-08-08 17:35:38.747345: Epoch time: 64.1 s 
2023-08-08 17:35:39.983353:  
2023-08-08 17:35:39.983452: Epoch 1734 
2023-08-08 17:35:39.983542: Current learning rate: 0.00016 
2023-08-08 17:36:44.227714: train_loss -0.4014 
2023-08-08 17:36:44.227861: val_loss -0.4465 
2023-08-08 17:36:44.227914: Pseudo dice [0.9111] 
2023-08-08 17:36:44.227965: Epoch time: 64.25 s 
2023-08-08 17:36:45.294188:  
2023-08-08 17:36:45.294290: Epoch 1735 
2023-08-08 17:36:45.294378: Current learning rate: 0.00016 
2023-08-08 17:37:49.417610: train_loss -0.3906 
2023-08-08 17:37:49.417765: val_loss -0.4128 
2023-08-08 17:37:49.417820: Pseudo dice [0.8864] 
2023-08-08 17:37:49.417869: Epoch time: 64.12 s 
2023-08-08 17:37:50.488966:  
2023-08-08 17:37:50.489068: Epoch 1736 
2023-08-08 17:37:50.489141: Current learning rate: 0.00016 
2023-08-08 17:38:54.557577: train_loss -0.4541 
2023-08-08 17:38:54.557726: val_loss -0.4958 
2023-08-08 17:38:54.557777: Pseudo dice [0.9228] 
2023-08-08 17:38:54.557842: Epoch time: 64.07 s 
2023-08-08 17:38:55.669251:  
2023-08-08 17:38:55.669346: Epoch 1737 
2023-08-08 17:38:55.669416: Current learning rate: 0.00016 
2023-08-08 17:39:59.660528: train_loss -0.3988 
2023-08-08 17:39:59.660676: val_loss -0.3644 
2023-08-08 17:39:59.660729: Pseudo dice [0.8513] 
2023-08-08 17:39:59.660779: Epoch time: 63.99 s 
2023-08-08 17:40:00.767343:  
2023-08-08 17:40:00.767439: Epoch 1738 
2023-08-08 17:40:00.767528: Current learning rate: 0.00016 
2023-08-08 17:41:04.952540: train_loss -0.4051 
2023-08-08 17:41:04.952695: val_loss -0.4069 
2023-08-08 17:41:04.952749: Pseudo dice [0.9069] 
2023-08-08 17:41:04.952800: Epoch time: 64.19 s 
2023-08-08 17:41:06.240283:  
2023-08-08 17:41:06.240393: Epoch 1739 
2023-08-08 17:41:06.240469: Current learning rate: 0.00016 
2023-08-08 17:42:10.534378: train_loss -0.4049 
2023-08-08 17:42:10.534526: val_loss -0.4725 
2023-08-08 17:42:10.534580: Pseudo dice [0.9114] 
2023-08-08 17:42:10.534630: Epoch time: 64.29 s 
2023-08-08 17:42:11.638725:  
2023-08-08 17:42:11.638825: Epoch 1740 
2023-08-08 17:42:11.638900: Current learning rate: 0.00016 
2023-08-08 17:43:15.696710: train_loss -0.3905 
2023-08-08 17:43:15.696867: val_loss -0.3835 
2023-08-08 17:43:15.696934: Pseudo dice [0.8839] 
2023-08-08 17:43:15.696983: Epoch time: 64.06 s 
2023-08-08 17:43:16.873427:  
2023-08-08 17:43:16.873519: Epoch 1741 
2023-08-08 17:43:16.873608: Current learning rate: 0.00016 
2023-08-08 17:44:21.133120: train_loss -0.4084 
2023-08-08 17:44:21.133271: val_loss -0.4135 
2023-08-08 17:44:21.133341: Pseudo dice [0.8964] 
2023-08-08 17:44:21.133393: Epoch time: 64.26 s 
2023-08-08 17:44:22.205890:  
2023-08-08 17:44:22.205988: Epoch 1742 
2023-08-08 17:44:22.206060: Current learning rate: 0.00016 
2023-08-08 17:45:26.377390: train_loss -0.3979 
2023-08-08 17:45:26.377552: val_loss -0.5068 
2023-08-08 17:45:26.377607: Pseudo dice [0.9189] 
2023-08-08 17:45:26.377657: Epoch time: 64.17 s 
2023-08-08 17:45:27.477099:  
2023-08-08 17:45:27.477194: Epoch 1743 
2023-08-08 17:45:27.477265: Current learning rate: 0.00016 
2023-08-08 17:46:31.641238: train_loss -0.3924 
2023-08-08 17:46:31.641386: val_loss -0.3995 
2023-08-08 17:46:31.641439: Pseudo dice [0.9005] 
2023-08-08 17:46:31.641505: Epoch time: 64.16 s 
2023-08-08 17:46:32.775056:  
2023-08-08 17:46:32.775264: Epoch 1744 
2023-08-08 17:46:32.775358: Current learning rate: 0.00016 
2023-08-08 17:47:37.056360: train_loss -0.397 
2023-08-08 17:47:37.056505: val_loss -0.4054 
2023-08-08 17:47:37.056559: Pseudo dice [0.8996] 
2023-08-08 17:47:37.056609: Epoch time: 64.28 s 
2023-08-08 17:47:38.159321:  
2023-08-08 17:47:38.159421: Epoch 1745 
2023-08-08 17:47:38.159510: Current learning rate: 0.00016 
2023-08-08 17:48:42.259487: train_loss -0.4328 
2023-08-08 17:48:42.259660: val_loss -0.4072 
2023-08-08 17:48:42.259712: Pseudo dice [0.9247] 
2023-08-08 17:48:42.259761: Epoch time: 64.1 s 
2023-08-08 17:48:43.352651:  
2023-08-08 17:48:43.352750: Epoch 1746 
2023-08-08 17:48:43.352826: Current learning rate: 0.00016 
2023-08-08 17:49:47.589561: train_loss -0.445 
2023-08-08 17:49:47.589711: val_loss -0.4164 
2023-08-08 17:49:47.589763: Pseudo dice [0.8971] 
2023-08-08 17:49:47.589814: Epoch time: 64.24 s 
2023-08-08 17:49:48.660905:  
2023-08-08 17:49:48.661018: Epoch 1747 
2023-08-08 17:49:48.661090: Current learning rate: 0.00016 
2023-08-08 17:50:52.737137: train_loss -0.3932 
2023-08-08 17:50:52.737291: val_loss -0.4323 
2023-08-08 17:50:52.737360: Pseudo dice [0.9177] 
2023-08-08 17:50:52.737411: Epoch time: 64.08 s 
2023-08-08 17:50:53.845389:  
2023-08-08 17:50:53.845492: Epoch 1748 
2023-08-08 17:50:53.845582: Current learning rate: 0.00016 
2023-08-08 17:51:58.045696: train_loss -0.4346 
2023-08-08 17:51:58.045848: val_loss -0.4468 
2023-08-08 17:51:58.045899: Pseudo dice [0.795] 
2023-08-08 17:51:58.045949: Epoch time: 64.2 s 
2023-08-08 17:51:59.126113:  
2023-08-08 17:51:59.126212: Epoch 1749 
2023-08-08 17:51:59.126284: Current learning rate: 0.00015 
2023-08-08 17:53:03.464430: train_loss -0.4287 
2023-08-08 17:53:03.464584: val_loss -0.3606 
2023-08-08 17:53:03.464635: Pseudo dice [0.9181] 
2023-08-08 17:53:03.464685: Epoch time: 64.34 s 
2023-08-08 17:53:05.140424:  
2023-08-08 17:53:05.140557: Epoch 1750 
2023-08-08 17:53:05.140631: Current learning rate: 0.00015 
2023-08-08 17:54:09.296507: train_loss -0.3752 
2023-08-08 17:54:09.296656: val_loss -0.4509 
2023-08-08 17:54:09.296707: Pseudo dice [0.8948] 
2023-08-08 17:54:09.296759: Epoch time: 64.16 s 
2023-08-08 17:54:10.402275:  
2023-08-08 17:54:10.402369: Epoch 1751 
2023-08-08 17:54:10.402459: Current learning rate: 0.00015 
2023-08-08 17:55:14.648989: train_loss -0.3888 
2023-08-08 17:55:14.649131: val_loss -0.4144 
2023-08-08 17:55:14.649183: Pseudo dice [0.8767] 
2023-08-08 17:55:14.649249: Epoch time: 64.25 s 
2023-08-08 17:55:15.757763:  
2023-08-08 17:55:15.757859: Epoch 1752 
2023-08-08 17:55:15.757932: Current learning rate: 0.00015 
2023-08-08 17:56:19.988425: train_loss -0.3817 
2023-08-08 17:56:19.988640: val_loss -0.4053 
2023-08-08 17:56:19.988731: Pseudo dice [0.9396] 
2023-08-08 17:56:19.988821: Epoch time: 64.23 s 
2023-08-08 17:56:21.070681:  
2023-08-08 17:56:21.070780: Epoch 1753 
2023-08-08 17:56:21.070851: Current learning rate: 0.00015 
2023-08-08 17:57:25.260255: train_loss -0.3906 
2023-08-08 17:57:25.260412: val_loss -0.3173 
2023-08-08 17:57:25.268749: Pseudo dice [0.8516] 
2023-08-08 17:57:25.268862: Epoch time: 64.19 s 
2023-08-08 17:57:26.356031:  
2023-08-08 17:57:26.356133: Epoch 1754 
2023-08-08 17:57:26.356207: Current learning rate: 0.00015 
2023-08-08 17:58:30.641133: train_loss -0.3762 
2023-08-08 17:58:30.641299: val_loss -0.443 
2023-08-08 17:58:30.641393: Pseudo dice [0.9322] 
2023-08-08 17:58:30.641443: Epoch time: 64.29 s 
2023-08-08 17:58:31.716942:  
2023-08-08 17:58:31.717046: Epoch 1755 
2023-08-08 17:58:31.717119: Current learning rate: 0.00015 
2023-08-08 17:59:35.896708: train_loss -0.392 
2023-08-08 17:59:35.896863: val_loss -0.3759 
2023-08-08 17:59:35.896914: Pseudo dice [0.8859] 
2023-08-08 17:59:35.896981: Epoch time: 64.18 s 
2023-08-08 17:59:36.966495:  
2023-08-08 17:59:36.966594: Epoch 1756 
2023-08-08 17:59:36.966666: Current learning rate: 0.00015 
2023-08-08 18:00:41.170583: train_loss -0.4109 
2023-08-08 18:00:41.170730: val_loss -0.4245 
2023-08-08 18:00:41.170779: Pseudo dice [0.8888] 
2023-08-08 18:00:41.170845: Epoch time: 64.2 s 
2023-08-08 18:00:42.320923:  
2023-08-08 18:00:42.321018: Epoch 1757 
2023-08-08 18:00:42.321090: Current learning rate: 0.00015 
2023-08-08 18:01:46.656179: train_loss -0.4221 
2023-08-08 18:01:46.656328: val_loss -0.4393 
2023-08-08 18:01:46.656381: Pseudo dice [0.9609] 
2023-08-08 18:01:46.656431: Epoch time: 64.34 s 
2023-08-08 18:01:47.731241:  
2023-08-08 18:01:47.731341: Epoch 1758 
2023-08-08 18:01:47.731412: Current learning rate: 0.00015 
2023-08-08 18:02:52.103710: train_loss -0.3939 
2023-08-08 18:02:52.103853: val_loss -0.404 
2023-08-08 18:02:52.103904: Pseudo dice [0.8831] 
2023-08-08 18:02:52.103952: Epoch time: 64.37 s 
2023-08-08 18:02:53.173686:  
2023-08-08 18:02:53.173779: Epoch 1759 
2023-08-08 18:02:53.173868: Current learning rate: 0.00015 
2023-08-08 18:03:57.471876: train_loss -0.4221 
2023-08-08 18:03:57.472016: val_loss -0.4032 
2023-08-08 18:03:57.472067: Pseudo dice [0.9299] 
2023-08-08 18:03:57.472117: Epoch time: 64.3 s 
2023-08-08 18:03:58.733178:  
2023-08-08 18:03:58.733276: Epoch 1760 
2023-08-08 18:03:58.733348: Current learning rate: 0.00015 
2023-08-08 18:05:02.964907: train_loss -0.4151 
2023-08-08 18:05:02.965052: val_loss -0.3753 
2023-08-08 18:05:02.965120: Pseudo dice [0.8501] 
2023-08-08 18:05:02.965170: Epoch time: 64.23 s 
2023-08-08 18:05:04.064562:  
2023-08-08 18:05:04.064662: Epoch 1761 
2023-08-08 18:05:04.064751: Current learning rate: 0.00015 
2023-08-08 18:06:08.323837: train_loss -0.3878 
2023-08-08 18:06:08.323990: val_loss -0.4014 
2023-08-08 18:06:08.324040: Pseudo dice [0.9189] 
2023-08-08 18:06:08.324091: Epoch time: 64.26 s 
2023-08-08 18:06:09.392994:  
2023-08-08 18:06:09.393090: Epoch 1762 
2023-08-08 18:06:09.393163: Current learning rate: 0.00015 
2023-08-08 18:07:13.564647: train_loss -0.4068 
2023-08-08 18:07:13.564798: val_loss -0.4179 
2023-08-08 18:07:13.564849: Pseudo dice [0.9235] 
2023-08-08 18:07:13.564900: Epoch time: 64.17 s 
2023-08-08 18:07:14.650264:  
2023-08-08 18:07:14.650369: Epoch 1763 
2023-08-08 18:07:14.650455: Current learning rate: 0.00015 
2023-08-08 18:08:18.869511: train_loss -0.4708 
2023-08-08 18:08:18.869665: val_loss -0.3382 
2023-08-08 18:08:18.869732: Pseudo dice [0.8879] 
2023-08-08 18:08:18.869790: Epoch time: 64.22 s 
2023-08-08 18:08:19.941025:  
2023-08-08 18:08:19.941118: Epoch 1764 
2023-08-08 18:08:19.941205: Current learning rate: 0.00015 
2023-08-08 18:09:24.144592: train_loss -0.3966 
2023-08-08 18:09:24.144741: val_loss -0.4454 
2023-08-08 18:09:24.144796: Pseudo dice [0.898] 
2023-08-08 18:09:24.144847: Epoch time: 64.2 s 
2023-08-08 18:09:25.376720:  
2023-08-08 18:09:25.376834: Epoch 1765 
2023-08-08 18:09:25.376907: Current learning rate: 0.00015 
2023-08-08 18:10:29.569327: train_loss -0.4115 
2023-08-08 18:10:29.569480: val_loss -0.4281 
2023-08-08 18:10:29.569532: Pseudo dice [0.9011] 
2023-08-08 18:10:29.569597: Epoch time: 64.19 s 
2023-08-08 18:10:30.679060:  
2023-08-08 18:10:30.679152: Epoch 1766 
2023-08-08 18:10:30.679225: Current learning rate: 0.00014 
2023-08-08 18:11:35.031666: train_loss -0.3798 
2023-08-08 18:11:35.031830: val_loss -0.3319 
2023-08-08 18:11:35.031882: Pseudo dice [0.8937] 
2023-08-08 18:11:35.031932: Epoch time: 64.35 s 
2023-08-08 18:11:36.135781:  
2023-08-08 18:11:36.136072: Epoch 1767 
2023-08-08 18:11:36.136198: Current learning rate: 0.00014 
2023-08-08 18:12:40.269288: train_loss -0.4118 
2023-08-08 18:12:40.269433: val_loss -0.3604 
2023-08-08 18:12:40.269483: Pseudo dice [0.8638] 
2023-08-08 18:12:40.269532: Epoch time: 64.13 s 
2023-08-08 18:12:41.374462:  
2023-08-08 18:12:41.374738: Epoch 1768 
2023-08-08 18:12:41.374935: Current learning rate: 0.00014 
2023-08-08 18:13:45.453708: train_loss -0.4166 
2023-08-08 18:13:45.453856: val_loss -0.4241 
2023-08-08 18:13:45.453906: Pseudo dice [0.8713] 
2023-08-08 18:13:45.453955: Epoch time: 64.08 s 
2023-08-08 18:13:46.556194:  
2023-08-08 18:13:46.556292: Epoch 1769 
2023-08-08 18:13:46.556365: Current learning rate: 0.00014 
2023-08-08 18:14:50.750736: train_loss -0.4444 
2023-08-08 18:14:50.750886: val_loss -0.4561 
2023-08-08 18:14:50.750936: Pseudo dice [0.8943] 
2023-08-08 18:14:50.751002: Epoch time: 64.2 s 
2023-08-08 18:14:51.989347:  
2023-08-08 18:14:51.989447: Epoch 1770 
2023-08-08 18:14:51.989517: Current learning rate: 0.00014 
2023-08-08 18:15:56.161936: train_loss -0.398 
2023-08-08 18:15:56.162111: val_loss -0.3962 
2023-08-08 18:15:56.162163: Pseudo dice [0.906] 
2023-08-08 18:15:56.162212: Epoch time: 64.17 s 
2023-08-08 18:15:57.263009:  
2023-08-08 18:15:57.263107: Epoch 1771 
2023-08-08 18:15:57.263194: Current learning rate: 0.00014 
2023-08-08 18:17:01.456608: train_loss -0.4033 
2023-08-08 18:17:01.456755: val_loss -0.4865 
2023-08-08 18:17:01.456809: Pseudo dice [0.8462] 
2023-08-08 18:17:01.456858: Epoch time: 64.19 s 
2023-08-08 18:17:02.560416:  
2023-08-08 18:17:02.560521: Epoch 1772 
2023-08-08 18:17:02.560594: Current learning rate: 0.00014 
2023-08-08 18:18:06.729138: train_loss -0.3976 
2023-08-08 18:18:06.729312: val_loss -0.3997 
2023-08-08 18:18:06.729366: Pseudo dice [0.9348] 
2023-08-08 18:18:06.729417: Epoch time: 64.17 s 
2023-08-08 18:18:07.817045:  
2023-08-08 18:18:07.817146: Epoch 1773 
2023-08-08 18:18:07.817219: Current learning rate: 0.00014 
2023-08-08 18:19:11.910760: train_loss -0.434 
2023-08-08 18:19:11.911016: val_loss -0.463 
2023-08-08 18:19:11.911073: Pseudo dice [0.9259] 
2023-08-08 18:19:11.911124: Epoch time: 64.09 s 
2023-08-08 18:19:13.025010:  
2023-08-08 18:19:13.025104: Epoch 1774 
2023-08-08 18:19:13.025174: Current learning rate: 0.00014 
2023-08-08 18:20:17.342414: train_loss -0.4082 
2023-08-08 18:20:17.342559: val_loss -0.4415 
2023-08-08 18:20:17.342608: Pseudo dice [0.8703] 
2023-08-08 18:20:17.342673: Epoch time: 64.32 s 
2023-08-08 18:20:18.417703:  
2023-08-08 18:20:18.417792: Epoch 1775 
2023-08-08 18:20:18.417880: Current learning rate: 0.00014 
2023-08-08 18:21:22.615014: train_loss -0.4297 
2023-08-08 18:21:22.615164: val_loss -0.407 
2023-08-08 18:21:22.615217: Pseudo dice [0.8869] 
2023-08-08 18:21:22.615268: Epoch time: 64.2 s 
2023-08-08 18:21:23.870146:  
2023-08-08 18:21:23.870242: Epoch 1776 
2023-08-08 18:21:23.870335: Current learning rate: 0.00014 
2023-08-08 18:22:28.179467: train_loss -0.4245 
2023-08-08 18:22:28.179656: val_loss -0.3622 
2023-08-08 18:22:28.179713: Pseudo dice [0.8645] 
2023-08-08 18:22:28.179763: Epoch time: 64.31 s 
2023-08-08 18:22:29.257654:  
2023-08-08 18:22:29.257764: Epoch 1777 
2023-08-08 18:22:29.257851: Current learning rate: 0.00014 
2023-08-08 18:23:33.425327: train_loss -0.4156 
2023-08-08 18:23:33.425480: val_loss -0.4255 
2023-08-08 18:23:33.425548: Pseudo dice [0.8734] 
2023-08-08 18:23:33.425597: Epoch time: 64.17 s 
2023-08-08 18:23:34.490279:  
2023-08-08 18:23:34.490383: Epoch 1778 
2023-08-08 18:23:34.490455: Current learning rate: 0.00014 
2023-08-08 18:24:38.607022: train_loss -0.3938 
2023-08-08 18:24:38.607225: val_loss -0.3925 
2023-08-08 18:24:38.607326: Pseudo dice [0.8928] 
2023-08-08 18:24:38.607387: Epoch time: 64.12 s 
2023-08-08 18:24:39.709932:  
2023-08-08 18:24:39.710034: Epoch 1779 
2023-08-08 18:24:39.710122: Current learning rate: 0.00014 
2023-08-08 18:25:44.054044: train_loss -0.4023 
2023-08-08 18:25:44.054192: val_loss -0.3762 
2023-08-08 18:25:44.054245: Pseudo dice [0.8729] 
2023-08-08 18:25:44.054310: Epoch time: 64.34 s 
2023-08-08 18:25:45.143243:  
2023-08-08 18:25:45.143338: Epoch 1780 
2023-08-08 18:25:45.143409: Current learning rate: 0.00014 
2023-08-08 18:26:49.389851: train_loss -0.3911 
2023-08-08 18:26:49.389996: val_loss -0.4131 
2023-08-08 18:26:49.390046: Pseudo dice [0.9617] 
2023-08-08 18:26:49.390113: Epoch time: 64.25 s 
2023-08-08 18:26:50.666739:  
2023-08-08 18:26:50.666843: Epoch 1781 
2023-08-08 18:26:50.666931: Current learning rate: 0.00014 
2023-08-08 18:27:54.673261: train_loss -0.4273 
2023-08-08 18:27:54.673409: val_loss -0.4441 
2023-08-08 18:27:54.673458: Pseudo dice [0.8636] 
2023-08-08 18:27:54.673524: Epoch time: 64.01 s 
2023-08-08 18:27:55.761173:  
2023-08-08 18:27:55.761275: Epoch 1782 
2023-08-08 18:27:55.761363: Current learning rate: 0.00014 
2023-08-08 18:28:59.981928: train_loss -0.3897 
2023-08-08 18:28:59.982080: val_loss -0.3719 
2023-08-08 18:28:59.982147: Pseudo dice [0.8639] 
2023-08-08 18:28:59.982198: Epoch time: 64.22 s 
2023-08-08 18:29:01.060229:  
2023-08-08 18:29:01.060331: Epoch 1783 
2023-08-08 18:29:01.060405: Current learning rate: 0.00014 
2023-08-08 18:30:05.313317: train_loss -0.3929 
2023-08-08 18:30:05.313481: val_loss -0.4903 
2023-08-08 18:30:05.313537: Pseudo dice [0.879] 
2023-08-08 18:30:05.313589: Epoch time: 64.25 s 
2023-08-08 18:30:06.391043:  
2023-08-08 18:30:06.391137: Epoch 1784 
2023-08-08 18:30:06.391227: Current learning rate: 0.00013 
2023-08-08 18:31:10.643081: train_loss -0.4447 
2023-08-08 18:31:10.643243: val_loss -0.3983 
2023-08-08 18:31:10.643294: Pseudo dice [0.8707] 
2023-08-08 18:31:10.643344: Epoch time: 64.25 s 
2023-08-08 18:31:11.718189:  
2023-08-08 18:31:11.718281: Epoch 1785 
2023-08-08 18:31:11.718352: Current learning rate: 0.00013 
2023-08-08 18:32:15.979750: train_loss -0.423 
2023-08-08 18:32:15.979903: val_loss -0.529 
2023-08-08 18:32:15.979953: Pseudo dice [0.908] 
2023-08-08 18:32:15.980003: Epoch time: 64.26 s 
2023-08-08 18:32:17.062083:  
2023-08-08 18:32:17.062193: Epoch 1786 
2023-08-08 18:32:17.062267: Current learning rate: 0.00013 
2023-08-08 18:33:21.371480: train_loss -0.4349 
2023-08-08 18:33:21.371647: val_loss -0.4283 
2023-08-08 18:33:21.371702: Pseudo dice [0.8569] 
2023-08-08 18:33:21.371753: Epoch time: 64.31 s 
2023-08-08 18:33:22.653057:  
2023-08-08 18:33:22.653159: Epoch 1787 
2023-08-08 18:33:22.653250: Current learning rate: 0.00013 
2023-08-08 18:34:27.056794: train_loss -0.3673 
2023-08-08 18:34:27.056969: val_loss -0.3455 
2023-08-08 18:34:27.057022: Pseudo dice [0.9143] 
2023-08-08 18:34:27.057093: Epoch time: 64.4 s 
2023-08-08 18:34:28.156496:  
2023-08-08 18:34:28.156587: Epoch 1788 
2023-08-08 18:34:28.156659: Current learning rate: 0.00013 
2023-08-08 18:35:32.221616: train_loss -0.4009 
2023-08-08 18:35:32.221768: val_loss -0.4228 
2023-08-08 18:35:32.221820: Pseudo dice [0.8812] 
2023-08-08 18:35:32.221871: Epoch time: 64.07 s 
2023-08-08 18:35:33.316615:  
2023-08-08 18:35:33.316710: Epoch 1789 
2023-08-08 18:35:33.316788: Current learning rate: 0.00013 
2023-08-08 18:36:37.469744: train_loss -0.4015 
2023-08-08 18:36:37.469914: val_loss -0.4132 
2023-08-08 18:36:37.469978: Pseudo dice [0.9355] 
2023-08-08 18:36:37.470038: Epoch time: 64.15 s 
2023-08-08 18:36:38.544863:  
2023-08-08 18:36:38.544957: Epoch 1790 
2023-08-08 18:36:38.545031: Current learning rate: 0.00013 
2023-08-08 18:37:42.678263: train_loss -0.364 
2023-08-08 18:37:42.678446: val_loss -0.3353 
2023-08-08 18:37:42.678499: Pseudo dice [0.8456] 
2023-08-08 18:37:42.678549: Epoch time: 64.13 s 
2023-08-08 18:37:43.765380:  
2023-08-08 18:37:43.765475: Epoch 1791 
2023-08-08 18:37:43.765561: Current learning rate: 0.00013 
2023-08-08 18:38:48.004924: train_loss -0.4154 
2023-08-08 18:38:48.005065: val_loss -0.4166 
2023-08-08 18:38:48.005114: Pseudo dice [0.8951] 
2023-08-08 18:38:48.005180: Epoch time: 64.24 s 
2023-08-08 18:38:49.235249:  
2023-08-08 18:38:49.235349: Epoch 1792 
2023-08-08 18:38:49.235435: Current learning rate: 0.00013 
2023-08-08 18:39:53.415353: train_loss -0.3754 
2023-08-08 18:39:53.415503: val_loss -0.3887 
2023-08-08 18:39:53.415579: Pseudo dice [0.8278] 
2023-08-08 18:39:53.415631: Epoch time: 64.18 s 
2023-08-08 18:39:54.485824:  
2023-08-08 18:39:54.485930: Epoch 1793 
2023-08-08 18:39:54.486019: Current learning rate: 0.00013 
2023-08-08 18:40:58.648696: train_loss -0.3974 
2023-08-08 18:40:58.648839: val_loss -0.3195 
2023-08-08 18:40:58.648886: Pseudo dice [0.8771] 
2023-08-08 18:40:58.648951: Epoch time: 64.16 s 
2023-08-08 18:40:59.748018:  
2023-08-08 18:40:59.748116: Epoch 1794 
2023-08-08 18:40:59.748206: Current learning rate: 0.00013 
2023-08-08 18:42:03.963489: train_loss -0.4042 
2023-08-08 18:42:03.963662: val_loss -0.3685 
2023-08-08 18:42:03.963714: Pseudo dice [0.8771] 
2023-08-08 18:42:03.963765: Epoch time: 64.22 s 
2023-08-08 18:42:05.039563:  
2023-08-08 18:42:05.039657: Epoch 1795 
2023-08-08 18:42:05.039730: Current learning rate: 0.00013 
2023-08-08 18:43:09.280187: train_loss -0.3985 
2023-08-08 18:43:09.280338: val_loss -0.3878 
2023-08-08 18:43:09.280393: Pseudo dice [0.8802] 
2023-08-08 18:43:09.280444: Epoch time: 64.24 s 
2023-08-08 18:43:10.378585:  
2023-08-08 18:43:10.378681: Epoch 1796 
2023-08-08 18:43:10.378772: Current learning rate: 0.00013 
2023-08-08 18:44:14.602199: train_loss -0.413 
2023-08-08 18:44:14.602345: val_loss -0.4517 
2023-08-08 18:44:14.602396: Pseudo dice [0.902] 
2023-08-08 18:44:14.602464: Epoch time: 64.22 s 
2023-08-08 18:44:15.704721:  
2023-08-08 18:44:15.704815: Epoch 1797 
2023-08-08 18:44:15.704907: Current learning rate: 0.00013 
2023-08-08 18:45:20.162522: train_loss -0.3876 
2023-08-08 18:45:20.162675: val_loss -0.3571 
2023-08-08 18:45:20.162728: Pseudo dice [0.8566] 
2023-08-08 18:45:20.162777: Epoch time: 64.46 s 
2023-08-08 18:45:21.249258:  
2023-08-08 18:45:21.249361: Epoch 1798 
2023-08-08 18:45:21.249435: Current learning rate: 0.00013 
2023-08-08 18:46:25.469604: train_loss -0.3941 
2023-08-08 18:46:25.469764: val_loss -0.441 
2023-08-08 18:46:25.469835: Pseudo dice [0.9067] 
2023-08-08 18:46:25.469885: Epoch time: 64.22 s 
2023-08-08 18:46:26.595272:  
2023-08-08 18:46:26.595375: Epoch 1799 
2023-08-08 18:46:26.595464: Current learning rate: 0.00013 
2023-08-08 18:47:30.600395: train_loss -0.4065 
2023-08-08 18:47:30.600541: val_loss -0.4371 
2023-08-08 18:47:30.600593: Pseudo dice [0.8676] 
2023-08-08 18:47:30.600642: Epoch time: 64.01 s 
2023-08-08 18:47:32.123047:  
2023-08-08 18:47:32.123228: Epoch 1800 
2023-08-08 18:47:32.123322: Current learning rate: 0.00013 
2023-08-08 18:48:36.254796: train_loss -0.3766 
2023-08-08 18:48:36.254949: val_loss -0.4117 
2023-08-08 18:48:36.255017: Pseudo dice [0.8692] 
2023-08-08 18:48:36.255067: Epoch time: 64.13 s 
2023-08-08 18:48:37.343924:  
2023-08-08 18:48:37.344019: Epoch 1801 
2023-08-08 18:48:37.344092: Current learning rate: 0.00013 
2023-08-08 18:49:41.526927: train_loss -0.4001 
2023-08-08 18:49:41.527087: val_loss -0.4953 
2023-08-08 18:49:41.527142: Pseudo dice [0.9099] 
2023-08-08 18:49:41.527194: Epoch time: 64.18 s 
2023-08-08 18:49:42.620629:  
2023-08-08 18:49:42.620726: Epoch 1802 
2023-08-08 18:49:42.620799: Current learning rate: 0.00012 
2023-08-08 18:50:47.079919: train_loss -0.3991 
2023-08-08 18:50:47.080068: val_loss -0.4105 
2023-08-08 18:50:47.080140: Pseudo dice [0.9354] 
2023-08-08 18:50:47.080193: Epoch time: 64.46 s 
2023-08-08 18:50:48.193967:  
2023-08-08 18:50:48.194067: Epoch 1803 
2023-08-08 18:50:48.194139: Current learning rate: 0.00012 
2023-08-08 18:51:52.411973: train_loss -0.3733 
2023-08-08 18:51:52.412125: val_loss -0.4452 
2023-08-08 18:51:52.412179: Pseudo dice [0.9412] 
2023-08-08 18:51:52.412229: Epoch time: 64.22 s 
2023-08-08 18:51:53.487163:  
2023-08-08 18:51:53.487270: Epoch 1804 
2023-08-08 18:51:53.487343: Current learning rate: 0.00012 
2023-08-08 18:52:57.784397: train_loss -0.3972 
2023-08-08 18:52:57.784548: val_loss -0.4671 
2023-08-08 18:52:57.784598: Pseudo dice [0.9035] 
2023-08-08 18:52:57.784648: Epoch time: 64.3 s 
2023-08-08 18:52:58.861360:  
2023-08-08 18:52:58.861467: Epoch 1805 
2023-08-08 18:52:58.861540: Current learning rate: 0.00012 
2023-08-08 18:54:03.178664: train_loss -0.3891 
2023-08-08 18:54:03.178817: val_loss -0.4249 
2023-08-08 18:54:03.178867: Pseudo dice [0.9372] 
2023-08-08 18:54:03.178917: Epoch time: 64.32 s 
2023-08-08 18:54:04.349036:  
2023-08-08 18:54:04.349296: Epoch 1806 
2023-08-08 18:54:04.349451: Current learning rate: 0.00012 
2023-08-08 18:55:08.508855: train_loss -0.3974 
2023-08-08 18:55:08.509009: val_loss -0.3971 
2023-08-08 18:55:08.509060: Pseudo dice [0.8977] 
2023-08-08 18:55:08.509111: Epoch time: 64.16 s 
2023-08-08 18:55:09.621768:  
2023-08-08 18:55:09.621860: Epoch 1807 
2023-08-08 18:55:09.621949: Current learning rate: 0.00012 
2023-08-08 18:56:13.831531: train_loss -0.4291 
2023-08-08 18:56:13.831691: val_loss -0.3723 
2023-08-08 18:56:13.831743: Pseudo dice [0.8481] 
2023-08-08 18:56:13.831793: Epoch time: 64.21 s 
2023-08-08 18:56:15.082649:  
2023-08-08 18:56:15.082748: Epoch 1808 
2023-08-08 18:56:15.082839: Current learning rate: 0.00012 
2023-08-08 18:57:19.207656: train_loss -0.3955 
2023-08-08 18:57:19.207805: val_loss -0.4278 
2023-08-08 18:57:19.207858: Pseudo dice [0.9533] 
2023-08-08 18:57:19.207910: Epoch time: 64.13 s 
2023-08-08 18:57:20.299003:  
2023-08-08 18:57:20.299103: Epoch 1809 
2023-08-08 18:57:20.299179: Current learning rate: 0.00012 
2023-08-08 18:58:24.523705: train_loss -0.42 
2023-08-08 18:58:24.523895: val_loss -0.3493 
2023-08-08 18:58:24.523948: Pseudo dice [0.8966] 
2023-08-08 18:58:24.523999: Epoch time: 64.23 s 
2023-08-08 18:58:25.621216:  
2023-08-08 18:58:25.621315: Epoch 1810 
2023-08-08 18:58:25.621390: Current learning rate: 0.00012 
2023-08-08 18:59:29.636762: train_loss -0.4033 
2023-08-08 18:59:29.636911: val_loss -0.3747 
2023-08-08 18:59:29.636964: Pseudo dice [0.9126] 
2023-08-08 18:59:29.637013: Epoch time: 64.02 s 
2023-08-08 18:59:30.709976:  
2023-08-08 18:59:30.710067: Epoch 1811 
2023-08-08 18:59:30.710137: Current learning rate: 0.00012 
2023-08-08 19:00:34.870251: train_loss -0.3822 
2023-08-08 19:00:34.870413: val_loss -0.348 
2023-08-08 19:00:34.870482: Pseudo dice [0.8969] 
2023-08-08 19:00:34.870532: Epoch time: 64.16 s 
2023-08-08 19:00:35.989783:  
2023-08-08 19:00:35.989874: Epoch 1812 
2023-08-08 19:00:35.989962: Current learning rate: 0.00012 
2023-08-08 19:01:40.226765: train_loss -0.4315 
2023-08-08 19:01:40.226907: val_loss -0.4445 
2023-08-08 19:01:40.226971: Pseudo dice [0.8793] 
2023-08-08 19:01:40.227020: Epoch time: 64.24 s 
2023-08-08 19:01:41.460105:  
2023-08-08 19:01:41.460209: Epoch 1813 
2023-08-08 19:01:41.460299: Current learning rate: 0.00012 
2023-08-08 19:02:45.675098: train_loss -0.4051 
2023-08-08 19:02:45.675254: val_loss -0.4443 
2023-08-08 19:02:45.675308: Pseudo dice [0.8823] 
2023-08-08 19:02:45.675376: Epoch time: 64.22 s 
2023-08-08 19:02:46.750031:  
2023-08-08 19:02:46.750131: Epoch 1814 
2023-08-08 19:02:46.750221: Current learning rate: 0.00012 
2023-08-08 19:03:51.100317: train_loss -0.4021 
2023-08-08 19:03:51.100470: val_loss -0.3697 
2023-08-08 19:03:51.100649: Pseudo dice [0.9126] 
2023-08-08 19:03:51.100745: Epoch time: 64.35 s 
2023-08-08 19:03:52.176653:  
2023-08-08 19:03:52.176749: Epoch 1815 
2023-08-08 19:03:52.176827: Current learning rate: 0.00012 
2023-08-08 19:04:56.526335: train_loss -0.4109 
2023-08-08 19:04:56.526488: val_loss -0.4141 
2023-08-08 19:04:56.526541: Pseudo dice [0.9051] 
2023-08-08 19:04:56.526607: Epoch time: 64.35 s 
2023-08-08 19:04:57.606971:  
2023-08-08 19:04:57.607070: Epoch 1816 
2023-08-08 19:04:57.607145: Current learning rate: 0.00012 
2023-08-08 19:06:01.907087: train_loss -0.4288 
2023-08-08 19:06:01.907249: val_loss -0.467 
2023-08-08 19:06:01.907300: Pseudo dice [0.8769] 
2023-08-08 19:06:01.907350: Epoch time: 64.3 s 
2023-08-08 19:06:02.989278:  
2023-08-08 19:06:02.989371: Epoch 1817 
2023-08-08 19:06:02.989440: Current learning rate: 0.00012 
2023-08-08 19:07:07.092466: train_loss -0.3954 
2023-08-08 19:07:07.092616: val_loss -0.4021 
2023-08-08 19:07:07.092670: Pseudo dice [0.918] 
2023-08-08 19:07:07.092719: Epoch time: 64.1 s 
2023-08-08 19:07:08.358210:  
2023-08-08 19:07:08.358308: Epoch 1818 
2023-08-08 19:07:08.358397: Current learning rate: 0.00012 
2023-08-08 19:08:12.723952: train_loss -0.4046 
2023-08-08 19:08:12.724099: val_loss -0.4465 
2023-08-08 19:08:12.724153: Pseudo dice [0.9376] 
2023-08-08 19:08:12.724203: Epoch time: 64.37 s 
2023-08-08 19:08:13.837646:  
2023-08-08 19:08:13.837747: Epoch 1819 
2023-08-08 19:08:13.837821: Current learning rate: 0.00012 
2023-08-08 19:09:18.118480: train_loss -0.4129 
2023-08-08 19:09:18.118637: val_loss -0.4247 
2023-08-08 19:09:18.118689: Pseudo dice [0.9212] 
2023-08-08 19:09:18.118757: Epoch time: 64.28 s 
2023-08-08 19:09:19.230052:  
2023-08-08 19:09:19.230151: Epoch 1820 
2023-08-08 19:09:19.230240: Current learning rate: 0.00011 
2023-08-08 19:10:23.533386: train_loss -0.4035 
2023-08-08 19:10:23.533540: val_loss -0.3836 
2023-08-08 19:10:23.533594: Pseudo dice [0.9269] 
2023-08-08 19:10:23.533663: Epoch time: 64.3 s 
2023-08-08 19:10:23.533704: Yayy! New best EMA pseudo Dice: 0.9068 
2023-08-08 19:10:24.990651:  
2023-08-08 19:10:24.990883: Epoch 1821 
2023-08-08 19:10:24.990961: Current learning rate: 0.00011 
2023-08-08 19:11:29.241510: train_loss -0.3992 
2023-08-08 19:11:29.241669: val_loss -0.3962 
2023-08-08 19:11:29.241736: Pseudo dice [0.9319] 
2023-08-08 19:11:29.241787: Epoch time: 64.25 s 
2023-08-08 19:11:29.241827: Yayy! New best EMA pseudo Dice: 0.9093 
2023-08-08 19:11:30.724674:  
2023-08-08 19:11:30.724910: Epoch 1822 
2023-08-08 19:11:30.725004: Current learning rate: 0.00011 
2023-08-08 19:12:34.671393: train_loss -0.3681 
2023-08-08 19:12:34.671837: val_loss -0.4359 
2023-08-08 19:12:34.672047: Pseudo dice [0.8717] 
2023-08-08 19:12:34.672346: Epoch time: 63.95 s 
2023-08-08 19:12:35.896709:  
2023-08-08 19:12:35.896819: Epoch 1823 
2023-08-08 19:12:35.896891: Current learning rate: 0.00011 
2023-08-08 19:13:40.259602: train_loss -0.4316 
2023-08-08 19:13:40.259772: val_loss -0.4647 
2023-08-08 19:13:40.259824: Pseudo dice [0.9023] 
2023-08-08 19:13:40.259875: Epoch time: 64.36 s 
2023-08-08 19:13:41.331948:  
2023-08-08 19:13:41.332047: Epoch 1824 
2023-08-08 19:13:41.332120: Current learning rate: 0.00011 
2023-08-08 19:14:45.441158: train_loss -0.3762 
2023-08-08 19:14:45.441310: val_loss -0.3869 
2023-08-08 19:14:45.441363: Pseudo dice [0.9094] 
2023-08-08 19:14:45.441411: Epoch time: 64.11 s 
2023-08-08 19:14:46.516671:  
2023-08-08 19:14:46.516772: Epoch 1825 
2023-08-08 19:14:46.516846: Current learning rate: 0.00011 
2023-08-08 19:15:50.447360: train_loss -0.4334 
2023-08-08 19:15:50.447899: val_loss -0.4254 
2023-08-08 19:15:50.448144: Pseudo dice [0.8611] 
2023-08-08 19:15:50.448290: Epoch time: 63.93 s 
2023-08-08 19:15:51.563098:  
2023-08-08 19:15:51.563196: Epoch 1826 
2023-08-08 19:15:51.563285: Current learning rate: 0.00011 
2023-08-08 19:16:55.593426: train_loss -0.4157 
2023-08-08 19:16:55.593579: val_loss -0.3796 
2023-08-08 19:16:55.593632: Pseudo dice [0.8736] 
2023-08-08 19:16:55.593683: Epoch time: 64.03 s 
2023-08-08 19:16:56.664401:  
2023-08-08 19:16:56.664498: Epoch 1827 
2023-08-08 19:16:56.664584: Current learning rate: 0.00011 
2023-08-08 19:18:00.527591: train_loss -0.4229 
2023-08-08 19:18:00.527757: val_loss -0.4653 
2023-08-08 19:18:00.527807: Pseudo dice [0.9452] 
2023-08-08 19:18:00.527856: Epoch time: 63.86 s 
2023-08-08 19:18:01.756152:  
2023-08-08 19:18:01.756257: Epoch 1828 
2023-08-08 19:18:01.756347: Current learning rate: 0.00011 
2023-08-08 19:19:05.687278: train_loss -0.3989 
2023-08-08 19:19:05.687433: val_loss -0.3832 
2023-08-08 19:19:05.695869: Pseudo dice [0.8579] 
2023-08-08 19:19:05.696093: Epoch time: 63.93 s 
2023-08-08 19:19:06.810835:  
2023-08-08 19:19:06.810945: Epoch 1829 
2023-08-08 19:19:06.811036: Current learning rate: 0.00011 
2023-08-08 19:20:10.755461: train_loss -0.4257 
2023-08-08 19:20:10.755636: val_loss -0.4227 
2023-08-08 19:20:10.755686: Pseudo dice [0.884] 
2023-08-08 19:20:10.755735: Epoch time: 63.95 s 
2023-08-08 19:20:11.828135:  
2023-08-08 19:20:11.828233: Epoch 1830 
2023-08-08 19:20:11.828307: Current learning rate: 0.00011 
2023-08-08 19:21:15.784247: train_loss -0.3949 
2023-08-08 19:21:15.784396: val_loss -0.4528 
2023-08-08 19:21:15.784450: Pseudo dice [0.9268] 
2023-08-08 19:21:15.784503: Epoch time: 63.96 s 
2023-08-08 19:21:16.858742:  
2023-08-08 19:21:16.858840: Epoch 1831 
2023-08-08 19:21:16.858928: Current learning rate: 0.00011 
2023-08-08 19:22:20.817331: train_loss -0.4049 
2023-08-08 19:22:20.817482: val_loss -0.4129 
2023-08-08 19:22:20.817536: Pseudo dice [0.9351] 
2023-08-08 19:22:20.817586: Epoch time: 63.96 s 
2023-08-08 19:22:21.890440:  
2023-08-08 19:22:21.890538: Epoch 1832 
2023-08-08 19:22:21.890653: Current learning rate: 0.00011 
2023-08-08 19:23:25.749852: train_loss -0.4507 
2023-08-08 19:23:25.750095: val_loss -0.3753 
2023-08-08 19:23:25.750152: Pseudo dice [0.9044] 
2023-08-08 19:23:25.750204: Epoch time: 63.86 s 
2023-08-08 19:23:26.994295:  
2023-08-08 19:23:26.994391: Epoch 1833 
2023-08-08 19:23:26.994483: Current learning rate: 0.00011 
2023-08-08 19:24:30.909945: train_loss -0.4212 
2023-08-08 19:24:30.910090: val_loss -0.4034 
2023-08-08 19:24:30.910141: Pseudo dice [0.9074] 
2023-08-08 19:24:30.910204: Epoch time: 63.92 s 
2023-08-08 19:24:32.010741:  
2023-08-08 19:24:32.010844: Epoch 1834 
2023-08-08 19:24:32.010937: Current learning rate: 0.00011 
2023-08-08 19:25:35.888440: train_loss -0.382 
2023-08-08 19:25:35.888590: val_loss -0.4456 
2023-08-08 19:25:35.888646: Pseudo dice [0.9058] 
2023-08-08 19:25:35.888697: Epoch time: 63.88 s 
2023-08-08 19:25:36.965302:  
2023-08-08 19:25:36.965403: Epoch 1835 
2023-08-08 19:25:36.965477: Current learning rate: 0.00011 
2023-08-08 19:26:40.947092: train_loss -0.4116 
2023-08-08 19:26:40.947249: val_loss -0.366 
2023-08-08 19:26:40.947302: Pseudo dice [0.9343] 
2023-08-08 19:26:40.947351: Epoch time: 63.98 s 
2023-08-08 19:26:42.066400:  
2023-08-08 19:26:42.066502: Epoch 1836 
2023-08-08 19:26:42.066595: Current learning rate: 0.00011 
2023-08-08 19:27:45.889058: train_loss -0.4173 
2023-08-08 19:27:45.889271: val_loss -0.574 
2023-08-08 19:27:45.889364: Pseudo dice [0.8852] 
2023-08-08 19:27:45.889454: Epoch time: 63.82 s 
2023-08-08 19:27:46.984423:  
2023-08-08 19:27:46.984519: Epoch 1837 
2023-08-08 19:27:46.984591: Current learning rate: 0.0001 
2023-08-08 19:28:50.628297: train_loss -0.4142 
2023-08-08 19:28:50.628453: val_loss -0.4329 
2023-08-08 19:28:50.628507: Pseudo dice [0.9325] 
2023-08-08 19:28:50.628577: Epoch time: 63.64 s 
2023-08-08 19:28:51.728299:  
2023-08-08 19:28:51.728395: Epoch 1838 
2023-08-08 19:28:51.728468: Current learning rate: 0.0001 
2023-08-08 19:29:55.353427: train_loss -0.3847 
2023-08-08 19:29:55.353584: val_loss -0.387 
2023-08-08 19:29:55.353635: Pseudo dice [0.9087] 
2023-08-08 19:29:55.353687: Epoch time: 63.63 s 
2023-08-08 19:29:56.661889:  
2023-08-08 19:29:56.661990: Epoch 1839 
2023-08-08 19:29:56.662086: Current learning rate: 0.0001 
2023-08-08 19:31:00.535542: train_loss -0.4394 
2023-08-08 19:31:00.535719: val_loss -0.3899 
2023-08-08 19:31:00.535781: Pseudo dice [0.9218] 
2023-08-08 19:31:00.535831: Epoch time: 63.87 s 
2023-08-08 19:31:01.613972:  
2023-08-08 19:31:01.614073: Epoch 1840 
2023-08-08 19:31:01.614145: Current learning rate: 0.0001 
2023-08-08 19:32:05.351436: train_loss -0.4378 
2023-08-08 19:32:05.351600: val_loss -0.4729 
2023-08-08 19:32:05.351673: Pseudo dice [0.8445] 
2023-08-08 19:32:05.351724: Epoch time: 63.74 s 
2023-08-08 19:32:06.464313:  
2023-08-08 19:32:06.464491: Epoch 1841 
2023-08-08 19:32:06.464568: Current learning rate: 0.0001 
2023-08-08 19:33:10.193667: train_loss -0.423 
2023-08-08 19:33:10.193810: val_loss -0.4742 
2023-08-08 19:33:10.193861: Pseudo dice [0.8765] 
2023-08-08 19:33:10.193926: Epoch time: 63.73 s 
2023-08-08 19:33:11.270387:  
2023-08-08 19:33:11.270495: Epoch 1842 
2023-08-08 19:33:11.270565: Current learning rate: 0.0001 
2023-08-08 19:34:14.962615: train_loss -0.4185 
2023-08-08 19:34:14.962784: val_loss -0.3297 
2023-08-08 19:34:14.962862: Pseudo dice [0.8407] 
2023-08-08 19:34:14.962913: Epoch time: 63.69 s 
2023-08-08 19:34:16.032077:  
2023-08-08 19:34:16.032171: Epoch 1843 
2023-08-08 19:34:16.032241: Current learning rate: 0.0001 
2023-08-08 19:35:19.713115: train_loss -0.4489 
2023-08-08 19:35:19.713265: val_loss -0.4735 
2023-08-08 19:35:19.713318: Pseudo dice [0.8937] 
2023-08-08 19:35:19.713368: Epoch time: 63.68 s 
2023-08-08 19:35:20.976693:  
2023-08-08 19:35:20.976804: Epoch 1844 
2023-08-08 19:35:20.976900: Current learning rate: 0.0001 
2023-08-08 19:36:24.580324: train_loss -0.4402 
2023-08-08 19:36:24.580492: val_loss -0.3931 
2023-08-08 19:36:24.580550: Pseudo dice [0.88] 
2023-08-08 19:36:24.580602: Epoch time: 63.6 s 
2023-08-08 19:36:25.697421:  
2023-08-08 19:36:25.697521: Epoch 1845 
2023-08-08 19:36:25.697608: Current learning rate: 0.0001 
2023-08-08 19:37:29.305108: train_loss -0.4147 
2023-08-08 19:37:29.305262: val_loss -0.4791 
2023-08-08 19:37:29.305331: Pseudo dice [0.9319] 
2023-08-08 19:37:29.305381: Epoch time: 63.61 s 
2023-08-08 19:37:30.374472:  
2023-08-08 19:37:30.374583: Epoch 1846 
2023-08-08 19:37:30.374654: Current learning rate: 0.0001 
2023-08-08 19:38:34.118363: train_loss -0.4302 
2023-08-08 19:38:34.118517: val_loss -0.3825 
2023-08-08 19:38:34.118587: Pseudo dice [0.9211] 
2023-08-08 19:38:34.118639: Epoch time: 63.74 s 
2023-08-08 19:38:35.193352:  
2023-08-08 19:38:35.193458: Epoch 1847 
2023-08-08 19:38:35.193531: Current learning rate: 0.0001 
2023-08-08 19:39:39.028676: train_loss -0.4166 
2023-08-08 19:39:39.028845: val_loss -0.4048 
2023-08-08 19:39:39.028911: Pseudo dice [0.9356] 
2023-08-08 19:39:39.028961: Epoch time: 63.84 s 
2023-08-08 19:39:40.095714:  
2023-08-08 19:39:40.095810: Epoch 1848 
2023-08-08 19:39:40.095882: Current learning rate: 0.0001 
2023-08-08 19:40:43.905633: train_loss -0.4373 
2023-08-08 19:40:43.905784: val_loss -0.4425 
2023-08-08 19:40:43.905853: Pseudo dice [0.9621] 
2023-08-08 19:40:43.905902: Epoch time: 63.81 s 
2023-08-08 19:40:44.977345:  
2023-08-08 19:40:44.977438: Epoch 1849 
2023-08-08 19:40:44.977510: Current learning rate: 0.0001 
2023-08-08 19:41:48.608659: train_loss -0.4366 
2023-08-08 19:41:48.608800: val_loss -0.5017 
2023-08-08 19:41:48.608850: Pseudo dice [0.8823] 
2023-08-08 19:41:48.608902: Epoch time: 63.63 s 
2023-08-08 19:41:50.294931:  
2023-08-08 19:41:50.295109: Epoch 1850 
2023-08-08 19:41:50.295202: Current learning rate: 0.0001 
2023-08-08 19:42:54.083788: train_loss -0.423 
2023-08-08 19:42:54.083937: val_loss -0.3961 
2023-08-08 19:42:54.083990: Pseudo dice [0.9318] 
2023-08-08 19:42:54.084041: Epoch time: 63.79 s 
2023-08-08 19:42:55.173764:  
2023-08-08 19:42:55.173865: Epoch 1851 
2023-08-08 19:42:55.173951: Current learning rate: 0.0001 
2023-08-08 19:43:58.861734: train_loss -0.4351 
2023-08-08 19:43:58.861887: val_loss -0.4017 
2023-08-08 19:43:58.861940: Pseudo dice [0.9135] 
2023-08-08 19:43:58.861990: Epoch time: 63.69 s 
2023-08-08 19:43:59.936974:  
2023-08-08 19:43:59.937074: Epoch 1852 
2023-08-08 19:43:59.937144: Current learning rate: 0.0001 
2023-08-08 19:45:03.677214: train_loss -0.4589 
2023-08-08 19:45:03.677369: val_loss -0.4569 
2023-08-08 19:45:03.677421: Pseudo dice [0.8749] 
2023-08-08 19:45:03.677472: Epoch time: 63.74 s 
2023-08-08 19:45:04.750852:  
2023-08-08 19:45:04.750947: Epoch 1853 
2023-08-08 19:45:04.751033: Current learning rate: 0.0001 
2023-08-08 19:46:08.554064: train_loss -0.4294 
2023-08-08 19:46:08.554300: val_loss -0.4341 
2023-08-08 19:46:08.554356: Pseudo dice [0.9295] 
2023-08-08 19:46:08.554406: Epoch time: 63.8 s 
2023-08-08 19:46:09.627572:  
2023-08-08 19:46:09.627687: Epoch 1854 
2023-08-08 19:46:09.627761: Current learning rate: 9e-05 
2023-08-08 19:47:13.321313: train_loss -0.4228 
2023-08-08 19:47:13.321458: val_loss -0.39 
2023-08-08 19:47:13.321510: Pseudo dice [0.8717] 
2023-08-08 19:47:13.321580: Epoch time: 63.69 s 
2023-08-08 19:47:14.569856:  
2023-08-08 19:47:14.569955: Epoch 1855 
2023-08-08 19:47:14.570027: Current learning rate: 9e-05 
2023-08-08 19:48:18.267870: train_loss -0.4145 
2023-08-08 19:48:18.268025: val_loss -0.4507 
2023-08-08 19:48:18.268078: Pseudo dice [0.8995] 
2023-08-08 19:48:18.268128: Epoch time: 63.7 s 
2023-08-08 19:48:19.370370:  
2023-08-08 19:48:19.370466: Epoch 1856 
2023-08-08 19:48:19.370555: Current learning rate: 9e-05 
2023-08-08 19:49:23.072503: train_loss -0.4431 
2023-08-08 19:49:23.072655: val_loss -0.4139 
2023-08-08 19:49:23.072705: Pseudo dice [0.8968] 
2023-08-08 19:49:23.072755: Epoch time: 63.7 s 
2023-08-08 19:49:24.152123:  
2023-08-08 19:49:24.152213: Epoch 1857 
2023-08-08 19:49:24.152300: Current learning rate: 9e-05 
2023-08-08 19:50:27.756239: train_loss -0.4069 
2023-08-08 19:50:27.756392: val_loss -0.404 
2023-08-08 19:50:27.756443: Pseudo dice [0.8878] 
2023-08-08 19:50:27.756493: Epoch time: 63.6 s 
2023-08-08 19:50:28.889768:  
2023-08-08 19:50:28.889860: Epoch 1858 
2023-08-08 19:50:28.889930: Current learning rate: 9e-05 
2023-08-08 19:51:32.618791: train_loss -0.422 
2023-08-08 19:51:32.618938: val_loss -0.3944 
2023-08-08 19:51:32.618990: Pseudo dice [0.8985] 
2023-08-08 19:51:32.619039: Epoch time: 63.73 s 
2023-08-08 19:51:33.730471:  
2023-08-08 19:51:33.730572: Epoch 1859 
2023-08-08 19:51:33.730644: Current learning rate: 9e-05 
2023-08-08 19:52:37.424172: train_loss -0.4671 
2023-08-08 19:52:37.424316: val_loss -0.4556 
2023-08-08 19:52:37.424365: Pseudo dice [0.922] 
2023-08-08 19:52:37.424414: Epoch time: 63.69 s 
2023-08-08 19:52:38.641381:  
2023-08-08 19:52:38.641484: Epoch 1860 
2023-08-08 19:52:38.641574: Current learning rate: 9e-05 
2023-08-08 19:53:42.360292: train_loss -0.4211 
2023-08-08 19:53:42.360436: val_loss -0.421 
2023-08-08 19:53:42.360485: Pseudo dice [0.9224] 
2023-08-08 19:53:42.360536: Epoch time: 63.72 s 
2023-08-08 19:53:43.441781:  
2023-08-08 19:53:43.441888: Epoch 1861 
2023-08-08 19:53:43.441988: Current learning rate: 9e-05 
2023-08-08 19:54:47.003943: train_loss -0.4015 
2023-08-08 19:54:47.004094: val_loss -0.4285 
2023-08-08 19:54:47.004149: Pseudo dice [0.9175] 
2023-08-08 19:54:47.004201: Epoch time: 63.56 s 
2023-08-08 19:54:48.096709:  
2023-08-08 19:54:48.096815: Epoch 1862 
2023-08-08 19:54:48.096887: Current learning rate: 9e-05 
2023-08-08 19:55:51.909791: train_loss -0.4269 
2023-08-08 19:55:51.910023: val_loss -0.4216 
2023-08-08 19:55:51.910076: Pseudo dice [0.8851] 
2023-08-08 19:55:51.910128: Epoch time: 63.81 s 
2023-08-08 19:55:53.009033:  
2023-08-08 19:55:53.009135: Epoch 1863 
2023-08-08 19:55:53.009208: Current learning rate: 9e-05 
2023-08-08 19:56:56.839964: train_loss -0.4398 
2023-08-08 19:56:56.840114: val_loss -0.4758 
2023-08-08 19:56:56.840165: Pseudo dice [0.8351] 
2023-08-08 19:56:56.840216: Epoch time: 63.83 s 
2023-08-08 19:56:57.909388:  
2023-08-08 19:56:57.909483: Epoch 1864 
2023-08-08 19:56:57.909554: Current learning rate: 9e-05 
2023-08-08 19:58:01.674045: train_loss -0.4044 
2023-08-08 19:58:01.674196: val_loss -0.4213 
2023-08-08 19:58:01.674263: Pseudo dice [0.9123] 
2023-08-08 19:58:01.674314: Epoch time: 63.77 s 
2023-08-08 19:58:02.760965:  
2023-08-08 19:58:02.761062: Epoch 1865 
2023-08-08 19:58:02.761152: Current learning rate: 9e-05 
2023-08-08 19:59:06.637666: train_loss -0.4295 
2023-08-08 19:59:06.637813: val_loss -0.4325 
2023-08-08 19:59:06.637881: Pseudo dice [0.8591] 
2023-08-08 19:59:06.637930: Epoch time: 63.88 s 
2023-08-08 19:59:07.905776:  
2023-08-08 19:59:07.905876: Epoch 1866 
2023-08-08 19:59:07.905968: Current learning rate: 9e-05 
2023-08-08 20:00:11.783365: train_loss -0.4287 
2023-08-08 20:00:11.783515: val_loss -0.4544 
2023-08-08 20:00:11.783580: Pseudo dice [0.9248] 
2023-08-08 20:00:11.783633: Epoch time: 63.88 s 
2023-08-08 20:00:12.892944:  
2023-08-08 20:00:12.893173: Epoch 1867 
2023-08-08 20:00:12.893333: Current learning rate: 9e-05 
2023-08-08 20:01:16.646484: train_loss -0.4426 
2023-08-08 20:01:16.646635: val_loss -0.4716 
2023-08-08 20:01:16.646687: Pseudo dice [0.9099] 
2023-08-08 20:01:16.646740: Epoch time: 63.76 s 
2023-08-08 20:01:17.724561:  
2023-08-08 20:01:17.724661: Epoch 1868 
2023-08-08 20:01:17.724735: Current learning rate: 9e-05 
2023-08-08 20:02:21.651363: train_loss -0.4085 
2023-08-08 20:02:21.651530: val_loss -0.3913 
2023-08-08 20:02:21.651592: Pseudo dice [0.9144] 
2023-08-08 20:02:21.651643: Epoch time: 63.93 s 
2023-08-08 20:02:22.725839:  
2023-08-08 20:02:22.725941: Epoch 1869 
2023-08-08 20:02:22.726033: Current learning rate: 9e-05 
2023-08-08 20:03:26.559122: train_loss -0.4675 
2023-08-08 20:03:26.559280: val_loss -0.4382 
2023-08-08 20:03:26.559335: Pseudo dice [0.8661] 
2023-08-08 20:03:26.559387: Epoch time: 63.83 s 
2023-08-08 20:03:27.625203:  
2023-08-08 20:03:27.625379: Epoch 1870 
2023-08-08 20:03:27.625473: Current learning rate: 9e-05 
2023-08-08 20:04:31.471849: train_loss -0.4283 
2023-08-08 20:04:31.472000: val_loss -0.4655 
2023-08-08 20:04:31.472050: Pseudo dice [0.8926] 
2023-08-08 20:04:31.472100: Epoch time: 63.85 s 
2023-08-08 20:04:32.732351:  
2023-08-08 20:04:32.732448: Epoch 1871 
2023-08-08 20:04:32.732543: Current learning rate: 8e-05 
2023-08-08 20:05:36.455833: train_loss -0.4413 
2023-08-08 20:05:36.455988: val_loss -0.4637 
2023-08-08 20:05:36.464401: Pseudo dice [0.9024] 
2023-08-08 20:05:36.464520: Epoch time: 63.72 s 
2023-08-08 20:05:37.546738:  
2023-08-08 20:05:37.546839: Epoch 1872 
2023-08-08 20:05:37.546929: Current learning rate: 8e-05 
2023-08-08 20:06:41.424805: train_loss -0.4279 
2023-08-08 20:06:41.424990: val_loss -0.4788 
2023-08-08 20:06:41.425049: Pseudo dice [0.8823] 
2023-08-08 20:06:41.425101: Epoch time: 63.88 s 
2023-08-08 20:06:42.521538:  
2023-08-08 20:06:42.521633: Epoch 1873 
2023-08-08 20:06:42.521724: Current learning rate: 8e-05 
2023-08-08 20:07:46.317464: train_loss -0.4502 
2023-08-08 20:07:46.317635: val_loss -0.4204 
2023-08-08 20:07:46.317685: Pseudo dice [0.8887] 
2023-08-08 20:07:46.317752: Epoch time: 63.8 s 
2023-08-08 20:07:47.424309:  
2023-08-08 20:07:47.424411: Epoch 1874 
2023-08-08 20:07:47.424503: Current learning rate: 8e-05 
2023-08-08 20:08:51.237707: train_loss -0.4275 
2023-08-08 20:08:51.237878: val_loss -0.4741 
2023-08-08 20:08:51.237930: Pseudo dice [0.9084] 
2023-08-08 20:08:51.237981: Epoch time: 63.81 s 
2023-08-08 20:08:52.319165:  
2023-08-08 20:08:52.319265: Epoch 1875 
2023-08-08 20:08:52.319338: Current learning rate: 8e-05 
2023-08-08 20:09:56.022034: train_loss -0.4381 
2023-08-08 20:09:56.022180: val_loss -0.5041 
2023-08-08 20:09:56.022232: Pseudo dice [0.9158] 
2023-08-08 20:09:56.022283: Epoch time: 63.7 s 
2023-08-08 20:09:57.102453:  
2023-08-08 20:09:57.102548: Epoch 1876 
2023-08-08 20:09:57.102639: Current learning rate: 8e-05 
2023-08-08 20:11:00.890517: train_loss -0.4444 
2023-08-08 20:11:00.890661: val_loss -0.4233 
2023-08-08 20:11:00.890711: Pseudo dice [0.8955] 
2023-08-08 20:11:00.890776: Epoch time: 63.79 s 
2023-08-08 20:11:02.131505:  
2023-08-08 20:11:02.131607: Epoch 1877 
2023-08-08 20:11:02.131695: Current learning rate: 8e-05 
2023-08-08 20:12:06.004620: train_loss -0.4592 
2023-08-08 20:12:06.004781: val_loss -0.4856 
2023-08-08 20:12:06.004875: Pseudo dice [0.9224] 
2023-08-08 20:12:06.004925: Epoch time: 63.87 s 
2023-08-08 20:12:07.086084:  
2023-08-08 20:12:07.086181: Epoch 1878 
2023-08-08 20:12:07.086257: Current learning rate: 8e-05 
2023-08-08 20:13:10.786488: train_loss -0.4156 
2023-08-08 20:13:10.786633: val_loss -0.4761 
2023-08-08 20:13:10.786701: Pseudo dice [0.9068] 
2023-08-08 20:13:10.786752: Epoch time: 63.7 s 
2023-08-08 20:13:11.859824:  
2023-08-08 20:13:11.859923: Epoch 1879 
2023-08-08 20:13:11.859996: Current learning rate: 8e-05 
2023-08-08 20:14:15.521485: train_loss -0.4034 
2023-08-08 20:14:15.521649: val_loss -0.4175 
2023-08-08 20:14:15.521703: Pseudo dice [0.8721] 
2023-08-08 20:14:15.521754: Epoch time: 63.66 s 
2023-08-08 20:14:16.604383:  
2023-08-08 20:14:16.604482: Epoch 1880 
2023-08-08 20:14:16.604555: Current learning rate: 8e-05 
2023-08-08 20:15:20.411545: train_loss -0.4256 
2023-08-08 20:15:20.411705: val_loss -0.4699 
2023-08-08 20:15:20.411755: Pseudo dice [0.8828] 
2023-08-08 20:15:20.411806: Epoch time: 63.81 s 
2023-08-08 20:15:21.479849:  
2023-08-08 20:15:21.479943: Epoch 1881 
2023-08-08 20:15:21.480015: Current learning rate: 8e-05 
2023-08-08 20:16:25.263032: train_loss -0.4421 
2023-08-08 20:16:25.263176: val_loss -0.4999 
2023-08-08 20:16:25.263226: Pseudo dice [0.91] 
2023-08-08 20:16:25.263291: Epoch time: 63.78 s 
2023-08-08 20:16:26.513707:  
2023-08-08 20:16:26.513947: Epoch 1882 
2023-08-08 20:16:26.514160: Current learning rate: 8e-05 
2023-08-08 20:17:30.228351: train_loss -0.4238 
2023-08-08 20:17:30.228502: val_loss -0.4449 
2023-08-08 20:17:30.228553: Pseudo dice [0.9136] 
2023-08-08 20:17:30.228603: Epoch time: 63.72 s 
2023-08-08 20:17:31.305891:  
2023-08-08 20:17:31.305990: Epoch 1883 
2023-08-08 20:17:31.306061: Current learning rate: 8e-05 
2023-08-08 20:18:35.106421: train_loss -0.4387 
2023-08-08 20:18:35.106581: val_loss -0.4655 
2023-08-08 20:18:35.106633: Pseudo dice [0.957] 
2023-08-08 20:18:35.106683: Epoch time: 63.8 s 
2023-08-08 20:18:36.205390:  
2023-08-08 20:18:36.205482: Epoch 1884 
2023-08-08 20:18:36.205573: Current learning rate: 8e-05 
2023-08-08 20:19:40.033267: train_loss -0.4297 
2023-08-08 20:19:40.033414: val_loss -0.4859 
2023-08-08 20:19:40.033467: Pseudo dice [0.9422] 
2023-08-08 20:19:40.033534: Epoch time: 63.83 s 
2023-08-08 20:19:41.102411:  
2023-08-08 20:19:41.102506: Epoch 1885 
2023-08-08 20:19:41.102593: Current learning rate: 8e-05 
2023-08-08 20:20:44.847602: train_loss -0.3995 
2023-08-08 20:20:44.847839: val_loss -0.4514 
2023-08-08 20:20:44.847951: Pseudo dice [0.8537] 
2023-08-08 20:20:44.848062: Epoch time: 63.75 s 
2023-08-08 20:20:45.953622:  
2023-08-08 20:20:45.953715: Epoch 1886 
2023-08-08 20:20:45.953787: Current learning rate: 8e-05 
2023-08-08 20:21:49.804329: train_loss -0.4411 
2023-08-08 20:21:49.804477: val_loss -0.4831 
2023-08-08 20:21:49.804529: Pseudo dice [0.9587] 
2023-08-08 20:21:49.804579: Epoch time: 63.85 s 
2023-08-08 20:21:50.878122:  
2023-08-08 20:21:50.878213: Epoch 1887 
2023-08-08 20:21:50.878286: Current learning rate: 8e-05 
2023-08-08 20:22:54.560249: train_loss -0.4458 
2023-08-08 20:22:54.560396: val_loss -0.425 
2023-08-08 20:22:54.560447: Pseudo dice [0.9047] 
2023-08-08 20:22:54.560498: Epoch time: 63.68 s 
2023-08-08 20:22:55.802386:  
2023-08-08 20:22:55.802487: Epoch 1888 
2023-08-08 20:22:55.802561: Current learning rate: 7e-05 
2023-08-08 20:23:59.751366: train_loss -0.4606 
2023-08-08 20:23:59.751520: val_loss -0.4375 
2023-08-08 20:23:59.751582: Pseudo dice [0.8868] 
2023-08-08 20:23:59.751652: Epoch time: 63.95 s 
2023-08-08 20:24:00.831742:  
2023-08-08 20:24:00.831843: Epoch 1889 
2023-08-08 20:24:00.831916: Current learning rate: 7e-05 
2023-08-08 20:25:04.389928: train_loss -0.4551 
2023-08-08 20:25:04.390079: val_loss -0.438 
2023-08-08 20:25:04.390131: Pseudo dice [0.9094] 
2023-08-08 20:25:04.390197: Epoch time: 63.56 s 
2023-08-08 20:25:05.478648:  
2023-08-08 20:25:05.478745: Epoch 1890 
2023-08-08 20:25:05.478818: Current learning rate: 7e-05 
2023-08-08 20:26:09.223188: train_loss -0.4207 
2023-08-08 20:26:09.223337: val_loss -0.472 
2023-08-08 20:26:09.223398: Pseudo dice [0.8914] 
2023-08-08 20:26:09.223466: Epoch time: 63.75 s 
2023-08-08 20:26:10.313268:  
2023-08-08 20:26:10.313365: Epoch 1891 
2023-08-08 20:26:10.313440: Current learning rate: 7e-05 
2023-08-08 20:27:14.225556: train_loss -0.4283 
2023-08-08 20:27:14.225828: val_loss -0.4546 
2023-08-08 20:27:14.225957: Pseudo dice [0.8751] 
2023-08-08 20:27:14.226097: Epoch time: 63.91 s 
2023-08-08 20:27:15.329768:  
2023-08-08 20:27:15.329872: Epoch 1892 
2023-08-08 20:27:15.329961: Current learning rate: 7e-05 
2023-08-08 20:28:19.342637: train_loss -0.4375 
2023-08-08 20:28:19.342783: val_loss -0.4288 
2023-08-08 20:28:19.342833: Pseudo dice [0.9249] 
2023-08-08 20:28:19.342901: Epoch time: 64.01 s 
2023-08-08 20:28:20.595793:  
2023-08-08 20:28:20.595903: Epoch 1893 
2023-08-08 20:28:20.595978: Current learning rate: 7e-05 
2023-08-08 20:29:24.555949: train_loss -0.4336 
2023-08-08 20:29:24.556097: val_loss -0.3943 
2023-08-08 20:29:24.556146: Pseudo dice [0.8512] 
2023-08-08 20:29:24.556196: Epoch time: 63.96 s 
2023-08-08 20:29:25.628458:  
2023-08-08 20:29:25.628558: Epoch 1894 
2023-08-08 20:29:25.628633: Current learning rate: 7e-05 
2023-08-08 20:30:29.458442: train_loss -0.423 
2023-08-08 20:30:29.458594: val_loss -0.4101 
2023-08-08 20:30:29.458661: Pseudo dice [0.8939] 
2023-08-08 20:30:29.458711: Epoch time: 63.83 s 
2023-08-08 20:30:30.537701:  
2023-08-08 20:30:30.537976: Epoch 1895 
2023-08-08 20:30:30.538155: Current learning rate: 7e-05 
2023-08-08 20:31:34.422931: train_loss -0.4194 
2023-08-08 20:31:34.423078: val_loss -0.4678 
2023-08-08 20:31:34.423127: Pseudo dice [0.919] 
2023-08-08 20:31:34.423178: Epoch time: 63.89 s 
2023-08-08 20:31:35.546135:  
2023-08-08 20:31:35.546313: Epoch 1896 
2023-08-08 20:31:35.546406: Current learning rate: 7e-05 
2023-08-08 20:32:39.478874: train_loss -0.4467 
2023-08-08 20:32:39.479036: val_loss -0.5159 
2023-08-08 20:32:39.479089: Pseudo dice [0.8944] 
2023-08-08 20:32:39.479139: Epoch time: 63.93 s 
2023-08-08 20:32:40.596793:  
2023-08-08 20:32:40.596892: Epoch 1897 
2023-08-08 20:32:40.596961: Current learning rate: 7e-05 
2023-08-08 20:33:44.400154: train_loss -0.4433 
2023-08-08 20:33:44.400303: val_loss -0.5392 
2023-08-08 20:33:44.400355: Pseudo dice [0.8869] 
2023-08-08 20:33:44.400405: Epoch time: 63.8 s 
2023-08-08 20:33:45.493377:  
2023-08-08 20:33:45.493473: Epoch 1898 
2023-08-08 20:33:45.493545: Current learning rate: 7e-05 
2023-08-08 20:34:49.121920: train_loss -0.4311 
2023-08-08 20:34:49.122067: val_loss -0.4717 
2023-08-08 20:34:49.122117: Pseudo dice [0.8907] 
2023-08-08 20:34:49.122183: Epoch time: 63.63 s 
2023-08-08 20:34:50.360280:  
2023-08-08 20:34:50.360588: Epoch 1899 
2023-08-08 20:34:50.360669: Current learning rate: 7e-05 
2023-08-08 20:35:53.853123: train_loss -0.4106 
2023-08-08 20:35:53.853271: val_loss -0.3633 
2023-08-08 20:35:53.853321: Pseudo dice [0.9307] 
2023-08-08 20:35:53.853372: Epoch time: 63.49 s 
2023-08-08 20:35:55.344356:  
2023-08-08 20:35:55.344646: Epoch 1900 
2023-08-08 20:35:55.344804: Current learning rate: 7e-05 
2023-08-08 20:36:59.366835: train_loss -0.4498 
2023-08-08 20:36:59.367115: val_loss -0.4029 
2023-08-08 20:36:59.367167: Pseudo dice [0.9173] 
2023-08-08 20:36:59.367219: Epoch time: 64.02 s 
2023-08-08 20:37:00.486853:  
2023-08-08 20:37:00.486952: Epoch 1901 
2023-08-08 20:37:00.487025: Current learning rate: 7e-05 
2023-08-08 20:38:04.129826: train_loss -0.4439 
2023-08-08 20:38:04.129977: val_loss -0.4285 
2023-08-08 20:38:04.130030: Pseudo dice [0.8899] 
2023-08-08 20:38:04.130080: Epoch time: 63.64 s 
2023-08-08 20:38:05.199298:  
2023-08-08 20:38:05.199392: Epoch 1902 
2023-08-08 20:38:05.199462: Current learning rate: 7e-05 
2023-08-08 20:39:08.720723: train_loss -0.3991 
2023-08-08 20:39:08.720896: val_loss -0.3918 
2023-08-08 20:39:08.720947: Pseudo dice [0.8933] 
2023-08-08 20:39:08.720998: Epoch time: 63.52 s 
2023-08-08 20:39:09.800345:  
2023-08-08 20:39:09.800444: Epoch 1903 
2023-08-08 20:39:09.800519: Current learning rate: 7e-05 
2023-08-08 20:40:13.550309: train_loss -0.416 
2023-08-08 20:40:13.550595: val_loss -0.4627 
2023-08-08 20:40:13.550651: Pseudo dice [0.893] 
2023-08-08 20:40:13.550701: Epoch time: 63.75 s 
2023-08-08 20:40:14.788450:  
2023-08-08 20:40:14.788555: Epoch 1904 
2023-08-08 20:40:14.788642: Current learning rate: 7e-05 
2023-08-08 20:41:18.638584: train_loss -0.4456 
2023-08-08 20:41:18.638740: val_loss -0.3997 
2023-08-08 20:41:18.638790: Pseudo dice [0.9236] 
2023-08-08 20:41:18.638856: Epoch time: 63.85 s 
2023-08-08 20:41:19.767105:  
2023-08-08 20:41:19.767202: Epoch 1905 
2023-08-08 20:41:19.767319: Current learning rate: 6e-05 
2023-08-08 20:42:23.568821: train_loss -0.4067 
2023-08-08 20:42:23.568975: val_loss -0.4771 
2023-08-08 20:42:23.569029: Pseudo dice [0.8694] 
2023-08-08 20:42:23.569081: Epoch time: 63.8 s 
2023-08-08 20:42:24.660797:  
2023-08-08 20:42:24.660903: Epoch 1906 
2023-08-08 20:42:24.660994: Current learning rate: 6e-05 
2023-08-08 20:43:28.388465: train_loss -0.4137 
2023-08-08 20:43:28.388620: val_loss -0.4841 
2023-08-08 20:43:28.388671: Pseudo dice [0.9532] 
2023-08-08 20:43:28.388722: Epoch time: 63.73 s 
2023-08-08 20:43:29.509983:  
2023-08-08 20:43:29.510078: Epoch 1907 
2023-08-08 20:43:29.510166: Current learning rate: 6e-05 
2023-08-08 20:44:33.346338: train_loss -0.4209 
2023-08-08 20:44:33.346483: val_loss -0.4112 
2023-08-08 20:44:33.346550: Pseudo dice [0.8885] 
2023-08-08 20:44:33.346599: Epoch time: 63.84 s 
2023-08-08 20:44:34.441310:  
2023-08-08 20:44:34.441423: Epoch 1908 
2023-08-08 20:44:34.441498: Current learning rate: 6e-05 
2023-08-08 20:45:38.336009: train_loss -0.4317 
2023-08-08 20:45:38.336163: val_loss -0.4443 
2023-08-08 20:45:38.336217: Pseudo dice [0.8991] 
2023-08-08 20:45:38.336268: Epoch time: 63.9 s 
2023-08-08 20:45:39.431135:  
2023-08-08 20:45:39.431229: Epoch 1909 
2023-08-08 20:45:39.431315: Current learning rate: 6e-05 
2023-08-08 20:46:43.474625: train_loss -0.4113 
2023-08-08 20:46:43.474810: val_loss -0.3876 
2023-08-08 20:46:43.474863: Pseudo dice [0.8451] 
2023-08-08 20:46:43.474915: Epoch time: 64.04 s 
2023-08-08 20:46:44.573184:  
2023-08-08 20:46:44.573284: Epoch 1910 
2023-08-08 20:46:44.573374: Current learning rate: 6e-05 
2023-08-08 20:47:48.206985: train_loss -0.478 
2023-08-08 20:47:48.207166: val_loss -0.4282 
2023-08-08 20:47:48.207219: Pseudo dice [0.8577] 
2023-08-08 20:47:48.207270: Epoch time: 63.63 s 
2023-08-08 20:47:49.329783:  
2023-08-08 20:47:49.329883: Epoch 1911 
2023-08-08 20:47:49.329972: Current learning rate: 6e-05 
2023-08-08 20:48:53.268028: train_loss -0.437 
2023-08-08 20:48:53.268187: val_loss -0.4436 
2023-08-08 20:48:53.268241: Pseudo dice [0.895] 
2023-08-08 20:48:53.268292: Epoch time: 63.94 s 
2023-08-08 20:48:54.384917:  
2023-08-08 20:48:54.385016: Epoch 1912 
2023-08-08 20:48:54.385092: Current learning rate: 6e-05 
2023-08-08 20:49:58.370676: train_loss -0.4121 
2023-08-08 20:49:58.370831: val_loss -0.3154 
2023-08-08 20:49:58.370898: Pseudo dice [0.8314] 
2023-08-08 20:49:58.370951: Epoch time: 63.99 s 
2023-08-08 20:49:59.462779:  
2023-08-08 20:49:59.462878: Epoch 1913 
2023-08-08 20:49:59.462968: Current learning rate: 6e-05 
2023-08-08 20:51:03.765216: train_loss -0.399 
2023-08-08 20:51:03.765360: val_loss -0.5059 
2023-08-08 20:51:03.765413: Pseudo dice [0.9184] 
2023-08-08 20:51:03.765464: Epoch time: 64.3 s 
2023-08-08 20:51:05.012409:  
2023-08-08 20:51:05.012515: Epoch 1914 
2023-08-08 20:51:05.012592: Current learning rate: 6e-05 
2023-08-08 20:52:09.437341: train_loss -0.43 
2023-08-08 20:52:09.437498: val_loss -0.52 
2023-08-08 20:52:09.437551: Pseudo dice [0.8638] 
2023-08-08 20:52:09.437602: Epoch time: 64.43 s 
2023-08-08 20:52:10.530811:  
2023-08-08 20:52:10.530910: Epoch 1915 
2023-08-08 20:52:10.530999: Current learning rate: 6e-05 
2023-08-08 20:53:14.733551: train_loss -0.4335 
2023-08-08 20:53:14.733695: val_loss -0.3779 
2023-08-08 20:53:14.733748: Pseudo dice [0.8549] 
2023-08-08 20:53:14.733813: Epoch time: 64.2 s 
2023-08-08 20:53:15.821566:  
2023-08-08 20:53:15.821665: Epoch 1916 
2023-08-08 20:53:15.821759: Current learning rate: 6e-05 
2023-08-08 20:54:20.226253: train_loss -0.4228 
2023-08-08 20:54:20.226413: val_loss -0.4103 
2023-08-08 20:54:20.226465: Pseudo dice [0.931] 
2023-08-08 20:54:20.226515: Epoch time: 64.41 s 
2023-08-08 20:54:21.325809:  
2023-08-08 20:54:21.325900: Epoch 1917 
2023-08-08 20:54:21.325990: Current learning rate: 6e-05 
2023-08-08 20:55:25.502681: train_loss -0.426 
2023-08-08 20:55:25.502829: val_loss -0.4815 
2023-08-08 20:55:25.502897: Pseudo dice [0.9341] 
2023-08-08 20:55:25.502949: Epoch time: 64.18 s 
2023-08-08 20:55:26.617975:  
2023-08-08 20:55:26.618075: Epoch 1918 
2023-08-08 20:55:26.618163: Current learning rate: 6e-05 
2023-08-08 20:56:31.104669: train_loss -0.4207 
2023-08-08 20:56:31.104824: val_loss -0.4592 
2023-08-08 20:56:31.104876: Pseudo dice [0.9639] 
2023-08-08 20:56:31.104928: Epoch time: 64.49 s 
2023-08-08 20:56:32.206848:  
2023-08-08 20:56:32.206942: Epoch 1919 
2023-08-08 20:56:32.207014: Current learning rate: 6e-05 
2023-08-08 20:57:36.579847: train_loss -0.4053 
2023-08-08 20:57:36.579992: val_loss -0.3764 
2023-08-08 20:57:36.580062: Pseudo dice [0.941] 
2023-08-08 20:57:36.580116: Epoch time: 64.37 s 
2023-08-08 20:57:37.834615:  
2023-08-08 20:57:37.834721: Epoch 1920 
2023-08-08 20:57:37.834798: Current learning rate: 6e-05 
2023-08-08 20:58:42.329105: train_loss -0.4571 
2023-08-08 20:58:42.329260: val_loss -0.5275 
2023-08-08 20:58:42.329314: Pseudo dice [0.8934] 
2023-08-08 20:58:42.329365: Epoch time: 64.5 s 
2023-08-08 20:58:43.416950:  
2023-08-08 20:58:43.417048: Epoch 1921 
2023-08-08 20:58:43.417120: Current learning rate: 5e-05 
2023-08-08 20:59:47.852944: train_loss -0.4247 
2023-08-08 20:59:47.853098: val_loss -0.4721 
2023-08-08 20:59:47.853148: Pseudo dice [0.9182] 
2023-08-08 20:59:47.853216: Epoch time: 64.44 s 
2023-08-08 20:59:48.967374:  
2023-08-08 20:59:48.967474: Epoch 1922 
2023-08-08 20:59:48.967547: Current learning rate: 5e-05 
2023-08-08 21:00:53.293061: train_loss -0.4248 
2023-08-08 21:00:53.293211: val_loss -0.4694 
2023-08-08 21:00:53.293262: Pseudo dice [0.8985] 
2023-08-08 21:00:53.293312: Epoch time: 64.33 s 
2023-08-08 21:00:54.409219:  
2023-08-08 21:00:54.409315: Epoch 1923 
2023-08-08 21:00:54.409403: Current learning rate: 5e-05 
2023-08-08 21:01:58.835962: train_loss -0.4091 
2023-08-08 21:01:58.836118: val_loss -0.4625 
2023-08-08 21:01:58.836169: Pseudo dice [0.8881] 
2023-08-08 21:01:58.836219: Epoch time: 64.43 s 
2023-08-08 21:01:59.964065:  
2023-08-08 21:01:59.964160: Epoch 1924 
2023-08-08 21:01:59.964250: Current learning rate: 5e-05 
2023-08-08 21:03:04.438526: train_loss -0.4465 
2023-08-08 21:03:04.438671: val_loss -0.4105 
2023-08-08 21:03:04.438721: Pseudo dice [0.9109] 
2023-08-08 21:03:04.438771: Epoch time: 64.48 s 
2023-08-08 21:03:05.684136:  
2023-08-08 21:03:05.684245: Epoch 1925 
2023-08-08 21:03:05.684334: Current learning rate: 5e-05 
2023-08-08 21:04:10.097165: train_loss -0.4496 
2023-08-08 21:04:10.097310: val_loss -0.5282 
2023-08-08 21:04:10.097377: Pseudo dice [0.8452] 
2023-08-08 21:04:10.097427: Epoch time: 64.41 s 
2023-08-08 21:04:11.202683:  
2023-08-08 21:04:11.202780: Epoch 1926 
2023-08-08 21:04:11.202853: Current learning rate: 5e-05 
2023-08-08 21:05:15.631721: train_loss -0.4117 
2023-08-08 21:05:15.631868: val_loss -0.4158 
2023-08-08 21:05:15.631919: Pseudo dice [0.8804] 
2023-08-08 21:05:15.631969: Epoch time: 64.43 s 
2023-08-08 21:05:16.714365:  
2023-08-08 21:05:16.714463: Epoch 1927 
2023-08-08 21:05:16.714536: Current learning rate: 5e-05 
2023-08-08 21:06:21.129826: train_loss -0.4382 
2023-08-08 21:06:21.129985: val_loss -0.4079 
2023-08-08 21:06:21.130038: Pseudo dice [0.9447] 
2023-08-08 21:06:21.130087: Epoch time: 64.42 s 
2023-08-08 21:06:22.210538:  
2023-08-08 21:06:22.210633: Epoch 1928 
2023-08-08 21:06:22.210706: Current learning rate: 5e-05 
2023-08-08 21:07:26.506466: train_loss -0.4488 
2023-08-08 21:07:26.506621: val_loss -0.4651 
2023-08-08 21:07:26.506673: Pseudo dice [0.8895] 
2023-08-08 21:07:26.506724: Epoch time: 64.3 s 
2023-08-08 21:07:27.598266:  
2023-08-08 21:07:27.598359: Epoch 1929 
2023-08-08 21:07:27.598429: Current learning rate: 5e-05 
2023-08-08 21:08:32.022215: train_loss -0.4123 
2023-08-08 21:08:32.022366: val_loss -0.4082 
2023-08-08 21:08:32.022433: Pseudo dice [0.8457] 
2023-08-08 21:08:32.022483: Epoch time: 64.42 s 
2023-08-08 21:08:33.263492:  
2023-08-08 21:08:33.263597: Epoch 1930 
2023-08-08 21:08:33.263688: Current learning rate: 5e-05 
2023-08-08 21:09:38.142541: train_loss -0.4459 
2023-08-08 21:09:38.142691: val_loss -0.4152 
2023-08-08 21:09:38.142742: Pseudo dice [0.8946] 
2023-08-08 21:09:38.142804: Epoch time: 64.88 s 
2023-08-08 21:09:39.222389:  
2023-08-08 21:09:39.222483: Epoch 1931 
2023-08-08 21:09:39.222555: Current learning rate: 5e-05 
2023-08-08 21:10:43.770143: train_loss -0.4343 
2023-08-08 21:10:43.770296: val_loss -0.4265 
2023-08-08 21:10:43.770346: Pseudo dice [0.8532] 
2023-08-08 21:10:43.770411: Epoch time: 64.55 s 
2023-08-08 21:10:44.906644:  
2023-08-08 21:10:44.906743: Epoch 1932 
2023-08-08 21:10:44.906829: Current learning rate: 5e-05 
2023-08-08 21:11:49.212364: train_loss -0.4619 
2023-08-08 21:11:49.212523: val_loss -0.4215 
2023-08-08 21:11:49.212575: Pseudo dice [0.8808] 
2023-08-08 21:11:49.212625: Epoch time: 64.31 s 
2023-08-08 21:11:50.310688:  
2023-08-08 21:11:50.310779: Epoch 1933 
2023-08-08 21:11:50.310848: Current learning rate: 5e-05 
2023-08-08 21:12:54.933644: train_loss -0.439 
2023-08-08 21:12:54.933791: val_loss -0.4407 
2023-08-08 21:12:54.933858: Pseudo dice [0.8733] 
2023-08-08 21:12:54.933909: Epoch time: 64.62 s 
2023-08-08 21:12:56.033097:  
2023-08-08 21:12:56.033194: Epoch 1934 
2023-08-08 21:12:56.033268: Current learning rate: 5e-05 
2023-08-08 21:14:00.261049: train_loss -0.445 
2023-08-08 21:14:00.261205: val_loss -0.4615 
2023-08-08 21:14:00.261275: Pseudo dice [0.8958] 
2023-08-08 21:14:00.261327: Epoch time: 64.23 s 
2023-08-08 21:14:01.362924:  
2023-08-08 21:14:01.363014: Epoch 1935 
2023-08-08 21:14:01.363085: Current learning rate: 5e-05 
2023-08-08 21:15:05.718686: train_loss -0.3997 
2023-08-08 21:15:05.718836: val_loss -0.4251 
2023-08-08 21:15:05.718951: Pseudo dice [0.8855] 
2023-08-08 21:15:05.719064: Epoch time: 64.36 s 
2023-08-08 21:15:06.997217:  
2023-08-08 21:15:06.997426: Epoch 1936 
2023-08-08 21:15:06.997607: Current learning rate: 5e-05 
2023-08-08 21:16:11.381773: train_loss -0.4162 
2023-08-08 21:16:11.381927: val_loss -0.4308 
2023-08-08 21:16:11.381980: Pseudo dice [0.9048] 
2023-08-08 21:16:11.382030: Epoch time: 64.39 s 
2023-08-08 21:16:12.474897:  
2023-08-08 21:16:12.474998: Epoch 1937 
2023-08-08 21:16:12.475075: Current learning rate: 4e-05 
2023-08-08 21:17:16.891508: train_loss -0.4177 
2023-08-08 21:17:16.891670: val_loss -0.4411 
2023-08-08 21:17:16.891724: Pseudo dice [0.8651] 
2023-08-08 21:17:16.891774: Epoch time: 64.42 s 
2023-08-08 21:17:17.990708:  
2023-08-08 21:17:17.990804: Epoch 1938 
2023-08-08 21:17:17.990894: Current learning rate: 4e-05 
2023-08-08 21:18:22.462877: train_loss -0.3984 
2023-08-08 21:18:22.463023: val_loss -0.4672 
2023-08-08 21:18:22.463075: Pseudo dice [0.8805] 
2023-08-08 21:18:22.463125: Epoch time: 64.47 s 
2023-08-08 21:18:23.558537:  
2023-08-08 21:18:23.558634: Epoch 1939 
2023-08-08 21:18:23.558707: Current learning rate: 4e-05 
2023-08-08 21:19:28.002703: train_loss -0.419 
2023-08-08 21:19:28.002856: val_loss -0.4646 
2023-08-08 21:19:28.002925: Pseudo dice [0.9181] 
2023-08-08 21:19:28.002975: Epoch time: 64.44 s 
2023-08-08 21:19:29.093884:  
2023-08-08 21:19:29.093982: Epoch 1940 
2023-08-08 21:19:29.094053: Current learning rate: 4e-05 
2023-08-08 21:20:33.336944: train_loss -0.415 
2023-08-08 21:20:33.337093: val_loss -0.3699 
2023-08-08 21:20:33.337144: Pseudo dice [0.9309] 
2023-08-08 21:20:33.337195: Epoch time: 64.24 s 
2023-08-08 21:20:34.648558:  
2023-08-08 21:20:34.648661: Epoch 1941 
2023-08-08 21:20:34.648735: Current learning rate: 4e-05 
2023-08-08 21:21:39.154582: train_loss -0.4448 
2023-08-08 21:21:39.154741: val_loss -0.4507 
2023-08-08 21:21:39.154792: Pseudo dice [0.9359] 
2023-08-08 21:21:39.154851: Epoch time: 64.51 s 
2023-08-08 21:21:40.268695:  
2023-08-08 21:21:40.268796: Epoch 1942 
2023-08-08 21:21:40.268874: Current learning rate: 4e-05 
2023-08-08 21:22:44.726086: train_loss -0.4665 
2023-08-08 21:22:44.726243: val_loss -0.4496 
2023-08-08 21:22:44.726296: Pseudo dice [0.911] 
2023-08-08 21:22:44.726348: Epoch time: 64.46 s 
2023-08-08 21:22:45.814260:  
2023-08-08 21:22:45.814359: Epoch 1943 
2023-08-08 21:22:45.814432: Current learning rate: 4e-05 
2023-08-08 21:23:50.198741: train_loss -0.4552 
2023-08-08 21:23:50.198977: val_loss -0.482 
2023-08-08 21:23:50.199036: Pseudo dice [0.939] 
2023-08-08 21:23:50.199087: Epoch time: 64.39 s 
2023-08-08 21:23:51.284834:  
2023-08-08 21:23:51.284932: Epoch 1944 
2023-08-08 21:23:51.285006: Current learning rate: 4e-05 
2023-08-08 21:24:55.687650: train_loss -0.4341 
2023-08-08 21:24:55.687793: val_loss -0.4741 
2023-08-08 21:24:55.687860: Pseudo dice [0.8965] 
2023-08-08 21:24:55.687910: Epoch time: 64.4 s 
2023-08-08 21:24:56.790695:  
2023-08-08 21:24:56.790792: Epoch 1945 
2023-08-08 21:24:56.790883: Current learning rate: 4e-05 
2023-08-08 21:26:01.205881: train_loss -0.4745 
2023-08-08 21:26:01.206028: val_loss -0.4217 
2023-08-08 21:26:01.206081: Pseudo dice [0.9055] 
2023-08-08 21:26:01.206150: Epoch time: 64.42 s 
2023-08-08 21:26:02.447110:  
2023-08-08 21:26:02.447217: Epoch 1946 
2023-08-08 21:26:02.447290: Current learning rate: 4e-05 
2023-08-08 21:27:06.936810: train_loss -0.4585 
2023-08-08 21:27:06.936961: val_loss -0.4657 
2023-08-08 21:27:06.937011: Pseudo dice [0.9253] 
2023-08-08 21:27:06.937061: Epoch time: 64.49 s 
2023-08-08 21:27:08.031891:  
2023-08-08 21:27:08.031994: Epoch 1947 
2023-08-08 21:27:08.032070: Current learning rate: 4e-05 
2023-08-08 21:28:12.495945: train_loss -0.4449 
2023-08-08 21:28:12.496093: val_loss -0.4037 
2023-08-08 21:28:12.496163: Pseudo dice [0.8832] 
2023-08-08 21:28:12.496213: Epoch time: 64.46 s 
2023-08-08 21:28:13.590636:  
2023-08-08 21:28:13.590752: Epoch 1948 
2023-08-08 21:28:13.590827: Current learning rate: 4e-05 
2023-08-08 21:29:17.861046: train_loss -0.4406 
2023-08-08 21:29:17.861199: val_loss -0.4468 
2023-08-08 21:29:17.861251: Pseudo dice [0.8903] 
2023-08-08 21:29:17.861301: Epoch time: 64.27 s 
2023-08-08 21:29:18.957107:  
2023-08-08 21:29:18.957203: Epoch 1949 
2023-08-08 21:29:18.957278: Current learning rate: 4e-05 
2023-08-08 21:30:23.370682: train_loss -0.4293 
2023-08-08 21:30:23.370847: val_loss -0.4975 
2023-08-08 21:30:23.370900: Pseudo dice [0.9143] 
2023-08-08 21:30:23.370951: Epoch time: 64.41 s 
2023-08-08 21:30:24.872663:  
2023-08-08 21:30:24.872760: Epoch 1950 
2023-08-08 21:30:24.872846: Current learning rate: 4e-05 
2023-08-08 21:31:29.216808: train_loss -0.4442 
2023-08-08 21:31:29.216964: val_loss -0.4564 
2023-08-08 21:31:29.217016: Pseudo dice [0.8819] 
2023-08-08 21:31:29.217066: Epoch time: 64.34 s 
2023-08-08 21:31:30.309309:  
2023-08-08 21:31:30.309400: Epoch 1951 
2023-08-08 21:31:30.309488: Current learning rate: 4e-05 
2023-08-08 21:32:34.766128: train_loss -0.4435 
2023-08-08 21:32:34.766286: val_loss -0.4075 
2023-08-08 21:32:34.772094: Pseudo dice [0.9036] 
2023-08-08 21:32:34.772206: Epoch time: 64.46 s 
2023-08-08 21:32:36.199311:  
2023-08-08 21:32:36.199408: Epoch 1952 
2023-08-08 21:32:36.199481: Current learning rate: 3e-05 
2023-08-08 21:33:40.602649: train_loss -0.4394 
2023-08-08 21:33:40.602811: val_loss -0.4256 
2023-08-08 21:33:40.602865: Pseudo dice [0.8881] 
2023-08-08 21:33:40.602916: Epoch time: 64.4 s 
2023-08-08 21:33:41.732562:  
2023-08-08 21:33:41.732669: Epoch 1953 
2023-08-08 21:33:41.732745: Current learning rate: 3e-05 
2023-08-08 21:34:45.955848: train_loss -0.3799 
2023-08-08 21:34:45.956001: val_loss -0.4462 
2023-08-08 21:34:45.956052: Pseudo dice [0.8849] 
2023-08-08 21:34:45.956103: Epoch time: 64.22 s 
2023-08-08 21:34:47.072217:  
2023-08-08 21:34:47.072310: Epoch 1954 
2023-08-08 21:34:47.072400: Current learning rate: 3e-05 
2023-08-08 21:35:51.452720: train_loss -0.427 
2023-08-08 21:35:51.452885: val_loss -0.4518 
2023-08-08 21:35:51.452938: Pseudo dice [0.9153] 
2023-08-08 21:35:51.453007: Epoch time: 64.38 s 
2023-08-08 21:35:52.553217:  
2023-08-08 21:35:52.553419: Epoch 1955 
2023-08-08 21:35:52.553499: Current learning rate: 3e-05 
2023-08-08 21:36:56.979452: train_loss -0.4059 
2023-08-08 21:36:56.979613: val_loss -0.4622 
2023-08-08 21:36:56.979686: Pseudo dice [0.8985] 
2023-08-08 21:36:56.979737: Epoch time: 64.43 s 
2023-08-08 21:36:58.104079:  
2023-08-08 21:36:58.104172: Epoch 1956 
2023-08-08 21:36:58.104261: Current learning rate: 3e-05 
2023-08-08 21:38:02.592070: train_loss -0.4211 
2023-08-08 21:38:02.592219: val_loss -0.3397 
2023-08-08 21:38:02.592272: Pseudo dice [0.8774] 
2023-08-08 21:38:02.592322: Epoch time: 64.49 s 
2023-08-08 21:38:03.685412:  
2023-08-08 21:38:03.685510: Epoch 1957 
2023-08-08 21:38:03.685600: Current learning rate: 3e-05 
2023-08-08 21:39:08.003477: train_loss -0.397 
2023-08-08 21:39:08.003653: val_loss -0.4293 
2023-08-08 21:39:08.003707: Pseudo dice [0.8667] 
2023-08-08 21:39:08.003758: Epoch time: 64.32 s 
2023-08-08 21:39:09.184253:  
2023-08-08 21:39:09.184350: Epoch 1958 
2023-08-08 21:39:09.184426: Current learning rate: 3e-05 
2023-08-08 21:40:13.549427: train_loss -0.4402 
2023-08-08 21:40:13.549575: val_loss -0.4167 
2023-08-08 21:40:13.549626: Pseudo dice [0.8558] 
2023-08-08 21:40:13.549675: Epoch time: 64.37 s 
2023-08-08 21:40:14.664191:  
2023-08-08 21:40:14.664290: Epoch 1959 
2023-08-08 21:40:14.664365: Current learning rate: 3e-05 
2023-08-08 21:41:19.111012: train_loss -0.4276 
2023-08-08 21:41:19.111168: val_loss -0.4588 
2023-08-08 21:41:19.111221: Pseudo dice [0.8886] 
2023-08-08 21:41:19.111274: Epoch time: 64.45 s 
2023-08-08 21:41:20.211905:  
2023-08-08 21:41:20.211998: Epoch 1960 
2023-08-08 21:41:20.212072: Current learning rate: 3e-05 
2023-08-08 21:42:24.613846: train_loss -0.4006 
2023-08-08 21:42:24.613990: val_loss -0.3251 
2023-08-08 21:42:24.614043: Pseudo dice [0.8764] 
2023-08-08 21:42:24.614093: Epoch time: 64.4 s 
2023-08-08 21:42:25.893375:  
2023-08-08 21:42:25.893576: Epoch 1961 
2023-08-08 21:42:25.893658: Current learning rate: 3e-05 
2023-08-08 21:43:30.219083: train_loss -0.4352 
2023-08-08 21:43:30.219231: val_loss -0.3739 
2023-08-08 21:43:30.219299: Pseudo dice [0.8532] 
2023-08-08 21:43:30.219349: Epoch time: 64.33 s 
2023-08-08 21:43:31.319197:  
2023-08-08 21:43:31.319296: Epoch 1962 
2023-08-08 21:43:31.319385: Current learning rate: 3e-05 
2023-08-08 21:44:35.747428: train_loss -0.4043 
2023-08-08 21:44:35.747592: val_loss -0.4545 
2023-08-08 21:44:35.747664: Pseudo dice [0.8855] 
2023-08-08 21:44:35.747715: Epoch time: 64.43 s 
2023-08-08 21:44:36.862071:  
2023-08-08 21:44:36.862172: Epoch 1963 
2023-08-08 21:44:36.862304: Current learning rate: 3e-05 
2023-08-08 21:45:41.403847: train_loss -0.4352 
2023-08-08 21:45:41.403997: val_loss -0.3869 
2023-08-08 21:45:41.404050: Pseudo dice [0.8962] 
2023-08-08 21:45:41.404100: Epoch time: 64.54 s 
2023-08-08 21:45:42.519856:  
2023-08-08 21:45:42.519954: Epoch 1964 
2023-08-08 21:45:42.520029: Current learning rate: 3e-05 
2023-08-08 21:46:46.988929: train_loss -0.4369 
2023-08-08 21:46:46.989083: val_loss -0.478 
2023-08-08 21:46:46.989162: Pseudo dice [0.9413] 
2023-08-08 21:46:46.989228: Epoch time: 64.47 s 
2023-08-08 21:46:48.100163:  
2023-08-08 21:46:48.100258: Epoch 1965 
2023-08-08 21:46:48.100329: Current learning rate: 3e-05 
2023-08-08 21:47:52.505397: train_loss -0.4282 
2023-08-08 21:47:52.505542: val_loss -0.4107 
2023-08-08 21:47:52.505611: Pseudo dice [0.8733] 
2023-08-08 21:47:52.505661: Epoch time: 64.41 s 
2023-08-08 21:47:53.632243:  
2023-08-08 21:47:53.632342: Epoch 1966 
2023-08-08 21:47:53.632416: Current learning rate: 3e-05 
2023-08-08 21:48:58.042094: train_loss -0.4347 
2023-08-08 21:48:58.042250: val_loss -0.411 
2023-08-08 21:48:58.042318: Pseudo dice [0.9372] 
2023-08-08 21:48:58.042367: Epoch time: 64.41 s 
2023-08-08 21:48:59.302351:  
2023-08-08 21:48:59.302454: Epoch 1967 
2023-08-08 21:48:59.302526: Current learning rate: 2e-05 
2023-08-08 21:50:03.629588: train_loss -0.4263 
2023-08-08 21:50:03.629744: val_loss -0.4348 
2023-08-08 21:50:03.629799: Pseudo dice [0.9584] 
2023-08-08 21:50:03.629867: Epoch time: 64.33 s 
2023-08-08 21:50:04.744985:  
2023-08-08 21:50:04.745084: Epoch 1968 
2023-08-08 21:50:04.745172: Current learning rate: 2e-05 
2023-08-08 21:51:08.967546: train_loss -0.4496 
2023-08-08 21:51:08.967697: val_loss -0.3744 
2023-08-08 21:51:08.967749: Pseudo dice [0.8409] 
2023-08-08 21:51:08.967799: Epoch time: 64.22 s 
2023-08-08 21:51:10.079849:  
2023-08-08 21:51:10.080029: Epoch 1969 
2023-08-08 21:51:10.080125: Current learning rate: 2e-05 
2023-08-08 21:52:14.563250: train_loss -0.4243 
2023-08-08 21:52:14.563404: val_loss -0.4426 
2023-08-08 21:52:14.563454: Pseudo dice [0.9042] 
2023-08-08 21:52:14.563505: Epoch time: 64.48 s 
2023-08-08 21:52:15.657604:  
2023-08-08 21:52:15.657698: Epoch 1970 
2023-08-08 21:52:15.657772: Current learning rate: 2e-05 
2023-08-08 21:53:19.961894: train_loss -0.3858 
2023-08-08 21:53:19.962063: val_loss -0.4381 
2023-08-08 21:53:19.970454: Pseudo dice [0.9055] 
2023-08-08 21:53:19.970600: Epoch time: 64.3 s 
2023-08-08 21:53:21.081750:  
2023-08-08 21:53:21.081842: Epoch 1971 
2023-08-08 21:53:21.081912: Current learning rate: 2e-05 
2023-08-08 21:54:25.535674: train_loss -0.4101 
2023-08-08 21:54:25.535830: val_loss -0.3493 
2023-08-08 21:54:25.535884: Pseudo dice [0.9093] 
2023-08-08 21:54:25.535935: Epoch time: 64.45 s 
2023-08-08 21:54:26.837439:  
2023-08-08 21:54:26.837536: Epoch 1972 
2023-08-08 21:54:26.837610: Current learning rate: 2e-05 
2023-08-08 21:55:31.464975: train_loss -0.4027 
2023-08-08 21:55:31.465126: val_loss -0.4031 
2023-08-08 21:55:31.465182: Pseudo dice [0.8969] 
2023-08-08 21:55:31.465233: Epoch time: 64.63 s 
2023-08-08 21:55:32.616489:  
2023-08-08 21:55:32.616589: Epoch 1973 
2023-08-08 21:55:32.616679: Current learning rate: 2e-05 
2023-08-08 21:56:37.071263: train_loss -0.4667 
2023-08-08 21:56:37.071414: val_loss -0.4297 
2023-08-08 21:56:37.071467: Pseudo dice [0.8935] 
2023-08-08 21:56:37.071517: Epoch time: 64.46 s 
2023-08-08 21:56:38.158748:  
2023-08-08 21:56:38.158846: Epoch 1974 
2023-08-08 21:56:38.158919: Current learning rate: 2e-05 
2023-08-08 21:57:42.434829: train_loss -0.4249 
2023-08-08 21:57:42.434982: val_loss -0.457 
2023-08-08 21:57:42.435054: Pseudo dice [0.8991] 
2023-08-08 21:57:42.435105: Epoch time: 64.28 s 
2023-08-08 21:57:43.539481:  
2023-08-08 21:57:43.539594: Epoch 1975 
2023-08-08 21:57:43.539668: Current learning rate: 2e-05 
2023-08-08 21:58:47.955794: train_loss -0.4221 
2023-08-08 21:58:47.955944: val_loss -0.4743 
2023-08-08 21:58:47.956011: Pseudo dice [0.9127] 
2023-08-08 21:58:47.956060: Epoch time: 64.42 s 
2023-08-08 21:58:49.084656:  
2023-08-08 21:58:49.084765: Epoch 1976 
2023-08-08 21:58:49.084839: Current learning rate: 2e-05 
2023-08-08 21:59:53.498980: train_loss -0.4624 
2023-08-08 21:59:53.499140: val_loss -0.4254 
2023-08-08 21:59:53.499219: Pseudo dice [0.9097] 
2023-08-08 21:59:53.499285: Epoch time: 64.42 s 
2023-08-08 21:59:54.749374:  
2023-08-08 21:59:54.749475: Epoch 1977 
2023-08-08 21:59:54.749569: Current learning rate: 2e-05 
2023-08-08 22:00:59.262946: train_loss -0.4292 
2023-08-08 22:00:59.263108: val_loss -0.3836 
2023-08-08 22:00:59.263159: Pseudo dice [0.8812] 
2023-08-08 22:00:59.263226: Epoch time: 64.51 s 
2023-08-08 22:01:00.377726:  
2023-08-08 22:01:00.377823: Epoch 1978 
2023-08-08 22:01:00.377897: Current learning rate: 2e-05 
2023-08-08 22:02:04.798509: train_loss -0.4119 
2023-08-08 22:02:04.798664: val_loss -0.4801 
2023-08-08 22:02:04.798715: Pseudo dice [0.8852] 
2023-08-08 22:02:04.798783: Epoch time: 64.42 s 
2023-08-08 22:02:05.922229:  
2023-08-08 22:02:05.922334: Epoch 1979 
2023-08-08 22:02:05.922424: Current learning rate: 2e-05 
2023-08-08 22:03:10.133145: train_loss -0.414 
2023-08-08 22:03:10.133307: val_loss -0.4146 
2023-08-08 22:03:10.133363: Pseudo dice [0.9013] 
2023-08-08 22:03:10.133413: Epoch time: 64.21 s 
2023-08-08 22:03:11.232428:  
2023-08-08 22:03:11.232531: Epoch 1980 
2023-08-08 22:03:11.232605: Current learning rate: 2e-05 
2023-08-08 22:04:15.499050: train_loss -0.4378 
2023-08-08 22:04:15.499205: val_loss -0.5336 
2023-08-08 22:04:15.499279: Pseudo dice [0.9065] 
2023-08-08 22:04:15.499330: Epoch time: 64.27 s 
2023-08-08 22:04:16.681108:  
2023-08-08 22:04:16.681210: Epoch 1981 
2023-08-08 22:04:16.681301: Current learning rate: 2e-05 
2023-08-08 22:05:21.201513: train_loss -0.4016 
2023-08-08 22:05:21.201666: val_loss -0.4527 
2023-08-08 22:05:21.201723: Pseudo dice [0.925] 
2023-08-08 22:05:21.201776: Epoch time: 64.52 s 
2023-08-08 22:05:22.323169:  
2023-08-08 22:05:22.323264: Epoch 1982 
2023-08-08 22:05:22.323353: Current learning rate: 1e-05 
2023-08-08 22:06:26.725496: train_loss -0.42 
2023-08-08 22:06:26.725652: val_loss -0.4191 
2023-08-08 22:06:26.725702: Pseudo dice [0.9036] 
2023-08-08 22:06:26.725754: Epoch time: 64.4 s 
2023-08-08 22:06:27.992693:  
2023-08-08 22:06:27.992798: Epoch 1983 
2023-08-08 22:06:27.992874: Current learning rate: 1e-05 
2023-08-08 22:07:32.631144: train_loss -0.4326 
2023-08-08 22:07:32.631293: val_loss -0.4341 
2023-08-08 22:07:32.631347: Pseudo dice [0.908] 
2023-08-08 22:07:32.631398: Epoch time: 64.64 s 
2023-08-08 22:07:33.800847:  
2023-08-08 22:07:33.800939: Epoch 1984 
2023-08-08 22:07:33.801031: Current learning rate: 1e-05 
2023-08-08 22:08:38.341210: train_loss -0.4412 
2023-08-08 22:08:38.341360: val_loss -0.41 
2023-08-08 22:08:38.341413: Pseudo dice [0.8681] 
2023-08-08 22:08:38.341464: Epoch time: 64.54 s 
2023-08-08 22:08:39.434380:  
2023-08-08 22:08:39.434479: Epoch 1985 
2023-08-08 22:08:39.434548: Current learning rate: 1e-05 
2023-08-08 22:09:44.012585: train_loss -0.4617 
2023-08-08 22:09:44.012728: val_loss -0.4014 
2023-08-08 22:09:44.012780: Pseudo dice [0.8715] 
2023-08-08 22:09:44.012829: Epoch time: 64.58 s 
2023-08-08 22:09:45.148682:  
2023-08-08 22:09:45.148795: Epoch 1986 
2023-08-08 22:09:45.148883: Current learning rate: 1e-05 
2023-08-08 22:10:49.641329: train_loss -0.4537 
2023-08-08 22:10:49.641473: val_loss -0.4509 
2023-08-08 22:10:49.641523: Pseudo dice [0.924] 
2023-08-08 22:10:49.641589: Epoch time: 64.49 s 
2023-08-08 22:10:50.737046:  
2023-08-08 22:10:50.737142: Epoch 1987 
2023-08-08 22:10:50.737229: Current learning rate: 1e-05 
2023-08-08 22:11:55.121124: train_loss -0.4321 
2023-08-08 22:11:55.121268: val_loss -0.3457 
2023-08-08 22:11:55.121318: Pseudo dice [0.9388] 
2023-08-08 22:11:55.121384: Epoch time: 64.38 s 
2023-08-08 22:11:56.368590:  
2023-08-08 22:11:56.368688: Epoch 1988 
2023-08-08 22:11:56.368784: Current learning rate: 1e-05 
2023-08-08 22:13:00.810683: train_loss -0.4355 
2023-08-08 22:13:00.810827: val_loss -0.4329 
2023-08-08 22:13:00.810877: Pseudo dice [0.9466] 
2023-08-08 22:13:00.810927: Epoch time: 64.44 s 
2023-08-08 22:13:01.911500:  
2023-08-08 22:13:01.911621: Epoch 1989 
2023-08-08 22:13:01.911697: Current learning rate: 1e-05 
2023-08-08 22:14:06.092416: train_loss -0.4473 
2023-08-08 22:14:06.092572: val_loss -0.4984 
2023-08-08 22:14:06.092625: Pseudo dice [0.9295] 
2023-08-08 22:14:06.092677: Epoch time: 64.18 s 
2023-08-08 22:14:06.092717: Yayy! New best EMA pseudo Dice: 0.9094 
2023-08-08 22:14:07.651353:  
2023-08-08 22:14:07.651455: Epoch 1990 
2023-08-08 22:14:07.651530: Current learning rate: 1e-05 
2023-08-08 22:15:12.012668: train_loss -0.4104 
2023-08-08 22:15:12.012840: val_loss -0.3527 
2023-08-08 22:15:12.012911: Pseudo dice [0.8602] 
2023-08-08 22:15:12.012960: Epoch time: 64.36 s 
2023-08-08 22:15:13.114454:  
2023-08-08 22:15:13.114556: Epoch 1991 
2023-08-08 22:15:13.114629: Current learning rate: 1e-05 
2023-08-08 22:16:17.526349: train_loss -0.4488 
2023-08-08 22:16:17.526499: val_loss -0.4164 
2023-08-08 22:16:17.526550: Pseudo dice [0.9081] 
2023-08-08 22:16:17.526601: Epoch time: 64.41 s 
2023-08-08 22:16:18.634617:  
2023-08-08 22:16:18.634714: Epoch 1992 
2023-08-08 22:16:18.634798: Current learning rate: 1e-05 
2023-08-08 22:17:23.256169: train_loss -0.4547 
2023-08-08 22:17:23.256326: val_loss -0.4048 
2023-08-08 22:17:23.256390: Pseudo dice [0.93] 
2023-08-08 22:17:23.256440: Epoch time: 64.62 s 
2023-08-08 22:17:24.527972:  
2023-08-08 22:17:24.528078: Epoch 1993 
2023-08-08 22:17:24.528166: Current learning rate: 1e-05 
2023-08-08 22:18:28.884329: train_loss -0.4271 
2023-08-08 22:18:28.884476: val_loss -0.4776 
2023-08-08 22:18:28.884531: Pseudo dice [0.9024] 
2023-08-08 22:18:28.884582: Epoch time: 64.36 s 
2023-08-08 22:18:29.997631:  
2023-08-08 22:18:29.997730: Epoch 1994 
2023-08-08 22:18:29.997803: Current learning rate: 1e-05 
2023-08-08 22:19:34.375622: train_loss -0.408 
2023-08-08 22:19:34.375762: val_loss -0.4719 
2023-08-08 22:19:34.375813: Pseudo dice [0.9009] 
2023-08-08 22:19:34.375867: Epoch time: 64.38 s 
2023-08-08 22:19:35.478348:  
2023-08-08 22:19:35.478445: Epoch 1995 
2023-08-08 22:19:35.478548: Current learning rate: 0.0 
2023-08-08 22:20:39.958746: train_loss -0.4267 
2023-08-08 22:20:39.958900: val_loss -0.3977 
2023-08-08 22:20:39.958969: Pseudo dice [0.8729] 
2023-08-08 22:20:39.959021: Epoch time: 64.48 s 
2023-08-08 22:20:41.053779:  
2023-08-08 22:20:41.053875: Epoch 1996 
2023-08-08 22:20:41.053944: Current learning rate: 0.0 
2023-08-08 22:21:45.547519: train_loss -0.4065 
2023-08-08 22:21:45.547688: val_loss -0.3994 
2023-08-08 22:21:45.547741: Pseudo dice [0.8667] 
2023-08-08 22:21:45.547791: Epoch time: 64.49 s 
2023-08-08 22:21:46.648166:  
2023-08-08 22:21:46.648265: Epoch 1997 
2023-08-08 22:21:46.648355: Current learning rate: 0.0 
2023-08-08 22:22:50.878801: train_loss -0.3922 
2023-08-08 22:22:50.878957: val_loss -0.4827 
2023-08-08 22:22:50.879006: Pseudo dice [0.9022] 
2023-08-08 22:22:50.879073: Epoch time: 64.23 s 
2023-08-08 22:22:51.985466:  
2023-08-08 22:22:51.985563: Epoch 1998 
2023-08-08 22:22:51.985635: Current learning rate: 0.0 
2023-08-08 22:23:56.252412: train_loss -0.462 
2023-08-08 22:23:56.252563: val_loss -0.4595 
2023-08-08 22:23:56.252613: Pseudo dice [0.8986] 
2023-08-08 22:23:56.252663: Epoch time: 64.27 s 
2023-08-08 22:23:57.558931:  
2023-08-08 22:23:57.559035: Epoch 1999 
2023-08-08 22:23:57.559124: Current learning rate: 0.0 
2023-08-08 22:25:01.907343: train_loss -0.4411 
2023-08-08 22:25:01.907494: val_loss -0.4015 
2023-08-08 22:25:01.907568: Pseudo dice [0.8788] 
2023-08-08 22:25:01.907620: Epoch time: 64.35 s 
2023-08-08 22:25:03.843839: predicting LUNG1-001 
2023-08-08 22:25:08.081876: predicting LUNG1-002 
2023-08-08 22:25:11.501916: predicting LUNG1-003 
2023-08-08 22:25:14.957771: predicting LUNG1-004 
2023-08-08 22:25:18.401860: predicting LUNG1-005 
2023-08-08 22:25:21.848000: predicting LUNG1-006 
2023-08-08 22:25:25.274666: predicting LUNG1-007 
2023-08-08 22:25:28.727150: predicting LUNG1-008 
2023-08-08 22:25:32.170348: predicting LUNG1-009 
2023-08-08 22:25:35.587792: predicting LUNG1-010 
2023-08-08 22:25:39.059982: predicting LUNG1-011 
2023-08-08 22:25:43.639760: predicting LUNG1-012 
2023-08-08 22:25:48.228221: predicting LUNG1-013 
2023-08-08 22:25:51.681683: predicting LUNG1-014 
2023-08-08 22:25:55.145459: predicting LUNG1-015 
2023-08-08 22:25:58.610758: predicting LUNG1-016 
2023-08-08 22:26:02.060822: predicting LUNG1-017 
2023-08-08 22:26:05.488023: predicting LUNG1-018 
2023-08-08 22:26:08.933099: predicting LUNG1-019 
2023-08-08 22:26:12.374299: predicting LUNG1-020 
2023-08-08 22:26:15.834869: predicting LUNG1-021 
2023-08-08 22:26:19.311597: predicting LUNG1-022 
2023-08-08 22:26:22.774806: predicting LUNG1-023 
2023-08-08 22:26:26.213897: predicting LUNG1-024 
2023-08-08 22:26:29.701951: predicting LUNG1-025 
2023-08-08 22:26:32.019355: predicting LUNG1-026 
2023-08-08 22:26:35.454508: predicting LUNG1-027 
2023-08-08 22:26:40.594031: predicting LUNG1-028 
2023-08-08 22:26:44.089066: predicting LUNG1-029 
2023-08-08 22:26:46.413321: predicting LUNG1-030 
2023-08-08 22:26:49.872819: predicting LUNG1-031 
2023-08-08 22:26:53.336829: predicting LUNG1-032 
2023-08-08 22:26:58.460379: predicting LUNG1-033 
2023-08-08 22:27:03.612733: predicting LUNG1-034 
2023-08-08 22:27:07.091012: predicting LUNG1-035 
2023-08-08 22:27:10.521741: predicting LUNG1-036 
2023-08-08 22:27:13.971952: predicting LUNG1-037 
2023-08-08 22:27:17.415565: predicting LUNG1-038 
2023-08-08 22:27:19.733515: predicting LUNG1-039 
2023-08-08 22:27:23.180627: predicting LUNG1-040 
2023-08-08 22:27:25.487649: predicting LUNG1-041 
2023-08-08 22:27:27.812439: predicting LUNG1-042 
2023-08-08 22:27:31.242344: predicting LUNG1-043 
2023-08-08 22:27:34.694616: predicting LUNG1-044 
2023-08-08 22:27:37.019910: predicting LUNG1-045 
2023-08-08 22:27:39.320145: predicting LUNG1-046 
2023-08-08 22:27:42.762765: predicting LUNG1-047 
2023-08-08 22:27:46.211731: predicting LUNG1-048 
2023-08-08 22:27:48.524188: predicting LUNG1-049 
2023-08-08 22:27:51.967420: predicting LUNG1-050 
2023-08-08 22:27:55.449994: predicting LUNG1-051 
2023-08-08 22:28:00.580505: predicting LUNG1-052 
2023-08-08 22:28:04.023649: predicting LUNG1-053 
2023-08-08 22:28:07.484615: predicting LUNG1-054 
2023-08-08 22:28:10.892834: predicting LUNG1-055 
2023-08-08 22:28:14.351285: predicting LUNG1-056 
2023-08-08 22:28:16.649524: predicting LUNG1-057 
2023-08-08 22:28:20.092575: predicting LUNG1-058 
2023-08-08 22:28:25.213491: predicting LUNG1-059 
2023-08-08 22:28:28.678346: predicting LUNG1-060 
2023-08-08 22:28:33.247887: predicting LUNG1-061 
2023-08-08 22:28:36.698531: predicting LUNG1-062 
2023-08-08 22:28:39.030600: predicting LUNG1-063 
2023-08-08 22:28:41.330014: predicting LUNG1-064 
2023-08-08 22:28:44.766300: predicting LUNG1-065 
2023-08-08 22:28:47.104369: predicting LUNG1-066 
2023-08-08 22:28:50.537124: predicting LUNG1-067 
2023-08-08 22:28:53.975465: predicting LUNG1-068 
2023-08-08 22:28:57.425157: predicting LUNG1-069 
2023-08-08 22:29:00.837271: predicting LUNG1-070 
2023-08-08 22:29:04.287314: predicting LUNG1-071 
2023-08-08 22:29:07.741739: predicting LUNG1-072 
2023-08-08 22:29:11.165251: predicting LUNG1-073 
2023-08-08 22:29:14.612688: predicting LUNG1-074 
2023-08-08 22:29:18.069862: predicting LUNG1-075 
2023-08-08 22:29:20.373895: predicting LUNG1-076 
2023-08-08 22:29:23.815793: predicting LUNG1-077 
2023-08-08 22:29:27.241146: predicting LUNG1-078 
2023-08-08 22:29:30.673156: predicting LUNG1-079 
2023-08-08 22:29:34.152497: predicting LUNG1-080 
2023-08-08 22:29:37.587050: predicting LUNG1-081 
2023-08-08 22:29:42.703799: predicting LUNG1-082 
2023-08-08 22:29:46.163380: predicting LUNG1-083 
2023-08-08 22:29:51.310343: predicting LUNG1-084 
2023-08-08 22:29:53.644672: predicting LUNG1-085 
2023-08-08 22:29:55.933478: predicting LUNG1-086 
2023-08-08 22:29:59.391430: predicting LUNG1-087 
2023-08-08 22:30:02.838780: predicting LUNG1-088 
2023-08-08 22:30:07.974081: predicting LUNG1-089 
2023-08-08 22:30:10.281672: predicting LUNG1-090 
2023-08-08 22:30:15.397130: predicting LUNG1-091 
2023-08-08 22:30:17.735143: predicting LUNG1-092 
2023-08-08 22:30:21.148674: predicting LUNG1-093 
2023-08-08 22:30:24.578146: predicting LUNG1-094 
2023-08-08 22:30:26.895717: predicting LUNG1-095 
2023-08-08 22:30:29.179605: predicting LUNG1-096 
2023-08-08 22:30:32.629489: predicting LUNG1-097 
2023-08-08 22:30:36.068563: predicting LUNG1-098 
2023-08-08 22:30:39.528199: predicting LUNG1-099 
2023-08-08 22:30:42.975754: predicting LUNG1-100 
2023-08-08 22:30:46.418979: predicting LUNG1-101 
2023-08-08 22:30:48.740389: predicting LUNG1-102 
2023-08-08 22:30:52.177398: predicting LUNG1-103 
2023-08-08 22:30:55.611610: predicting LUNG1-104 
2023-08-08 22:30:59.047658: predicting LUNG1-105 
2023-08-08 22:31:01.339271: predicting LUNG1-106 
2023-08-08 22:31:04.782619: predicting LUNG1-107 
2023-08-08 22:31:08.204923: predicting LUNG1-108 
2023-08-08 22:31:11.642317: predicting LUNG1-109 
2023-08-08 22:31:15.088823: predicting LUNG1-110 
2023-08-08 22:31:17.397810: predicting LUNG1-111 
2023-08-08 22:31:20.812528: predicting LUNG1-112 
2023-08-08 22:31:24.249621: predicting LUNG1-113 
2023-08-08 22:31:27.738904: predicting LUNG1-114 
2023-08-08 22:31:31.168549: predicting LUNG1-115 
2023-08-08 22:31:34.602746: predicting LUNG1-116 
2023-08-08 22:31:38.053871: predicting LUNG1-117 
2023-08-08 22:31:41.505493: predicting LUNG1-118 
2023-08-08 22:31:44.949738: predicting LUNG1-119 
2023-08-08 22:31:47.277257: predicting LUNG1-120 
2023-08-08 22:31:50.727758: predicting LUNG1-121 
2023-08-08 22:31:54.172412: predicting LUNG1-122 
2023-08-08 22:31:57.627378: predicting LUNG1-123 
2023-08-08 22:32:01.050741: predicting LUNG1-124 
2023-08-08 22:32:04.515425: predicting LUNG1-125 
2023-08-08 22:32:07.957863: predicting LUNG1-126 
2023-08-08 22:32:11.382352: predicting LUNG1-127 
2023-08-08 22:32:13.697995: predicting LUNG1-129 
2023-08-08 22:32:17.130875: predicting LUNG1-130 
2023-08-08 22:32:20.553820: predicting LUNG1-131 
2023-08-08 22:32:24.001215: predicting LUNG1-132 
2023-08-08 22:32:27.444522: predicting LUNG1-133 
2023-08-08 22:32:30.853862: predicting LUNG1-134 
2023-08-08 22:32:34.311169: predicting LUNG1-135 
2023-08-08 22:32:37.766029: predicting LUNG1-136 
2023-08-08 22:32:41.185738: predicting LUNG1-137 
2023-08-08 22:32:44.638244: predicting LUNG1-138 
2023-08-08 22:32:46.951105: predicting LUNG1-139 
2023-08-08 22:32:50.396422: predicting LUNG1-140 
2023-08-08 22:32:52.708921: predicting LUNG1-141 
2023-08-08 22:32:54.994353: predicting LUNG1-142 
2023-08-08 22:32:58.446229: predicting LUNG1-143 
2023-08-08 22:33:00.745304: predicting LUNG1-144 
2023-08-08 22:33:04.196411: predicting LUNG1-145 
2023-08-08 22:33:07.628201: predicting LUNG1-146 
2023-08-08 22:33:11.037122: predicting LUNG1-147 
2023-08-08 22:33:14.502252: predicting LUNG1-148 
2023-08-08 22:33:17.930351: predicting LUNG1-149 
2023-08-08 22:33:21.356366: predicting LUNG1-150 
2023-08-08 22:33:26.485619: predicting LUNG1-151 
2023-08-08 22:33:31.624543: predicting LUNG1-152 
2023-08-08 22:33:36.754938: predicting LUNG1-153 
2023-08-08 22:33:37.938573: predicting LUNG1-154 
2023-08-08 22:33:41.345602: predicting LUNG1-155 
2023-08-08 22:33:43.674239: predicting LUNG1-156 
2023-08-08 22:33:47.113503: predicting LUNG1-157 
2023-08-08 22:33:50.542290: predicting LUNG1-158 
2023-08-08 22:33:53.975646: predicting LUNG1-159 
2023-08-08 22:33:57.413547: predicting LUNG1-160 
2023-08-08 22:34:02.530037: predicting LUNG1-161 
2023-08-08 22:34:07.682256: predicting LUNG1-162 
2023-08-08 22:34:11.133024: predicting LUNG1-163 
2023-08-08 22:34:13.447679: predicting LUNG1-164 
2023-08-08 22:34:16.872473: predicting LUNG1-165 
2023-08-08 22:34:19.168374: predicting LUNG1-166 
2023-08-08 22:34:22.627401: predicting LUNG1-167 
2023-08-08 22:34:26.042566: predicting LUNG1-168 
2023-08-08 22:34:29.481107: predicting LUNG1-169 
2023-08-08 22:34:32.912151: predicting LUNG1-170 
2023-08-08 22:34:36.323802: predicting LUNG1-171 
2023-08-08 22:34:39.784807: predicting LUNG1-172 
2023-08-08 22:34:42.097632: predicting LUNG1-173 
2023-08-08 22:34:45.511036: predicting LUNG1-174 
2023-08-08 22:34:48.946244: predicting LUNG1-175 
2023-08-08 22:34:52.381822: predicting LUNG1-176 
2023-08-08 22:34:54.664576: predicting LUNG1-177 
2023-08-08 22:34:56.983759: predicting LUNG1-178 
2023-08-08 22:35:00.403582: predicting LUNG1-179 
2023-08-08 22:35:03.841851: predicting LUNG1-180 
2023-08-08 22:35:07.284795: predicting LUNG1-181 
2023-08-08 22:35:10.710455: predicting LUNG1-182 
2023-08-08 22:35:14.190952: predicting LUNG1-183 
2023-08-08 22:35:17.629346: predicting LUNG1-184 
2023-08-08 22:35:22.747184: predicting LUNG1-185 
2023-08-08 22:35:26.188672: predicting LUNG1-186 
2023-08-08 22:35:29.622786: predicting LUNG1-187 
2023-08-08 22:35:31.941832: predicting LUNG1-188 
2023-08-08 22:35:35.371174: predicting LUNG1-189 
2023-08-08 22:35:38.825333: predicting LUNG1-190 
2023-08-08 22:35:42.262523: predicting LUNG1-191 
2023-08-08 22:35:45.686620: predicting LUNG1-192 
2023-08-08 22:35:49.146336: predicting LUNG1-193 
2023-08-08 22:35:52.610703: predicting LUNG1-194 
2023-08-08 22:35:56.030274: predicting LUNG1-195 
2023-08-08 22:35:58.362181: predicting LUNG1-196 
2023-08-08 22:36:00.648478: predicting LUNG1-197 
2023-08-08 22:36:02.976082: predicting LUNG1-198 
2023-08-08 22:36:06.405162: predicting LUNG1-199 
2023-08-08 22:36:09.853475: predicting LUNG1-200 
2023-08-08 22:36:13.300484: predicting LUNG1-201 
2023-08-08 22:36:16.738485: predicting LUNG1-202 
2023-08-08 22:36:19.047210: predicting LUNG1-203 
2023-08-08 22:36:22.490125: predicting LUNG1-204 
2023-08-08 22:36:25.899296: predicting LUNG1-205 
2023-08-08 22:36:29.337317: predicting LUNG1-206 
2023-08-08 22:36:32.765961: predicting LUNG1-207 
2023-08-08 22:36:36.182755: predicting LUNG1-208 
2023-08-08 22:36:39.665990: predicting LUNG1-209 
2023-08-08 22:36:44.804608: predicting LUNG1-210 
2023-08-08 22:36:49.982415: predicting LUNG1-211 
2023-08-08 22:36:53.432532: predicting LUNG1-212 
2023-08-08 22:36:56.866358: predicting LUNG1-213 
2023-08-08 22:36:59.157905: predicting LUNG1-214 
2023-08-08 22:37:02.616086: predicting LUNG1-215 
2023-08-08 22:37:04.355123: predicting LUNG1-216 
2023-08-08 22:37:07.795447: predicting LUNG1-217 
2023-08-08 22:37:10.094375: predicting LUNG1-218 
2023-08-08 22:37:12.394802: predicting LUNG1-219 
2023-08-08 22:37:14.681116: predicting LUNG1-220 
2023-08-08 22:37:16.994289: predicting LUNG1-221 
2023-08-08 22:37:20.397817: predicting LUNG1-222 
2023-08-08 22:37:23.826301: predicting LUNG1-223 
2023-08-08 22:37:26.129878: predicting LUNG1-224 
2023-08-08 22:37:28.461685: predicting LUNG1-225 
2023-08-08 22:37:31.893928: predicting LUNG1-226 
2023-08-08 22:37:35.300803: predicting LUNG1-227 
2023-08-08 22:37:38.756717: predicting LUNG1-228 
2023-08-08 22:37:41.047420: predicting LUNG1-229 
2023-08-08 22:37:44.485929: predicting LUNG1-230 
2023-08-08 22:37:47.930382: predicting LUNG1-231 
2023-08-08 22:37:50.224346: predicting LUNG1-232 
2023-08-08 22:37:53.658011: predicting LUNG1-233 
2023-08-08 22:37:57.096155: predicting LUNG1-234 
2023-08-08 22:37:59.382362: predicting LUNG1-235 
2023-08-08 22:38:01.677893: predicting LUNG1-236 
2023-08-08 22:38:03.976747: predicting LUNG1-237 
2023-08-08 22:38:07.406516: predicting LUNG1-238 
2023-08-08 22:38:10.843492: predicting LUNG1-239 
2023-08-08 22:38:14.288281: predicting LUNG1-240 
2023-08-08 22:38:17.730144: predicting LUNG1-241 
2023-08-08 22:38:21.198499: predicting LUNG1-242 
2023-08-08 22:38:24.650397: predicting LUNG1-243 
2023-08-08 22:38:28.086582: predicting LUNG1-244 
2023-08-08 22:38:31.510857: predicting LUNG1-245 
2023-08-08 22:38:34.956554: predicting LUNG1-246 
2023-08-08 22:38:37.271993: predicting LUNG1-247 
2023-08-08 22:38:39.554697: predicting LUNG1-248 
2023-08-08 22:38:41.857387: predicting LUNG1-249 
2023-08-08 22:38:45.301416: predicting LUNG1-250 
2023-08-08 22:38:48.821812: predicting LUNG1-251 
2023-08-08 22:38:51.206105: predicting LUNG1-252 
2023-08-08 22:38:54.665709: predicting LUNG1-253 
2023-08-08 22:38:59.822923: predicting LUNG1-254 
2023-08-08 22:39:02.169373: predicting LUNG1-255 
2023-08-08 22:39:05.627938: predicting LUNG1-256 
2023-08-08 22:39:07.977111: predicting LUNG1-257 
2023-08-08 22:39:11.416794: predicting LUNG1-258 
2023-08-08 22:39:14.861238: predicting LUNG1-259 
2023-08-08 22:39:17.260102: predicting LUNG1-260 
2023-08-08 22:39:20.693428: predicting LUNG1-261 
2023-08-08 22:39:23.031755: predicting LUNG1-262 
2023-08-08 22:39:25.314502: predicting LUNG1-263 
2023-08-08 22:39:28.752432: predicting LUNG1-264 
2023-08-08 22:39:32.228267: predicting LUNG1-265 
2023-08-08 22:39:37.354362: predicting LUNG1-266 
2023-08-08 22:39:40.796206: predicting LUNG1-267 
2023-08-08 22:39:44.242440: predicting LUNG1-268 
2023-08-08 22:39:49.392208: predicting LUNG1-269 
2023-08-08 22:39:52.849939: predicting LUNG1-270 
2023-08-08 22:39:56.265925: predicting LUNG1-271 
2023-08-08 22:40:00.850876: predicting LUNG1-272 
2023-08-08 22:40:04.315666: predicting LUNG1-273 
2023-08-08 22:40:09.446394: predicting LUNG1-274 
2023-08-08 22:40:12.890672: predicting LUNG1-275 
2023-08-08 22:40:16.302518: predicting LUNG1-276 
2023-08-08 22:40:19.750350: predicting LUNG1-277 
2023-08-08 22:40:22.076097: predicting LUNG1-278 
2023-08-08 22:40:25.512784: predicting LUNG1-279 
2023-08-08 22:40:28.970496: predicting LUNG1-280 
2023-08-08 22:40:32.437820: predicting LUNG1-281 
2023-08-08 22:40:35.871716: predicting LUNG1-282 
2023-08-08 22:40:39.314557: predicting LUNG1-283 
2023-08-08 22:40:41.605806: predicting LUNG1-284 
2023-08-08 22:40:45.041636: predicting LUNG1-285 
2023-08-08 22:40:48.487833: predicting LUNG1-286 
2023-08-08 22:40:51.917977: predicting LUNG1-287 
2023-08-08 22:40:54.219079: predicting LUNG1-288 
2023-08-08 22:40:57.649919: predicting LUNG1-289 
2023-08-08 22:41:01.082546: predicting LUNG1-290 
2023-08-08 22:41:04.522632: predicting LUNG1-291 
2023-08-08 22:41:07.965894: predicting LUNG1-292 
2023-08-08 22:41:11.373768: predicting LUNG1-293 
2023-08-08 22:41:14.822569: predicting LUNG1-294 
2023-08-08 22:41:18.272887: predicting LUNG1-295 
2023-08-08 22:41:21.696954: predicting LUNG1-296 
2023-08-08 22:41:25.135385: predicting LUNG1-297 
2023-08-08 22:41:28.569522: predicting LUNG1-298 
2023-08-08 22:41:32.008264: predicting LUNG1-299 
2023-08-08 22:41:35.448764: predicting LUNG1-300 
2023-08-08 22:41:40.570927: predicting LUNG1-301 
2023-08-08 22:41:44.045504: predicting LUNG1-302 
2023-08-08 22:41:47.492655: predicting LUNG1-303 
2023-08-08 22:41:52.697520: predicting LUNG1-304 
2023-08-08 22:41:53.889647: predicting LUNG1-305 
2023-08-08 22:41:55.626681: predicting LUNG1-306 
2023-08-08 22:41:57.930688: predicting LUNG1-307 
2023-08-08 22:42:00.228506: predicting LUNG1-308 
2023-08-08 22:42:03.683294: predicting LUNG1-309 
2023-08-08 22:42:07.112358: predicting LUNG1-310 
2023-08-08 22:42:09.441071: predicting LUNG1-311 
2023-08-08 22:42:14.568563: predicting LUNG1-312 
2023-08-08 22:42:19.693168: predicting LUNG1-313 
2023-08-08 22:42:23.175491: predicting LUNG1-314 
2023-08-08 22:42:24.929231: predicting LUNG1-315 
2023-08-08 22:42:27.241324: predicting LUNG1-316 
2023-08-08 22:42:29.542595: predicting LUNG1-317 
2023-08-08 22:42:32.984436: predicting LUNG1-318 
2023-08-08 22:42:36.407460: predicting LUNG1-319 
2023-08-08 22:42:39.857081: predicting LUNG1-320 
2023-08-08 22:42:43.274415: predicting LUNG1-321 
2023-08-08 22:42:48.426461: predicting LUNG1-322 
2023-08-08 22:42:53.596370: predicting LUNG1-323 
2023-08-08 22:42:57.060767: predicting LUNG1-324 
2023-08-08 22:42:59.355245: predicting LUNG1-325 
2023-08-08 22:43:02.804258: predicting LUNG1-326 
2023-08-08 22:43:06.243428: predicting LUNG1-327 
2023-08-08 22:43:08.546569: predicting LUNG1-328 
2023-08-08 22:43:13.652848: predicting LUNG1-329 
2023-08-08 22:43:15.973020: predicting LUNG1-330 
2023-08-08 22:43:19.411461: predicting LUNG1-331 
2023-08-08 22:43:22.883269: predicting LUNG1-332 
2023-08-08 22:43:28.017671: predicting LUNG1-333 
2023-08-08 22:43:31.482219: predicting LUNG1-334 
2023-08-08 22:43:33.806441: predicting LUNG1-335 
2023-08-08 22:43:37.231783: predicting LUNG1-336 
2023-08-08 22:43:40.646596: predicting LUNG1-337 
2023-08-08 22:43:42.969667: predicting LUNG1-338 
2023-08-08 22:43:46.389195: predicting LUNG1-339 
2023-08-08 22:43:51.555998: predicting LUNG1-340 
2023-08-08 22:43:55.041622: predicting LUNG1-341 
2023-08-08 22:43:58.494838: predicting LUNG1-342 
2023-08-08 22:44:00.800659: predicting LUNG1-343 
2023-08-08 22:44:04.249999: predicting LUNG1-344 
2023-08-08 22:44:07.688954: predicting LUNG1-345 
2023-08-08 22:44:11.120657: predicting LUNG1-346 
2023-08-08 22:44:13.433413: predicting LUNG1-347 
2023-08-08 22:44:15.736531: predicting LUNG1-348 
2023-08-08 22:44:19.178636: predicting LUNG1-349 
2023-08-08 22:44:22.626666: predicting LUNG1-350 
2023-08-08 22:44:23.806755: predicting LUNG1-351 
2023-08-08 22:44:26.101739: predicting LUNG1-352 
2023-08-08 22:44:29.532816: predicting LUNG1-353 
2023-08-08 22:44:33.016060: predicting LUNG1-354 
2023-08-08 22:44:35.303883: predicting LUNG1-355 
2023-08-08 22:44:37.634234: predicting LUNG1-356 
2023-08-08 22:44:41.047182: predicting LUNG1-357 
2023-08-08 22:44:44.490751: predicting LUNG1-358 
2023-08-08 22:44:46.791781: predicting LUNG1-359 
2023-08-08 22:44:49.090776: predicting LUNG1-360 
2023-08-08 22:44:52.533569: predicting LUNG1-361 
2023-08-08 22:44:55.954312: predicting LUNG1-362 
2023-08-08 22:44:59.419216: predicting LUNG1-363 
2023-08-08 22:45:02.854308: predicting LUNG1-364 
2023-08-08 22:45:05.146243: predicting LUNG1-365 
2023-08-08 22:45:08.575601: predicting LUNG1-366 
2023-08-08 22:45:12.029724: predicting LUNG1-367 
2023-08-08 22:45:18.849003: predicting LUNG1-368 
2023-08-08 22:45:22.336656: predicting LUNG1-369 
2023-08-08 22:45:24.641275: predicting LUNG1-370 
2023-08-08 22:45:29.782043: predicting LUNG1-371 
2023-08-08 22:45:33.270983: predicting LUNG1-372 
2023-08-08 22:45:35.574718: predicting LUNG1-373 
2023-08-08 22:45:39.006088: predicting LUNG1-374 
2023-08-08 22:45:43.586632: predicting LUNG1-375 
2023-08-08 22:45:45.921801: predicting LUNG1-376 
2023-08-08 22:45:49.348186: predicting LUNG1-377 
2023-08-08 22:45:54.467828: predicting LUNG1-378 
2023-08-08 22:45:57.964787: predicting LUNG1-379 
2023-08-08 22:46:00.250898: predicting LUNG1-380 
2023-08-08 22:46:03.702576: predicting LUNG1-381 
2023-08-08 22:46:06.005166: predicting LUNG1-382 
2023-08-08 22:46:09.435559: predicting LUNG1-383 
2023-08-08 22:46:16.273420: predicting LUNG1-384 
2023-08-08 22:46:19.762165: predicting LUNG1-385 
2023-08-08 22:46:23.193076: predicting LUNG1-386 
2023-08-08 22:46:26.599026: predicting LUNG1-387 
2023-08-08 22:46:28.910527: predicting LUNG1-388 
2023-08-08 22:46:32.362221: predicting LUNG1-389 
2023-08-08 22:46:35.807293: predicting LUNG1-390 
2023-08-08 22:46:40.937813: predicting LUNG1-391 
2023-08-08 22:46:44.395503: predicting LUNG1-392 
2023-08-08 22:46:47.824928: predicting LUNG1-393 
2023-08-08 22:46:52.975763: predicting LUNG1-394 
2023-08-08 22:46:56.432497: predicting LUNG1-395 
2023-08-08 22:46:59.885486: predicting LUNG1-396 
2023-08-08 22:47:02.204420: predicting LUNG1-397 
2023-08-08 22:47:04.512307: predicting LUNG1-398 
2023-08-08 22:47:07.949177: predicting LUNG1-399 
2023-08-08 22:47:10.264570: predicting LUNG1-400 
2023-08-08 22:47:13.713965: predicting LUNG1-401 
2023-08-08 22:47:18.821298: predicting LUNG1-402 
2023-08-08 22:47:23.995347: predicting LUNG1-403 
2023-08-08 22:47:26.312839: predicting LUNG1-404 
2023-08-08 22:47:29.742288: predicting LUNG1-405 
2023-08-08 22:47:33.216397: predicting LUNG1-406 
2023-08-08 22:47:36.631847: predicting LUNG1-407 
2023-08-08 22:47:40.087190: predicting LUNG1-408 
2023-08-08 22:47:42.418676: predicting LUNG1-409 
2023-08-08 22:47:45.823616: predicting LUNG1-410 
2023-08-08 22:47:49.286404: predicting LUNG1-411 
2023-08-08 22:47:52.731993: predicting LUNG1-412 
2023-08-08 22:47:57.861107: predicting LUNG1-413 
2023-08-08 22:48:00.181436: predicting LUNG1-414 
2023-08-08 22:48:03.615740: predicting LUNG1-415 
2023-08-08 22:48:07.049627: predicting LUNG1-416 
2023-08-08 22:48:10.463840: predicting LUNG1-417 
2023-08-08 22:48:13.908904: predicting LUNG1-418 
2023-08-08 22:48:17.372805: predicting LUNG1-419 
2023-08-08 22:48:20.805056: predicting LUNG1-420 
2023-08-08 22:48:24.275877: predicting LUNG1-421 
2023-08-08 22:48:26.565652: predicting LUNG1-422 
2023-08-08 22:48:30.010703: predicting MED_LYMPH_001 
2023-08-08 22:48:35.154374: predicting MED_LYMPH_002 
2023-08-08 22:48:38.692536: predicting MED_LYMPH_003 
2023-08-08 22:48:43.885261: predicting MED_LYMPH_004 
2023-08-08 22:48:47.408692: predicting MED_LYMPH_005 
2023-08-08 22:48:50.899729: predicting MED_LYMPH_006 
2023-08-08 22:48:54.408822: predicting MED_LYMPH_007 
2023-08-08 22:48:56.743762: predicting MED_LYMPH_008 
2023-08-08 22:49:01.958129: predicting MED_LYMPH_009 
2023-08-08 22:49:07.162486: predicting MED_LYMPH_010 
2023-08-08 22:49:09.506067: predicting MED_LYMPH_011 
2023-08-08 22:49:13.043083: predicting MED_LYMPH_012 
2023-08-08 22:49:15.375679: predicting MED_LYMPH_013 
2023-08-08 22:49:18.847186: predicting MED_LYMPH_014 
2023-08-08 22:49:21.180977: predicting MED_LYMPH_015 
2023-08-08 22:49:24.675805: predicting MED_LYMPH_016 
2023-08-08 22:49:28.173090: predicting MED_LYMPH_017 
2023-08-08 22:49:30.510504: predicting MED_LYMPH_018 
2023-08-08 22:49:34.011548: predicting MED_LYMPH_019 
2023-08-08 22:49:37.506021: predicting MED_LYMPH_020 
2023-08-08 22:49:40.975633: predicting MED_LYMPH_021 
2023-08-08 22:49:43.332663: predicting MED_LYMPH_022 
2023-08-08 22:49:46.784981: predicting MED_LYMPH_023 
2023-08-08 22:49:50.260992: predicting MED_LYMPH_024 
2023-08-08 22:49:55.450426: predicting MED_LYMPH_025 
2023-08-08 22:50:00.720581: predicting MED_LYMPH_026 
2023-08-08 22:50:04.245362: predicting MED_LYMPH_027 
2023-08-08 22:50:09.454837: predicting MED_LYMPH_028 
2023-08-08 22:50:12.933100: predicting MED_LYMPH_029 
2023-08-08 22:50:16.397836: predicting MED_LYMPH_030 
2023-08-08 22:50:18.760529: predicting MED_LYMPH_031 
2023-08-08 22:50:21.091325: predicting MED_LYMPH_032 
2023-08-08 22:50:24.586570: predicting MED_LYMPH_033 
2023-08-08 22:50:26.914760: predicting MED_LYMPH_034 
2023-08-08 22:50:30.362192: predicting MED_LYMPH_035 
2023-08-08 22:50:33.863685: predicting MED_LYMPH_036 
2023-08-08 22:50:36.203582: predicting MED_LYMPH_037 
2023-08-08 22:50:39.705060: predicting MED_LYMPH_038 
2023-08-08 22:50:43.217134: predicting MED_LYMPH_039 
2023-08-08 22:50:44.402571: predicting MED_LYMPH_040 
2023-08-08 22:50:46.734644: predicting MED_LYMPH_041 
2023-08-08 22:50:50.207267: predicting MED_LYMPH_042 
2023-08-08 22:50:53.678526: predicting MED_LYMPH_043 
2023-08-08 22:50:55.421559: predicting MED_LYMPH_044 
2023-08-08 22:50:57.785428: predicting MED_LYMPH_045 
2023-08-08 22:51:00.102372: predicting MED_LYMPH_046 
2023-08-08 22:51:06.973899: predicting MED_LYMPH_047 
2023-08-08 22:51:12.160767: predicting MED_LYMPH_048 
2023-08-08 22:51:14.527916: predicting MED_LYMPH_049 
2023-08-08 22:51:16.863229: predicting MED_LYMPH_050 
2023-08-08 22:51:22.038405: predicting MED_LYMPH_051 
2023-08-08 22:51:24.352886: predicting MED_LYMPH_052 
2023-08-08 22:51:27.843116: predicting MED_LYMPH_053 
2023-08-08 22:51:33.032991: predicting MED_LYMPH_054 
2023-08-08 22:51:35.370302: predicting MED_LYMPH_055 
2023-08-08 22:51:40.588438: predicting MED_LYMPH_056 
2023-08-08 22:51:48.349927: predicting MED_LYMPH_057 
2023-08-08 22:51:56.136600: predicting MED_LYMPH_058 
2023-08-08 22:51:59.707203: predicting MED_LYMPH_059 
2023-08-08 22:52:02.070212: predicting MED_LYMPH_060 
2023-08-08 22:52:05.564167: predicting MED_LYMPH_061 
2023-08-08 22:52:09.063252: predicting MED_LYMPH_062 
2023-08-08 22:52:14.273026: predicting MED_LYMPH_063 
2023-08-08 22:52:17.806957: predicting MED_LYMPH_064 
2023-08-08 22:52:21.268434: predicting MED_LYMPH_065 
2023-08-08 22:52:24.776191: predicting MED_LYMPH_066 
2023-08-08 22:52:27.122332: predicting MED_LYMPH_067 
2023-08-08 22:52:30.613506: predicting MED_LYMPH_068 
2023-08-08 22:52:34.123076: predicting MED_LYMPH_069 
2023-08-08 22:52:39.324497: predicting MED_LYMPH_070 
2023-08-08 22:52:41.679722: predicting MED_LYMPH_071 
2023-08-08 22:52:49.392350: predicting MED_LYMPH_072 
2023-08-08 22:52:52.906406: predicting MED_LYMPH_073 
2023-08-08 22:52:56.387365: predicting MED_LYMPH_074 
2023-08-08 22:52:59.860099: predicting MED_LYMPH_075 
2023-08-08 22:53:03.343644: predicting MED_LYMPH_076 
2023-08-08 22:53:05.650710: predicting MED_LYMPH_077 
2023-08-08 22:53:09.126096: predicting MED_LYMPH_078 
2023-08-08 22:53:12.596529: predicting MED_LYMPH_079 
2023-08-08 22:53:16.055626: predicting MED_LYMPH_080 
2023-08-08 22:53:18.423430: predicting MED_LYMPH_081 
2023-08-08 22:53:20.763994: predicting MED_LYMPH_082 
2023-08-08 22:53:24.266596: predicting MED_LYMPH_083 
2023-08-08 22:53:27.727230: predicting MED_LYMPH_084 
2023-08-08 22:53:31.241632: predicting MED_LYMPH_085 
2023-08-08 22:53:34.743743: predicting MED_LYMPH_086 
2023-08-08 22:53:42.511761: predicting MED_LYMPH_087 
2023-08-08 22:53:47.765014: predicting MED_LYMPH_088 
2023-08-08 22:53:51.238094: predicting MED_LYMPH_089 
2023-08-08 22:53:53.593156: predicting MED_LYMPH_090 
2023-08-08 22:53:55.931420: predicting R01-001 
2023-08-08 22:53:58.279561: predicting R01-002 
2023-08-08 22:54:01.746866: predicting R01-004 
2023-08-08 22:54:06.923107: predicting R01-005 
2023-08-08 22:54:10.449922: predicting R01-006 
2023-08-08 22:54:17.392205: predicting R01-007 
2023-08-08 22:54:22.616605: predicting R01-008 
2023-08-08 22:54:26.117102: predicting R01-010 
2023-08-08 22:54:29.618457: predicting R01-011 
2023-08-08 22:54:31.997012: predicting R01-012 
2023-08-08 22:54:35.502958: predicting R01-013 
2023-08-08 22:54:39.003546: predicting R01-014 
2023-08-08 22:54:41.319385: predicting R01-015 
2023-08-08 22:54:46.514423: predicting R01-016 
2023-08-08 22:54:50.034129: predicting R01-017 
2023-08-08 22:54:53.559936: predicting R01-018 
2023-08-08 22:54:57.049317: predicting R01-019 
2023-08-08 22:55:02.286005: predicting R01-020 
2023-08-08 22:55:05.798481: predicting R01-021 
2023-08-08 22:55:08.138335: predicting R01-022 
2023-08-08 22:55:11.600126: predicting R01-023 
2023-08-08 22:55:15.101793: predicting R01-024 
2023-08-08 22:55:18.575979: predicting R01-025 
2023-08-08 22:55:22.076990: predicting R01-026 
2023-08-08 22:55:27.328358: predicting R01-027 
2023-08-08 22:55:30.844043: predicting R01-028 
2023-08-08 22:55:38.611395: predicting R01-029 
2023-08-08 22:55:43.823465: predicting R01-030 
2023-08-08 22:55:47.329967: predicting R01-031 
2023-08-08 22:55:50.808878: predicting R01-032 
2023-08-08 22:55:55.977864: predicting R01-033 
2023-08-08 22:55:59.480906: predicting R01-034 
2023-08-08 22:56:03.010758: predicting R01-035 
2023-08-08 22:56:08.189776: predicting R01-036 
2023-08-08 22:56:13.373398: predicting R01-037 
2023-08-08 22:56:16.874815: predicting R01-038 
2023-08-08 22:56:22.085397: predicting R01-039 
2023-08-08 22:56:27.265001: predicting R01-040 
2023-08-08 22:56:35.007948: predicting R01-041 
2023-08-08 22:56:38.526479: predicting R01-042 
2023-08-08 22:56:42.025981: predicting R01-043 
2023-08-08 22:56:44.360166: predicting R01-044 
2023-08-08 22:56:47.830491: predicting R01-045 
2023-08-08 22:56:50.170577: predicting R01-046 
2023-08-08 22:56:53.648417: predicting R01-047 
2023-08-08 22:56:57.131476: predicting R01-048 
2023-08-08 22:57:00.622734: predicting R01-049 
2023-08-08 22:57:04.121033: predicting R01-050 
2023-08-08 22:57:06.478566: predicting R01-051 
2023-08-08 22:57:09.994693: predicting R01-052 
2023-08-08 22:57:13.494922: predicting R01-053 
2023-08-08 22:57:15.848255: predicting R01-054 
2023-08-08 22:57:19.307763: predicting R01-055 
2023-08-08 22:57:22.770390: predicting R01-056 
2023-08-08 22:57:26.259913: predicting R01-057 
2023-08-08 22:57:29.772985: predicting R01-058 
2023-08-08 22:57:33.290886: predicting R01-059 
2023-08-08 22:57:35.624015: predicting R01-060 
2023-08-08 22:57:39.078851: predicting R01-061 
2023-08-08 22:57:42.574609: predicting R01-062 
2023-08-08 22:57:46.027306: predicting R01-063 
2023-08-08 22:57:51.207523: predicting R01-064 
2023-08-08 22:57:54.758726: predicting R01-065 
2023-08-08 22:57:59.386261: predicting R01-066 
2023-08-08 22:58:02.880783: predicting R01-067 
2023-08-08 22:58:06.396628: predicting R01-068 
2023-08-08 22:58:11.600559: predicting R01-069 
2023-08-08 22:58:15.130998: predicting R01-070 
2023-08-08 22:58:18.631516: predicting R01-071 
2023-08-08 22:58:23.822900: predicting R01-072 
2023-08-08 22:58:29.063468: predicting R01-073 
2023-08-08 22:58:32.574142: predicting R01-074 
2023-08-08 22:58:36.062465: predicting R01-075 
2023-08-08 22:58:41.264454: predicting R01-076 
2023-08-08 22:58:46.483514: predicting R01-077 
2023-08-08 22:58:48.879095: predicting R01-078 
2023-08-08 22:58:51.207183: predicting R01-079 
2023-08-08 22:58:54.723112: predicting R01-080 
2023-08-08 22:58:59.908882: predicting R01-081 
2023-08-08 22:59:02.287877: predicting R01-082 
2023-08-08 22:59:05.779974: predicting R01-083 
2023-08-08 22:59:10.988090: predicting R01-084 
2023-08-08 22:59:14.494842: predicting R01-085 
2023-08-08 22:59:17.996736: predicting R01-086 
2023-08-08 22:59:21.492491: predicting R01-087 
2023-08-08 22:59:24.971298: predicting R01-088 
2023-08-08 22:59:30.127784: predicting R01-089 
2023-08-08 22:59:33.647427: predicting R01-090 
2023-08-08 22:59:37.159621: predicting R01-091 
2023-08-08 22:59:39.469190: predicting R01-092 
2023-08-08 22:59:42.961575: predicting R01-093 
2023-08-08 22:59:48.178860: predicting R01-094 
2023-08-08 22:59:51.701329: predicting R01-095 
2023-08-08 22:59:56.327557: predicting R01-096 
2023-08-08 23:00:03.278953: predicting R01-097 
2023-08-08 23:00:06.796648: predicting R01-098 
2023-08-08 23:00:09.162758: predicting R01-099 
2023-08-08 23:00:11.491745: predicting R01-100 
2023-08-08 23:00:13.840338: predicting R01-101 
2023-08-08 23:00:17.318689: predicting R01-102 
2023-08-08 23:00:20.798461: predicting R01-103 
2023-08-08 23:00:24.304075: predicting R01-104 
2023-08-08 23:00:27.799326: predicting R01-105 
2023-08-08 23:00:31.299229: predicting R01-106 
2023-08-08 23:00:36.475705: predicting R01-107 
2023-08-08 23:00:38.859877: predicting R01-108 
2023-08-08 23:00:42.343980: predicting R01-109 
2023-08-08 23:00:45.834727: predicting R01-110 
2023-08-08 23:00:51.055647: predicting R01-111 
2023-08-08 23:00:56.241944: predicting R01-112 
2023-08-08 23:01:03.154928: predicting R01-113 
2023-08-08 23:01:06.652830: predicting R01-114 
2023-08-08 23:01:11.825144: predicting R01-115 
2023-08-08 23:01:15.322634: predicting R01-116 
2023-08-08 23:01:18.825590: predicting R01-117 
2023-08-08 23:01:22.319254: predicting R01-118 
2023-08-08 23:01:26.925582: predicting R01-119 
2023-08-08 23:01:32.150115: predicting R01-120 
2023-08-08 23:01:35.647444: predicting R01-121 
2023-08-08 23:01:39.173516: predicting R01-122 
2023-08-08 23:01:42.693583: predicting R01-123 
2023-08-08 23:01:49.571956: predicting R01-124 
2023-08-08 23:01:54.798619: predicting R01-125 
2023-08-08 23:01:58.328271: predicting R01-126 
2023-08-08 23:02:03.508460: predicting R01-127 
2023-08-08 23:02:07.030235: predicting R01-128 
2023-08-08 23:02:10.520784: predicting R01-129 
2023-08-08 23:02:15.736174: predicting R01-130 
2023-08-08 23:02:19.293425: predicting R01-131 
2023-08-08 23:02:22.790800: predicting R01-132 
2023-08-08 23:02:26.273777: predicting R01-133 
2023-08-08 23:02:29.789034: predicting R01-134 
2023-08-08 23:02:33.302444: predicting R01-135 
2023-08-08 23:02:36.761198: predicting R01-136 
2023-08-08 23:02:39.093478: predicting R01-137 
2023-08-08 23:02:42.583728: predicting R01-138 
2023-08-08 23:02:46.049248: predicting R01-139 
2023-08-08 23:02:49.550574: predicting R01-140 
2023-08-08 23:02:51.851192: predicting R01-141 
2023-08-08 23:02:55.311299: predicting R01-142 
2023-08-08 23:02:57.671245: predicting R01-144 
2023-08-08 23:03:01.116651: predicting R01-145 
2023-08-08 23:03:06.278387: predicting R01-146 
2023-08-08 23:03:07.486540: predicting interobs05 
2023-08-08 23:03:10.973570: predicting interobs06 
2023-08-08 23:03:14.447540: predicting interobs08 
2023-08-08 23:03:19.596819: predicting interobs10 
2023-08-08 23:03:21.937446: predicting interobs11 
2023-08-08 23:03:25.371303: predicting interobs12 
2023-08-08 23:03:28.819826: predicting interobs13 
2023-08-08 23:03:31.107530: predicting interobs14 
2023-08-08 23:03:34.550622: predicting interobs15 
2023-08-08 23:03:38.010527: predicting interobs18 
2023-08-08 23:03:41.462250: predicting interobs19 
2023-08-08 23:03:46.046894: predicting interobs20 
2023-08-08 23:03:49.510209: predicting interobs21 
2023-08-08 23:03:52.955996: predicting interobs22 
2023-08-08 23:03:56.400335: predicting interobs27 
2023-08-08 23:03:58.711502: predicting interobs28 
2023-08-08 23:04:01.003444: predicting interobs29 
2023-08-08 23:04:04.448313: predicting interobs31 
2023-08-08 23:04:07.903085: predicting interobs32 
2023-08-08 23:04:11.340672: predicting interobs33 
2023-08-08 23:04:14.787643: predicting interobs34 
2023-08-08 23:04:18.222897: predicting lnq2023-train-0005 
2023-08-08 23:04:21.661769: predicting lnq2023-train-0006 
2023-08-08 23:04:23.977724: predicting lnq2023-train-0009 
2023-08-08 23:04:26.281003: predicting lnq2023-train-0012 
2023-08-08 23:04:28.632419: predicting lnq2023-train-0017 
2023-08-08 23:04:32.092750: predicting lnq2023-train-0021 
2023-08-08 23:04:35.520620: predicting lnq2023-train-0023 
2023-08-08 23:04:38.995281: predicting lnq2023-train-0024 
2023-08-08 23:04:42.464565: predicting lnq2023-train-0026 
2023-08-08 23:04:44.767336: predicting lnq2023-train-0029 
2023-08-08 23:04:49.890811: predicting lnq2023-train-0032 
2023-08-08 23:04:52.239061: predicting lnq2023-train-0033 
2023-08-08 23:04:55.682632: predicting lnq2023-train-0034 
2023-08-08 23:04:58.022340: predicting lnq2023-train-0035 
2023-08-08 23:05:03.147786: predicting lnq2023-train-0040 
2023-08-08 23:05:08.302132: predicting lnq2023-train-0042 
2023-08-08 23:05:10.603440: predicting lnq2023-train-0044 
2023-08-08 23:05:12.910000: predicting lnq2023-train-0048 
2023-08-08 23:05:15.209307: predicting lnq2023-train-0050 
2023-08-08 23:05:20.356104: predicting lnq2023-train-0052 
2023-08-08 23:05:23.842952: predicting lnq2023-train-0053 
2023-08-08 23:05:27.312580: predicting lnq2023-train-0054 
2023-08-08 23:05:30.752856: predicting lnq2023-train-0055 
2023-08-08 23:05:33.112416: predicting lnq2023-train-0057 
2023-08-08 23:05:36.539881: predicting lnq2023-train-0058 
2023-08-08 23:05:39.980689: predicting lnq2023-train-0064 
2023-08-08 23:05:43.418853: predicting lnq2023-train-0068 
2023-08-08 23:05:51.109621: predicting lnq2023-train-0069 
2023-08-08 23:05:54.581447: predicting lnq2023-train-0074 
2023-08-08 23:05:56.887734: predicting lnq2023-train-0076 
2023-08-08 23:06:04.556668: predicting lnq2023-train-0078 
2023-08-08 23:06:08.089708: predicting lnq2023-train-0088 
2023-08-08 23:06:10.411804: predicting lnq2023-train-0092 
2023-08-08 23:06:12.746417: predicting lnq2023-train-0093 
2023-08-08 23:06:15.033647: predicting lnq2023-train-0101 
2023-08-08 23:06:18.510403: predicting lnq2023-train-0102 
2023-08-08 23:06:21.949685: predicting lnq2023-train-0109 
2023-08-08 23:06:27.114623: predicting lnq2023-train-0110 
2023-08-08 23:06:30.562095: predicting lnq2023-train-0111 
2023-08-08 23:06:32.868897: predicting lnq2023-train-0113 
2023-08-08 23:06:38.014392: predicting lnq2023-train-0115 
2023-08-08 23:06:40.358683: predicting lnq2023-train-0116 
2023-08-08 23:06:45.510504: predicting lnq2023-train-0117 
2023-08-08 23:06:49.002880: predicting lnq2023-train-0119 
2023-08-08 23:06:52.490042: predicting lnq2023-train-0125 
2023-08-08 23:06:54.811740: predicting lnq2023-train-0126 
2023-08-08 23:06:58.271842: predicting lnq2023-train-0129 
2023-08-08 23:07:00.591256: predicting lnq2023-train-0131 
2023-08-08 23:07:04.062196: predicting lnq2023-train-0136 
2023-08-08 23:07:07.523985: predicting lnq2023-train-0149 
2023-08-08 23:07:15.246050: predicting lnq2023-train-0150 
2023-08-08 23:07:20.428430: predicting lnq2023-train-0152 
2023-08-08 23:07:23.914855: predicting lnq2023-train-0155 
2023-08-08 23:07:27.361201: predicting lnq2023-train-0158 
2023-08-08 23:07:29.716604: predicting lnq2023-train-0159 
2023-08-08 23:07:34.874132: predicting lnq2023-train-0160 
2023-08-08 23:07:37.246912: predicting lnq2023-train-0164 
2023-08-08 23:07:42.410284: predicting lnq2023-train-0165 
2023-08-08 23:07:45.872992: predicting lnq2023-train-0166 
2023-08-08 23:07:49.317745: predicting lnq2023-train-0170 
2023-08-08 23:07:52.802960: predicting lnq2023-train-0171 
2023-08-08 23:07:56.260750: predicting lnq2023-train-0177 
2023-08-08 23:07:59.736126: predicting lnq2023-train-0178 
2023-08-08 23:08:03.193583: predicting lnq2023-train-0182 
2023-08-08 23:08:06.642574: predicting lnq2023-train-0183 
2023-08-08 23:08:10.093112: predicting lnq2023-train-0187 
2023-08-08 23:08:13.550049: predicting lnq2023-train-0189 
2023-08-08 23:08:15.854011: predicting lnq2023-train-0191 
2023-08-08 23:08:20.979152: predicting lnq2023-train-0193 
2023-08-08 23:08:24.450180: predicting lnq2023-train-0194 
2023-08-08 23:08:27.946657: predicting lnq2023-train-0197 
2023-08-08 23:08:31.395510: predicting lnq2023-train-0199 
2023-08-08 23:08:34.870043: predicting lnq2023-train-0202 
2023-08-08 23:08:38.321507: predicting lnq2023-train-0203 
2023-08-08 23:08:40.624907: predicting lnq2023-train-0204 
2023-08-08 23:08:44.057792: predicting lnq2023-train-0216 
2023-08-08 23:08:47.536483: predicting lnq2023-train-0219 
2023-08-08 23:08:49.865744: predicting lnq2023-train-0222 
2023-08-08 23:08:53.342491: predicting lnq2023-train-0223 
2023-08-08 23:08:56.758989: predicting lnq2023-train-0225 
2023-08-08 23:08:59.091661: predicting lnq2023-train-0227 
2023-08-08 23:09:01.395056: predicting lnq2023-train-0229 
2023-08-08 23:09:03.700767: predicting lnq2023-train-0232 
2023-08-08 23:09:07.158967: predicting lnq2023-train-0236 
2023-08-08 23:09:10.618435: predicting lnq2023-train-0238 
2023-08-08 23:09:12.924059: predicting lnq2023-train-0240 
2023-08-08 23:09:18.055031: predicting lnq2023-train-0244 
2023-08-08 23:09:21.546063: predicting lnq2023-train-0247 
2023-08-08 23:09:23.882181: predicting lnq2023-train-0250 
2023-08-08 23:09:27.329731: predicting lnq2023-train-0259 
2023-08-08 23:09:30.742345: predicting lnq2023-train-0267 
2023-08-08 23:09:33.098358: predicting lnq2023-train-0269 
2023-08-08 23:09:36.524340: predicting lnq2023-train-0270 
2023-08-08 23:09:38.835885: predicting lnq2023-train-0271 
2023-08-08 23:09:43.982794: predicting lnq2023-train-0273 
2023-08-08 23:09:46.326060: predicting lnq2023-train-0278 
2023-08-08 23:09:49.760227: predicting lnq2023-train-0279 
2023-08-08 23:09:52.073334: predicting lnq2023-train-0281 
2023-08-08 23:09:55.499850: predicting lnq2023-train-0282 
2023-08-08 23:09:57.836005: predicting lnq2023-train-0283 
2023-08-08 23:10:01.270284: predicting lnq2023-train-0287 
2023-08-08 23:10:06.455338: predicting lnq2023-train-0288 
2023-08-08 23:10:14.165521: predicting lnq2023-train-0295 
2023-08-08 23:10:17.671946: predicting lnq2023-train-0296 
2023-08-08 23:10:21.134221: predicting lnq2023-train-0297 
2023-08-08 23:10:22.898497: predicting lnq2023-train-0301 
2023-08-08 23:10:26.316207: predicting lnq2023-train-0302 
2023-08-08 23:10:31.477051: predicting lnq2023-train-0304 
2023-08-08 23:10:36.649188: predicting lnq2023-train-0308 
2023-08-08 23:10:38.998819: predicting lnq2023-train-0313 
2023-08-08 23:10:42.472228: predicting lnq2023-train-0315 
2023-08-08 23:10:45.916711: predicting lnq2023-train-0317 
2023-08-08 23:10:51.067493: predicting lnq2023-train-0320 
2023-08-08 23:10:54.560812: predicting lnq2023-train-0322 
2023-08-08 23:10:58.013518: predicting lnq2023-train-0327 
2023-08-08 23:11:03.160651: predicting lnq2023-train-0328 
2023-08-08 23:11:05.504843: predicting lnq2023-train-0329 
2023-08-08 23:11:08.971713: predicting lnq2023-train-0331 
2023-08-08 23:11:14.094720: predicting lnq2023-train-0333 
2023-08-08 23:11:17.581834: predicting lnq2023-train-0334 
2023-08-08 23:11:21.066200: predicting lnq2023-train-0338 
2023-08-08 23:11:24.529664: predicting lnq2023-train-0343 
2023-08-08 23:11:29.701573: predicting lnq2023-train-0348 
2023-08-08 23:11:32.069837: predicting lnq2023-train-0354 
2023-08-08 23:11:35.499507: predicting lnq2023-train-0356 
2023-08-08 23:11:38.959404: predicting lnq2023-train-0357 
2023-08-08 23:11:41.281210: predicting lnq2023-train-0364 
2023-08-08 23:11:44.714783: predicting lnq2023-train-0368 
2023-08-08 23:11:48.164140: predicting lnq2023-train-0376 
2023-08-08 23:11:51.584652: predicting lnq2023-train-0380 
2023-08-08 23:11:56.809614: predicting lnq2023-train-0384 
2023-08-08 23:12:00.278121: predicting lnq2023-train-0385 
2023-08-08 23:12:03.754430: predicting lnq2023-train-0386 
2023-08-08 23:12:06.035567: predicting lnq2023-train-0392 
2023-08-08 23:12:09.510529: predicting lnq2023-train-0394 
2023-08-08 23:12:12.981307: predicting lnq2023-train-0395 
2023-08-08 23:12:16.404656: predicting lnq2023-train-0396 
2023-08-08 23:12:18.734264: predicting lnq2023-train-0401 
2023-08-08 23:12:22.162029: predicting lnq2023-train-0402 
2023-08-08 23:12:25.600000: predicting lnq2023-train-0406 
2023-08-08 23:12:29.068070: predicting lnq2023-train-0411 
2023-08-08 23:12:32.503178: predicting lnq2023-train-0415 
2023-08-08 23:12:37.661927: predicting lnq2023-train-0417 
2023-08-08 23:12:45.343730: predicting lnq2023-train-0418 
2023-08-08 23:12:48.847625: predicting lnq2023-train-0419 
2023-08-08 23:12:53.992689: predicting lnq2023-train-0421 
2023-08-08 23:12:57.486706: predicting lnq2023-train-0423 
2023-08-08 23:13:00.913491: predicting lnq2023-train-0424 
2023-08-08 23:13:03.238490: predicting lnq2023-train-0428 
2023-08-08 23:13:05.540533: predicting lnq2023-train-0431 
2023-08-08 23:13:07.856750: predicting lnq2023-train-0436 
2023-08-08 23:13:11.286426: predicting lnq2023-train-0437 
2023-08-08 23:13:14.727794: predicting lnq2023-train-0440 
2023-08-08 23:13:22.430728: predicting lnq2023-train-0441 
2023-08-08 23:13:27.594103: predicting lnq2023-train-0444 
2023-08-08 23:13:29.909038: predicting lnq2023-train-0445 
2023-08-08 23:13:33.342025: predicting lnq2023-train-0446 
2023-08-08 23:13:36.788296: predicting lnq2023-train-0448 
2023-08-08 23:13:39.109188: predicting lnq2023-train-0449 
2023-08-08 23:13:41.398501: predicting lnq2023-train-0450 
2023-08-08 23:13:44.837210: predicting lnq2023-train-0456 
2023-08-08 23:13:49.971784: predicting lnq2023-train-0459 
2023-08-08 23:13:53.437394: predicting lnq2023-train-0463 
2023-08-08 23:13:56.869862: predicting lnq2023-train-0466 
2023-08-08 23:14:00.302031: predicting lnq2023-train-0468 
2023-08-08 23:14:03.757540: predicting lnq2023-train-0469 
2023-08-08 23:14:08.912765: predicting lnq2023-train-0470 
2023-08-08 23:14:14.098797: predicting lnq2023-train-0474 
2023-08-08 23:14:21.791992: predicting lnq2023-train-0475 
2023-08-08 23:14:25.263966: predicting lnq2023-train-0480 
2023-08-08 23:14:28.714463: predicting lnq2023-train-0481 
2023-08-08 23:14:32.177742: predicting lnq2023-train-0482 
2023-08-08 23:14:35.629807: predicting lnq2023-train-0487 
2023-08-08 23:14:39.076832: predicting lnq2023-train-0489 
2023-08-08 23:14:41.398593: predicting lnq2023-train-0491 
2023-08-08 23:14:46.524516: predicting lnq2023-train-0493 
2023-08-08 23:14:49.998499: predicting lnq2023-train-0496 
2023-08-08 23:14:52.344484: predicting lnq2023-train-0499 
2023-08-08 23:14:55.790377: predicting lnq2023-train-0504 
2023-08-08 23:15:00.942546: predicting lnq2023-train-0506 
2023-08-08 23:15:04.442550: predicting lnq2023-train-0509 
2023-08-08 23:15:09.598985: predicting lnq2023-train-0512 
2023-08-08 23:15:11.921318: predicting lnq2023-train-0514 
2023-08-08 23:15:17.062655: predicting lnq2023-train-0515 
2023-08-08 23:15:20.542429: predicting lnq2023-train-0518 
2023-08-08 23:15:22.866991: predicting lnq2023-train-0519 
2023-08-08 23:15:26.332437: predicting lnq2023-train-0522 
2023-08-08 23:15:34.059894: predicting lnq2023-train-0531 
2023-08-08 23:15:37.535691: predicting lnq2023-train-0532 
2023-08-08 23:15:40.972146: predicting lnq2023-train-0545 
2023-08-08 23:15:45.553344: predicting lnq2023-train-0546 
2023-08-08 23:15:47.932498: predicting lnq2023-train-0547 
2023-08-08 23:15:51.337137: predicting lnq2023-train-0548 
2023-08-08 23:15:54.832421: predicting lnq2023-train-0551 
2023-08-08 23:15:58.276732: predicting lnq2023-train-0552 
2023-08-08 23:16:01.720785: predicting lnq2023-train-0553 
2023-08-08 23:16:05.171758: predicting lnq2023-train-0554 
2023-08-08 23:16:08.608504: predicting lnq2023-train-0556 
2023-08-08 23:16:10.894277: predicting lnq2023-train-0558 
2023-08-08 23:16:13.220129: predicting lnq2023-train-0567 
2023-08-08 23:16:15.511378: predicting lnq2023-train-0573 
2023-08-08 23:16:20.620792: predicting lnq2023-train-0577 
2023-08-08 23:16:22.996333: predicting lnq2023-train-0582 
2023-08-08 23:16:25.293243: predicting lnq2023-train-0586 
2023-08-08 23:16:30.422913: predicting lnq2023-train-0596 
2023-08-08 23:16:35.576247: predicting lnq2023-train-0601 
2023-08-08 23:16:39.056541: predicting lnq2023-train-0604 
2023-08-08 23:16:42.504339: predicting lnq2023-train-0605 
2023-08-08 23:16:45.974472: predicting lnq2023-train-0607 
2023-08-08 23:16:48.289657: predicting lnq2023-train-0610 
2023-08-08 23:16:49.452298: predicting lnq2023-train-0611 
2023-08-08 23:16:52.901894: predicting lnq2023-train-0614 
2023-08-08 23:16:56.345188: predicting lnq2023-train-0615 
2023-08-08 23:16:59.811576: predicting lnq2023-train-0616 
2023-08-08 23:17:03.270612: predicting lnq2023-train-0618 
2023-08-08 23:17:05.580076: predicting lnq2023-train-0622 
2023-08-08 23:17:10.730503: predicting lnq2023-train-0626 
2023-08-08 23:17:14.202178: predicting lnq2023-train-0628 
2023-08-08 23:17:16.544408: predicting lnq2023-train-0638 
2023-08-08 23:17:18.877655: predicting lnq2023-train-0645 
2023-08-08 23:17:21.189652: predicting lnq2023-train-0646 
2023-08-08 23:17:26.327790: predicting lnq2023-train-0648 
2023-08-08 23:17:31.515121: predicting lnq2023-train-0649 
2023-08-08 23:17:34.988168: predicting lnq2023-train-0651 
2023-08-08 23:17:38.431450: predicting lnq2023-train-0655 
2023-08-08 23:17:40.746746: predicting lnq2023-train-0656 
2023-08-08 23:17:43.077862: predicting lnq2023-train-0657 
2023-08-08 23:17:46.527126: predicting lnq2023-train-0658 
2023-08-08 23:17:49.980612: predicting lnq2023-train-0659 
2023-08-08 23:17:53.446190: predicting lnq2023-train-0662 
2023-08-08 23:17:55.737565: predicting lnq2023-train-0663 
2023-08-08 23:17:59.189485: predicting lnq2023-train-0668 
2023-08-08 23:18:02.637757: predicting lnq2023-train-0669 
2023-08-08 23:18:04.951349: predicting lnq2023-train-0671 
2023-08-08 23:18:08.406803: predicting lnq2023-train-0679 
2023-08-08 23:18:11.829330: predicting lnq2023-train-0682 
2023-08-08 23:18:15.275328: predicting lnq2023-train-0683 
2023-08-08 23:18:18.733531: predicting lnq2023-train-0685 
2023-08-08 23:18:21.046260: predicting lnq2023-train-0688 
2023-08-08 23:18:23.393920: predicting lnq2023-train-0690 
2023-08-08 23:18:26.827015: predicting lnq2023-train-0691 
2023-08-08 23:18:30.284739: predicting lnq2023-train-0695 
2023-08-08 23:18:37.142324: predicting lnq2023-train-0697 
2023-08-08 23:18:39.502815: predicting lnq2023-train-0700 
2023-08-08 23:18:41.799045: predicting lnq2023-train-0702 
2023-08-08 23:18:45.236136: predicting lnq2023-train-0704 
2023-08-08 23:18:52.902018: predicting lnq2023-train-0707 
2023-08-08 23:18:55.255989: predicting lnq2023-train-0708 
2023-08-08 23:18:58.721451: predicting lnq2023-train-0709 
2023-08-08 23:19:02.187563: predicting lnq2023-train-0715 
2023-08-08 23:19:05.633792: predicting lnq2023-train-0717 
2023-08-08 23:19:09.088328: predicting lnq2023-train-0720 
2023-08-08 23:19:12.533694: predicting lnq2023-train-0727 
2023-08-08 23:19:15.964987: predicting lnq2023-train-0731 
2023-08-08 23:19:19.445007: predicting lnq2023-train-0732 
2023-08-08 23:19:22.910831: predicting lnq2023-train-0737 
2023-08-08 23:19:26.359374: predicting lnq2023-train-0738 
2023-08-08 23:19:29.802208: predicting lnq2023-train-0740 
2023-08-08 23:19:32.102300: predicting lnq2023-train-0742 
2023-08-08 23:19:35.555619: predicting lnq2023-train-0748 
2023-08-08 23:19:38.994575: predicting lnq2023-train-0749 
2023-08-08 23:19:49.252219: predicting lnq2023-train-0752 
2023-08-08 23:19:51.602067: predicting lnq2023-train-0754 
2023-08-08 23:19:56.750386: predicting lnq2023-train-0758 
2023-08-08 23:19:59.073813: predicting lnq2023-train-0761 
2023-08-08 23:20:01.392004: predicting lnq2023-train-0764 
2023-08-08 23:20:04.867934: predicting lnq2023-train-0765 
2023-08-08 23:20:08.335785: predicting lnq2023-train-0766 
2023-08-08 23:20:10.645913: predicting lnq2023-train-0767 
2023-08-08 23:20:12.958937: predicting lnq2023-train-0768 
2023-08-08 23:20:15.262732: predicting lnq2023-train-0769 
2023-08-08 23:20:18.712204: predicting lnq2023-train-0772 
2023-08-08 23:20:22.164114: predicting lnq2023-train-0773 
2023-08-08 23:20:24.476239: predicting lnq2023-train-0774 
2023-08-08 23:20:29.627150: predicting lnq2023-train-0775 
2023-08-08 23:20:33.162542: predicting lnq2023-train-0782 
2023-08-08 23:20:36.616151: predicting lnq2023-train-0784 
2023-08-08 23:20:44.306368: predicting lnq2023-train-0786 
2023-08-08 23:20:47.800110: predicting lnq2023-train-0788 
2023-08-08 23:20:51.232537: predicting lnq2023-train-0790 
2023-08-08 23:20:54.684482: predicting lnq2023-train-0792 
2023-08-08 23:20:56.987638: predicting lnq2023-train-0793 
2023-08-08 23:21:04.688772: predicting lnq2023-train-0796 
2023-08-08 23:21:08.181120: predicting lnq2023-train-0798 
2023-08-08 23:21:11.640372: predicting lnq2023-train-0799 
2023-08-08 23:21:13.977594: predicting lnq2023-train-0800 
2023-08-08 23:21:16.289427: predicting lnq2023-train-0803 
2023-08-08 23:21:19.742553: predicting lnq2023-train-0804 
2023-08-08 23:21:20.916902: predicting lnq2023-train-0817 
2023-08-08 23:21:23.247433: predicting lnq2023-train-0818 
2023-08-08 23:21:26.677646: predicting lnq2023-train-0820 
2023-08-08 23:21:30.149647: predicting lnq2023-train-0823 
2023-08-08 23:21:32.472491: predicting lnq2023-train-0825 
2023-08-08 23:21:35.933343: predicting lnq2023-train-0826 
2023-08-08 23:21:38.298177: predicting lnq2023-train-0827 
2023-08-08 23:21:41.746524: predicting lnq2023-train-0831 
2023-08-08 23:21:44.062613: predicting lnq2023-train-0833 
2023-08-08 23:21:47.520379: predicting lnq2023-train-0838 
2023-08-08 23:21:50.981567: predicting lnq2023-train-0847 
2023-08-08 23:21:53.313650: predicting lnq2023-train-0849 
2023-08-08 23:21:58.473993: predicting lnq2023-train-0854 
2023-08-08 23:22:01.976214: predicting lnq2023-train-0856 
2023-08-08 23:22:05.431800: predicting lnq2023-train-0858 
2023-08-08 23:22:05.766714: predicting lnq2023-train-0860 
2023-08-08 23:22:09.247104: predicting lnq2023-train-0863 
2023-08-08 23:22:11.005528: predicting lnq2023-train-0864 
2023-08-08 23:22:14.450486: predicting lnq2023-train-0865 
2023-08-08 23:22:17.937671: predicting lnq2023-train-0866 
2023-08-08 23:22:21.356423: predicting lnq2023-train-0868 
2023-08-08 23:22:24.800177: predicting lnq2023-train-0869 
2023-08-08 23:22:28.279351: predicting lnq2023-train-0874 
2023-08-08 23:22:30.601494: predicting lnq2023-train-0880 
2023-08-08 23:22:32.938426: predicting lnq2023-train-0883 
2023-08-08 23:22:35.228384: predicting lnq2023-train-0885 
2023-08-08 23:22:38.694598: predicting lnq2023-train-0895 
2023-08-08 23:22:41.014918: predicting lnq2023-train-0902 
2023-08-08 23:22:43.354155: predicting lnq2023-train-0903 
2023-08-08 23:22:46.811739: predicting lnq2023-train-0906 
2023-08-08 23:22:49.157880: predicting lnq2023-train-0909 
2023-08-08 23:22:52.592390: predicting lnq2023-train-0911 
2023-08-08 23:22:56.012932: predicting lnq2023-train-0922 
2023-08-08 23:22:59.495036: predicting lnq2023-train-0926 
2023-08-08 23:23:02.948348: predicting lnq2023-train-0927 
2023-08-08 23:23:05.253170: predicting lnq2023-train-0931 
2023-08-08 23:23:08.702314: predicting lnq2023-train-0932 
2023-08-08 23:23:12.146459: predicting lnq2023-train-0933 
2023-08-08 23:23:15.579746: predicting lnq2023-train-0934 
2023-08-08 23:23:19.030472: predicting lnq2023-train-0935 
2023-08-08 23:23:22.484162: predicting lnq2023-train-0938 
2023-08-08 23:23:25.942250: predicting lnq2023-train-0941 
2023-08-08 23:23:29.382311: predicting lnq2023-train-0943 
2023-08-08 23:23:32.838876: predicting lnq2023-train-0944 
2023-08-08 23:23:36.264868: predicting lnq2023-train-0945 
2023-08-08 23:23:39.751211: predicting lnq2023-train-0949 
2023-08-08 23:23:43.199094: predicting lnq2023-train-0951 
2023-08-08 23:23:46.633356: predicting lnq2023-train-0952 
2023-08-08 23:23:50.112115: predicting lnq2023-train-0954 
2023-08-08 23:23:51.294732: predicting lnq2023-train-0955 
2023-08-08 23:23:53.604896: predicting lnq2023-train-0958 
2023-08-08 23:23:55.339780: predicting lnq2023-train-0962 
2023-08-08 23:23:58.803069: predicting lnq2023-train-0967 
2023-08-08 23:24:03.967166: predicting lnq2023-train-0969 
2023-08-08 23:24:07.455542: predicting lnq2023-train-0972 
2023-08-08 23:24:12.585313: predicting lnq2023-train-0974 
2023-08-08 23:24:14.890700: predicting lnq2023-train-0977 
2023-08-08 23:24:18.342417: predicting lnq2023-train-0979 
2023-08-08 23:24:25.171739: predicting lnq2023-train-0980 
2023-08-08 23:24:27.543068: predicting lnq2023-train-0982 
2023-08-08 23:24:30.982394: predicting lnq2023-train-0985 
2023-08-08 23:24:36.131720: predicting lnq2023-train-0986 
2023-08-08 23:24:39.607505: predicting lnq2023-train-0989 
2023-08-08 23:24:44.748413: predicting lnq2023-train-0992 
2023-08-08 23:24:47.088295: predicting lnq2023-train-0993 
2023-08-08 23:24:50.542228: predicting lnq2023-train-0995 
2023-08-08 23:24:52.899168: predicting lnq2023-train-0997 
2023-08-08 23:24:56.353370: predicting lnq2023-train-1002 
2023-08-08 23:24:58.685557: predicting lnq2023-train-1007 
2023-08-08 23:25:01.001060: predicting lnq2023-train-1012 
2023-08-08 23:25:01.319774: predicting lnq2023-train-1013 
2023-08-08 23:25:03.634276: predicting lnq2023-train-1017 
2023-08-08 23:25:08.802013: predicting lnq2023-train-1018 
2023-08-08 23:25:12.289881: predicting lnq2023-train-1019 
2023-08-08 23:25:19.965694: predicting lnq2023-train-1020 
2023-08-08 23:25:23.485797: predicting lnq2023-train-1022 
2023-08-08 23:25:25.785443: predicting lnq2023-train-1023 
2023-08-08 23:25:28.095623: predicting lnq2023-train-1034 
2023-08-08 23:25:33.236645: predicting lnq2023-train-1042 
2023-08-08 23:25:35.566354: predicting lnq2023-train-1044 
2023-08-08 23:25:39.006897: predicting lnq2023-train-1045 
2023-08-08 23:25:42.481281: predicting lnq2023-train-1047 
2023-08-08 23:25:45.908702: predicting lnq2023-train-1051 
2023-08-08 23:25:48.239960: predicting lnq2023-train-1057 
2023-08-08 23:25:52.835048: predicting lnq2023-train-1060 
2023-08-08 23:25:55.146461: predicting lnq2023-train-1062 
2023-08-08 23:25:58.595564: predicting lnq2023-train-1064 
2023-08-08 23:26:03.741146: predicting lnq2023-train-1065 
2023-08-08 23:26:06.061223: predicting lnq2023-train-1067 
2023-08-08 23:26:11.194320: predicting lnq2023-train-1071 
2023-08-08 23:26:14.682862: predicting lnq2023-train-1072 
2023-08-08 23:26:18.136039: predicting lnq2023-train-1076 
2023-08-08 23:26:21.601541: predicting lnq2023-train-1077 
2023-08-08 23:26:25.048039: predicting lnq2023-train-1081 
2023-08-08 23:26:27.382519: predicting lnq2023-train-1082 
2023-08-08 23:26:29.701994: predicting lnq2023-train-1084 
2023-08-08 23:26:33.145924: predicting lnq2023-train-1088 
2023-08-08 23:26:35.461651: predicting lnq2023-train-1090 
2023-08-08 23:26:37.771930: predicting lnq2023-train-1091 
2023-08-08 23:26:40.082484: predicting lnq2023-train-1092 
2023-08-08 23:26:45.226616: predicting lnq2023-train-1093 
2023-08-08 23:26:47.613775: predicting lnq2023-train-1096 
2023-08-08 23:26:52.755978: predicting lnq2023-train-1097 
2023-08-08 23:26:56.197407: predicting lnq2023-train-1098 
2023-08-08 23:26:59.689659: predicting lnq2023-train-1100 
2023-08-08 23:27:34.253271: Validation complete 
2023-08-08 23:27:34.253346: Mean Validation Dice:  0.7084671891491465 
